// Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.

package shared

import (
	"encoding/json"
	"fmt"
	"github.com/speakeasy/terraform-provider-cribl-terraform/internal/sdk/internal/utils"
)

type OutputAzureEventhubType string

const (
	OutputAzureEventhubTypeAzureEventhub OutputAzureEventhubType = "azure_eventhub"
)

func (e OutputAzureEventhubType) ToPointer() *OutputAzureEventhubType {
	return &e
}
func (e *OutputAzureEventhubType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "azure_eventhub":
		*e = OutputAzureEventhubType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputAzureEventhubType: %v", v)
	}
}

// Acknowledgments - Control the number of required acknowledgments
type Acknowledgments int64

const (
	AcknowledgmentsOne    Acknowledgments = 1
	AcknowledgmentsZero   Acknowledgments = 0
	AcknowledgmentsMinus1 Acknowledgments = -1
)

func (e Acknowledgments) ToPointer() *Acknowledgments {
	return &e
}
func (e *Acknowledgments) UnmarshalJSON(data []byte) error {
	var v int64
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case 1:
		fallthrough
	case 0:
		fallthrough
	case -1:
		*e = Acknowledgments(v)
		return nil
	default:
		return fmt.Errorf("invalid value for Acknowledgments: %v", v)
	}
}

// OutputAzureEventhubRecordDataFormat - Format to use to serialize events before writing to the Event Hubs Kafka brokers.
type OutputAzureEventhubRecordDataFormat string

const (
	OutputAzureEventhubRecordDataFormatJSON OutputAzureEventhubRecordDataFormat = "json"
	OutputAzureEventhubRecordDataFormatRaw  OutputAzureEventhubRecordDataFormat = "raw"
)

func (e OutputAzureEventhubRecordDataFormat) ToPointer() *OutputAzureEventhubRecordDataFormat {
	return &e
}
func (e *OutputAzureEventhubRecordDataFormat) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "json":
		fallthrough
	case "raw":
		*e = OutputAzureEventhubRecordDataFormat(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputAzureEventhubRecordDataFormat: %v", v)
	}
}

// OutputAzureEventhubSASLMechanism - SASL authentication mechanism to use
type OutputAzureEventhubSASLMechanism string

const (
	OutputAzureEventhubSASLMechanismPlain       OutputAzureEventhubSASLMechanism = "plain"
	OutputAzureEventhubSASLMechanismOauthbearer OutputAzureEventhubSASLMechanism = "oauthbearer"
)

func (e OutputAzureEventhubSASLMechanism) ToPointer() *OutputAzureEventhubSASLMechanism {
	return &e
}
func (e *OutputAzureEventhubSASLMechanism) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "plain":
		fallthrough
	case "oauthbearer":
		*e = OutputAzureEventhubSASLMechanism(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputAzureEventhubSASLMechanism: %v", v)
	}
}

// OutputAzureEventhubAuthentication - Authentication parameters to use when connecting to brokers. Using TLS is highly recommended.
type OutputAzureEventhubAuthentication struct {
	// Enable authentication.
	Disabled *bool `default:"false" json:"disabled"`
	// SASL authentication mechanism to use
	Mechanism *OutputAzureEventhubSASLMechanism `default:"plain" json:"mechanism"`
}

func (o OutputAzureEventhubAuthentication) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputAzureEventhubAuthentication) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputAzureEventhubAuthentication) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *OutputAzureEventhubAuthentication) GetMechanism() *OutputAzureEventhubSASLMechanism {
	if o == nil {
		return nil
	}
	return o.Mechanism
}

type OutputAzureEventhubTLSSettingsClientSide struct {
	Disabled *bool `default:"false" json:"disabled"`
	// Reject certs that are not authorized by a CA in the CA certificate path, or by another trusted CA (e.g., the system's CA).
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
}

func (o OutputAzureEventhubTLSSettingsClientSide) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputAzureEventhubTLSSettingsClientSide) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputAzureEventhubTLSSettingsClientSide) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *OutputAzureEventhubTLSSettingsClientSide) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

// OutputAzureEventhubBackpressureBehavior - Whether to block, drop, or queue events when all receivers are exerting backpressure.
type OutputAzureEventhubBackpressureBehavior string

const (
	OutputAzureEventhubBackpressureBehaviorBlock OutputAzureEventhubBackpressureBehavior = "block"
	OutputAzureEventhubBackpressureBehaviorDrop  OutputAzureEventhubBackpressureBehavior = "drop"
	OutputAzureEventhubBackpressureBehaviorQueue OutputAzureEventhubBackpressureBehavior = "queue"
)

func (e OutputAzureEventhubBackpressureBehavior) ToPointer() *OutputAzureEventhubBackpressureBehavior {
	return &e
}
func (e *OutputAzureEventhubBackpressureBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		fallthrough
	case "queue":
		*e = OutputAzureEventhubBackpressureBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputAzureEventhubBackpressureBehavior: %v", v)
	}
}

// OutputAzureEventhubCompression - Codec to use to compress the persisted data.
type OutputAzureEventhubCompression string

const (
	OutputAzureEventhubCompressionNone OutputAzureEventhubCompression = "none"
	OutputAzureEventhubCompressionGzip OutputAzureEventhubCompression = "gzip"
)

func (e OutputAzureEventhubCompression) ToPointer() *OutputAzureEventhubCompression {
	return &e
}
func (e *OutputAzureEventhubCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = OutputAzureEventhubCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputAzureEventhubCompression: %v", v)
	}
}

// OutputAzureEventhubQueueFullBehavior - Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
type OutputAzureEventhubQueueFullBehavior string

const (
	OutputAzureEventhubQueueFullBehaviorBlock OutputAzureEventhubQueueFullBehavior = "block"
	OutputAzureEventhubQueueFullBehaviorDrop  OutputAzureEventhubQueueFullBehavior = "drop"
)

func (e OutputAzureEventhubQueueFullBehavior) ToPointer() *OutputAzureEventhubQueueFullBehavior {
	return &e
}
func (e *OutputAzureEventhubQueueFullBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputAzureEventhubQueueFullBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputAzureEventhubQueueFullBehavior: %v", v)
	}
}

// OutputAzureEventhubMode - In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
type OutputAzureEventhubMode string

const (
	OutputAzureEventhubModeError        OutputAzureEventhubMode = "error"
	OutputAzureEventhubModeBackpressure OutputAzureEventhubMode = "backpressure"
	OutputAzureEventhubModeAlways       OutputAzureEventhubMode = "always"
)

func (e OutputAzureEventhubMode) ToPointer() *OutputAzureEventhubMode {
	return &e
}
func (e *OutputAzureEventhubMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "error":
		fallthrough
	case "backpressure":
		fallthrough
	case "always":
		*e = OutputAzureEventhubMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputAzureEventhubMode: %v", v)
	}
}

type OutputAzureEventhubPqControls struct {
}

type OutputAzureEventhub struct {
	// Unique ID for this output
	ID   *string                  `json:"id,omitempty"`
	Type *OutputAzureEventhubType `json:"type,omitempty"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// List of Event Hubs Kafka brokers to connect to, eg. yourdomain.servicebus.windows.net:9093. The hostname can be found in the host portion of the primary or secondary connection string in Shared Access Policies.
	Brokers []string `json:"brokers"`
	// The name of the Event Hub (a.k.a. Kafka Topic) to publish events. Can be overwritten using field __topicOut.
	Topic string `json:"topic"`
	// Control the number of required acknowledgments
	Ack *Acknowledgments `default:"1" json:"ack"`
	// Format to use to serialize events before writing to the Event Hubs Kafka brokers.
	Format *OutputAzureEventhubRecordDataFormat `default:"json" json:"format"`
	// Maximum size (KB) of each record batch before compression. Setting should be < message.max.bytes settings in Event Hubs brokers.
	MaxRecordSizeKB *float64 `default:"768" json:"maxRecordSizeKB"`
	// Maximum number of events in a batch before forcing a flush.
	FlushEventCount *float64 `default:"1000" json:"flushEventCount"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Max record size.
	FlushPeriodSec *float64 `default:"1" json:"flushPeriodSec"`
	// Maximum time to wait for a connection to complete successfully
	ConnectionTimeout *float64 `default:"10000" json:"connectionTimeout"`
	// Maximum time to wait for Kafka to respond to a request
	RequestTimeout *float64 `default:"60000" json:"requestTimeout"`
	// If messages are failing, you can set the maximum number of retries as high as 100 to prevent loss of data.
	MaxRetries *float64 `default:"5" json:"maxRetries"`
	// The maximum wait time for a retry, in milliseconds. Default (and minimum) is 30,000 ms (30 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackOff *float64 `default:"30000" json:"maxBackOff"`
	// Initial value used to calculate the retry, in milliseconds. Maximum is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"300" json:"initialBackoff"`
	// Set the backoff multiplier (2-20) to control the retry frequency for failed messages. For faster retries, use a lower multiplier. For slower retries with more delay between attempts, use a higher multiplier. The multiplier is used in an exponential backoff formula; see the Kafka [documentation](https://kafka.js.org/docs/retry-detailed) for details.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// Maximum time to wait for Kafka to respond to an authentication request
	AuthenticationTimeout *float64 `default:"10000" json:"authenticationTimeout"`
	// Specifies a time window during which @{product} can reauthenticate if needed. Creates the window measuring backwards from the moment when credentials are set to expire.
	ReauthenticationThreshold *float64 `default:"10000" json:"reauthenticationThreshold"`
	// Authentication parameters to use when connecting to brokers. Using TLS is highly recommended.
	Sasl *OutputAzureEventhubAuthentication        `json:"sasl,omitempty"`
	TLS  *OutputAzureEventhubTLSSettingsClientSide `json:"tls,omitempty"`
	// Whether to block, drop, or queue events when all receivers are exerting backpressure.
	OnBackpressure *OutputAzureEventhubBackpressureBehavior `default:"block" json:"onBackpressure"`
	Description    *string                                  `json:"description,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.).
	PqMaxFileSize *string `default:"1 MB" json:"pqMaxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `default:"5GB" json:"pqMaxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `default:"\\$CRIBL_HOME/state/queues" json:"pqPath"`
	// Codec to use to compress the persisted data.
	PqCompress *OutputAzureEventhubCompression `default:"none" json:"pqCompress"`
	// Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *OutputAzureEventhubQueueFullBehavior `default:"block" json:"pqOnBackpressure"`
	// In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
	PqMode     *OutputAzureEventhubMode       `default:"error" json:"pqMode"`
	PqControls *OutputAzureEventhubPqControls `json:"pqControls,omitempty"`
}

func (o OutputAzureEventhub) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputAzureEventhub) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *OutputAzureEventhub) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *OutputAzureEventhub) GetType() *OutputAzureEventhubType {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *OutputAzureEventhub) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputAzureEventhub) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputAzureEventhub) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputAzureEventhub) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputAzureEventhub) GetBrokers() []string {
	if o == nil {
		return []string{}
	}
	return o.Brokers
}

func (o *OutputAzureEventhub) GetTopic() string {
	if o == nil {
		return ""
	}
	return o.Topic
}

func (o *OutputAzureEventhub) GetAck() *Acknowledgments {
	if o == nil {
		return nil
	}
	return o.Ack
}

func (o *OutputAzureEventhub) GetFormat() *OutputAzureEventhubRecordDataFormat {
	if o == nil {
		return nil
	}
	return o.Format
}

func (o *OutputAzureEventhub) GetMaxRecordSizeKB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxRecordSizeKB
}

func (o *OutputAzureEventhub) GetFlushEventCount() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushEventCount
}

func (o *OutputAzureEventhub) GetFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushPeriodSec
}

func (o *OutputAzureEventhub) GetConnectionTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.ConnectionTimeout
}

func (o *OutputAzureEventhub) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *OutputAzureEventhub) GetMaxRetries() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxRetries
}

func (o *OutputAzureEventhub) GetMaxBackOff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackOff
}

func (o *OutputAzureEventhub) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *OutputAzureEventhub) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *OutputAzureEventhub) GetAuthenticationTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.AuthenticationTimeout
}

func (o *OutputAzureEventhub) GetReauthenticationThreshold() *float64 {
	if o == nil {
		return nil
	}
	return o.ReauthenticationThreshold
}

func (o *OutputAzureEventhub) GetSasl() *OutputAzureEventhubAuthentication {
	if o == nil {
		return nil
	}
	return o.Sasl
}

func (o *OutputAzureEventhub) GetTLS() *OutputAzureEventhubTLSSettingsClientSide {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *OutputAzureEventhub) GetOnBackpressure() *OutputAzureEventhubBackpressureBehavior {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputAzureEventhub) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputAzureEventhub) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputAzureEventhub) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputAzureEventhub) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputAzureEventhub) GetPqCompress() *OutputAzureEventhubCompression {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputAzureEventhub) GetPqOnBackpressure() *OutputAzureEventhubQueueFullBehavior {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputAzureEventhub) GetPqMode() *OutputAzureEventhubMode {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputAzureEventhub) GetPqControls() *OutputAzureEventhubPqControls {
	if o == nil {
		return nil
	}
	return o.PqControls
}
