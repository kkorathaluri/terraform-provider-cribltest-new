// Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.

package shared

import (
	"encoding/json"
	"errors"
	"fmt"
	"github.com/speakeasy/terraform-provider-cribl-terraform/internal/sdk/internal/utils"
)

type OutputDynatraceOtlpType string

const (
	OutputDynatraceOtlpTypeDynatraceOtlp OutputDynatraceOtlpType = "dynatrace_otlp"
)

func (e OutputDynatraceOtlpType) ToPointer() *OutputDynatraceOtlpType {
	return &e
}
func (e *OutputDynatraceOtlpType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "dynatrace_otlp":
		*e = OutputDynatraceOtlpType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputDynatraceOtlpType: %v", v)
	}
}

// OutputDynatraceOtlpProtocol - Select a transport option for Dynatrace
type OutputDynatraceOtlpProtocol string

const (
	OutputDynatraceOtlpProtocolHTTP OutputDynatraceOtlpProtocol = "http"
)

func (e OutputDynatraceOtlpProtocol) ToPointer() *OutputDynatraceOtlpProtocol {
	return &e
}
func (e *OutputDynatraceOtlpProtocol) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "http":
		*e = OutputDynatraceOtlpProtocol(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputDynatraceOtlpProtocol: %v", v)
	}
}

// OutputDynatraceOTLPOTLPVersion - The version of OTLP Protobuf definitions to use when structuring data to send
type OutputDynatraceOTLPOTLPVersion string

const (
	OutputDynatraceOTLPOTLPVersionOneDot3Dot1 OutputDynatraceOTLPOTLPVersion = "1.3.1"
)

func (e OutputDynatraceOTLPOTLPVersion) ToPointer() *OutputDynatraceOTLPOTLPVersion {
	return &e
}
func (e *OutputDynatraceOTLPOTLPVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "1.3.1":
		*e = OutputDynatraceOTLPOTLPVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputDynatraceOTLPOTLPVersion: %v", v)
	}
}

// OutputDynatraceOtlpCompression - Type of compression to apply to messages sent to the OpenTelemetry endpoint
type OutputDynatraceOtlpCompression string

const (
	OutputDynatraceOtlpCompressionNone    OutputDynatraceOtlpCompression = "none"
	OutputDynatraceOtlpCompressionDeflate OutputDynatraceOtlpCompression = "deflate"
	OutputDynatraceOtlpCompressionGzip    OutputDynatraceOtlpCompression = "gzip"
)

func (e OutputDynatraceOtlpCompression) ToPointer() *OutputDynatraceOtlpCompression {
	return &e
}
func (e *OutputDynatraceOtlpCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "deflate":
		fallthrough
	case "gzip":
		*e = OutputDynatraceOtlpCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputDynatraceOtlpCompression: %v", v)
	}
}

// OutputDynatraceOtlpOutputCompression - Type of compression to apply to messages sent to the OpenTelemetry endpoint
type OutputDynatraceOtlpOutputCompression string

const (
	OutputDynatraceOtlpOutputCompressionNone OutputDynatraceOtlpOutputCompression = "none"
	OutputDynatraceOtlpOutputCompressionGzip OutputDynatraceOtlpOutputCompression = "gzip"
)

func (e OutputDynatraceOtlpOutputCompression) ToPointer() *OutputDynatraceOtlpOutputCompression {
	return &e
}
func (e *OutputDynatraceOtlpOutputCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = OutputDynatraceOtlpOutputCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputDynatraceOtlpOutputCompression: %v", v)
	}
}

type OutputDynatraceOtlpMetadata struct {
	Key   *string `default:"" json:"key"`
	Value string  `json:"value"`
}

func (o OutputDynatraceOtlpMetadata) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputDynatraceOtlpMetadata) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputDynatraceOtlpMetadata) GetKey() *string {
	if o == nil {
		return nil
	}
	return o.Key
}

func (o *OutputDynatraceOtlpMetadata) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// OutputDynatraceOtlpFailedRequestLoggingMode - Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
type OutputDynatraceOtlpFailedRequestLoggingMode string

const (
	OutputDynatraceOtlpFailedRequestLoggingModePayload           OutputDynatraceOtlpFailedRequestLoggingMode = "payload"
	OutputDynatraceOtlpFailedRequestLoggingModePayloadAndHeaders OutputDynatraceOtlpFailedRequestLoggingMode = "payloadAndHeaders"
	OutputDynatraceOtlpFailedRequestLoggingModeNone              OutputDynatraceOtlpFailedRequestLoggingMode = "none"
)

func (e OutputDynatraceOtlpFailedRequestLoggingMode) ToPointer() *OutputDynatraceOtlpFailedRequestLoggingMode {
	return &e
}
func (e *OutputDynatraceOtlpFailedRequestLoggingMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "payload":
		fallthrough
	case "payloadAndHeaders":
		fallthrough
	case "none":
		*e = OutputDynatraceOtlpFailedRequestLoggingMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputDynatraceOtlpFailedRequestLoggingMode: %v", v)
	}
}

// EndpointType - Select the type of Dynatrace endpoint configured
type EndpointType string

const (
	EndpointTypeSaas EndpointType = "saas"
	EndpointTypeAg   EndpointType = "ag"
)

func (e EndpointType) ToPointer() *EndpointType {
	return &e
}
func (e *EndpointType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "saas":
		fallthrough
	case "ag":
		*e = EndpointType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for EndpointType: %v", v)
	}
}

// OutputDynatraceOtlpBackpressureBehavior - Whether to block, drop, or queue events when all receivers are exerting backpressure.
type OutputDynatraceOtlpBackpressureBehavior string

const (
	OutputDynatraceOtlpBackpressureBehaviorBlock OutputDynatraceOtlpBackpressureBehavior = "block"
	OutputDynatraceOtlpBackpressureBehaviorDrop  OutputDynatraceOtlpBackpressureBehavior = "drop"
	OutputDynatraceOtlpBackpressureBehaviorQueue OutputDynatraceOtlpBackpressureBehavior = "queue"
)

func (e OutputDynatraceOtlpBackpressureBehavior) ToPointer() *OutputDynatraceOtlpBackpressureBehavior {
	return &e
}
func (e *OutputDynatraceOtlpBackpressureBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		fallthrough
	case "queue":
		*e = OutputDynatraceOtlpBackpressureBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputDynatraceOtlpBackpressureBehavior: %v", v)
	}
}

type OutputDynatraceOtlpExtraHTTPHeaders struct {
	// Field name
	Name *string `json:"name,omitempty"`
	// Field value
	Value string `json:"value"`
}

func (o *OutputDynatraceOtlpExtraHTTPHeaders) GetName() *string {
	if o == nil {
		return nil
	}
	return o.Name
}

func (o *OutputDynatraceOtlpExtraHTTPHeaders) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type OutputDynatraceOtlpResponseRetrySettings struct {
	// The HTTP response status code that will trigger retries
	HTTPStatus float64 `json:"httpStatus"`
	// How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"1000" json:"initialBackoff"`
	// Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackoff *float64 `default:"10000" json:"maxBackoff"`
}

func (o OutputDynatraceOtlpResponseRetrySettings) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputDynatraceOtlpResponseRetrySettings) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputDynatraceOtlpResponseRetrySettings) GetHTTPStatus() float64 {
	if o == nil {
		return 0.0
	}
	return o.HTTPStatus
}

func (o *OutputDynatraceOtlpResponseRetrySettings) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *OutputDynatraceOtlpResponseRetrySettings) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *OutputDynatraceOtlpResponseRetrySettings) GetMaxBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackoff
}

type OutputDynatraceOtlpTimeoutRetrySettings struct {
	// Enable to retry on request timeout
	TimeoutRetry *bool `default:"false" json:"timeoutRetry"`
	// How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"1000" json:"initialBackoff"`
	// Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackoff *float64 `default:"10000" json:"maxBackoff"`
}

func (o OutputDynatraceOtlpTimeoutRetrySettings) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputDynatraceOtlpTimeoutRetrySettings) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputDynatraceOtlpTimeoutRetrySettings) GetTimeoutRetry() *bool {
	if o == nil {
		return nil
	}
	return o.TimeoutRetry
}

func (o *OutputDynatraceOtlpTimeoutRetrySettings) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *OutputDynatraceOtlpTimeoutRetrySettings) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *OutputDynatraceOtlpTimeoutRetrySettings) GetMaxBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackoff
}

// OutputDynatraceOtlpOutputPqCompressCompression - Codec to use to compress the persisted data.
type OutputDynatraceOtlpOutputPqCompressCompression string

const (
	OutputDynatraceOtlpOutputPqCompressCompressionNone OutputDynatraceOtlpOutputPqCompressCompression = "none"
	OutputDynatraceOtlpOutputPqCompressCompressionGzip OutputDynatraceOtlpOutputPqCompressCompression = "gzip"
)

func (e OutputDynatraceOtlpOutputPqCompressCompression) ToPointer() *OutputDynatraceOtlpOutputPqCompressCompression {
	return &e
}
func (e *OutputDynatraceOtlpOutputPqCompressCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = OutputDynatraceOtlpOutputPqCompressCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputDynatraceOtlpOutputPqCompressCompression: %v", v)
	}
}

// OutputDynatraceOtlpQueueFullBehavior - Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
type OutputDynatraceOtlpQueueFullBehavior string

const (
	OutputDynatraceOtlpQueueFullBehaviorBlock OutputDynatraceOtlpQueueFullBehavior = "block"
	OutputDynatraceOtlpQueueFullBehaviorDrop  OutputDynatraceOtlpQueueFullBehavior = "drop"
)

func (e OutputDynatraceOtlpQueueFullBehavior) ToPointer() *OutputDynatraceOtlpQueueFullBehavior {
	return &e
}
func (e *OutputDynatraceOtlpQueueFullBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputDynatraceOtlpQueueFullBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputDynatraceOtlpQueueFullBehavior: %v", v)
	}
}

// OutputDynatraceOtlpMode - In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
type OutputDynatraceOtlpMode string

const (
	OutputDynatraceOtlpModeError        OutputDynatraceOtlpMode = "error"
	OutputDynatraceOtlpModeBackpressure OutputDynatraceOtlpMode = "backpressure"
	OutputDynatraceOtlpModeAlways       OutputDynatraceOtlpMode = "always"
)

func (e OutputDynatraceOtlpMode) ToPointer() *OutputDynatraceOtlpMode {
	return &e
}
func (e *OutputDynatraceOtlpMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "error":
		fallthrough
	case "backpressure":
		fallthrough
	case "always":
		*e = OutputDynatraceOtlpMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputDynatraceOtlpMode: %v", v)
	}
}

type OutputDynatraceOtlpPqControls struct {
}

type OutputDynatraceOtlp struct {
	// Unique ID for this output
	ID   *string                  `json:"id,omitempty"`
	Type *OutputDynatraceOtlpType `json:"type,omitempty"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Select a transport option for Dynatrace
	Protocol *OutputDynatraceOtlpProtocol `default:"http" json:"protocol"`
	// The endpoint where Dynatrace events will be sent. Enter any valid URL or an IP address (IPv4 or IPv6; enclose IPv6 addresses in square brackets)
	Endpoint *string `default:"https://{your-environment-id}.live.dynatrace.com/api/v2/otlp" json:"endpoint"`
	// The version of OTLP Protobuf definitions to use when structuring data to send
	OtlpVersion *OutputDynatraceOTLPOTLPVersion `default:"1.3.1" json:"otlpVersion"`
	// Type of compression to apply to messages sent to the OpenTelemetry endpoint
	Compress *OutputDynatraceOtlpCompression `default:"gzip" json:"compress"`
	// Type of compression to apply to messages sent to the OpenTelemetry endpoint
	HTTPCompress *OutputDynatraceOtlpOutputCompression `default:"gzip" json:"httpCompress"`
	// If you want to send traces to the default `{endpoint}/v1/traces` endpoint, leave this field empty; otherwise, specify the desired endpoint
	HTTPTracesEndpointOverride *string `json:"httpTracesEndpointOverride,omitempty"`
	// If you want to send metrics to the default `{endpoint}/v1/metrics` endpoint, leave this field empty; otherwise, specify the desired endpoint
	HTTPMetricsEndpointOverride *string `json:"httpMetricsEndpointOverride,omitempty"`
	// If you want to send logs to the default `{endpoint}/v1/logs` endpoint, leave this field empty; otherwise, specify the desired endpoint
	HTTPLogsEndpointOverride *string `json:"httpLogsEndpointOverride,omitempty"`
	// List of key-value pairs to send with each gRPC request. Value supports JavaScript expressions that are evaluated just once, when the destination gets started. To pass credentials as metadata, use 'C.Secret'.
	Metadata []OutputDynatraceOtlpMetadata `json:"metadata,omitempty"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `default:"5" json:"concurrency"`
	// Maximum size (in KB) of the request body. The maximum payload size is 4 MB. If this limit is exceeded, the entire OTLP message is dropped
	MaxPayloadSizeKB *float64 `default:"2048" json:"maxPayloadSizeKB"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `default:"30" json:"timeoutSec"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Max body size.
	FlushPeriodSec *float64 `default:"1" json:"flushPeriodSec"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *OutputDynatraceOtlpFailedRequestLoggingMode `default:"none" json:"failedRequestLoggingMode"`
	// Amount of time (milliseconds) to wait for the connection to establish before retrying
	ConnectionTimeout *float64 `default:"10000" json:"connectionTimeout"`
	// How often the sender should ping the peer to keep the connection open
	KeepAliveTime *float64 `default:"30" json:"keepAliveTime"`
	// Disable to close the connection immediately after sending the outgoing request
	KeepAlive *bool `default:"true" json:"keepAlive"`
	// Select the type of Dynatrace endpoint configured
	EndpointType *EndpointType `default:"saas" json:"endpointType"`
	// Select or create a stored text secret
	TokenSecret   string  `json:"tokenSecret"`
	AuthTokenName *string `default:"Authorization" json:"authTokenName"`
	// Whether to block, drop, or queue events when all receivers are exerting backpressure.
	OnBackpressure *OutputDynatraceOtlpBackpressureBehavior `default:"block" json:"onBackpressure"`
	Description    *string                                  `json:"description,omitempty"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Defaults to Yes. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Enables round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `default:"false" json:"useRoundRobinDns"`
	// Headers to add to all events.
	ExtraHTTPHeaders []OutputDynatraceOtlpExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable).
	ResponseRetrySettings []OutputDynatraceOtlpResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *OutputDynatraceOtlpTimeoutRetrySettings   `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `default:"false" json:"responseHonorRetryAfterHeader"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.).
	PqMaxFileSize *string `default:"1 MB" json:"pqMaxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `default:"5GB" json:"pqMaxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `default:"\\$CRIBL_HOME/state/queues" json:"pqPath"`
	// Codec to use to compress the persisted data.
	PqCompress *OutputDynatraceOtlpOutputPqCompressCompression `default:"none" json:"pqCompress"`
	// Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *OutputDynatraceOtlpQueueFullBehavior `default:"block" json:"pqOnBackpressure"`
	// In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
	PqMode     *OutputDynatraceOtlpMode       `default:"error" json:"pqMode"`
	PqControls *OutputDynatraceOtlpPqControls `json:"pqControls,omitempty"`
	Status     *TFStatus                      `json:"status,omitempty"`
}

func (o OutputDynatraceOtlp) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputDynatraceOtlp) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *OutputDynatraceOtlp) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *OutputDynatraceOtlp) GetType() *OutputDynatraceOtlpType {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *OutputDynatraceOtlp) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputDynatraceOtlp) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputDynatraceOtlp) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputDynatraceOtlp) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputDynatraceOtlp) GetProtocol() *OutputDynatraceOtlpProtocol {
	if o == nil {
		return nil
	}
	return o.Protocol
}

func (o *OutputDynatraceOtlp) GetEndpoint() *string {
	if o == nil {
		return nil
	}
	return o.Endpoint
}

func (o *OutputDynatraceOtlp) GetOtlpVersion() *OutputDynatraceOTLPOTLPVersion {
	if o == nil {
		return nil
	}
	return o.OtlpVersion
}

func (o *OutputDynatraceOtlp) GetCompress() *OutputDynatraceOtlpCompression {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *OutputDynatraceOtlp) GetHTTPCompress() *OutputDynatraceOtlpOutputCompression {
	if o == nil {
		return nil
	}
	return o.HTTPCompress
}

func (o *OutputDynatraceOtlp) GetHTTPTracesEndpointOverride() *string {
	if o == nil {
		return nil
	}
	return o.HTTPTracesEndpointOverride
}

func (o *OutputDynatraceOtlp) GetHTTPMetricsEndpointOverride() *string {
	if o == nil {
		return nil
	}
	return o.HTTPMetricsEndpointOverride
}

func (o *OutputDynatraceOtlp) GetHTTPLogsEndpointOverride() *string {
	if o == nil {
		return nil
	}
	return o.HTTPLogsEndpointOverride
}

func (o *OutputDynatraceOtlp) GetMetadata() []OutputDynatraceOtlpMetadata {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *OutputDynatraceOtlp) GetConcurrency() *float64 {
	if o == nil {
		return nil
	}
	return o.Concurrency
}

func (o *OutputDynatraceOtlp) GetMaxPayloadSizeKB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadSizeKB
}

func (o *OutputDynatraceOtlp) GetTimeoutSec() *float64 {
	if o == nil {
		return nil
	}
	return o.TimeoutSec
}

func (o *OutputDynatraceOtlp) GetFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushPeriodSec
}

func (o *OutputDynatraceOtlp) GetFailedRequestLoggingMode() *OutputDynatraceOtlpFailedRequestLoggingMode {
	if o == nil {
		return nil
	}
	return o.FailedRequestLoggingMode
}

func (o *OutputDynatraceOtlp) GetConnectionTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.ConnectionTimeout
}

func (o *OutputDynatraceOtlp) GetKeepAliveTime() *float64 {
	if o == nil {
		return nil
	}
	return o.KeepAliveTime
}

func (o *OutputDynatraceOtlp) GetKeepAlive() *bool {
	if o == nil {
		return nil
	}
	return o.KeepAlive
}

func (o *OutputDynatraceOtlp) GetEndpointType() *EndpointType {
	if o == nil {
		return nil
	}
	return o.EndpointType
}

func (o *OutputDynatraceOtlp) GetTokenSecret() string {
	if o == nil {
		return ""
	}
	return o.TokenSecret
}

func (o *OutputDynatraceOtlp) GetAuthTokenName() *string {
	if o == nil {
		return nil
	}
	return o.AuthTokenName
}

func (o *OutputDynatraceOtlp) GetOnBackpressure() *OutputDynatraceOtlpBackpressureBehavior {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputDynatraceOtlp) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputDynatraceOtlp) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputDynatraceOtlp) GetUseRoundRobinDNS() *bool {
	if o == nil {
		return nil
	}
	return o.UseRoundRobinDNS
}

func (o *OutputDynatraceOtlp) GetExtraHTTPHeaders() []OutputDynatraceOtlpExtraHTTPHeaders {
	if o == nil {
		return nil
	}
	return o.ExtraHTTPHeaders
}

func (o *OutputDynatraceOtlp) GetSafeHeaders() []string {
	if o == nil {
		return nil
	}
	return o.SafeHeaders
}

func (o *OutputDynatraceOtlp) GetResponseRetrySettings() []OutputDynatraceOtlpResponseRetrySettings {
	if o == nil {
		return nil
	}
	return o.ResponseRetrySettings
}

func (o *OutputDynatraceOtlp) GetTimeoutRetrySettings() *OutputDynatraceOtlpTimeoutRetrySettings {
	if o == nil {
		return nil
	}
	return o.TimeoutRetrySettings
}

func (o *OutputDynatraceOtlp) GetResponseHonorRetryAfterHeader() *bool {
	if o == nil {
		return nil
	}
	return o.ResponseHonorRetryAfterHeader
}

func (o *OutputDynatraceOtlp) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputDynatraceOtlp) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputDynatraceOtlp) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputDynatraceOtlp) GetPqCompress() *OutputDynatraceOtlpOutputPqCompressCompression {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputDynatraceOtlp) GetPqOnBackpressure() *OutputDynatraceOtlpQueueFullBehavior {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputDynatraceOtlp) GetPqMode() *OutputDynatraceOtlpMode {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputDynatraceOtlp) GetPqControls() *OutputDynatraceOtlpPqControls {
	if o == nil {
		return nil
	}
	return o.PqControls
}

func (o *OutputDynatraceOtlp) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type OutputDynatraceHTTPType string

const (
	OutputDynatraceHTTPTypeDynatraceHTTP OutputDynatraceHTTPType = "dynatrace_http"
)

func (e OutputDynatraceHTTPType) ToPointer() *OutputDynatraceHTTPType {
	return &e
}
func (e *OutputDynatraceHTTPType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "dynatrace_http":
		*e = OutputDynatraceHTTPType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputDynatraceHTTPType: %v", v)
	}
}

// OutputDynatraceHTTPMethod - The method to use when sending events. Defaults to POST.
type OutputDynatraceHTTPMethod string

const (
	OutputDynatraceHTTPMethodPost  OutputDynatraceHTTPMethod = "POST"
	OutputDynatraceHTTPMethodPut   OutputDynatraceHTTPMethod = "PUT"
	OutputDynatraceHTTPMethodPatch OutputDynatraceHTTPMethod = "PATCH"
)

func (e OutputDynatraceHTTPMethod) ToPointer() *OutputDynatraceHTTPMethod {
	return &e
}
func (e *OutputDynatraceHTTPMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "POST":
		fallthrough
	case "PUT":
		fallthrough
	case "PATCH":
		*e = OutputDynatraceHTTPMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputDynatraceHTTPMethod: %v", v)
	}
}

type OutputDynatraceHTTPExtraHTTPHeaders struct {
	// Field name
	Name *string `json:"name,omitempty"`
	// Field value
	Value string `json:"value"`
}

func (o *OutputDynatraceHTTPExtraHTTPHeaders) GetName() *string {
	if o == nil {
		return nil
	}
	return o.Name
}

func (o *OutputDynatraceHTTPExtraHTTPHeaders) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// OutputDynatraceHTTPFailedRequestLoggingMode - Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
type OutputDynatraceHTTPFailedRequestLoggingMode string

const (
	OutputDynatraceHTTPFailedRequestLoggingModePayload           OutputDynatraceHTTPFailedRequestLoggingMode = "payload"
	OutputDynatraceHTTPFailedRequestLoggingModePayloadAndHeaders OutputDynatraceHTTPFailedRequestLoggingMode = "payloadAndHeaders"
	OutputDynatraceHTTPFailedRequestLoggingModeNone              OutputDynatraceHTTPFailedRequestLoggingMode = "none"
)

func (e OutputDynatraceHTTPFailedRequestLoggingMode) ToPointer() *OutputDynatraceHTTPFailedRequestLoggingMode {
	return &e
}
func (e *OutputDynatraceHTTPFailedRequestLoggingMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "payload":
		fallthrough
	case "payloadAndHeaders":
		fallthrough
	case "none":
		*e = OutputDynatraceHTTPFailedRequestLoggingMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputDynatraceHTTPFailedRequestLoggingMode: %v", v)
	}
}

type OutputDynatraceHTTPResponseRetrySettings struct {
	// The HTTP response status code that will trigger retries
	HTTPStatus float64 `json:"httpStatus"`
	// How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"1000" json:"initialBackoff"`
	// Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackoff *float64 `default:"10000" json:"maxBackoff"`
}

func (o OutputDynatraceHTTPResponseRetrySettings) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputDynatraceHTTPResponseRetrySettings) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputDynatraceHTTPResponseRetrySettings) GetHTTPStatus() float64 {
	if o == nil {
		return 0.0
	}
	return o.HTTPStatus
}

func (o *OutputDynatraceHTTPResponseRetrySettings) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *OutputDynatraceHTTPResponseRetrySettings) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *OutputDynatraceHTTPResponseRetrySettings) GetMaxBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackoff
}

type OutputDynatraceHTTPTimeoutRetrySettings struct {
	// Enable to retry on request timeout
	TimeoutRetry *bool `default:"false" json:"timeoutRetry"`
	// How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"1000" json:"initialBackoff"`
	// Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackoff *float64 `default:"10000" json:"maxBackoff"`
}

func (o OutputDynatraceHTTPTimeoutRetrySettings) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputDynatraceHTTPTimeoutRetrySettings) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputDynatraceHTTPTimeoutRetrySettings) GetTimeoutRetry() *bool {
	if o == nil {
		return nil
	}
	return o.TimeoutRetry
}

func (o *OutputDynatraceHTTPTimeoutRetrySettings) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *OutputDynatraceHTTPTimeoutRetrySettings) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *OutputDynatraceHTTPTimeoutRetrySettings) GetMaxBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackoff
}

// OutputDynatraceHTTPBackpressureBehavior - Whether to block, drop, or queue events when all receivers are exerting backpressure.
type OutputDynatraceHTTPBackpressureBehavior string

const (
	OutputDynatraceHTTPBackpressureBehaviorBlock OutputDynatraceHTTPBackpressureBehavior = "block"
	OutputDynatraceHTTPBackpressureBehaviorDrop  OutputDynatraceHTTPBackpressureBehavior = "drop"
	OutputDynatraceHTTPBackpressureBehaviorQueue OutputDynatraceHTTPBackpressureBehavior = "queue"
)

func (e OutputDynatraceHTTPBackpressureBehavior) ToPointer() *OutputDynatraceHTTPBackpressureBehavior {
	return &e
}
func (e *OutputDynatraceHTTPBackpressureBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		fallthrough
	case "queue":
		*e = OutputDynatraceHTTPBackpressureBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputDynatraceHTTPBackpressureBehavior: %v", v)
	}
}

type OutputDynatraceHTTPAuthenticationType string

const (
	OutputDynatraceHTTPAuthenticationTypeToken      OutputDynatraceHTTPAuthenticationType = "token"
	OutputDynatraceHTTPAuthenticationTypeTextSecret OutputDynatraceHTTPAuthenticationType = "textSecret"
)

func (e OutputDynatraceHTTPAuthenticationType) ToPointer() *OutputDynatraceHTTPAuthenticationType {
	return &e
}
func (e *OutputDynatraceHTTPAuthenticationType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "token":
		fallthrough
	case "textSecret":
		*e = OutputDynatraceHTTPAuthenticationType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputDynatraceHTTPAuthenticationType: %v", v)
	}
}

// OutputDynatraceHTTPFormat - How to format events before sending. Defaults to JSON. Plaintext is not currently supported.
type OutputDynatraceHTTPFormat string

const (
	OutputDynatraceHTTPFormatJSONArray OutputDynatraceHTTPFormat = "json_array"
	OutputDynatraceHTTPFormatPlaintext OutputDynatraceHTTPFormat = "plaintext"
)

func (e OutputDynatraceHTTPFormat) ToPointer() *OutputDynatraceHTTPFormat {
	return &e
}
func (e *OutputDynatraceHTTPFormat) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "json_array":
		fallthrough
	case "plaintext":
		*e = OutputDynatraceHTTPFormat(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputDynatraceHTTPFormat: %v", v)
	}
}

type Endpoint string

const (
	EndpointCloud      Endpoint = "cloud"
	EndpointActiveGate Endpoint = "activeGate"
	EndpointManual     Endpoint = "manual"
)

func (e Endpoint) ToPointer() *Endpoint {
	return &e
}
func (e *Endpoint) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "cloud":
		fallthrough
	case "activeGate":
		fallthrough
	case "manual":
		*e = Endpoint(v)
		return nil
	default:
		return fmt.Errorf("invalid value for Endpoint: %v", v)
	}
}

type TelemetryType string

const (
	TelemetryTypeLogs    TelemetryType = "logs"
	TelemetryTypeMetrics TelemetryType = "metrics"
)

func (e TelemetryType) ToPointer() *TelemetryType {
	return &e
}
func (e *TelemetryType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "logs":
		fallthrough
	case "metrics":
		*e = TelemetryType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TelemetryType: %v", v)
	}
}

// OutputDynatraceHTTPCompression - Codec to use to compress the persisted data.
type OutputDynatraceHTTPCompression string

const (
	OutputDynatraceHTTPCompressionNone OutputDynatraceHTTPCompression = "none"
	OutputDynatraceHTTPCompressionGzip OutputDynatraceHTTPCompression = "gzip"
)

func (e OutputDynatraceHTTPCompression) ToPointer() *OutputDynatraceHTTPCompression {
	return &e
}
func (e *OutputDynatraceHTTPCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = OutputDynatraceHTTPCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputDynatraceHTTPCompression: %v", v)
	}
}

// OutputDynatraceHTTPQueueFullBehavior - Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
type OutputDynatraceHTTPQueueFullBehavior string

const (
	OutputDynatraceHTTPQueueFullBehaviorBlock OutputDynatraceHTTPQueueFullBehavior = "block"
	OutputDynatraceHTTPQueueFullBehaviorDrop  OutputDynatraceHTTPQueueFullBehavior = "drop"
)

func (e OutputDynatraceHTTPQueueFullBehavior) ToPointer() *OutputDynatraceHTTPQueueFullBehavior {
	return &e
}
func (e *OutputDynatraceHTTPQueueFullBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputDynatraceHTTPQueueFullBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputDynatraceHTTPQueueFullBehavior: %v", v)
	}
}

// OutputDynatraceHTTPMode - In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
type OutputDynatraceHTTPMode string

const (
	OutputDynatraceHTTPModeError        OutputDynatraceHTTPMode = "error"
	OutputDynatraceHTTPModeBackpressure OutputDynatraceHTTPMode = "backpressure"
	OutputDynatraceHTTPModeAlways       OutputDynatraceHTTPMode = "always"
)

func (e OutputDynatraceHTTPMode) ToPointer() *OutputDynatraceHTTPMode {
	return &e
}
func (e *OutputDynatraceHTTPMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "error":
		fallthrough
	case "backpressure":
		fallthrough
	case "always":
		*e = OutputDynatraceHTTPMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputDynatraceHTTPMode: %v", v)
	}
}

type OutputDynatraceHTTPPqControls struct {
}

type OutputDynatraceHTTP struct {
	// Unique ID for this output
	ID   *string                  `json:"id,omitempty"`
	Type *OutputDynatraceHTTPType `json:"type,omitempty"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// The method to use when sending events. Defaults to POST.
	Method *OutputDynatraceHTTPMethod `default:"POST" json:"method"`
	// Disable to close the connection immediately after sending the outgoing request
	KeepAlive *bool `default:"true" json:"keepAlive"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `default:"5" json:"concurrency"`
	// Maximum size, in KB, of the request body
	MaxPayloadSizeKB *float64 `default:"4096" json:"maxPayloadSizeKB"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited).
	MaxPayloadEvents *float64 `default:"0" json:"maxPayloadEvents"`
	// Compress the payload body before sending
	Compress *bool `default:"true" json:"compress"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Defaults to Yes. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `default:"30" json:"timeoutSec"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Max body size.
	FlushPeriodSec *float64 `default:"1" json:"flushPeriodSec"`
	// Headers to add to all events. You can also add headers dynamically on a per-event basis in the __headers field, as explained [here](https://docs.cribl.io/stream/destinations-webhook/#internal-fields).
	ExtraHTTPHeaders []OutputDynatraceHTTPExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// Enables round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `default:"false" json:"useRoundRobinDns"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *OutputDynatraceHTTPFailedRequestLoggingMode `default:"none" json:"failedRequestLoggingMode"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable).
	ResponseRetrySettings []OutputDynatraceHTTPResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *OutputDynatraceHTTPTimeoutRetrySettings   `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `default:"false" json:"responseHonorRetryAfterHeader"`
	// Whether to block, drop, or queue events when all receivers are exerting backpressure.
	OnBackpressure *OutputDynatraceHTTPBackpressureBehavior `default:"block" json:"onBackpressure"`
	AuthType       *OutputDynatraceHTTPAuthenticationType   `default:"token" json:"authType"`
	// How to format events before sending. Defaults to JSON. Plaintext is not currently supported.
	Format        *OutputDynatraceHTTPFormat `default:"json_array" json:"format"`
	Endpoint      *Endpoint                  `default:"cloud" json:"endpoint"`
	TelemetryType *TelemetryType             `default:"logs" json:"telemetryType"`
	// Maximum total size of the batches waiting to be sent. If left blank, defaults to 5 times the max body size (if set). If 0, no limit is enforced.
	TotalMemoryLimitKB *float64 `json:"totalMemoryLimitKB,omitempty"`
	Description        *string  `json:"description,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.).
	PqMaxFileSize *string `default:"1 MB" json:"pqMaxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `default:"5GB" json:"pqMaxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `default:"\\$CRIBL_HOME/state/queues" json:"pqPath"`
	// Codec to use to compress the persisted data.
	PqCompress *OutputDynatraceHTTPCompression `default:"none" json:"pqCompress"`
	// Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *OutputDynatraceHTTPQueueFullBehavior `default:"block" json:"pqOnBackpressure"`
	// In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
	PqMode     *OutputDynatraceHTTPMode       `default:"error" json:"pqMode"`
	PqControls *OutputDynatraceHTTPPqControls `json:"pqControls,omitempty"`
	// Bearer token to include in the authorization header
	Token *string `json:"token,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// ID of the environment to send to
	EnvironmentID *string `json:"environmentId,omitempty"`
	// ActiveGate domain with Log analytics collector module enabled. For example https://{activeGate-domain}:9999/e/{environment-id}/api/v2/logs/ingest.
	ActiveGateDomain *string `json:"activeGateDomain,omitempty"`
	// URL to send events to. Can be overwritten by an event's __url field.
	URL    *string   `json:"url,omitempty"`
	Status *TFStatus `json:"status,omitempty"`
}

func (o OutputDynatraceHTTP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputDynatraceHTTP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *OutputDynatraceHTTP) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *OutputDynatraceHTTP) GetType() *OutputDynatraceHTTPType {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *OutputDynatraceHTTP) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputDynatraceHTTP) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputDynatraceHTTP) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputDynatraceHTTP) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputDynatraceHTTP) GetMethod() *OutputDynatraceHTTPMethod {
	if o == nil {
		return nil
	}
	return o.Method
}

func (o *OutputDynatraceHTTP) GetKeepAlive() *bool {
	if o == nil {
		return nil
	}
	return o.KeepAlive
}

func (o *OutputDynatraceHTTP) GetConcurrency() *float64 {
	if o == nil {
		return nil
	}
	return o.Concurrency
}

func (o *OutputDynatraceHTTP) GetMaxPayloadSizeKB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadSizeKB
}

func (o *OutputDynatraceHTTP) GetMaxPayloadEvents() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadEvents
}

func (o *OutputDynatraceHTTP) GetCompress() *bool {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *OutputDynatraceHTTP) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputDynatraceHTTP) GetTimeoutSec() *float64 {
	if o == nil {
		return nil
	}
	return o.TimeoutSec
}

func (o *OutputDynatraceHTTP) GetFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushPeriodSec
}

func (o *OutputDynatraceHTTP) GetExtraHTTPHeaders() []OutputDynatraceHTTPExtraHTTPHeaders {
	if o == nil {
		return nil
	}
	return o.ExtraHTTPHeaders
}

func (o *OutputDynatraceHTTP) GetUseRoundRobinDNS() *bool {
	if o == nil {
		return nil
	}
	return o.UseRoundRobinDNS
}

func (o *OutputDynatraceHTTP) GetFailedRequestLoggingMode() *OutputDynatraceHTTPFailedRequestLoggingMode {
	if o == nil {
		return nil
	}
	return o.FailedRequestLoggingMode
}

func (o *OutputDynatraceHTTP) GetSafeHeaders() []string {
	if o == nil {
		return nil
	}
	return o.SafeHeaders
}

func (o *OutputDynatraceHTTP) GetResponseRetrySettings() []OutputDynatraceHTTPResponseRetrySettings {
	if o == nil {
		return nil
	}
	return o.ResponseRetrySettings
}

func (o *OutputDynatraceHTTP) GetTimeoutRetrySettings() *OutputDynatraceHTTPTimeoutRetrySettings {
	if o == nil {
		return nil
	}
	return o.TimeoutRetrySettings
}

func (o *OutputDynatraceHTTP) GetResponseHonorRetryAfterHeader() *bool {
	if o == nil {
		return nil
	}
	return o.ResponseHonorRetryAfterHeader
}

func (o *OutputDynatraceHTTP) GetOnBackpressure() *OutputDynatraceHTTPBackpressureBehavior {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputDynatraceHTTP) GetAuthType() *OutputDynatraceHTTPAuthenticationType {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *OutputDynatraceHTTP) GetFormat() *OutputDynatraceHTTPFormat {
	if o == nil {
		return nil
	}
	return o.Format
}

func (o *OutputDynatraceHTTP) GetEndpoint() *Endpoint {
	if o == nil {
		return nil
	}
	return o.Endpoint
}

func (o *OutputDynatraceHTTP) GetTelemetryType() *TelemetryType {
	if o == nil {
		return nil
	}
	return o.TelemetryType
}

func (o *OutputDynatraceHTTP) GetTotalMemoryLimitKB() *float64 {
	if o == nil {
		return nil
	}
	return o.TotalMemoryLimitKB
}

func (o *OutputDynatraceHTTP) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputDynatraceHTTP) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputDynatraceHTTP) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputDynatraceHTTP) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputDynatraceHTTP) GetPqCompress() *OutputDynatraceHTTPCompression {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputDynatraceHTTP) GetPqOnBackpressure() *OutputDynatraceHTTPQueueFullBehavior {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputDynatraceHTTP) GetPqMode() *OutputDynatraceHTTPMode {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputDynatraceHTTP) GetPqControls() *OutputDynatraceHTTPPqControls {
	if o == nil {
		return nil
	}
	return o.PqControls
}

func (o *OutputDynatraceHTTP) GetToken() *string {
	if o == nil {
		return nil
	}
	return o.Token
}

func (o *OutputDynatraceHTTP) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *OutputDynatraceHTTP) GetEnvironmentID() *string {
	if o == nil {
		return nil
	}
	return o.EnvironmentID
}

func (o *OutputDynatraceHTTP) GetActiveGateDomain() *string {
	if o == nil {
		return nil
	}
	return o.ActiveGateDomain
}

func (o *OutputDynatraceHTTP) GetURL() *string {
	if o == nil {
		return nil
	}
	return o.URL
}

func (o *OutputDynatraceHTTP) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type OutputNetflowType string

const (
	OutputNetflowTypeNetflow OutputNetflowType = "netflow"
)

func (e OutputNetflowType) ToPointer() *OutputNetflowType {
	return &e
}
func (e *OutputNetflowType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "netflow":
		*e = OutputNetflowType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputNetflowType: %v", v)
	}
}

type OutputNetflowHosts struct {
	// Destination host
	Host string `json:"host"`
	// Destination port, default is 2055
	Port *float64 `default:"2055" json:"port"`
}

func (o OutputNetflowHosts) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputNetflowHosts) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputNetflowHosts) GetHost() string {
	if o == nil {
		return ""
	}
	return o.Host
}

func (o *OutputNetflowHosts) GetPort() *float64 {
	if o == nil {
		return nil
	}
	return o.Port
}

type OutputNetflow struct {
	// Unique ID for this output
	ID   *string           `json:"id,omitempty"`
	Type OutputNetflowType `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// One or more NetFlow destinations to forward events to
	Hosts []OutputNetflowHosts `json:"hosts"`
	// How often to resolve the destination hostname to an IP address. Ignored if all destinations are IP addresses. A value of 0 means every datagram sent will incur a DNS lookup.
	DNSResolvePeriodSec *float64  `default:"0" json:"dnsResolvePeriodSec"`
	Description         *string   `json:"description,omitempty"`
	Status              *TFStatus `json:"status,omitempty"`
}

func (o OutputNetflow) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputNetflow) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *OutputNetflow) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *OutputNetflow) GetType() OutputNetflowType {
	if o == nil {
		return OutputNetflowType("")
	}
	return o.Type
}

func (o *OutputNetflow) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputNetflow) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputNetflow) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputNetflow) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputNetflow) GetHosts() []OutputNetflowHosts {
	if o == nil {
		return []OutputNetflowHosts{}
	}
	return o.Hosts
}

func (o *OutputNetflow) GetDNSResolvePeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.DNSResolvePeriodSec
}

func (o *OutputNetflow) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputNetflow) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type OutputXsiamType string

const (
	OutputXsiamTypeXsiam OutputXsiamType = "xsiam"
)

func (e OutputXsiamType) ToPointer() *OutputXsiamType {
	return &e
}
func (e *OutputXsiamType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "xsiam":
		*e = OutputXsiamType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputXsiamType: %v", v)
	}
}

type OutputXsiamExtraHTTPHeaders struct {
	// Field name
	Name *string `json:"name,omitempty"`
	// Field value
	Value string `json:"value"`
}

func (o *OutputXsiamExtraHTTPHeaders) GetName() *string {
	if o == nil {
		return nil
	}
	return o.Name
}

func (o *OutputXsiamExtraHTTPHeaders) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// OutputXsiamFailedRequestLoggingMode - Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
type OutputXsiamFailedRequestLoggingMode string

const (
	OutputXsiamFailedRequestLoggingModePayload           OutputXsiamFailedRequestLoggingMode = "payload"
	OutputXsiamFailedRequestLoggingModePayloadAndHeaders OutputXsiamFailedRequestLoggingMode = "payloadAndHeaders"
	OutputXsiamFailedRequestLoggingModeNone              OutputXsiamFailedRequestLoggingMode = "none"
)

func (e OutputXsiamFailedRequestLoggingMode) ToPointer() *OutputXsiamFailedRequestLoggingMode {
	return &e
}
func (e *OutputXsiamFailedRequestLoggingMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "payload":
		fallthrough
	case "payloadAndHeaders":
		fallthrough
	case "none":
		*e = OutputXsiamFailedRequestLoggingMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputXsiamFailedRequestLoggingMode: %v", v)
	}
}

// OutputXsiamAuthenticationMethod - Enter a token directly, or provide a secret referencing a token
type OutputXsiamAuthenticationMethod string

const (
	OutputXsiamAuthenticationMethodToken  OutputXsiamAuthenticationMethod = "token"
	OutputXsiamAuthenticationMethodSecret OutputXsiamAuthenticationMethod = "secret"
)

func (e OutputXsiamAuthenticationMethod) ToPointer() *OutputXsiamAuthenticationMethod {
	return &e
}
func (e *OutputXsiamAuthenticationMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "token":
		fallthrough
	case "secret":
		*e = OutputXsiamAuthenticationMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputXsiamAuthenticationMethod: %v", v)
	}
}

type OutputXsiamResponseRetrySettings struct {
	// The HTTP response status code that will trigger retries
	HTTPStatus float64 `json:"httpStatus"`
	// How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"1000" json:"initialBackoff"`
	// Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackoff *float64 `default:"10000" json:"maxBackoff"`
}

func (o OutputXsiamResponseRetrySettings) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputXsiamResponseRetrySettings) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputXsiamResponseRetrySettings) GetHTTPStatus() float64 {
	if o == nil {
		return 0.0
	}
	return o.HTTPStatus
}

func (o *OutputXsiamResponseRetrySettings) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *OutputXsiamResponseRetrySettings) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *OutputXsiamResponseRetrySettings) GetMaxBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackoff
}

type OutputXsiamTimeoutRetrySettings struct {
	// Enable to retry on request timeout
	TimeoutRetry *bool `default:"false" json:"timeoutRetry"`
	// How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"1000" json:"initialBackoff"`
	// Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackoff *float64 `default:"10000" json:"maxBackoff"`
}

func (o OutputXsiamTimeoutRetrySettings) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputXsiamTimeoutRetrySettings) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputXsiamTimeoutRetrySettings) GetTimeoutRetry() *bool {
	if o == nil {
		return nil
	}
	return o.TimeoutRetry
}

func (o *OutputXsiamTimeoutRetrySettings) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *OutputXsiamTimeoutRetrySettings) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *OutputXsiamTimeoutRetrySettings) GetMaxBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackoff
}

// OutputXsiamBackpressureBehavior - Whether to block, drop, or queue events when all receivers are exerting backpressure.
type OutputXsiamBackpressureBehavior string

const (
	OutputXsiamBackpressureBehaviorBlock OutputXsiamBackpressureBehavior = "block"
	OutputXsiamBackpressureBehaviorDrop  OutputXsiamBackpressureBehavior = "drop"
	OutputXsiamBackpressureBehaviorQueue OutputXsiamBackpressureBehavior = "queue"
)

func (e OutputXsiamBackpressureBehavior) ToPointer() *OutputXsiamBackpressureBehavior {
	return &e
}
func (e *OutputXsiamBackpressureBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		fallthrough
	case "queue":
		*e = OutputXsiamBackpressureBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputXsiamBackpressureBehavior: %v", v)
	}
}

type OutputXsiamUrls struct {
	URL any `json:"url"`
	// Assign a weight (>0) to each endpoint to indicate its traffic-handling capability
	Weight *float64 `default:"1" json:"weight"`
}

func (o OutputXsiamUrls) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputXsiamUrls) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputXsiamUrls) GetURL() any {
	if o == nil {
		return nil
	}
	return o.URL
}

func (o *OutputXsiamUrls) GetWeight() *float64 {
	if o == nil {
		return nil
	}
	return o.Weight
}

// OutputXsiamCompression - Codec to use to compress the persisted data.
type OutputXsiamCompression string

const (
	OutputXsiamCompressionNone OutputXsiamCompression = "none"
	OutputXsiamCompressionGzip OutputXsiamCompression = "gzip"
)

func (e OutputXsiamCompression) ToPointer() *OutputXsiamCompression {
	return &e
}
func (e *OutputXsiamCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = OutputXsiamCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputXsiamCompression: %v", v)
	}
}

// OutputXsiamQueueFullBehavior - Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
type OutputXsiamQueueFullBehavior string

const (
	OutputXsiamQueueFullBehaviorBlock OutputXsiamQueueFullBehavior = "block"
	OutputXsiamQueueFullBehaviorDrop  OutputXsiamQueueFullBehavior = "drop"
)

func (e OutputXsiamQueueFullBehavior) ToPointer() *OutputXsiamQueueFullBehavior {
	return &e
}
func (e *OutputXsiamQueueFullBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputXsiamQueueFullBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputXsiamQueueFullBehavior: %v", v)
	}
}

// OutputXsiamMode - In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
type OutputXsiamMode string

const (
	OutputXsiamModeError        OutputXsiamMode = "error"
	OutputXsiamModeBackpressure OutputXsiamMode = "backpressure"
	OutputXsiamModeAlways       OutputXsiamMode = "always"
)

func (e OutputXsiamMode) ToPointer() *OutputXsiamMode {
	return &e
}
func (e *OutputXsiamMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "error":
		fallthrough
	case "backpressure":
		fallthrough
	case "always":
		*e = OutputXsiamMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputXsiamMode: %v", v)
	}
}

type OutputXsiamPqControls struct {
}

type OutputXsiam struct {
	// Unique ID for this output
	ID   string          `json:"id"`
	Type OutputXsiamType `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Enable for optimal performance. Even if you have one hostname, it can expand to multiple IPs. If disabled, consider enabling round-robin DNS.
	LoadBalanced *bool `default:"false" json:"loadBalanced"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `default:"5" json:"concurrency"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited).
	MaxPayloadEvents *float64 `default:"0" json:"maxPayloadEvents"`
	// Compress the payload body before sending
	Compress *bool `default:"true" json:"compress"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Defaults to Yes. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `default:"30" json:"timeoutSec"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Max body size.
	FlushPeriodSec *float64 `default:"1" json:"flushPeriodSec"`
	// Headers to add to all events.
	ExtraHTTPHeaders []OutputXsiamExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *OutputXsiamFailedRequestLoggingMode `default:"none" json:"failedRequestLoggingMode"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// Enter a token directly, or provide a secret referencing a token
	AuthType *OutputXsiamAuthenticationMethod `default:"token" json:"authType"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable).
	ResponseRetrySettings []OutputXsiamResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *OutputXsiamTimeoutRetrySettings   `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `default:"false" json:"responseHonorRetryAfterHeader"`
	// Maximum number of requests to limit to per second
	ThrottleRateReqPerSec *int64 `default:"400" json:"throttleRateReqPerSec"`
	// Whether to block, drop, or queue events when all receivers are exerting backpressure.
	OnBackpressure *OutputXsiamBackpressureBehavior `default:"block" json:"onBackpressure"`
	Description    *string                          `json:"description,omitempty"`
	// XSIAM endpoint URL to send events to, such as https://api-{tenant external URL}/logs/v1/event
	URL *string `default:"http://localhost:8088/logs/v1/event" json:"url"`
	// Enables round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `default:"false" json:"useRoundRobinDns"`
	// Exclude all IPs of the current host from the list of any resolved hostnames.
	ExcludeSelf *bool             `default:"false" json:"excludeSelf"`
	Urls        []OutputXsiamUrls `json:"urls,omitempty"`
	// Re-resolve any hostnames every this many seconds and pick up destinations from A records.
	DNSResolvePeriodSec *float64 `default:"600" json:"dnsResolvePeriodSec"`
	// How far back in time to keep traffic stats for load balancing purposes.
	LoadBalanceStatsPeriodSec *float64 `default:"300" json:"loadBalanceStatsPeriodSec"`
	// XSIAM authentication token
	Token *string `json:"token,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.).
	PqMaxFileSize *string `default:"1 MB" json:"pqMaxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `default:"5GB" json:"pqMaxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `default:"\\$CRIBL_HOME/state/queues" json:"pqPath"`
	// Codec to use to compress the persisted data.
	PqCompress *OutputXsiamCompression `default:"none" json:"pqCompress"`
	// Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *OutputXsiamQueueFullBehavior `default:"block" json:"pqOnBackpressure"`
	// In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
	PqMode     *OutputXsiamMode       `default:"error" json:"pqMode"`
	PqControls *OutputXsiamPqControls `json:"pqControls,omitempty"`
	Status     *TFStatus              `json:"status,omitempty"`
}

func (o OutputXsiam) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputXsiam) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *OutputXsiam) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *OutputXsiam) GetType() OutputXsiamType {
	if o == nil {
		return OutputXsiamType("")
	}
	return o.Type
}

func (o *OutputXsiam) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputXsiam) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputXsiam) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputXsiam) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputXsiam) GetLoadBalanced() *bool {
	if o == nil {
		return nil
	}
	return o.LoadBalanced
}

func (o *OutputXsiam) GetConcurrency() *float64 {
	if o == nil {
		return nil
	}
	return o.Concurrency
}

func (o *OutputXsiam) GetMaxPayloadEvents() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadEvents
}

func (o *OutputXsiam) GetCompress() *bool {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *OutputXsiam) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputXsiam) GetTimeoutSec() *float64 {
	if o == nil {
		return nil
	}
	return o.TimeoutSec
}

func (o *OutputXsiam) GetFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushPeriodSec
}

func (o *OutputXsiam) GetExtraHTTPHeaders() []OutputXsiamExtraHTTPHeaders {
	if o == nil {
		return nil
	}
	return o.ExtraHTTPHeaders
}

func (o *OutputXsiam) GetFailedRequestLoggingMode() *OutputXsiamFailedRequestLoggingMode {
	if o == nil {
		return nil
	}
	return o.FailedRequestLoggingMode
}

func (o *OutputXsiam) GetSafeHeaders() []string {
	if o == nil {
		return nil
	}
	return o.SafeHeaders
}

func (o *OutputXsiam) GetAuthType() *OutputXsiamAuthenticationMethod {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *OutputXsiam) GetResponseRetrySettings() []OutputXsiamResponseRetrySettings {
	if o == nil {
		return nil
	}
	return o.ResponseRetrySettings
}

func (o *OutputXsiam) GetTimeoutRetrySettings() *OutputXsiamTimeoutRetrySettings {
	if o == nil {
		return nil
	}
	return o.TimeoutRetrySettings
}

func (o *OutputXsiam) GetResponseHonorRetryAfterHeader() *bool {
	if o == nil {
		return nil
	}
	return o.ResponseHonorRetryAfterHeader
}

func (o *OutputXsiam) GetThrottleRateReqPerSec() *int64 {
	if o == nil {
		return nil
	}
	return o.ThrottleRateReqPerSec
}

func (o *OutputXsiam) GetOnBackpressure() *OutputXsiamBackpressureBehavior {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputXsiam) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputXsiam) GetURL() *string {
	if o == nil {
		return nil
	}
	return o.URL
}

func (o *OutputXsiam) GetUseRoundRobinDNS() *bool {
	if o == nil {
		return nil
	}
	return o.UseRoundRobinDNS
}

func (o *OutputXsiam) GetExcludeSelf() *bool {
	if o == nil {
		return nil
	}
	return o.ExcludeSelf
}

func (o *OutputXsiam) GetUrls() []OutputXsiamUrls {
	if o == nil {
		return nil
	}
	return o.Urls
}

func (o *OutputXsiam) GetDNSResolvePeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.DNSResolvePeriodSec
}

func (o *OutputXsiam) GetLoadBalanceStatsPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.LoadBalanceStatsPeriodSec
}

func (o *OutputXsiam) GetToken() *string {
	if o == nil {
		return nil
	}
	return o.Token
}

func (o *OutputXsiam) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *OutputXsiam) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputXsiam) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputXsiam) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputXsiam) GetPqCompress() *OutputXsiamCompression {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputXsiam) GetPqOnBackpressure() *OutputXsiamQueueFullBehavior {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputXsiam) GetPqMode() *OutputXsiamMode {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputXsiam) GetPqControls() *OutputXsiamPqControls {
	if o == nil {
		return nil
	}
	return o.PqControls
}

func (o *OutputXsiam) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type OutputClickHouseType string

const (
	OutputClickHouseTypeClickHouse OutputClickHouseType = "click_house"
)

func (e OutputClickHouseType) ToPointer() *OutputClickHouseType {
	return &e
}
func (e *OutputClickHouseType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "click_house":
		*e = OutputClickHouseType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputClickHouseType: %v", v)
	}
}

type OutputClickHouseAuthenticationType string

const (
	OutputClickHouseAuthenticationTypeNone               OutputClickHouseAuthenticationType = "none"
	OutputClickHouseAuthenticationTypeBasic              OutputClickHouseAuthenticationType = "basic"
	OutputClickHouseAuthenticationTypeCredentialsSecret  OutputClickHouseAuthenticationType = "credentialsSecret"
	OutputClickHouseAuthenticationTypeSslUserCertificate OutputClickHouseAuthenticationType = "sslUserCertificate"
	OutputClickHouseAuthenticationTypeToken              OutputClickHouseAuthenticationType = "token"
	OutputClickHouseAuthenticationTypeTextSecret         OutputClickHouseAuthenticationType = "textSecret"
	OutputClickHouseAuthenticationTypeOauth              OutputClickHouseAuthenticationType = "oauth"
)

func (e OutputClickHouseAuthenticationType) ToPointer() *OutputClickHouseAuthenticationType {
	return &e
}
func (e *OutputClickHouseAuthenticationType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "basic":
		fallthrough
	case "credentialsSecret":
		fallthrough
	case "sslUserCertificate":
		fallthrough
	case "token":
		fallthrough
	case "textSecret":
		fallthrough
	case "oauth":
		*e = OutputClickHouseAuthenticationType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputClickHouseAuthenticationType: %v", v)
	}
}

// OutputClickHouseFormat - Data format to use when sending data to ClickHouse. Defaults to JSON Compact.
type OutputClickHouseFormat string

const (
	OutputClickHouseFormatJSONCompactEachRowWithNames OutputClickHouseFormat = "json-compact-each-row-with-names"
	OutputClickHouseFormatJSONEachRow                 OutputClickHouseFormat = "json-each-row"
)

func (e OutputClickHouseFormat) ToPointer() *OutputClickHouseFormat {
	return &e
}
func (e *OutputClickHouseFormat) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "json-compact-each-row-with-names":
		fallthrough
	case "json-each-row":
		*e = OutputClickHouseFormat(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputClickHouseFormat: %v", v)
	}
}

// OutputClickHouseMappingType - How event fields are mapped to ClickHouse columns.
type OutputClickHouseMappingType string

const (
	OutputClickHouseMappingTypeAutomatic OutputClickHouseMappingType = "automatic"
	OutputClickHouseMappingTypeCustom    OutputClickHouseMappingType = "custom"
)

func (e OutputClickHouseMappingType) ToPointer() *OutputClickHouseMappingType {
	return &e
}
func (e *OutputClickHouseMappingType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "automatic":
		fallthrough
	case "custom":
		*e = OutputClickHouseMappingType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputClickHouseMappingType: %v", v)
	}
}

// OutputClickHouseMinimumTLSVersion - Minimum TLS version to use when connecting
type OutputClickHouseMinimumTLSVersion string

const (
	OutputClickHouseMinimumTLSVersionTlSv1  OutputClickHouseMinimumTLSVersion = "TLSv1"
	OutputClickHouseMinimumTLSVersionTlSv11 OutputClickHouseMinimumTLSVersion = "TLSv1.1"
	OutputClickHouseMinimumTLSVersionTlSv12 OutputClickHouseMinimumTLSVersion = "TLSv1.2"
	OutputClickHouseMinimumTLSVersionTlSv13 OutputClickHouseMinimumTLSVersion = "TLSv1.3"
)

func (e OutputClickHouseMinimumTLSVersion) ToPointer() *OutputClickHouseMinimumTLSVersion {
	return &e
}
func (e *OutputClickHouseMinimumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = OutputClickHouseMinimumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputClickHouseMinimumTLSVersion: %v", v)
	}
}

// OutputClickHouseMaximumTLSVersion - Maximum TLS version to use when connecting
type OutputClickHouseMaximumTLSVersion string

const (
	OutputClickHouseMaximumTLSVersionTlSv1  OutputClickHouseMaximumTLSVersion = "TLSv1"
	OutputClickHouseMaximumTLSVersionTlSv11 OutputClickHouseMaximumTLSVersion = "TLSv1.1"
	OutputClickHouseMaximumTLSVersionTlSv12 OutputClickHouseMaximumTLSVersion = "TLSv1.2"
	OutputClickHouseMaximumTLSVersionTlSv13 OutputClickHouseMaximumTLSVersion = "TLSv1.3"
)

func (e OutputClickHouseMaximumTLSVersion) ToPointer() *OutputClickHouseMaximumTLSVersion {
	return &e
}
func (e *OutputClickHouseMaximumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = OutputClickHouseMaximumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputClickHouseMaximumTLSVersion: %v", v)
	}
}

type OutputClickHouseTLSSettingsClientSide struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.
	Servername *string `json:"servername,omitempty"`
	// The name of the predefined certificate.
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Passphrase to use to decrypt private key.
	Passphrase *string `json:"passphrase,omitempty"`
	// Minimum TLS version to use when connecting
	MinVersion *OutputClickHouseMinimumTLSVersion `json:"minVersion,omitempty"`
	// Maximum TLS version to use when connecting
	MaxVersion *OutputClickHouseMaximumTLSVersion `json:"maxVersion,omitempty"`
}

func (o OutputClickHouseTLSSettingsClientSide) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputClickHouseTLSSettingsClientSide) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputClickHouseTLSSettingsClientSide) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *OutputClickHouseTLSSettingsClientSide) GetServername() *string {
	if o == nil {
		return nil
	}
	return o.Servername
}

func (o *OutputClickHouseTLSSettingsClientSide) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *OutputClickHouseTLSSettingsClientSide) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *OutputClickHouseTLSSettingsClientSide) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *OutputClickHouseTLSSettingsClientSide) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *OutputClickHouseTLSSettingsClientSide) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *OutputClickHouseTLSSettingsClientSide) GetMinVersion() *OutputClickHouseMinimumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *OutputClickHouseTLSSettingsClientSide) GetMaxVersion() *OutputClickHouseMaximumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

type OutputClickHouseExtraHTTPHeaders struct {
	// Field name
	Name *string `json:"name,omitempty"`
	// Field value
	Value string `json:"value"`
}

func (o *OutputClickHouseExtraHTTPHeaders) GetName() *string {
	if o == nil {
		return nil
	}
	return o.Name
}

func (o *OutputClickHouseExtraHTTPHeaders) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// OutputClickHouseFailedRequestLoggingMode - Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
type OutputClickHouseFailedRequestLoggingMode string

const (
	OutputClickHouseFailedRequestLoggingModePayload           OutputClickHouseFailedRequestLoggingMode = "payload"
	OutputClickHouseFailedRequestLoggingModePayloadAndHeaders OutputClickHouseFailedRequestLoggingMode = "payloadAndHeaders"
	OutputClickHouseFailedRequestLoggingModeNone              OutputClickHouseFailedRequestLoggingMode = "none"
)

func (e OutputClickHouseFailedRequestLoggingMode) ToPointer() *OutputClickHouseFailedRequestLoggingMode {
	return &e
}
func (e *OutputClickHouseFailedRequestLoggingMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "payload":
		fallthrough
	case "payloadAndHeaders":
		fallthrough
	case "none":
		*e = OutputClickHouseFailedRequestLoggingMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputClickHouseFailedRequestLoggingMode: %v", v)
	}
}

type OutputClickHouseResponseRetrySettings struct {
	// The HTTP response status code that will trigger retries
	HTTPStatus float64 `json:"httpStatus"`
	// How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"1000" json:"initialBackoff"`
	// Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackoff *float64 `default:"10000" json:"maxBackoff"`
}

func (o OutputClickHouseResponseRetrySettings) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputClickHouseResponseRetrySettings) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputClickHouseResponseRetrySettings) GetHTTPStatus() float64 {
	if o == nil {
		return 0.0
	}
	return o.HTTPStatus
}

func (o *OutputClickHouseResponseRetrySettings) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *OutputClickHouseResponseRetrySettings) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *OutputClickHouseResponseRetrySettings) GetMaxBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackoff
}

type OutputClickHouseTimeoutRetrySettings struct {
	// Enable to retry on request timeout
	TimeoutRetry *bool `default:"false" json:"timeoutRetry"`
	// How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"1000" json:"initialBackoff"`
	// Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackoff *float64 `default:"10000" json:"maxBackoff"`
}

func (o OutputClickHouseTimeoutRetrySettings) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputClickHouseTimeoutRetrySettings) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputClickHouseTimeoutRetrySettings) GetTimeoutRetry() *bool {
	if o == nil {
		return nil
	}
	return o.TimeoutRetry
}

func (o *OutputClickHouseTimeoutRetrySettings) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *OutputClickHouseTimeoutRetrySettings) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *OutputClickHouseTimeoutRetrySettings) GetMaxBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackoff
}

// OutputClickHouseBackpressureBehavior - Whether to block, drop, or queue events when all receivers are exerting backpressure.
type OutputClickHouseBackpressureBehavior string

const (
	OutputClickHouseBackpressureBehaviorBlock OutputClickHouseBackpressureBehavior = "block"
	OutputClickHouseBackpressureBehaviorDrop  OutputClickHouseBackpressureBehavior = "drop"
	OutputClickHouseBackpressureBehaviorQueue OutputClickHouseBackpressureBehavior = "queue"
)

func (e OutputClickHouseBackpressureBehavior) ToPointer() *OutputClickHouseBackpressureBehavior {
	return &e
}
func (e *OutputClickHouseBackpressureBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		fallthrough
	case "queue":
		*e = OutputClickHouseBackpressureBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputClickHouseBackpressureBehavior: %v", v)
	}
}

type OutputClickHouseOauthParams struct {
	// OAuth parameter name
	Name string `json:"name"`
	// OAuth parameter value
	Value string `json:"value"`
}

func (o *OutputClickHouseOauthParams) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *OutputClickHouseOauthParams) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type OutputClickHouseOauthHeaders struct {
	// OAuth header name
	Name string `json:"name"`
	// OAuth header value
	Value string `json:"value"`
}

func (o *OutputClickHouseOauthHeaders) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *OutputClickHouseOauthHeaders) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type OutputClickHouseColumnMappings struct {
	// Name of the column in ClickHouse that will store field value
	ColumnName string `json:"columnName"`
	// Type of the column in the ClickHouse database
	ColumnType *string `json:"columnType,omitempty"`
	// JavaScript expression to compute value to be inserted into ClickHouse table
	ColumnValueExpression string `json:"columnValueExpression"`
}

func (o *OutputClickHouseColumnMappings) GetColumnName() string {
	if o == nil {
		return ""
	}
	return o.ColumnName
}

func (o *OutputClickHouseColumnMappings) GetColumnType() *string {
	if o == nil {
		return nil
	}
	return o.ColumnType
}

func (o *OutputClickHouseColumnMappings) GetColumnValueExpression() string {
	if o == nil {
		return ""
	}
	return o.ColumnValueExpression
}

// OutputClickHouseCompression - Codec to use to compress the persisted data.
type OutputClickHouseCompression string

const (
	OutputClickHouseCompressionNone OutputClickHouseCompression = "none"
	OutputClickHouseCompressionGzip OutputClickHouseCompression = "gzip"
)

func (e OutputClickHouseCompression) ToPointer() *OutputClickHouseCompression {
	return &e
}
func (e *OutputClickHouseCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = OutputClickHouseCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputClickHouseCompression: %v", v)
	}
}

// OutputClickHouseQueueFullBehavior - Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
type OutputClickHouseQueueFullBehavior string

const (
	OutputClickHouseQueueFullBehaviorBlock OutputClickHouseQueueFullBehavior = "block"
	OutputClickHouseQueueFullBehaviorDrop  OutputClickHouseQueueFullBehavior = "drop"
)

func (e OutputClickHouseQueueFullBehavior) ToPointer() *OutputClickHouseQueueFullBehavior {
	return &e
}
func (e *OutputClickHouseQueueFullBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputClickHouseQueueFullBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputClickHouseQueueFullBehavior: %v", v)
	}
}

// OutputClickHouseMode - In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
type OutputClickHouseMode string

const (
	OutputClickHouseModeError        OutputClickHouseMode = "error"
	OutputClickHouseModeBackpressure OutputClickHouseMode = "backpressure"
	OutputClickHouseModeAlways       OutputClickHouseMode = "always"
)

func (e OutputClickHouseMode) ToPointer() *OutputClickHouseMode {
	return &e
}
func (e *OutputClickHouseMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "error":
		fallthrough
	case "backpressure":
		fallthrough
	case "always":
		*e = OutputClickHouseMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputClickHouseMode: %v", v)
	}
}

type OutputClickHousePqControls struct {
}

type OutputClickHouse struct {
	// Unique ID for this output
	ID   *string               `json:"id,omitempty"`
	Type *OutputClickHouseType `json:"type,omitempty"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// URL of the ClickHouse instance. Example: http://localhost:8123/
	URL      string                              `json:"url"`
	AuthType *OutputClickHouseAuthenticationType `default:"none" json:"authType"`
	Database string                              `json:"database"`
	// Name of the ClickHouse table where data will be inserted. Name can contain letters (A-Z, a-z), numbers (0-9), and the character "_", and must start with either a letter or the character "_".
	TableName string `json:"tableName"`
	// Data format to use when sending data to ClickHouse. Defaults to JSON Compact.
	Format *OutputClickHouseFormat `default:"json-compact-each-row-with-names" json:"format"`
	// How event fields are mapped to ClickHouse columns.
	MappingType *OutputClickHouseMappingType `default:"automatic" json:"mappingType"`
	// Collect data into batches for later processing. Disable to write to a ClickHouse table immediately.
	AsyncInserts *bool                                  `default:"false" json:"asyncInserts"`
	TLS          *OutputClickHouseTLSSettingsClientSide `json:"tls,omitempty"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `default:"5" json:"concurrency"`
	// Maximum size, in KB, of the request body
	MaxPayloadSizeKB *float64 `default:"4096" json:"maxPayloadSizeKB"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited).
	MaxPayloadEvents *float64 `default:"0" json:"maxPayloadEvents"`
	// Compress the payload body before sending
	Compress *bool `default:"true" json:"compress"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Defaults to Yes. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `default:"30" json:"timeoutSec"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Max body size.
	FlushPeriodSec *float64 `default:"1" json:"flushPeriodSec"`
	// Headers to add to all events.
	ExtraHTTPHeaders []OutputClickHouseExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// Enables round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `default:"false" json:"useRoundRobinDns"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *OutputClickHouseFailedRequestLoggingMode `default:"none" json:"failedRequestLoggingMode"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable).
	ResponseRetrySettings []OutputClickHouseResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *OutputClickHouseTimeoutRetrySettings   `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `default:"false" json:"responseHonorRetryAfterHeader"`
	// Log the most recent event that fails to match the table schema
	DumpFormatErrorsToDisk *bool `default:"false" json:"dumpFormatErrorsToDisk"`
	// Whether to block, drop, or queue events when all receivers are exerting backpressure.
	OnBackpressure *OutputClickHouseBackpressureBehavior `default:"block" json:"onBackpressure"`
	Description    *string                               `json:"description,omitempty"`
	Username       *string                               `json:"username,omitempty"`
	Password       *string                               `json:"password,omitempty"`
	// Bearer token to include in the authorization header
	Token *string `json:"token,omitempty"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// URL for OAuth
	LoginURL *string `json:"loginUrl,omitempty"`
	// Secret parameter name to pass in request body
	SecretParamName *string `json:"secretParamName,omitempty"`
	// Secret parameter value to pass in request body
	Secret *string `json:"secret,omitempty"`
	// Name of the auth token attribute in the OAuth response. Can be top-level (e.g., 'token'); or nested, using a period (e.g., 'data.token').
	TokenAttributeName *string `json:"tokenAttributeName,omitempty"`
	// JavaScript expression to compute the Authorization header value to pass in requests. The value `${token}` is used to reference the token obtained from authentication, e.g.: `Bearer ${token}`.
	AuthHeaderExpr *string `default:"Bearer \\${token}" json:"authHeaderExpr"`
	// How often the OAuth token should be refreshed.
	TokenTimeoutSecs *float64 `default:"3600" json:"tokenTimeoutSecs"`
	// Additional parameters to send in the OAuth login request. @{product} will combine the secret with these parameters, and will send the URL-encoded result in a POST request to the endpoint specified in the 'Login URL'. We'll automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthParams []OutputClickHouseOauthParams `json:"oauthParams,omitempty"`
	// Additional headers to send in the OAuth login request. @{product} will automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthHeaders []OutputClickHouseOauthHeaders `json:"oauthHeaders,omitempty"`
	// Username for certificate authentication
	SQLUsername *string `json:"sqlUsername,omitempty"`
	// Cribl will wait for confirmation that data has been fully inserted into the ClickHouse database before proceeding. Disabling this option can increase throughput, but Cribl wont be able to verify data has been completely inserted.
	WaitForAsyncInserts *bool `default:"true" json:"waitForAsyncInserts"`
	// Fields to exclude from sending to ClickHouse
	ExcludeMappingFields []string `json:"excludeMappingFields,omitempty"`
	// Retrieves the table schema from ClickHouse and populates the Column Mapping table
	DescribeTable  *string                          `json:"describeTable,omitempty"`
	ColumnMappings []OutputClickHouseColumnMappings `json:"columnMappings,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.).
	PqMaxFileSize *string `default:"1 MB" json:"pqMaxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `default:"5GB" json:"pqMaxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `default:"\\$CRIBL_HOME/state/queues" json:"pqPath"`
	// Codec to use to compress the persisted data.
	PqCompress *OutputClickHouseCompression `default:"none" json:"pqCompress"`
	// Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *OutputClickHouseQueueFullBehavior `default:"block" json:"pqOnBackpressure"`
	// In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
	PqMode     *OutputClickHouseMode       `default:"error" json:"pqMode"`
	PqControls *OutputClickHousePqControls `json:"pqControls,omitempty"`
	Status     *TFStatus                   `json:"status,omitempty"`
}

func (o OutputClickHouse) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputClickHouse) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *OutputClickHouse) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *OutputClickHouse) GetType() *OutputClickHouseType {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *OutputClickHouse) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputClickHouse) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputClickHouse) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputClickHouse) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputClickHouse) GetURL() string {
	if o == nil {
		return ""
	}
	return o.URL
}

func (o *OutputClickHouse) GetAuthType() *OutputClickHouseAuthenticationType {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *OutputClickHouse) GetDatabase() string {
	if o == nil {
		return ""
	}
	return o.Database
}

func (o *OutputClickHouse) GetTableName() string {
	if o == nil {
		return ""
	}
	return o.TableName
}

func (o *OutputClickHouse) GetFormat() *OutputClickHouseFormat {
	if o == nil {
		return nil
	}
	return o.Format
}

func (o *OutputClickHouse) GetMappingType() *OutputClickHouseMappingType {
	if o == nil {
		return nil
	}
	return o.MappingType
}

func (o *OutputClickHouse) GetAsyncInserts() *bool {
	if o == nil {
		return nil
	}
	return o.AsyncInserts
}

func (o *OutputClickHouse) GetTLS() *OutputClickHouseTLSSettingsClientSide {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *OutputClickHouse) GetConcurrency() *float64 {
	if o == nil {
		return nil
	}
	return o.Concurrency
}

func (o *OutputClickHouse) GetMaxPayloadSizeKB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadSizeKB
}

func (o *OutputClickHouse) GetMaxPayloadEvents() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadEvents
}

func (o *OutputClickHouse) GetCompress() *bool {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *OutputClickHouse) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputClickHouse) GetTimeoutSec() *float64 {
	if o == nil {
		return nil
	}
	return o.TimeoutSec
}

func (o *OutputClickHouse) GetFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushPeriodSec
}

func (o *OutputClickHouse) GetExtraHTTPHeaders() []OutputClickHouseExtraHTTPHeaders {
	if o == nil {
		return nil
	}
	return o.ExtraHTTPHeaders
}

func (o *OutputClickHouse) GetUseRoundRobinDNS() *bool {
	if o == nil {
		return nil
	}
	return o.UseRoundRobinDNS
}

func (o *OutputClickHouse) GetFailedRequestLoggingMode() *OutputClickHouseFailedRequestLoggingMode {
	if o == nil {
		return nil
	}
	return o.FailedRequestLoggingMode
}

func (o *OutputClickHouse) GetSafeHeaders() []string {
	if o == nil {
		return nil
	}
	return o.SafeHeaders
}

func (o *OutputClickHouse) GetResponseRetrySettings() []OutputClickHouseResponseRetrySettings {
	if o == nil {
		return nil
	}
	return o.ResponseRetrySettings
}

func (o *OutputClickHouse) GetTimeoutRetrySettings() *OutputClickHouseTimeoutRetrySettings {
	if o == nil {
		return nil
	}
	return o.TimeoutRetrySettings
}

func (o *OutputClickHouse) GetResponseHonorRetryAfterHeader() *bool {
	if o == nil {
		return nil
	}
	return o.ResponseHonorRetryAfterHeader
}

func (o *OutputClickHouse) GetDumpFormatErrorsToDisk() *bool {
	if o == nil {
		return nil
	}
	return o.DumpFormatErrorsToDisk
}

func (o *OutputClickHouse) GetOnBackpressure() *OutputClickHouseBackpressureBehavior {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputClickHouse) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputClickHouse) GetUsername() *string {
	if o == nil {
		return nil
	}
	return o.Username
}

func (o *OutputClickHouse) GetPassword() *string {
	if o == nil {
		return nil
	}
	return o.Password
}

func (o *OutputClickHouse) GetToken() *string {
	if o == nil {
		return nil
	}
	return o.Token
}

func (o *OutputClickHouse) GetCredentialsSecret() *string {
	if o == nil {
		return nil
	}
	return o.CredentialsSecret
}

func (o *OutputClickHouse) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *OutputClickHouse) GetLoginURL() *string {
	if o == nil {
		return nil
	}
	return o.LoginURL
}

func (o *OutputClickHouse) GetSecretParamName() *string {
	if o == nil {
		return nil
	}
	return o.SecretParamName
}

func (o *OutputClickHouse) GetSecret() *string {
	if o == nil {
		return nil
	}
	return o.Secret
}

func (o *OutputClickHouse) GetTokenAttributeName() *string {
	if o == nil {
		return nil
	}
	return o.TokenAttributeName
}

func (o *OutputClickHouse) GetAuthHeaderExpr() *string {
	if o == nil {
		return nil
	}
	return o.AuthHeaderExpr
}

func (o *OutputClickHouse) GetTokenTimeoutSecs() *float64 {
	if o == nil {
		return nil
	}
	return o.TokenTimeoutSecs
}

func (o *OutputClickHouse) GetOauthParams() []OutputClickHouseOauthParams {
	if o == nil {
		return nil
	}
	return o.OauthParams
}

func (o *OutputClickHouse) GetOauthHeaders() []OutputClickHouseOauthHeaders {
	if o == nil {
		return nil
	}
	return o.OauthHeaders
}

func (o *OutputClickHouse) GetSQLUsername() *string {
	if o == nil {
		return nil
	}
	return o.SQLUsername
}

func (o *OutputClickHouse) GetWaitForAsyncInserts() *bool {
	if o == nil {
		return nil
	}
	return o.WaitForAsyncInserts
}

func (o *OutputClickHouse) GetExcludeMappingFields() []string {
	if o == nil {
		return nil
	}
	return o.ExcludeMappingFields
}

func (o *OutputClickHouse) GetDescribeTable() *string {
	if o == nil {
		return nil
	}
	return o.DescribeTable
}

func (o *OutputClickHouse) GetColumnMappings() []OutputClickHouseColumnMappings {
	if o == nil {
		return nil
	}
	return o.ColumnMappings
}

func (o *OutputClickHouse) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputClickHouse) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputClickHouse) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputClickHouse) GetPqCompress() *OutputClickHouseCompression {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputClickHouse) GetPqOnBackpressure() *OutputClickHouseQueueFullBehavior {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputClickHouse) GetPqMode() *OutputClickHouseMode {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputClickHouse) GetPqControls() *OutputClickHousePqControls {
	if o == nil {
		return nil
	}
	return o.PqControls
}

func (o *OutputClickHouse) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type OutputDiskSpoolType string

const (
	OutputDiskSpoolTypeDiskSpool OutputDiskSpoolType = "disk_spool"
)

func (e OutputDiskSpoolType) ToPointer() *OutputDiskSpoolType {
	return &e
}
func (e *OutputDiskSpoolType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "disk_spool":
		*e = OutputDiskSpoolType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputDiskSpoolType: %v", v)
	}
}

// OutputDiskSpoolCompression - Data compression format. Default is gzip.
type OutputDiskSpoolCompression string

const (
	OutputDiskSpoolCompressionNone OutputDiskSpoolCompression = "none"
	OutputDiskSpoolCompressionGzip OutputDiskSpoolCompression = "gzip"
)

func (e OutputDiskSpoolCompression) ToPointer() *OutputDiskSpoolCompression {
	return &e
}
func (e *OutputDiskSpoolCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = OutputDiskSpoolCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputDiskSpoolCompression: %v", v)
	}
}

type OutputDiskSpool struct {
	// Unique ID for this output
	ID   string              `json:"id"`
	Type OutputDiskSpoolType `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Time period for grouping spooled events. Default is 10m.
	TimeWindow *string `default:"10m" json:"timeWindow"`
	// Maximum disk space that can be consumed before older buckets are deleted. Examples: 420MB, 4GB. Default is 1GB.
	MaxDataSize *string `default:"1GB" json:"maxDataSize"`
	// Maximum amount of time to retain data before older buckets are deleted. Examples: 2h, 4d. Default is 24h.
	MaxDataTime *string `default:"24h" json:"maxDataTime"`
	// Data compression format. Default is gzip.
	Compress *OutputDiskSpoolCompression `default:"gzip" json:"compress"`
	// JavaScript expression defining how files are partitioned and organized within the time-buckets. If blank, the event's __partition property is used and otherwise, events go directly into the time-bucket directory.
	PartitionExpr *string   `json:"partitionExpr,omitempty"`
	Description   *string   `json:"description,omitempty"`
	Status        *TFStatus `json:"status,omitempty"`
}

func (o OutputDiskSpool) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputDiskSpool) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *OutputDiskSpool) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *OutputDiskSpool) GetType() OutputDiskSpoolType {
	if o == nil {
		return OutputDiskSpoolType("")
	}
	return o.Type
}

func (o *OutputDiskSpool) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputDiskSpool) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputDiskSpool) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputDiskSpool) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputDiskSpool) GetTimeWindow() *string {
	if o == nil {
		return nil
	}
	return o.TimeWindow
}

func (o *OutputDiskSpool) GetMaxDataSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxDataSize
}

func (o *OutputDiskSpool) GetMaxDataTime() *string {
	if o == nil {
		return nil
	}
	return o.MaxDataTime
}

func (o *OutputDiskSpool) GetCompress() *OutputDiskSpoolCompression {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *OutputDiskSpool) GetPartitionExpr() *string {
	if o == nil {
		return nil
	}
	return o.PartitionExpr
}

func (o *OutputDiskSpool) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputDiskSpool) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type OutputCriblLakeType string

const (
	OutputCriblLakeTypeCriblLake OutputCriblLakeType = "cribl_lake"
)

func (e OutputCriblLakeType) ToPointer() *OutputCriblLakeType {
	return &e
}
func (e *OutputCriblLakeType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "cribl_lake":
		*e = OutputCriblLakeType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputCriblLakeType: %v", v)
	}
}

// OutputCriblLakeSignatureVersion - Signature version to use for signing S3 requests
type OutputCriblLakeSignatureVersion string

const (
	OutputCriblLakeSignatureVersionV2 OutputCriblLakeSignatureVersion = "v2"
	OutputCriblLakeSignatureVersionV4 OutputCriblLakeSignatureVersion = "v4"
)

func (e OutputCriblLakeSignatureVersion) ToPointer() *OutputCriblLakeSignatureVersion {
	return &e
}
func (e *OutputCriblLakeSignatureVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "v2":
		fallthrough
	case "v4":
		*e = OutputCriblLakeSignatureVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputCriblLakeSignatureVersion: %v", v)
	}
}

// OutputCriblLakeObjectACL - Object ACL to assign to uploaded objects.
type OutputCriblLakeObjectACL string

const (
	OutputCriblLakeObjectACLPrivate                OutputCriblLakeObjectACL = "private"
	OutputCriblLakeObjectACLPublicRead             OutputCriblLakeObjectACL = "public-read"
	OutputCriblLakeObjectACLPublicReadWrite        OutputCriblLakeObjectACL = "public-read-write"
	OutputCriblLakeObjectACLAuthenticatedRead      OutputCriblLakeObjectACL = "authenticated-read"
	OutputCriblLakeObjectACLAwsExecRead            OutputCriblLakeObjectACL = "aws-exec-read"
	OutputCriblLakeObjectACLBucketOwnerRead        OutputCriblLakeObjectACL = "bucket-owner-read"
	OutputCriblLakeObjectACLBucketOwnerFullControl OutputCriblLakeObjectACL = "bucket-owner-full-control"
)

func (e OutputCriblLakeObjectACL) ToPointer() *OutputCriblLakeObjectACL {
	return &e
}
func (e *OutputCriblLakeObjectACL) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "private":
		fallthrough
	case "public-read":
		fallthrough
	case "public-read-write":
		fallthrough
	case "authenticated-read":
		fallthrough
	case "aws-exec-read":
		fallthrough
	case "bucket-owner-read":
		fallthrough
	case "bucket-owner-full-control":
		*e = OutputCriblLakeObjectACL(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputCriblLakeObjectACL: %v", v)
	}
}

// OutputCriblLakeStorageClass - Storage class to select for uploaded objects.
type OutputCriblLakeStorageClass string

const (
	OutputCriblLakeStorageClassStandard           OutputCriblLakeStorageClass = "STANDARD"
	OutputCriblLakeStorageClassReducedRedundancy  OutputCriblLakeStorageClass = "REDUCED_REDUNDANCY"
	OutputCriblLakeStorageClassStandardIa         OutputCriblLakeStorageClass = "STANDARD_IA"
	OutputCriblLakeStorageClassOnezoneIa          OutputCriblLakeStorageClass = "ONEZONE_IA"
	OutputCriblLakeStorageClassIntelligentTiering OutputCriblLakeStorageClass = "INTELLIGENT_TIERING"
	OutputCriblLakeStorageClassGlacier            OutputCriblLakeStorageClass = "GLACIER"
	OutputCriblLakeStorageClassGlacierIr          OutputCriblLakeStorageClass = "GLACIER_IR"
	OutputCriblLakeStorageClassDeepArchive        OutputCriblLakeStorageClass = "DEEP_ARCHIVE"
)

func (e OutputCriblLakeStorageClass) ToPointer() *OutputCriblLakeStorageClass {
	return &e
}
func (e *OutputCriblLakeStorageClass) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "STANDARD":
		fallthrough
	case "REDUCED_REDUNDANCY":
		fallthrough
	case "STANDARD_IA":
		fallthrough
	case "ONEZONE_IA":
		fallthrough
	case "INTELLIGENT_TIERING":
		fallthrough
	case "GLACIER":
		fallthrough
	case "GLACIER_IR":
		fallthrough
	case "DEEP_ARCHIVE":
		*e = OutputCriblLakeStorageClass(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputCriblLakeStorageClass: %v", v)
	}
}

// OutputCriblLakeServerSideEncryption - Server-side encryption for uploaded objects.
type OutputCriblLakeServerSideEncryption string

const (
	OutputCriblLakeServerSideEncryptionAes256 OutputCriblLakeServerSideEncryption = "AES256"
	OutputCriblLakeServerSideEncryptionAwsKms OutputCriblLakeServerSideEncryption = "aws:kms"
)

func (e OutputCriblLakeServerSideEncryption) ToPointer() *OutputCriblLakeServerSideEncryption {
	return &e
}
func (e *OutputCriblLakeServerSideEncryption) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "AES256":
		fallthrough
	case "aws:kms":
		*e = OutputCriblLakeServerSideEncryption(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputCriblLakeServerSideEncryption: %v", v)
	}
}

// OutputCriblLakeBackpressureBehavior - Whether to block or drop events when all receivers are exerting backpressure
type OutputCriblLakeBackpressureBehavior string

const (
	OutputCriblLakeBackpressureBehaviorBlock OutputCriblLakeBackpressureBehavior = "block"
	OutputCriblLakeBackpressureBehaviorDrop  OutputCriblLakeBackpressureBehavior = "drop"
)

func (e OutputCriblLakeBackpressureBehavior) ToPointer() *OutputCriblLakeBackpressureBehavior {
	return &e
}
func (e *OutputCriblLakeBackpressureBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputCriblLakeBackpressureBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputCriblLakeBackpressureBehavior: %v", v)
	}
}

// OutputCriblLakeDiskSpaceProtection - Whether to block or drop events when disk space is below the global 'Min free disk space' limit
type OutputCriblLakeDiskSpaceProtection string

const (
	OutputCriblLakeDiskSpaceProtectionBlock OutputCriblLakeDiskSpaceProtection = "block"
	OutputCriblLakeDiskSpaceProtectionDrop  OutputCriblLakeDiskSpaceProtection = "drop"
)

func (e OutputCriblLakeDiskSpaceProtection) ToPointer() *OutputCriblLakeDiskSpaceProtection {
	return &e
}
func (e *OutputCriblLakeDiskSpaceProtection) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputCriblLakeDiskSpaceProtection(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputCriblLakeDiskSpaceProtection: %v", v)
	}
}

type AwsAuthenticationMethod string

const (
	AwsAuthenticationMethodAuto    AwsAuthenticationMethod = "auto"
	AwsAuthenticationMethodAutoRPC AwsAuthenticationMethod = "auto_rpc"
	AwsAuthenticationMethodManual  AwsAuthenticationMethod = "manual"
)

func (e AwsAuthenticationMethod) ToPointer() *AwsAuthenticationMethod {
	return &e
}
func (e *AwsAuthenticationMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "auto":
		fallthrough
	case "auto_rpc":
		fallthrough
	case "manual":
		*e = AwsAuthenticationMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for AwsAuthenticationMethod: %v", v)
	}
}

type OutputCriblLakeFormat string

const (
	OutputCriblLakeFormatJSON    OutputCriblLakeFormat = "json"
	OutputCriblLakeFormatParquet OutputCriblLakeFormat = "parquet"
	OutputCriblLakeFormatDdss    OutputCriblLakeFormat = "ddss"
)

func (e OutputCriblLakeFormat) ToPointer() *OutputCriblLakeFormat {
	return &e
}
func (e *OutputCriblLakeFormat) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "json":
		fallthrough
	case "parquet":
		fallthrough
	case "ddss":
		*e = OutputCriblLakeFormat(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputCriblLakeFormat: %v", v)
	}
}

type OutputCriblLake struct {
	// Unique ID for this output
	ID   *string             `json:"id,omitempty"`
	Type OutputCriblLakeType `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Name of the destination S3 bucket. Must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at init time. E.g., referencing a Global Variable: `myBucket-${C.vars.myVar}`.
	Bucket *string `json:"bucket,omitempty"`
	// Region where the S3 bucket is located.
	Region *string `json:"region,omitempty"`
	// Secret key. This value can be a constant or a JavaScript expression(e.g., `${C.env.SOME_SECRET}`).
	AwsSecretKey *string `json:"awsSecretKey,omitempty"`
	// S3 service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to S3-compatible endpoint.
	Endpoint *string `json:"endpoint,omitempty"`
	// Signature version to use for signing S3 requests
	SignatureVersion *OutputCriblLakeSignatureVersion `default:"v4" json:"signatureVersion"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `default:"true" json:"reuseConnections"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Use Assume Role credentials to access S3
	EnableAssumeRole *bool `default:"false" json:"enableAssumeRole"`
	// Amazon Resource Name (ARN) of the role to assume
	AssumeRoleArn *string `json:"assumeRoleArn,omitempty"`
	// External ID to use when assuming role
	AssumeRoleExternalID *string `json:"assumeRoleExternalId,omitempty"`
	// Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
	DurationSeconds *float64 `default:"3600" json:"durationSeconds"`
	// Filesystem location in which to buffer files, before compressing and moving to final destination. Use performant stable storage.
	StagePath *string `default:"\\$CRIBL_HOME/state/outputs/staging" json:"stagePath"`
	// Append output's ID to staging location
	AddIDToStagePath *bool `default:"true" json:"addIdToStagePath"`
	// Lake dataset to send the data to.
	DestPath string `json:"destPath"`
	// Object ACL to assign to uploaded objects.
	ObjectACL *OutputCriblLakeObjectACL `default:"private" json:"objectACL"`
	// Storage class to select for uploaded objects.
	StorageClass *OutputCriblLakeStorageClass `json:"storageClass,omitempty"`
	// Server-side encryption for uploaded objects.
	ServerSideEncryption *OutputCriblLakeServerSideEncryption `json:"serverSideEncryption,omitempty"`
	// ID or ARN of the KMS customer-managed key to use for encryption
	KmsKeyID *string `json:"kmsKeyId,omitempty"`
	// Remove empty staging directories after moving files
	RemoveEmptyDirs *bool `default:"true" json:"removeEmptyDirs"`
	// JavaScript expression to define the output filename prefix (can be constant)
	BaseFileName *string `default:"CriblOut" json:"baseFileName"`
	// JavaScript expression to define the output filename suffix (can be constant).  The `__format` variable refers to the value of the `Data format` field (`json` or `raw`).  The `__compression` field refers to the kind of compression being used (`none` or `gzip`).
	FileNameSuffix *string `default:".\\${C.env[\"CRIBL_WORKER_ID\"]}.\\${__format}\\${__compression === \"gzip\" ? \".gz\" : \"\"}" json:"fileNameSuffix"`
	// Maximum uncompressed output file size. Files of this size will be closed and moved to final output location.
	MaxFileSizeMB *float64 `default:"32" json:"maxFileSizeMB"`
	// Maximum number of files to keep open concurrently. When exceeded, @{product} will close the oldest open files and move them to the final output location.
	MaxOpenFiles *float64 `default:"100" json:"maxOpenFiles"`
	// If set, this line will be written to the beginning of each output file
	HeaderLine *string `default:"" json:"headerLine"`
	// Buffer size used to write to a file
	WriteHighWaterMark *float64 `default:"64" json:"writeHighWaterMark"`
	// Whether to block or drop events when all receivers are exerting backpressure
	OnBackpressure *OutputCriblLakeBackpressureBehavior `default:"block" json:"onBackpressure"`
	// If a file fails to move to its final destination after the maximum number of retries, dead-letter it to prevent further errors.
	DeadletterEnabled *bool `default:"false" json:"deadletterEnabled"`
	// Whether to block or drop events when disk space is below the global 'Min free disk space' limit
	OnDiskFullBackpressure *OutputCriblLakeDiskSpaceProtection `default:"block" json:"onDiskFullBackpressure"`
	// Maximum amount of time to write to a file. Files open for longer than this will be closed and moved to final output location.
	MaxFileOpenTimeSec *float64 `default:"300" json:"maxFileOpenTimeSec"`
	// Maximum amount of time to keep inactive files open. Files open for longer than this will be closed and moved to final output location.
	MaxFileIdleTimeSec *float64 `default:"30" json:"maxFileIdleTimeSec"`
	// Disable if you can access files within the bucket but not the bucket itself.
	VerifyPermissions *bool `default:"true" json:"verifyPermissions"`
	// Maximum number of files that can be waiting for upload before backpressure is applied
	MaxClosingFilesToBackpressure *float64                 `default:"100" json:"maxClosingFilesToBackpressure"`
	AwsAuthenticationMethod       *AwsAuthenticationMethod `default:"auto" json:"awsAuthenticationMethod"`
	Format                        *OutputCriblLakeFormat   `json:"format,omitempty"`
	// Maximum number of parts to upload in parallel per file. Minimum part size is 5MB.
	MaxConcurrentFileParts *float64 `default:"1" json:"maxConcurrentFileParts"`
	Description            *string  `json:"description,omitempty"`
	// How frequently, in seconds, to clean up empty directories when 'Remove empty staging dirs' is enabled
	EmptyDirCleanupSec *float64 `default:"300" json:"emptyDirCleanupSec"`
	// Storage location for files that fail to reach their final destination after maximum retries are exceeded
	DeadletterPath *string `default:"\\$CRIBL_HOME/state/outputs/dead-letter" json:"deadletterPath"`
	// The maximum number of times a file will attempt to move to its final destination before being dead-lettered
	MaxRetryNum *float64  `default:"20" json:"maxRetryNum"`
	Status      *TFStatus `json:"status,omitempty"`
}

func (o OutputCriblLake) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputCriblLake) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *OutputCriblLake) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *OutputCriblLake) GetType() OutputCriblLakeType {
	if o == nil {
		return OutputCriblLakeType("")
	}
	return o.Type
}

func (o *OutputCriblLake) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputCriblLake) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputCriblLake) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputCriblLake) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputCriblLake) GetBucket() *string {
	if o == nil {
		return nil
	}
	return o.Bucket
}

func (o *OutputCriblLake) GetRegion() *string {
	if o == nil {
		return nil
	}
	return o.Region
}

func (o *OutputCriblLake) GetAwsSecretKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecretKey
}

func (o *OutputCriblLake) GetEndpoint() *string {
	if o == nil {
		return nil
	}
	return o.Endpoint
}

func (o *OutputCriblLake) GetSignatureVersion() *OutputCriblLakeSignatureVersion {
	if o == nil {
		return nil
	}
	return o.SignatureVersion
}

func (o *OutputCriblLake) GetReuseConnections() *bool {
	if o == nil {
		return nil
	}
	return o.ReuseConnections
}

func (o *OutputCriblLake) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputCriblLake) GetEnableAssumeRole() *bool {
	if o == nil {
		return nil
	}
	return o.EnableAssumeRole
}

func (o *OutputCriblLake) GetAssumeRoleArn() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleArn
}

func (o *OutputCriblLake) GetAssumeRoleExternalID() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleExternalID
}

func (o *OutputCriblLake) GetDurationSeconds() *float64 {
	if o == nil {
		return nil
	}
	return o.DurationSeconds
}

func (o *OutputCriblLake) GetStagePath() *string {
	if o == nil {
		return nil
	}
	return o.StagePath
}

func (o *OutputCriblLake) GetAddIDToStagePath() *bool {
	if o == nil {
		return nil
	}
	return o.AddIDToStagePath
}

func (o *OutputCriblLake) GetDestPath() string {
	if o == nil {
		return ""
	}
	return o.DestPath
}

func (o *OutputCriblLake) GetObjectACL() *OutputCriblLakeObjectACL {
	if o == nil {
		return nil
	}
	return o.ObjectACL
}

func (o *OutputCriblLake) GetStorageClass() *OutputCriblLakeStorageClass {
	if o == nil {
		return nil
	}
	return o.StorageClass
}

func (o *OutputCriblLake) GetServerSideEncryption() *OutputCriblLakeServerSideEncryption {
	if o == nil {
		return nil
	}
	return o.ServerSideEncryption
}

func (o *OutputCriblLake) GetKmsKeyID() *string {
	if o == nil {
		return nil
	}
	return o.KmsKeyID
}

func (o *OutputCriblLake) GetRemoveEmptyDirs() *bool {
	if o == nil {
		return nil
	}
	return o.RemoveEmptyDirs
}

func (o *OutputCriblLake) GetBaseFileName() *string {
	if o == nil {
		return nil
	}
	return o.BaseFileName
}

func (o *OutputCriblLake) GetFileNameSuffix() *string {
	if o == nil {
		return nil
	}
	return o.FileNameSuffix
}

func (o *OutputCriblLake) GetMaxFileSizeMB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxFileSizeMB
}

func (o *OutputCriblLake) GetMaxOpenFiles() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxOpenFiles
}

func (o *OutputCriblLake) GetHeaderLine() *string {
	if o == nil {
		return nil
	}
	return o.HeaderLine
}

func (o *OutputCriblLake) GetWriteHighWaterMark() *float64 {
	if o == nil {
		return nil
	}
	return o.WriteHighWaterMark
}

func (o *OutputCriblLake) GetOnBackpressure() *OutputCriblLakeBackpressureBehavior {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputCriblLake) GetDeadletterEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.DeadletterEnabled
}

func (o *OutputCriblLake) GetOnDiskFullBackpressure() *OutputCriblLakeDiskSpaceProtection {
	if o == nil {
		return nil
	}
	return o.OnDiskFullBackpressure
}

func (o *OutputCriblLake) GetMaxFileOpenTimeSec() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxFileOpenTimeSec
}

func (o *OutputCriblLake) GetMaxFileIdleTimeSec() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxFileIdleTimeSec
}

func (o *OutputCriblLake) GetVerifyPermissions() *bool {
	if o == nil {
		return nil
	}
	return o.VerifyPermissions
}

func (o *OutputCriblLake) GetMaxClosingFilesToBackpressure() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxClosingFilesToBackpressure
}

func (o *OutputCriblLake) GetAwsAuthenticationMethod() *AwsAuthenticationMethod {
	if o == nil {
		return nil
	}
	return o.AwsAuthenticationMethod
}

func (o *OutputCriblLake) GetFormat() *OutputCriblLakeFormat {
	if o == nil {
		return nil
	}
	return o.Format
}

func (o *OutputCriblLake) GetMaxConcurrentFileParts() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxConcurrentFileParts
}

func (o *OutputCriblLake) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputCriblLake) GetEmptyDirCleanupSec() *float64 {
	if o == nil {
		return nil
	}
	return o.EmptyDirCleanupSec
}

func (o *OutputCriblLake) GetDeadletterPath() *string {
	if o == nil {
		return nil
	}
	return o.DeadletterPath
}

func (o *OutputCriblLake) GetMaxRetryNum() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxRetryNum
}

func (o *OutputCriblLake) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type OutputSecurityLakeType string

const (
	OutputSecurityLakeTypeSecurityLake OutputSecurityLakeType = "security_lake"
)

func (e OutputSecurityLakeType) ToPointer() *OutputSecurityLakeType {
	return &e
}
func (e *OutputSecurityLakeType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "security_lake":
		*e = OutputSecurityLakeType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSecurityLakeType: %v", v)
	}
}

// OutputSecurityLakeAuthenticationMethod - AWS authentication method. Choose Auto to use IAM roles.
type OutputSecurityLakeAuthenticationMethod string

const (
	OutputSecurityLakeAuthenticationMethodAuto   OutputSecurityLakeAuthenticationMethod = "auto"
	OutputSecurityLakeAuthenticationMethodManual OutputSecurityLakeAuthenticationMethod = "manual"
	OutputSecurityLakeAuthenticationMethodSecret OutputSecurityLakeAuthenticationMethod = "secret"
)

func (e OutputSecurityLakeAuthenticationMethod) ToPointer() *OutputSecurityLakeAuthenticationMethod {
	return &e
}
func (e *OutputSecurityLakeAuthenticationMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "auto":
		fallthrough
	case "manual":
		fallthrough
	case "secret":
		*e = OutputSecurityLakeAuthenticationMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSecurityLakeAuthenticationMethod: %v", v)
	}
}

// OutputSecurityLakeSignatureVersion - Signature version to use for signing Amazon Security Lake requests
type OutputSecurityLakeSignatureVersion string

const (
	OutputSecurityLakeSignatureVersionV2 OutputSecurityLakeSignatureVersion = "v2"
	OutputSecurityLakeSignatureVersionV4 OutputSecurityLakeSignatureVersion = "v4"
)

func (e OutputSecurityLakeSignatureVersion) ToPointer() *OutputSecurityLakeSignatureVersion {
	return &e
}
func (e *OutputSecurityLakeSignatureVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "v2":
		fallthrough
	case "v4":
		*e = OutputSecurityLakeSignatureVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSecurityLakeSignatureVersion: %v", v)
	}
}

// OutputSecurityLakeObjectACL - Object ACL to assign to uploaded objects.
type OutputSecurityLakeObjectACL string

const (
	OutputSecurityLakeObjectACLPrivate                OutputSecurityLakeObjectACL = "private"
	OutputSecurityLakeObjectACLPublicRead             OutputSecurityLakeObjectACL = "public-read"
	OutputSecurityLakeObjectACLPublicReadWrite        OutputSecurityLakeObjectACL = "public-read-write"
	OutputSecurityLakeObjectACLAuthenticatedRead      OutputSecurityLakeObjectACL = "authenticated-read"
	OutputSecurityLakeObjectACLAwsExecRead            OutputSecurityLakeObjectACL = "aws-exec-read"
	OutputSecurityLakeObjectACLBucketOwnerRead        OutputSecurityLakeObjectACL = "bucket-owner-read"
	OutputSecurityLakeObjectACLBucketOwnerFullControl OutputSecurityLakeObjectACL = "bucket-owner-full-control"
)

func (e OutputSecurityLakeObjectACL) ToPointer() *OutputSecurityLakeObjectACL {
	return &e
}
func (e *OutputSecurityLakeObjectACL) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "private":
		fallthrough
	case "public-read":
		fallthrough
	case "public-read-write":
		fallthrough
	case "authenticated-read":
		fallthrough
	case "aws-exec-read":
		fallthrough
	case "bucket-owner-read":
		fallthrough
	case "bucket-owner-full-control":
		*e = OutputSecurityLakeObjectACL(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSecurityLakeObjectACL: %v", v)
	}
}

// OutputSecurityLakeStorageClass - Storage class to select for uploaded objects.
type OutputSecurityLakeStorageClass string

const (
	OutputSecurityLakeStorageClassStandard           OutputSecurityLakeStorageClass = "STANDARD"
	OutputSecurityLakeStorageClassReducedRedundancy  OutputSecurityLakeStorageClass = "REDUCED_REDUNDANCY"
	OutputSecurityLakeStorageClassStandardIa         OutputSecurityLakeStorageClass = "STANDARD_IA"
	OutputSecurityLakeStorageClassOnezoneIa          OutputSecurityLakeStorageClass = "ONEZONE_IA"
	OutputSecurityLakeStorageClassIntelligentTiering OutputSecurityLakeStorageClass = "INTELLIGENT_TIERING"
	OutputSecurityLakeStorageClassGlacier            OutputSecurityLakeStorageClass = "GLACIER"
	OutputSecurityLakeStorageClassGlacierIr          OutputSecurityLakeStorageClass = "GLACIER_IR"
	OutputSecurityLakeStorageClassDeepArchive        OutputSecurityLakeStorageClass = "DEEP_ARCHIVE"
)

func (e OutputSecurityLakeStorageClass) ToPointer() *OutputSecurityLakeStorageClass {
	return &e
}
func (e *OutputSecurityLakeStorageClass) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "STANDARD":
		fallthrough
	case "REDUCED_REDUNDANCY":
		fallthrough
	case "STANDARD_IA":
		fallthrough
	case "ONEZONE_IA":
		fallthrough
	case "INTELLIGENT_TIERING":
		fallthrough
	case "GLACIER":
		fallthrough
	case "GLACIER_IR":
		fallthrough
	case "DEEP_ARCHIVE":
		*e = OutputSecurityLakeStorageClass(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSecurityLakeStorageClass: %v", v)
	}
}

// OutputSecurityLakeServerSideEncryption - Server-side encryption for uploaded objects.
type OutputSecurityLakeServerSideEncryption string

const (
	OutputSecurityLakeServerSideEncryptionAes256 OutputSecurityLakeServerSideEncryption = "AES256"
	OutputSecurityLakeServerSideEncryptionAwsKms OutputSecurityLakeServerSideEncryption = "aws:kms"
)

func (e OutputSecurityLakeServerSideEncryption) ToPointer() *OutputSecurityLakeServerSideEncryption {
	return &e
}
func (e *OutputSecurityLakeServerSideEncryption) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "AES256":
		fallthrough
	case "aws:kms":
		*e = OutputSecurityLakeServerSideEncryption(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSecurityLakeServerSideEncryption: %v", v)
	}
}

// OutputSecurityLakeBackpressureBehavior - Whether to block or drop events when all receivers are exerting backpressure
type OutputSecurityLakeBackpressureBehavior string

const (
	OutputSecurityLakeBackpressureBehaviorBlock OutputSecurityLakeBackpressureBehavior = "block"
	OutputSecurityLakeBackpressureBehaviorDrop  OutputSecurityLakeBackpressureBehavior = "drop"
)

func (e OutputSecurityLakeBackpressureBehavior) ToPointer() *OutputSecurityLakeBackpressureBehavior {
	return &e
}
func (e *OutputSecurityLakeBackpressureBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputSecurityLakeBackpressureBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSecurityLakeBackpressureBehavior: %v", v)
	}
}

// OutputSecurityLakeDiskSpaceProtection - Whether to block or drop events when disk space is below the global 'Min free disk space' limit
type OutputSecurityLakeDiskSpaceProtection string

const (
	OutputSecurityLakeDiskSpaceProtectionBlock OutputSecurityLakeDiskSpaceProtection = "block"
	OutputSecurityLakeDiskSpaceProtectionDrop  OutputSecurityLakeDiskSpaceProtection = "drop"
)

func (e OutputSecurityLakeDiskSpaceProtection) ToPointer() *OutputSecurityLakeDiskSpaceProtection {
	return &e
}
func (e *OutputSecurityLakeDiskSpaceProtection) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputSecurityLakeDiskSpaceProtection(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSecurityLakeDiskSpaceProtection: %v", v)
	}
}

// OutputSecurityLakeParquetVersion - Determines which data types are supported and how they are represented
type OutputSecurityLakeParquetVersion string

const (
	OutputSecurityLakeParquetVersionParquet10 OutputSecurityLakeParquetVersion = "PARQUET_1_0"
	OutputSecurityLakeParquetVersionParquet24 OutputSecurityLakeParquetVersion = "PARQUET_2_4"
	OutputSecurityLakeParquetVersionParquet26 OutputSecurityLakeParquetVersion = "PARQUET_2_6"
)

func (e OutputSecurityLakeParquetVersion) ToPointer() *OutputSecurityLakeParquetVersion {
	return &e
}
func (e *OutputSecurityLakeParquetVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "PARQUET_1_0":
		fallthrough
	case "PARQUET_2_4":
		fallthrough
	case "PARQUET_2_6":
		*e = OutputSecurityLakeParquetVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSecurityLakeParquetVersion: %v", v)
	}
}

// OutputSecurityLakeDataPageVersion - Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
type OutputSecurityLakeDataPageVersion string

const (
	OutputSecurityLakeDataPageVersionDataPageV1 OutputSecurityLakeDataPageVersion = "DATA_PAGE_V1"
	OutputSecurityLakeDataPageVersionDataPageV2 OutputSecurityLakeDataPageVersion = "DATA_PAGE_V2"
)

func (e OutputSecurityLakeDataPageVersion) ToPointer() *OutputSecurityLakeDataPageVersion {
	return &e
}
func (e *OutputSecurityLakeDataPageVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "DATA_PAGE_V1":
		fallthrough
	case "DATA_PAGE_V2":
		*e = OutputSecurityLakeDataPageVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSecurityLakeDataPageVersion: %v", v)
	}
}

type OutputSecurityLakeKeyValueMetadata struct {
	Key   *string `default:"" json:"key"`
	Value string  `json:"value"`
}

func (o OutputSecurityLakeKeyValueMetadata) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputSecurityLakeKeyValueMetadata) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputSecurityLakeKeyValueMetadata) GetKey() *string {
	if o == nil {
		return nil
	}
	return o.Key
}

func (o *OutputSecurityLakeKeyValueMetadata) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type OutputSecurityLake struct {
	// Unique ID for this output
	ID   *string                 `json:"id,omitempty"`
	Type *OutputSecurityLakeType `json:"type,omitempty"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards. These fields are added as dimensions and labels to generated metrics and logs, respectively.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Name of the destination S3 bucket. Must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at init time. E.g., referencing a Global Variable: `myBucket-${C.vars.myVar}`.
	Bucket string `json:"bucket"`
	// Region where the Amazon Security Lake is located.
	Region       string  `json:"region"`
	AwsSecretKey *string `json:"awsSecretKey,omitempty"`
	// AWS authentication method. Choose Auto to use IAM roles.
	AwsAuthenticationMethod *OutputSecurityLakeAuthenticationMethod `default:"auto" json:"awsAuthenticationMethod"`
	// Amazon Security Lake service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to Amazon Security Lake-compatible endpoint.
	Endpoint *string `json:"endpoint,omitempty"`
	// Signature version to use for signing Amazon Security Lake requests
	SignatureVersion *OutputSecurityLakeSignatureVersion `default:"v4" json:"signatureVersion"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `default:"true" json:"reuseConnections"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Use Assume Role credentials to access S3
	EnableAssumeRole *bool `default:"false" json:"enableAssumeRole"`
	// Amazon Resource Name (ARN) of the role to assume
	AssumeRoleArn string `json:"assumeRoleArn"`
	// External ID to use when assuming role
	AssumeRoleExternalID *string `json:"assumeRoleExternalId,omitempty"`
	// Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
	DurationSeconds *float64 `default:"3600" json:"durationSeconds"`
	// Filesystem location in which to buffer files, before compressing and moving to final destination. Use performant stable storage.
	StagePath *string `default:"\\$CRIBL_HOME/state/outputs/staging" json:"stagePath"`
	// Append output's ID to staging location
	AddIDToStagePath *bool `default:"true" json:"addIdToStagePath"`
	// Object ACL to assign to uploaded objects.
	ObjectACL *OutputSecurityLakeObjectACL `default:"private" json:"objectACL"`
	// Storage class to select for uploaded objects.
	StorageClass *OutputSecurityLakeStorageClass `json:"storageClass,omitempty"`
	// Server-side encryption for uploaded objects.
	ServerSideEncryption *OutputSecurityLakeServerSideEncryption `json:"serverSideEncryption,omitempty"`
	// ID or ARN of the KMS customer-managed key to use for encryption
	KmsKeyID *string `json:"kmsKeyId,omitempty"`
	// Remove empty staging directories after moving files
	RemoveEmptyDirs *bool `default:"true" json:"removeEmptyDirs"`
	// JavaScript expression to define the output filename prefix (can be constant)
	BaseFileName *string `default:"CriblOut" json:"baseFileName"`
	// Maximum uncompressed output file size. Files of this size will be closed and moved to final output location.
	MaxFileSizeMB *float64 `default:"32" json:"maxFileSizeMB"`
	// Maximum number of files to keep open concurrently. When exceeded, @{product} will close the oldest open files and move them to the final output location.
	MaxOpenFiles *float64 `default:"100" json:"maxOpenFiles"`
	// If set, this line will be written to the beginning of each output file
	HeaderLine *string `default:"" json:"headerLine"`
	// Buffer size used to write to a file
	WriteHighWaterMark *float64 `default:"64" json:"writeHighWaterMark"`
	// Whether to block or drop events when all receivers are exerting backpressure
	OnBackpressure *OutputSecurityLakeBackpressureBehavior `default:"block" json:"onBackpressure"`
	// If a file fails to move to its final destination after the maximum number of retries, dead-letter it to prevent further errors.
	DeadletterEnabled *bool `default:"false" json:"deadletterEnabled"`
	// Whether to block or drop events when disk space is below the global 'Min free disk space' limit
	OnDiskFullBackpressure *OutputSecurityLakeDiskSpaceProtection `default:"block" json:"onDiskFullBackpressure"`
	// Maximum amount of time to write to a file. Files open for longer than this will be closed and moved to final output location.
	MaxFileOpenTimeSec *float64 `default:"300" json:"maxFileOpenTimeSec"`
	// Maximum amount of time to keep inactive files open. Files open for longer than this will be closed and moved to final output location.
	MaxFileIdleTimeSec *float64 `default:"30" json:"maxFileIdleTimeSec"`
	// Maximum number of parts to upload in parallel per file. Minimum part size is 5MB.
	MaxConcurrentFileParts *float64 `default:"4" json:"maxConcurrentFileParts"`
	// Disable if you can access files within the bucket but not the bucket itself.
	VerifyPermissions *bool `default:"true" json:"verifyPermissions"`
	// Maximum number of files that can be waiting for upload before backpressure is applied
	MaxClosingFilesToBackpressure *float64 `default:"100" json:"maxClosingFilesToBackpressure"`
	// ID of the AWS account whose data the Destination will write to Security Lake. This should have been configured when creating the Amazon Security Lake custom source.
	AccountID string `json:"accountId"`
	// Name of the custom source configured in Amazon Security Lake
	CustomSource string `json:"customSource"`
	// Automatically calculate the schema based on the events of each Parquet file generated
	AutomaticSchema *bool `default:"false" json:"automaticSchema"`
	// Determines which data types are supported and how they are represented
	ParquetVersion *OutputSecurityLakeParquetVersion `default:"PARQUET_2_6" json:"parquetVersion"`
	// Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
	ParquetDataPageVersion *OutputSecurityLakeDataPageVersion `default:"DATA_PAGE_V2" json:"parquetDataPageVersion"`
	// The number of rows that every group will contain. The final group can contain a smaller number of rows.
	ParquetRowGroupLength *float64 `default:"10000" json:"parquetRowGroupLength"`
	// Target memory size for page segments, such as 1MB or 128MB. Generally, lower values improve reading speed, while higher values improve compression.
	ParquetPageSize *string `default:"1MB" json:"parquetPageSize"`
	// Log up to 3 rows that @{product} skips due to data mismatch
	ShouldLogInvalidRows *bool `json:"shouldLogInvalidRows,omitempty"`
	// The metadata of files the Destination writes will include the properties you add here as key-value pairs. Useful for tagging, e.g., "key":"OCSF Event Class", "value":"9001".
	KeyValueMetadata []OutputSecurityLakeKeyValueMetadata `json:"keyValueMetadata,omitempty"`
	// Statistics profile an entire file in terms of minimum/maximum values within data, numbers of nulls, etc. You can use Parquet tools to view statistics.
	EnableStatistics *bool `default:"true" json:"enableStatistics"`
	// One page index contains statistics for one data page. Parquet readers use statistics to enable page skipping.
	EnableWritePageIndex *bool `default:"true" json:"enableWritePageIndex"`
	// Parquet tools can use the checksum of a Parquet page to verify data integrity
	EnablePageChecksum *bool   `default:"false" json:"enablePageChecksum"`
	Description        *string `json:"description,omitempty"`
	// This value can be a constant or a JavaScript expression (`${C.env.SOME_ACCESS_KEY}`)
	AwsAPIKey *string `json:"awsApiKey,omitempty"`
	// Select or create a stored secret that references your access key and secret key
	AwsSecret *string `json:"awsSecret,omitempty"`
	// How frequently, in seconds, to clean up empty directories when 'Remove empty staging dirs' is enabled
	EmptyDirCleanupSec *float64 `default:"300" json:"emptyDirCleanupSec"`
	// To add a new schema, navigate to Processing > Knowledge > Parquet Schemas
	ParquetSchema *string `json:"parquetSchema,omitempty"`
	// Storage location for files that fail to reach their final destination after maximum retries are exceeded
	DeadletterPath *string `default:"\\$CRIBL_HOME/state/outputs/dead-letter" json:"deadletterPath"`
	// The maximum number of times a file will attempt to move to its final destination before being dead-lettered
	MaxRetryNum *float64  `default:"20" json:"maxRetryNum"`
	Status      *TFStatus `json:"status,omitempty"`
}

func (o OutputSecurityLake) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputSecurityLake) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *OutputSecurityLake) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *OutputSecurityLake) GetType() *OutputSecurityLakeType {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *OutputSecurityLake) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputSecurityLake) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputSecurityLake) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputSecurityLake) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputSecurityLake) GetBucket() string {
	if o == nil {
		return ""
	}
	return o.Bucket
}

func (o *OutputSecurityLake) GetRegion() string {
	if o == nil {
		return ""
	}
	return o.Region
}

func (o *OutputSecurityLake) GetAwsSecretKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecretKey
}

func (o *OutputSecurityLake) GetAwsAuthenticationMethod() *OutputSecurityLakeAuthenticationMethod {
	if o == nil {
		return nil
	}
	return o.AwsAuthenticationMethod
}

func (o *OutputSecurityLake) GetEndpoint() *string {
	if o == nil {
		return nil
	}
	return o.Endpoint
}

func (o *OutputSecurityLake) GetSignatureVersion() *OutputSecurityLakeSignatureVersion {
	if o == nil {
		return nil
	}
	return o.SignatureVersion
}

func (o *OutputSecurityLake) GetReuseConnections() *bool {
	if o == nil {
		return nil
	}
	return o.ReuseConnections
}

func (o *OutputSecurityLake) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputSecurityLake) GetEnableAssumeRole() *bool {
	if o == nil {
		return nil
	}
	return o.EnableAssumeRole
}

func (o *OutputSecurityLake) GetAssumeRoleArn() string {
	if o == nil {
		return ""
	}
	return o.AssumeRoleArn
}

func (o *OutputSecurityLake) GetAssumeRoleExternalID() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleExternalID
}

func (o *OutputSecurityLake) GetDurationSeconds() *float64 {
	if o == nil {
		return nil
	}
	return o.DurationSeconds
}

func (o *OutputSecurityLake) GetStagePath() *string {
	if o == nil {
		return nil
	}
	return o.StagePath
}

func (o *OutputSecurityLake) GetAddIDToStagePath() *bool {
	if o == nil {
		return nil
	}
	return o.AddIDToStagePath
}

func (o *OutputSecurityLake) GetObjectACL() *OutputSecurityLakeObjectACL {
	if o == nil {
		return nil
	}
	return o.ObjectACL
}

func (o *OutputSecurityLake) GetStorageClass() *OutputSecurityLakeStorageClass {
	if o == nil {
		return nil
	}
	return o.StorageClass
}

func (o *OutputSecurityLake) GetServerSideEncryption() *OutputSecurityLakeServerSideEncryption {
	if o == nil {
		return nil
	}
	return o.ServerSideEncryption
}

func (o *OutputSecurityLake) GetKmsKeyID() *string {
	if o == nil {
		return nil
	}
	return o.KmsKeyID
}

func (o *OutputSecurityLake) GetRemoveEmptyDirs() *bool {
	if o == nil {
		return nil
	}
	return o.RemoveEmptyDirs
}

func (o *OutputSecurityLake) GetBaseFileName() *string {
	if o == nil {
		return nil
	}
	return o.BaseFileName
}

func (o *OutputSecurityLake) GetMaxFileSizeMB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxFileSizeMB
}

func (o *OutputSecurityLake) GetMaxOpenFiles() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxOpenFiles
}

func (o *OutputSecurityLake) GetHeaderLine() *string {
	if o == nil {
		return nil
	}
	return o.HeaderLine
}

func (o *OutputSecurityLake) GetWriteHighWaterMark() *float64 {
	if o == nil {
		return nil
	}
	return o.WriteHighWaterMark
}

func (o *OutputSecurityLake) GetOnBackpressure() *OutputSecurityLakeBackpressureBehavior {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputSecurityLake) GetDeadletterEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.DeadletterEnabled
}

func (o *OutputSecurityLake) GetOnDiskFullBackpressure() *OutputSecurityLakeDiskSpaceProtection {
	if o == nil {
		return nil
	}
	return o.OnDiskFullBackpressure
}

func (o *OutputSecurityLake) GetMaxFileOpenTimeSec() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxFileOpenTimeSec
}

func (o *OutputSecurityLake) GetMaxFileIdleTimeSec() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxFileIdleTimeSec
}

func (o *OutputSecurityLake) GetMaxConcurrentFileParts() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxConcurrentFileParts
}

func (o *OutputSecurityLake) GetVerifyPermissions() *bool {
	if o == nil {
		return nil
	}
	return o.VerifyPermissions
}

func (o *OutputSecurityLake) GetMaxClosingFilesToBackpressure() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxClosingFilesToBackpressure
}

func (o *OutputSecurityLake) GetAccountID() string {
	if o == nil {
		return ""
	}
	return o.AccountID
}

func (o *OutputSecurityLake) GetCustomSource() string {
	if o == nil {
		return ""
	}
	return o.CustomSource
}

func (o *OutputSecurityLake) GetAutomaticSchema() *bool {
	if o == nil {
		return nil
	}
	return o.AutomaticSchema
}

func (o *OutputSecurityLake) GetParquetVersion() *OutputSecurityLakeParquetVersion {
	if o == nil {
		return nil
	}
	return o.ParquetVersion
}

func (o *OutputSecurityLake) GetParquetDataPageVersion() *OutputSecurityLakeDataPageVersion {
	if o == nil {
		return nil
	}
	return o.ParquetDataPageVersion
}

func (o *OutputSecurityLake) GetParquetRowGroupLength() *float64 {
	if o == nil {
		return nil
	}
	return o.ParquetRowGroupLength
}

func (o *OutputSecurityLake) GetParquetPageSize() *string {
	if o == nil {
		return nil
	}
	return o.ParquetPageSize
}

func (o *OutputSecurityLake) GetShouldLogInvalidRows() *bool {
	if o == nil {
		return nil
	}
	return o.ShouldLogInvalidRows
}

func (o *OutputSecurityLake) GetKeyValueMetadata() []OutputSecurityLakeKeyValueMetadata {
	if o == nil {
		return nil
	}
	return o.KeyValueMetadata
}

func (o *OutputSecurityLake) GetEnableStatistics() *bool {
	if o == nil {
		return nil
	}
	return o.EnableStatistics
}

func (o *OutputSecurityLake) GetEnableWritePageIndex() *bool {
	if o == nil {
		return nil
	}
	return o.EnableWritePageIndex
}

func (o *OutputSecurityLake) GetEnablePageChecksum() *bool {
	if o == nil {
		return nil
	}
	return o.EnablePageChecksum
}

func (o *OutputSecurityLake) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputSecurityLake) GetAwsAPIKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsAPIKey
}

func (o *OutputSecurityLake) GetAwsSecret() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecret
}

func (o *OutputSecurityLake) GetEmptyDirCleanupSec() *float64 {
	if o == nil {
		return nil
	}
	return o.EmptyDirCleanupSec
}

func (o *OutputSecurityLake) GetParquetSchema() *string {
	if o == nil {
		return nil
	}
	return o.ParquetSchema
}

func (o *OutputSecurityLake) GetDeadletterPath() *string {
	if o == nil {
		return nil
	}
	return o.DeadletterPath
}

func (o *OutputSecurityLake) GetMaxRetryNum() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxRetryNum
}

func (o *OutputSecurityLake) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type OutputDlS3Type string

const (
	OutputDlS3TypeDlS3 OutputDlS3Type = "dl_s3"
)

func (e OutputDlS3Type) ToPointer() *OutputDlS3Type {
	return &e
}
func (e *OutputDlS3Type) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "dl_s3":
		*e = OutputDlS3Type(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputDlS3Type: %v", v)
	}
}

// OutputDlS3AuthenticationMethod - AWS authentication method. Choose Auto to use IAM roles.
type OutputDlS3AuthenticationMethod string

const (
	OutputDlS3AuthenticationMethodAuto   OutputDlS3AuthenticationMethod = "auto"
	OutputDlS3AuthenticationMethodManual OutputDlS3AuthenticationMethod = "manual"
	OutputDlS3AuthenticationMethodSecret OutputDlS3AuthenticationMethod = "secret"
)

func (e OutputDlS3AuthenticationMethod) ToPointer() *OutputDlS3AuthenticationMethod {
	return &e
}
func (e *OutputDlS3AuthenticationMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "auto":
		fallthrough
	case "manual":
		fallthrough
	case "secret":
		*e = OutputDlS3AuthenticationMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputDlS3AuthenticationMethod: %v", v)
	}
}

// OutputDlS3SignatureVersion - Signature version to use for signing S3 requests
type OutputDlS3SignatureVersion string

const (
	OutputDlS3SignatureVersionV2 OutputDlS3SignatureVersion = "v2"
	OutputDlS3SignatureVersionV4 OutputDlS3SignatureVersion = "v4"
)

func (e OutputDlS3SignatureVersion) ToPointer() *OutputDlS3SignatureVersion {
	return &e
}
func (e *OutputDlS3SignatureVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "v2":
		fallthrough
	case "v4":
		*e = OutputDlS3SignatureVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputDlS3SignatureVersion: %v", v)
	}
}

// OutputDlS3ObjectACL - Object ACL to assign to uploaded objects.
type OutputDlS3ObjectACL string

const (
	OutputDlS3ObjectACLPrivate                OutputDlS3ObjectACL = "private"
	OutputDlS3ObjectACLPublicRead             OutputDlS3ObjectACL = "public-read"
	OutputDlS3ObjectACLPublicReadWrite        OutputDlS3ObjectACL = "public-read-write"
	OutputDlS3ObjectACLAuthenticatedRead      OutputDlS3ObjectACL = "authenticated-read"
	OutputDlS3ObjectACLAwsExecRead            OutputDlS3ObjectACL = "aws-exec-read"
	OutputDlS3ObjectACLBucketOwnerRead        OutputDlS3ObjectACL = "bucket-owner-read"
	OutputDlS3ObjectACLBucketOwnerFullControl OutputDlS3ObjectACL = "bucket-owner-full-control"
)

func (e OutputDlS3ObjectACL) ToPointer() *OutputDlS3ObjectACL {
	return &e
}
func (e *OutputDlS3ObjectACL) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "private":
		fallthrough
	case "public-read":
		fallthrough
	case "public-read-write":
		fallthrough
	case "authenticated-read":
		fallthrough
	case "aws-exec-read":
		fallthrough
	case "bucket-owner-read":
		fallthrough
	case "bucket-owner-full-control":
		*e = OutputDlS3ObjectACL(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputDlS3ObjectACL: %v", v)
	}
}

// OutputDlS3StorageClass - Storage class to select for uploaded objects.
type OutputDlS3StorageClass string

const (
	OutputDlS3StorageClassStandard           OutputDlS3StorageClass = "STANDARD"
	OutputDlS3StorageClassReducedRedundancy  OutputDlS3StorageClass = "REDUCED_REDUNDANCY"
	OutputDlS3StorageClassStandardIa         OutputDlS3StorageClass = "STANDARD_IA"
	OutputDlS3StorageClassOnezoneIa          OutputDlS3StorageClass = "ONEZONE_IA"
	OutputDlS3StorageClassIntelligentTiering OutputDlS3StorageClass = "INTELLIGENT_TIERING"
	OutputDlS3StorageClassGlacier            OutputDlS3StorageClass = "GLACIER"
	OutputDlS3StorageClassGlacierIr          OutputDlS3StorageClass = "GLACIER_IR"
	OutputDlS3StorageClassDeepArchive        OutputDlS3StorageClass = "DEEP_ARCHIVE"
)

func (e OutputDlS3StorageClass) ToPointer() *OutputDlS3StorageClass {
	return &e
}
func (e *OutputDlS3StorageClass) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "STANDARD":
		fallthrough
	case "REDUCED_REDUNDANCY":
		fallthrough
	case "STANDARD_IA":
		fallthrough
	case "ONEZONE_IA":
		fallthrough
	case "INTELLIGENT_TIERING":
		fallthrough
	case "GLACIER":
		fallthrough
	case "GLACIER_IR":
		fallthrough
	case "DEEP_ARCHIVE":
		*e = OutputDlS3StorageClass(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputDlS3StorageClass: %v", v)
	}
}

// OutputDlS3ServerSideEncryption - Server-side encryption for uploaded objects.
type OutputDlS3ServerSideEncryption string

const (
	OutputDlS3ServerSideEncryptionAes256 OutputDlS3ServerSideEncryption = "AES256"
	OutputDlS3ServerSideEncryptionAwsKms OutputDlS3ServerSideEncryption = "aws:kms"
)

func (e OutputDlS3ServerSideEncryption) ToPointer() *OutputDlS3ServerSideEncryption {
	return &e
}
func (e *OutputDlS3ServerSideEncryption) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "AES256":
		fallthrough
	case "aws:kms":
		*e = OutputDlS3ServerSideEncryption(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputDlS3ServerSideEncryption: %v", v)
	}
}

// OutputDlS3DataFormat - Format of the output data
type OutputDlS3DataFormat string

const (
	OutputDlS3DataFormatJSON    OutputDlS3DataFormat = "json"
	OutputDlS3DataFormatRaw     OutputDlS3DataFormat = "raw"
	OutputDlS3DataFormatParquet OutputDlS3DataFormat = "parquet"
)

func (e OutputDlS3DataFormat) ToPointer() *OutputDlS3DataFormat {
	return &e
}
func (e *OutputDlS3DataFormat) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "json":
		fallthrough
	case "raw":
		fallthrough
	case "parquet":
		*e = OutputDlS3DataFormat(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputDlS3DataFormat: %v", v)
	}
}

// OutputDlS3BackpressureBehavior - Whether to block or drop events when all receivers are exerting backpressure
type OutputDlS3BackpressureBehavior string

const (
	OutputDlS3BackpressureBehaviorBlock OutputDlS3BackpressureBehavior = "block"
	OutputDlS3BackpressureBehaviorDrop  OutputDlS3BackpressureBehavior = "drop"
)

func (e OutputDlS3BackpressureBehavior) ToPointer() *OutputDlS3BackpressureBehavior {
	return &e
}
func (e *OutputDlS3BackpressureBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputDlS3BackpressureBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputDlS3BackpressureBehavior: %v", v)
	}
}

// OutputDlS3DiskSpaceProtection - Whether to block or drop events when disk space is below the global 'Min free disk space' limit
type OutputDlS3DiskSpaceProtection string

const (
	OutputDlS3DiskSpaceProtectionBlock OutputDlS3DiskSpaceProtection = "block"
	OutputDlS3DiskSpaceProtectionDrop  OutputDlS3DiskSpaceProtection = "drop"
)

func (e OutputDlS3DiskSpaceProtection) ToPointer() *OutputDlS3DiskSpaceProtection {
	return &e
}
func (e *OutputDlS3DiskSpaceProtection) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputDlS3DiskSpaceProtection(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputDlS3DiskSpaceProtection: %v", v)
	}
}

// OutputDlS3Compress - Choose data compression format to apply before moving files to final destination
type OutputDlS3Compress string

const (
	OutputDlS3CompressNone OutputDlS3Compress = "none"
	OutputDlS3CompressGzip OutputDlS3Compress = "gzip"
)

func (e OutputDlS3Compress) ToPointer() *OutputDlS3Compress {
	return &e
}
func (e *OutputDlS3Compress) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = OutputDlS3Compress(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputDlS3Compress: %v", v)
	}
}

// OutputDlS3CompressionLevel - Compression level to apply before moving files to final destination
type OutputDlS3CompressionLevel string

const (
	OutputDlS3CompressionLevelBestSpeed       OutputDlS3CompressionLevel = "best_speed"
	OutputDlS3CompressionLevelNormal          OutputDlS3CompressionLevel = "normal"
	OutputDlS3CompressionLevelBestCompression OutputDlS3CompressionLevel = "best_compression"
)

func (e OutputDlS3CompressionLevel) ToPointer() *OutputDlS3CompressionLevel {
	return &e
}
func (e *OutputDlS3CompressionLevel) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "best_speed":
		fallthrough
	case "normal":
		fallthrough
	case "best_compression":
		*e = OutputDlS3CompressionLevel(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputDlS3CompressionLevel: %v", v)
	}
}

// OutputDlS3ParquetVersion - Determines which data types are supported and how they are represented
type OutputDlS3ParquetVersion string

const (
	OutputDlS3ParquetVersionParquet10 OutputDlS3ParquetVersion = "PARQUET_1_0"
	OutputDlS3ParquetVersionParquet24 OutputDlS3ParquetVersion = "PARQUET_2_4"
	OutputDlS3ParquetVersionParquet26 OutputDlS3ParquetVersion = "PARQUET_2_6"
)

func (e OutputDlS3ParquetVersion) ToPointer() *OutputDlS3ParquetVersion {
	return &e
}
func (e *OutputDlS3ParquetVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "PARQUET_1_0":
		fallthrough
	case "PARQUET_2_4":
		fallthrough
	case "PARQUET_2_6":
		*e = OutputDlS3ParquetVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputDlS3ParquetVersion: %v", v)
	}
}

// OutputDlS3DataPageVersion - Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
type OutputDlS3DataPageVersion string

const (
	OutputDlS3DataPageVersionDataPageV1 OutputDlS3DataPageVersion = "DATA_PAGE_V1"
	OutputDlS3DataPageVersionDataPageV2 OutputDlS3DataPageVersion = "DATA_PAGE_V2"
)

func (e OutputDlS3DataPageVersion) ToPointer() *OutputDlS3DataPageVersion {
	return &e
}
func (e *OutputDlS3DataPageVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "DATA_PAGE_V1":
		fallthrough
	case "DATA_PAGE_V2":
		*e = OutputDlS3DataPageVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputDlS3DataPageVersion: %v", v)
	}
}

type OutputDlS3KeyValueMetadata struct {
	Key   *string `default:"" json:"key"`
	Value string  `json:"value"`
}

func (o OutputDlS3KeyValueMetadata) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputDlS3KeyValueMetadata) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputDlS3KeyValueMetadata) GetKey() *string {
	if o == nil {
		return nil
	}
	return o.Key
}

func (o *OutputDlS3KeyValueMetadata) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type OutputDlS3 struct {
	// Unique ID for this output
	ID   *string         `json:"id,omitempty"`
	Type *OutputDlS3Type `json:"type,omitempty"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Name of the destination S3 bucket. Must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at init time. E.g., referencing a Global Variable: `myBucket-${C.vars.myVar}`.
	Bucket string `json:"bucket"`
	// Region where the S3 bucket is located.
	Region *string `json:"region,omitempty"`
	// Secret key. This value can be a constant or a JavaScript expression(e.g., `${C.env.SOME_SECRET}`).
	AwsSecretKey *string `json:"awsSecretKey,omitempty"`
	// AWS authentication method. Choose Auto to use IAM roles.
	AwsAuthenticationMethod *OutputDlS3AuthenticationMethod `default:"auto" json:"awsAuthenticationMethod"`
	// S3 service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to S3-compatible endpoint.
	Endpoint *string `json:"endpoint,omitempty"`
	// Signature version to use for signing S3 requests
	SignatureVersion *OutputDlS3SignatureVersion `default:"v4" json:"signatureVersion"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `default:"true" json:"reuseConnections"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Use Assume Role credentials to access S3
	EnableAssumeRole *bool `default:"false" json:"enableAssumeRole"`
	// Amazon Resource Name (ARN) of the role to assume
	AssumeRoleArn *string `json:"assumeRoleArn,omitempty"`
	// External ID to use when assuming role
	AssumeRoleExternalID *string `json:"assumeRoleExternalId,omitempty"`
	// Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
	DurationSeconds *float64 `default:"3600" json:"durationSeconds"`
	// Filesystem location in which to buffer files, before compressing and moving to final destination. Use performant stable storage.
	StagePath *string `default:"\\$CRIBL_HOME/state/outputs/staging" json:"stagePath"`
	// Append output's ID to staging location
	AddIDToStagePath *bool `default:"true" json:"addIdToStagePath"`
	// Prefix to append to files before uploading. Must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at init time. E.g., referencing a Global Variable: `myKeyPrefix-${C.vars.myVar}`.
	DestPath *string `default:"" json:"destPath"`
	// Object ACL to assign to uploaded objects.
	ObjectACL *OutputDlS3ObjectACL `default:"private" json:"objectACL"`
	// Storage class to select for uploaded objects.
	StorageClass *OutputDlS3StorageClass `json:"storageClass,omitempty"`
	// Server-side encryption for uploaded objects.
	ServerSideEncryption *OutputDlS3ServerSideEncryption `json:"serverSideEncryption,omitempty"`
	// ID or ARN of the KMS customer-managed key to use for encryption
	KmsKeyID *string `json:"kmsKeyId,omitempty"`
	// Remove empty staging directories after moving files
	RemoveEmptyDirs *bool `default:"true" json:"removeEmptyDirs"`
	// Format of the output data
	Format *OutputDlS3DataFormat `default:"json" json:"format"`
	// JavaScript expression to define the output filename prefix (can be constant)
	BaseFileName *string `default:"CriblOut" json:"baseFileName"`
	// JavaScript expression to define the output filename suffix (can be constant).  The `__format` variable refers to the value of the `Data format` field (`json` or `raw`).  The `__compression` field refers to the kind of compression being used (`none` or `gzip`).
	FileNameSuffix *string `default:".\\${C.env[\"CRIBL_WORKER_ID\"]}.\\${__format}\\${__compression === \"gzip\" ? \".gz\" : \"\"}" json:"fileNameSuffix"`
	// Maximum uncompressed output file size. Files of this size will be closed and moved to final output location.
	MaxFileSizeMB *float64 `default:"32" json:"maxFileSizeMB"`
	// Maximum number of files to keep open concurrently. When exceeded, @{product} will close the oldest open files and move them to the final output location.
	MaxOpenFiles *float64 `default:"100" json:"maxOpenFiles"`
	// If set, this line will be written to the beginning of each output file
	HeaderLine *string `default:"" json:"headerLine"`
	// Buffer size used to write to a file
	WriteHighWaterMark *float64 `default:"64" json:"writeHighWaterMark"`
	// Whether to block or drop events when all receivers are exerting backpressure
	OnBackpressure *OutputDlS3BackpressureBehavior `default:"block" json:"onBackpressure"`
	// If a file fails to move to its final destination after the maximum number of retries, dead-letter it to prevent further errors.
	DeadletterEnabled *bool `default:"false" json:"deadletterEnabled"`
	// Whether to block or drop events when disk space is below the global 'Min free disk space' limit
	OnDiskFullBackpressure *OutputDlS3DiskSpaceProtection `default:"block" json:"onDiskFullBackpressure"`
	// Maximum amount of time to write to a file. Files open for longer than this will be closed and moved to final output location.
	MaxFileOpenTimeSec *float64 `default:"300" json:"maxFileOpenTimeSec"`
	// Maximum amount of time to keep inactive files open. Files open for longer than this will be closed and moved to final output location.
	MaxFileIdleTimeSec *float64 `default:"30" json:"maxFileIdleTimeSec"`
	// Maximum number of parts to upload in parallel per file. Minimum part size is 5MB.
	MaxConcurrentFileParts *float64 `default:"4" json:"maxConcurrentFileParts"`
	// Disable if you can access files within the bucket but not the bucket itself.
	VerifyPermissions *bool `default:"true" json:"verifyPermissions"`
	// Maximum number of files that can be waiting for upload before backpressure is applied
	MaxClosingFilesToBackpressure *float64 `default:"100" json:"maxClosingFilesToBackpressure"`
	// List of fields to partition the path by, in addition to time, which is included automatically. The effective partition will be YYYY/MM/DD/HH/<list/of/fields>.
	PartitioningFields []string `json:"partitioningFields,omitempty"`
	Description        *string  `json:"description,omitempty"`
	// This value can be a constant or a JavaScript expression (`${C.env.SOME_ACCESS_KEY}`)
	AwsAPIKey *string `json:"awsApiKey,omitempty"`
	// Select or create a stored secret that references your access key and secret key
	AwsSecret *string `json:"awsSecret,omitempty"`
	// Choose data compression format to apply before moving files to final destination
	Compress *OutputDlS3Compress `default:"gzip" json:"compress"`
	// Compression level to apply before moving files to final destination
	CompressionLevel *OutputDlS3CompressionLevel `default:"best_speed" json:"compressionLevel"`
	// Automatically calculate the schema based on the events of each Parquet file generated
	AutomaticSchema *bool `default:"false" json:"automaticSchema"`
	// Determines which data types are supported and how they are represented
	ParquetVersion *OutputDlS3ParquetVersion `default:"PARQUET_2_6" json:"parquetVersion"`
	// Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
	ParquetDataPageVersion *OutputDlS3DataPageVersion `default:"DATA_PAGE_V2" json:"parquetDataPageVersion"`
	// The number of rows that every group will contain. The final group can contain a smaller number of rows.
	ParquetRowGroupLength *float64 `default:"10000" json:"parquetRowGroupLength"`
	// Target memory size for page segments, such as 1MB or 128MB. Generally, lower values improve reading speed, while higher values improve compression.
	ParquetPageSize *string `default:"1MB" json:"parquetPageSize"`
	// Log up to 3 rows that @{product} skips due to data mismatch
	ShouldLogInvalidRows *bool `json:"shouldLogInvalidRows,omitempty"`
	// The metadata of files the Destination writes will include the properties you add here as key-value pairs. Useful for tagging, e.g., "key":"OCSF Event Class", "value":"9001".
	KeyValueMetadata []OutputDlS3KeyValueMetadata `json:"keyValueMetadata,omitempty"`
	// Statistics profile an entire file in terms of minimum/maximum values within data, numbers of nulls, etc. You can use Parquet tools to view statistics.
	EnableStatistics *bool `default:"true" json:"enableStatistics"`
	// One page index contains statistics for one data page. Parquet readers use statistics to enable page skipping.
	EnableWritePageIndex *bool `default:"true" json:"enableWritePageIndex"`
	// Parquet tools can use the checksum of a Parquet page to verify data integrity
	EnablePageChecksum *bool `default:"false" json:"enablePageChecksum"`
	// How frequently, in seconds, to clean up empty directories when 'Remove empty staging dirs' is enabled
	EmptyDirCleanupSec *float64 `default:"300" json:"emptyDirCleanupSec"`
	// Storage location for files that fail to reach their final destination after maximum retries are exceeded
	DeadletterPath *string `default:"\\$CRIBL_HOME/state/outputs/dead-letter" json:"deadletterPath"`
	// The maximum number of times a file will attempt to move to its final destination before being dead-lettered
	MaxRetryNum *float64  `default:"20" json:"maxRetryNum"`
	Status      *TFStatus `json:"status,omitempty"`
}

func (o OutputDlS3) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputDlS3) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *OutputDlS3) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *OutputDlS3) GetType() *OutputDlS3Type {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *OutputDlS3) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputDlS3) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputDlS3) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputDlS3) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputDlS3) GetBucket() string {
	if o == nil {
		return ""
	}
	return o.Bucket
}

func (o *OutputDlS3) GetRegion() *string {
	if o == nil {
		return nil
	}
	return o.Region
}

func (o *OutputDlS3) GetAwsSecretKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecretKey
}

func (o *OutputDlS3) GetAwsAuthenticationMethod() *OutputDlS3AuthenticationMethod {
	if o == nil {
		return nil
	}
	return o.AwsAuthenticationMethod
}

func (o *OutputDlS3) GetEndpoint() *string {
	if o == nil {
		return nil
	}
	return o.Endpoint
}

func (o *OutputDlS3) GetSignatureVersion() *OutputDlS3SignatureVersion {
	if o == nil {
		return nil
	}
	return o.SignatureVersion
}

func (o *OutputDlS3) GetReuseConnections() *bool {
	if o == nil {
		return nil
	}
	return o.ReuseConnections
}

func (o *OutputDlS3) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputDlS3) GetEnableAssumeRole() *bool {
	if o == nil {
		return nil
	}
	return o.EnableAssumeRole
}

func (o *OutputDlS3) GetAssumeRoleArn() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleArn
}

func (o *OutputDlS3) GetAssumeRoleExternalID() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleExternalID
}

func (o *OutputDlS3) GetDurationSeconds() *float64 {
	if o == nil {
		return nil
	}
	return o.DurationSeconds
}

func (o *OutputDlS3) GetStagePath() *string {
	if o == nil {
		return nil
	}
	return o.StagePath
}

func (o *OutputDlS3) GetAddIDToStagePath() *bool {
	if o == nil {
		return nil
	}
	return o.AddIDToStagePath
}

func (o *OutputDlS3) GetDestPath() *string {
	if o == nil {
		return nil
	}
	return o.DestPath
}

func (o *OutputDlS3) GetObjectACL() *OutputDlS3ObjectACL {
	if o == nil {
		return nil
	}
	return o.ObjectACL
}

func (o *OutputDlS3) GetStorageClass() *OutputDlS3StorageClass {
	if o == nil {
		return nil
	}
	return o.StorageClass
}

func (o *OutputDlS3) GetServerSideEncryption() *OutputDlS3ServerSideEncryption {
	if o == nil {
		return nil
	}
	return o.ServerSideEncryption
}

func (o *OutputDlS3) GetKmsKeyID() *string {
	if o == nil {
		return nil
	}
	return o.KmsKeyID
}

func (o *OutputDlS3) GetRemoveEmptyDirs() *bool {
	if o == nil {
		return nil
	}
	return o.RemoveEmptyDirs
}

func (o *OutputDlS3) GetFormat() *OutputDlS3DataFormat {
	if o == nil {
		return nil
	}
	return o.Format
}

func (o *OutputDlS3) GetBaseFileName() *string {
	if o == nil {
		return nil
	}
	return o.BaseFileName
}

func (o *OutputDlS3) GetFileNameSuffix() *string {
	if o == nil {
		return nil
	}
	return o.FileNameSuffix
}

func (o *OutputDlS3) GetMaxFileSizeMB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxFileSizeMB
}

func (o *OutputDlS3) GetMaxOpenFiles() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxOpenFiles
}

func (o *OutputDlS3) GetHeaderLine() *string {
	if o == nil {
		return nil
	}
	return o.HeaderLine
}

func (o *OutputDlS3) GetWriteHighWaterMark() *float64 {
	if o == nil {
		return nil
	}
	return o.WriteHighWaterMark
}

func (o *OutputDlS3) GetOnBackpressure() *OutputDlS3BackpressureBehavior {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputDlS3) GetDeadletterEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.DeadletterEnabled
}

func (o *OutputDlS3) GetOnDiskFullBackpressure() *OutputDlS3DiskSpaceProtection {
	if o == nil {
		return nil
	}
	return o.OnDiskFullBackpressure
}

func (o *OutputDlS3) GetMaxFileOpenTimeSec() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxFileOpenTimeSec
}

func (o *OutputDlS3) GetMaxFileIdleTimeSec() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxFileIdleTimeSec
}

func (o *OutputDlS3) GetMaxConcurrentFileParts() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxConcurrentFileParts
}

func (o *OutputDlS3) GetVerifyPermissions() *bool {
	if o == nil {
		return nil
	}
	return o.VerifyPermissions
}

func (o *OutputDlS3) GetMaxClosingFilesToBackpressure() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxClosingFilesToBackpressure
}

func (o *OutputDlS3) GetPartitioningFields() []string {
	if o == nil {
		return nil
	}
	return o.PartitioningFields
}

func (o *OutputDlS3) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputDlS3) GetAwsAPIKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsAPIKey
}

func (o *OutputDlS3) GetAwsSecret() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecret
}

func (o *OutputDlS3) GetCompress() *OutputDlS3Compress {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *OutputDlS3) GetCompressionLevel() *OutputDlS3CompressionLevel {
	if o == nil {
		return nil
	}
	return o.CompressionLevel
}

func (o *OutputDlS3) GetAutomaticSchema() *bool {
	if o == nil {
		return nil
	}
	return o.AutomaticSchema
}

func (o *OutputDlS3) GetParquetVersion() *OutputDlS3ParquetVersion {
	if o == nil {
		return nil
	}
	return o.ParquetVersion
}

func (o *OutputDlS3) GetParquetDataPageVersion() *OutputDlS3DataPageVersion {
	if o == nil {
		return nil
	}
	return o.ParquetDataPageVersion
}

func (o *OutputDlS3) GetParquetRowGroupLength() *float64 {
	if o == nil {
		return nil
	}
	return o.ParquetRowGroupLength
}

func (o *OutputDlS3) GetParquetPageSize() *string {
	if o == nil {
		return nil
	}
	return o.ParquetPageSize
}

func (o *OutputDlS3) GetShouldLogInvalidRows() *bool {
	if o == nil {
		return nil
	}
	return o.ShouldLogInvalidRows
}

func (o *OutputDlS3) GetKeyValueMetadata() []OutputDlS3KeyValueMetadata {
	if o == nil {
		return nil
	}
	return o.KeyValueMetadata
}

func (o *OutputDlS3) GetEnableStatistics() *bool {
	if o == nil {
		return nil
	}
	return o.EnableStatistics
}

func (o *OutputDlS3) GetEnableWritePageIndex() *bool {
	if o == nil {
		return nil
	}
	return o.EnableWritePageIndex
}

func (o *OutputDlS3) GetEnablePageChecksum() *bool {
	if o == nil {
		return nil
	}
	return o.EnablePageChecksum
}

func (o *OutputDlS3) GetEmptyDirCleanupSec() *float64 {
	if o == nil {
		return nil
	}
	return o.EmptyDirCleanupSec
}

func (o *OutputDlS3) GetDeadletterPath() *string {
	if o == nil {
		return nil
	}
	return o.DeadletterPath
}

func (o *OutputDlS3) GetMaxRetryNum() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxRetryNum
}

func (o *OutputDlS3) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type OutputCrowdstrikeNextGenSiemType string

const (
	OutputCrowdstrikeNextGenSiemTypeCrowdstrikeNextGenSiem OutputCrowdstrikeNextGenSiemType = "crowdstrike_next_gen_siem"
)

func (e OutputCrowdstrikeNextGenSiemType) ToPointer() *OutputCrowdstrikeNextGenSiemType {
	return &e
}
func (e *OutputCrowdstrikeNextGenSiemType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "crowdstrike_next_gen_siem":
		*e = OutputCrowdstrikeNextGenSiemType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputCrowdstrikeNextGenSiemType: %v", v)
	}
}

type OutputCrowdstrikeNextGenSiemExtraHTTPHeaders struct {
	// Field name
	Name *string `json:"name,omitempty"`
	// Field value
	Value string `json:"value"`
}

func (o *OutputCrowdstrikeNextGenSiemExtraHTTPHeaders) GetName() *string {
	if o == nil {
		return nil
	}
	return o.Name
}

func (o *OutputCrowdstrikeNextGenSiemExtraHTTPHeaders) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// OutputCrowdstrikeNextGenSiemFailedRequestLoggingMode - Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
type OutputCrowdstrikeNextGenSiemFailedRequestLoggingMode string

const (
	OutputCrowdstrikeNextGenSiemFailedRequestLoggingModePayload           OutputCrowdstrikeNextGenSiemFailedRequestLoggingMode = "payload"
	OutputCrowdstrikeNextGenSiemFailedRequestLoggingModePayloadAndHeaders OutputCrowdstrikeNextGenSiemFailedRequestLoggingMode = "payloadAndHeaders"
	OutputCrowdstrikeNextGenSiemFailedRequestLoggingModeNone              OutputCrowdstrikeNextGenSiemFailedRequestLoggingMode = "none"
)

func (e OutputCrowdstrikeNextGenSiemFailedRequestLoggingMode) ToPointer() *OutputCrowdstrikeNextGenSiemFailedRequestLoggingMode {
	return &e
}
func (e *OutputCrowdstrikeNextGenSiemFailedRequestLoggingMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "payload":
		fallthrough
	case "payloadAndHeaders":
		fallthrough
	case "none":
		*e = OutputCrowdstrikeNextGenSiemFailedRequestLoggingMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputCrowdstrikeNextGenSiemFailedRequestLoggingMode: %v", v)
	}
}

// OutputCrowdstrikeNextGenSiemRequestFormat - When set to JSON, the event is automatically formatted with required fields before sending. When set to Raw, only the event's `_raw` value is sent.
type OutputCrowdstrikeNextGenSiemRequestFormat string

const (
	OutputCrowdstrikeNextGenSiemRequestFormatJSON OutputCrowdstrikeNextGenSiemRequestFormat = "JSON"
	OutputCrowdstrikeNextGenSiemRequestFormatRaw  OutputCrowdstrikeNextGenSiemRequestFormat = "raw"
)

func (e OutputCrowdstrikeNextGenSiemRequestFormat) ToPointer() *OutputCrowdstrikeNextGenSiemRequestFormat {
	return &e
}
func (e *OutputCrowdstrikeNextGenSiemRequestFormat) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "JSON":
		fallthrough
	case "raw":
		*e = OutputCrowdstrikeNextGenSiemRequestFormat(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputCrowdstrikeNextGenSiemRequestFormat: %v", v)
	}
}

// OutputCrowdstrikeNextGenSiemAuthenticationMethod - Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
type OutputCrowdstrikeNextGenSiemAuthenticationMethod string

const (
	OutputCrowdstrikeNextGenSiemAuthenticationMethodManual OutputCrowdstrikeNextGenSiemAuthenticationMethod = "manual"
	OutputCrowdstrikeNextGenSiemAuthenticationMethodSecret OutputCrowdstrikeNextGenSiemAuthenticationMethod = "secret"
)

func (e OutputCrowdstrikeNextGenSiemAuthenticationMethod) ToPointer() *OutputCrowdstrikeNextGenSiemAuthenticationMethod {
	return &e
}
func (e *OutputCrowdstrikeNextGenSiemAuthenticationMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "manual":
		fallthrough
	case "secret":
		*e = OutputCrowdstrikeNextGenSiemAuthenticationMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputCrowdstrikeNextGenSiemAuthenticationMethod: %v", v)
	}
}

type OutputCrowdstrikeNextGenSiemResponseRetrySettings struct {
	// The HTTP response status code that will trigger retries
	HTTPStatus float64 `json:"httpStatus"`
	// How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"1000" json:"initialBackoff"`
	// Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackoff *float64 `default:"10000" json:"maxBackoff"`
}

func (o OutputCrowdstrikeNextGenSiemResponseRetrySettings) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputCrowdstrikeNextGenSiemResponseRetrySettings) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputCrowdstrikeNextGenSiemResponseRetrySettings) GetHTTPStatus() float64 {
	if o == nil {
		return 0.0
	}
	return o.HTTPStatus
}

func (o *OutputCrowdstrikeNextGenSiemResponseRetrySettings) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *OutputCrowdstrikeNextGenSiemResponseRetrySettings) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *OutputCrowdstrikeNextGenSiemResponseRetrySettings) GetMaxBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackoff
}

type OutputCrowdstrikeNextGenSiemTimeoutRetrySettings struct {
	// Enable to retry on request timeout
	TimeoutRetry *bool `default:"false" json:"timeoutRetry"`
	// How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"1000" json:"initialBackoff"`
	// Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackoff *float64 `default:"10000" json:"maxBackoff"`
}

func (o OutputCrowdstrikeNextGenSiemTimeoutRetrySettings) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputCrowdstrikeNextGenSiemTimeoutRetrySettings) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputCrowdstrikeNextGenSiemTimeoutRetrySettings) GetTimeoutRetry() *bool {
	if o == nil {
		return nil
	}
	return o.TimeoutRetry
}

func (o *OutputCrowdstrikeNextGenSiemTimeoutRetrySettings) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *OutputCrowdstrikeNextGenSiemTimeoutRetrySettings) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *OutputCrowdstrikeNextGenSiemTimeoutRetrySettings) GetMaxBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackoff
}

// OutputCrowdstrikeNextGenSiemBackpressureBehavior - Whether to block, drop, or queue events when all receivers are exerting backpressure.
type OutputCrowdstrikeNextGenSiemBackpressureBehavior string

const (
	OutputCrowdstrikeNextGenSiemBackpressureBehaviorBlock OutputCrowdstrikeNextGenSiemBackpressureBehavior = "block"
	OutputCrowdstrikeNextGenSiemBackpressureBehaviorDrop  OutputCrowdstrikeNextGenSiemBackpressureBehavior = "drop"
	OutputCrowdstrikeNextGenSiemBackpressureBehaviorQueue OutputCrowdstrikeNextGenSiemBackpressureBehavior = "queue"
)

func (e OutputCrowdstrikeNextGenSiemBackpressureBehavior) ToPointer() *OutputCrowdstrikeNextGenSiemBackpressureBehavior {
	return &e
}
func (e *OutputCrowdstrikeNextGenSiemBackpressureBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		fallthrough
	case "queue":
		*e = OutputCrowdstrikeNextGenSiemBackpressureBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputCrowdstrikeNextGenSiemBackpressureBehavior: %v", v)
	}
}

// OutputCrowdstrikeNextGenSiemCompression - Codec to use to compress the persisted data.
type OutputCrowdstrikeNextGenSiemCompression string

const (
	OutputCrowdstrikeNextGenSiemCompressionNone OutputCrowdstrikeNextGenSiemCompression = "none"
	OutputCrowdstrikeNextGenSiemCompressionGzip OutputCrowdstrikeNextGenSiemCompression = "gzip"
)

func (e OutputCrowdstrikeNextGenSiemCompression) ToPointer() *OutputCrowdstrikeNextGenSiemCompression {
	return &e
}
func (e *OutputCrowdstrikeNextGenSiemCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = OutputCrowdstrikeNextGenSiemCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputCrowdstrikeNextGenSiemCompression: %v", v)
	}
}

// OutputCrowdstrikeNextGenSiemQueueFullBehavior - Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
type OutputCrowdstrikeNextGenSiemQueueFullBehavior string

const (
	OutputCrowdstrikeNextGenSiemQueueFullBehaviorBlock OutputCrowdstrikeNextGenSiemQueueFullBehavior = "block"
	OutputCrowdstrikeNextGenSiemQueueFullBehaviorDrop  OutputCrowdstrikeNextGenSiemQueueFullBehavior = "drop"
)

func (e OutputCrowdstrikeNextGenSiemQueueFullBehavior) ToPointer() *OutputCrowdstrikeNextGenSiemQueueFullBehavior {
	return &e
}
func (e *OutputCrowdstrikeNextGenSiemQueueFullBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputCrowdstrikeNextGenSiemQueueFullBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputCrowdstrikeNextGenSiemQueueFullBehavior: %v", v)
	}
}

// OutputCrowdstrikeNextGenSiemMode - In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
type OutputCrowdstrikeNextGenSiemMode string

const (
	OutputCrowdstrikeNextGenSiemModeError        OutputCrowdstrikeNextGenSiemMode = "error"
	OutputCrowdstrikeNextGenSiemModeBackpressure OutputCrowdstrikeNextGenSiemMode = "backpressure"
	OutputCrowdstrikeNextGenSiemModeAlways       OutputCrowdstrikeNextGenSiemMode = "always"
)

func (e OutputCrowdstrikeNextGenSiemMode) ToPointer() *OutputCrowdstrikeNextGenSiemMode {
	return &e
}
func (e *OutputCrowdstrikeNextGenSiemMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "error":
		fallthrough
	case "backpressure":
		fallthrough
	case "always":
		*e = OutputCrowdstrikeNextGenSiemMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputCrowdstrikeNextGenSiemMode: %v", v)
	}
}

type OutputCrowdstrikeNextGenSiemPqControls struct {
}

type OutputCrowdstrikeNextGenSiem struct {
	// Unique ID for this output
	ID   *string                           `json:"id,omitempty"`
	Type *OutputCrowdstrikeNextGenSiemType `json:"type,omitempty"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// URL provided from a CrowdStrike data connector, e.g. https://<your-api-key>.ingest.<your-region>.crowdstrike.com/services/collector
	URL string `json:"url"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `default:"5" json:"concurrency"`
	// Maximum size, in KB, of the request body
	MaxPayloadSizeKB *float64 `default:"4096" json:"maxPayloadSizeKB"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited).
	MaxPayloadEvents *float64 `default:"0" json:"maxPayloadEvents"`
	// Compress the payload body before sending
	Compress *bool `default:"true" json:"compress"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Defaults to Yes. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `default:"30" json:"timeoutSec"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Max body size.
	FlushPeriodSec *float64 `default:"1" json:"flushPeriodSec"`
	// Headers to add to all events.
	ExtraHTTPHeaders []OutputCrowdstrikeNextGenSiemExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// Enables round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `default:"true" json:"useRoundRobinDns"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *OutputCrowdstrikeNextGenSiemFailedRequestLoggingMode `default:"none" json:"failedRequestLoggingMode"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// When set to JSON, the event is automatically formatted with required fields before sending. When set to Raw, only the event's `_raw` value is sent.
	Format *OutputCrowdstrikeNextGenSiemRequestFormat `default:"raw" json:"format"`
	// Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
	AuthType *OutputCrowdstrikeNextGenSiemAuthenticationMethod `default:"manual" json:"authType"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable).
	ResponseRetrySettings []OutputCrowdstrikeNextGenSiemResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *OutputCrowdstrikeNextGenSiemTimeoutRetrySettings   `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `default:"false" json:"responseHonorRetryAfterHeader"`
	// Whether to block, drop, or queue events when all receivers are exerting backpressure.
	OnBackpressure *OutputCrowdstrikeNextGenSiemBackpressureBehavior `default:"block" json:"onBackpressure"`
	Description    *string                                           `json:"description,omitempty"`
	// CrowdStrike Next-Gen SIEM authentication token
	Token *string `json:"token,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.).
	PqMaxFileSize *string `default:"1 MB" json:"pqMaxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `default:"5GB" json:"pqMaxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `default:"\\$CRIBL_HOME/state/queues" json:"pqPath"`
	// Codec to use to compress the persisted data.
	PqCompress *OutputCrowdstrikeNextGenSiemCompression `default:"none" json:"pqCompress"`
	// Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *OutputCrowdstrikeNextGenSiemQueueFullBehavior `default:"block" json:"pqOnBackpressure"`
	// In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
	PqMode     *OutputCrowdstrikeNextGenSiemMode       `default:"error" json:"pqMode"`
	PqControls *OutputCrowdstrikeNextGenSiemPqControls `json:"pqControls,omitempty"`
	Status     *TFStatus                               `json:"status,omitempty"`
}

func (o OutputCrowdstrikeNextGenSiem) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputCrowdstrikeNextGenSiem) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *OutputCrowdstrikeNextGenSiem) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *OutputCrowdstrikeNextGenSiem) GetType() *OutputCrowdstrikeNextGenSiemType {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *OutputCrowdstrikeNextGenSiem) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputCrowdstrikeNextGenSiem) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputCrowdstrikeNextGenSiem) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputCrowdstrikeNextGenSiem) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputCrowdstrikeNextGenSiem) GetURL() string {
	if o == nil {
		return ""
	}
	return o.URL
}

func (o *OutputCrowdstrikeNextGenSiem) GetConcurrency() *float64 {
	if o == nil {
		return nil
	}
	return o.Concurrency
}

func (o *OutputCrowdstrikeNextGenSiem) GetMaxPayloadSizeKB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadSizeKB
}

func (o *OutputCrowdstrikeNextGenSiem) GetMaxPayloadEvents() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadEvents
}

func (o *OutputCrowdstrikeNextGenSiem) GetCompress() *bool {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *OutputCrowdstrikeNextGenSiem) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputCrowdstrikeNextGenSiem) GetTimeoutSec() *float64 {
	if o == nil {
		return nil
	}
	return o.TimeoutSec
}

func (o *OutputCrowdstrikeNextGenSiem) GetFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushPeriodSec
}

func (o *OutputCrowdstrikeNextGenSiem) GetExtraHTTPHeaders() []OutputCrowdstrikeNextGenSiemExtraHTTPHeaders {
	if o == nil {
		return nil
	}
	return o.ExtraHTTPHeaders
}

func (o *OutputCrowdstrikeNextGenSiem) GetUseRoundRobinDNS() *bool {
	if o == nil {
		return nil
	}
	return o.UseRoundRobinDNS
}

func (o *OutputCrowdstrikeNextGenSiem) GetFailedRequestLoggingMode() *OutputCrowdstrikeNextGenSiemFailedRequestLoggingMode {
	if o == nil {
		return nil
	}
	return o.FailedRequestLoggingMode
}

func (o *OutputCrowdstrikeNextGenSiem) GetSafeHeaders() []string {
	if o == nil {
		return nil
	}
	return o.SafeHeaders
}

func (o *OutputCrowdstrikeNextGenSiem) GetFormat() *OutputCrowdstrikeNextGenSiemRequestFormat {
	if o == nil {
		return nil
	}
	return o.Format
}

func (o *OutputCrowdstrikeNextGenSiem) GetAuthType() *OutputCrowdstrikeNextGenSiemAuthenticationMethod {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *OutputCrowdstrikeNextGenSiem) GetResponseRetrySettings() []OutputCrowdstrikeNextGenSiemResponseRetrySettings {
	if o == nil {
		return nil
	}
	return o.ResponseRetrySettings
}

func (o *OutputCrowdstrikeNextGenSiem) GetTimeoutRetrySettings() *OutputCrowdstrikeNextGenSiemTimeoutRetrySettings {
	if o == nil {
		return nil
	}
	return o.TimeoutRetrySettings
}

func (o *OutputCrowdstrikeNextGenSiem) GetResponseHonorRetryAfterHeader() *bool {
	if o == nil {
		return nil
	}
	return o.ResponseHonorRetryAfterHeader
}

func (o *OutputCrowdstrikeNextGenSiem) GetOnBackpressure() *OutputCrowdstrikeNextGenSiemBackpressureBehavior {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputCrowdstrikeNextGenSiem) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputCrowdstrikeNextGenSiem) GetToken() *string {
	if o == nil {
		return nil
	}
	return o.Token
}

func (o *OutputCrowdstrikeNextGenSiem) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *OutputCrowdstrikeNextGenSiem) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputCrowdstrikeNextGenSiem) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputCrowdstrikeNextGenSiem) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputCrowdstrikeNextGenSiem) GetPqCompress() *OutputCrowdstrikeNextGenSiemCompression {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputCrowdstrikeNextGenSiem) GetPqOnBackpressure() *OutputCrowdstrikeNextGenSiemQueueFullBehavior {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputCrowdstrikeNextGenSiem) GetPqMode() *OutputCrowdstrikeNextGenSiemMode {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputCrowdstrikeNextGenSiem) GetPqControls() *OutputCrowdstrikeNextGenSiemPqControls {
	if o == nil {
		return nil
	}
	return o.PqControls
}

func (o *OutputCrowdstrikeNextGenSiem) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type OutputHumioHecType string

const (
	OutputHumioHecTypeHumioHec OutputHumioHecType = "humio_hec"
)

func (e OutputHumioHecType) ToPointer() *OutputHumioHecType {
	return &e
}
func (e *OutputHumioHecType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "humio_hec":
		*e = OutputHumioHecType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputHumioHecType: %v", v)
	}
}

type OutputHumioHecExtraHTTPHeaders struct {
	// Field name
	Name *string `json:"name,omitempty"`
	// Field value
	Value string `json:"value"`
}

func (o *OutputHumioHecExtraHTTPHeaders) GetName() *string {
	if o == nil {
		return nil
	}
	return o.Name
}

func (o *OutputHumioHecExtraHTTPHeaders) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// OutputHumioHecFailedRequestLoggingMode - Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
type OutputHumioHecFailedRequestLoggingMode string

const (
	OutputHumioHecFailedRequestLoggingModePayload           OutputHumioHecFailedRequestLoggingMode = "payload"
	OutputHumioHecFailedRequestLoggingModePayloadAndHeaders OutputHumioHecFailedRequestLoggingMode = "payloadAndHeaders"
	OutputHumioHecFailedRequestLoggingModeNone              OutputHumioHecFailedRequestLoggingMode = "none"
)

func (e OutputHumioHecFailedRequestLoggingMode) ToPointer() *OutputHumioHecFailedRequestLoggingMode {
	return &e
}
func (e *OutputHumioHecFailedRequestLoggingMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "payload":
		fallthrough
	case "payloadAndHeaders":
		fallthrough
	case "none":
		*e = OutputHumioHecFailedRequestLoggingMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputHumioHecFailedRequestLoggingMode: %v", v)
	}
}

// RequestFormat - When set to JSON, the event is automatically formatted with required fields before sending. When set to Raw, only the event's `_raw` value is sent.
type RequestFormat string

const (
	RequestFormatJSON RequestFormat = "JSON"
	RequestFormatRaw  RequestFormat = "raw"
)

func (e RequestFormat) ToPointer() *RequestFormat {
	return &e
}
func (e *RequestFormat) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "JSON":
		fallthrough
	case "raw":
		*e = RequestFormat(v)
		return nil
	default:
		return fmt.Errorf("invalid value for RequestFormat: %v", v)
	}
}

// OutputHumioHecAuthenticationMethod - Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
type OutputHumioHecAuthenticationMethod string

const (
	OutputHumioHecAuthenticationMethodManual OutputHumioHecAuthenticationMethod = "manual"
	OutputHumioHecAuthenticationMethodSecret OutputHumioHecAuthenticationMethod = "secret"
)

func (e OutputHumioHecAuthenticationMethod) ToPointer() *OutputHumioHecAuthenticationMethod {
	return &e
}
func (e *OutputHumioHecAuthenticationMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "manual":
		fallthrough
	case "secret":
		*e = OutputHumioHecAuthenticationMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputHumioHecAuthenticationMethod: %v", v)
	}
}

type OutputHumioHecResponseRetrySettings struct {
	// The HTTP response status code that will trigger retries
	HTTPStatus float64 `json:"httpStatus"`
	// How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"1000" json:"initialBackoff"`
	// Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackoff *float64 `default:"10000" json:"maxBackoff"`
}

func (o OutputHumioHecResponseRetrySettings) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputHumioHecResponseRetrySettings) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputHumioHecResponseRetrySettings) GetHTTPStatus() float64 {
	if o == nil {
		return 0.0
	}
	return o.HTTPStatus
}

func (o *OutputHumioHecResponseRetrySettings) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *OutputHumioHecResponseRetrySettings) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *OutputHumioHecResponseRetrySettings) GetMaxBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackoff
}

type OutputHumioHecTimeoutRetrySettings struct {
	// Enable to retry on request timeout
	TimeoutRetry *bool `default:"false" json:"timeoutRetry"`
	// How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"1000" json:"initialBackoff"`
	// Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackoff *float64 `default:"10000" json:"maxBackoff"`
}

func (o OutputHumioHecTimeoutRetrySettings) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputHumioHecTimeoutRetrySettings) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputHumioHecTimeoutRetrySettings) GetTimeoutRetry() *bool {
	if o == nil {
		return nil
	}
	return o.TimeoutRetry
}

func (o *OutputHumioHecTimeoutRetrySettings) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *OutputHumioHecTimeoutRetrySettings) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *OutputHumioHecTimeoutRetrySettings) GetMaxBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackoff
}

// OutputHumioHecBackpressureBehavior - Whether to block, drop, or queue events when all receivers are exerting backpressure.
type OutputHumioHecBackpressureBehavior string

const (
	OutputHumioHecBackpressureBehaviorBlock OutputHumioHecBackpressureBehavior = "block"
	OutputHumioHecBackpressureBehaviorDrop  OutputHumioHecBackpressureBehavior = "drop"
	OutputHumioHecBackpressureBehaviorQueue OutputHumioHecBackpressureBehavior = "queue"
)

func (e OutputHumioHecBackpressureBehavior) ToPointer() *OutputHumioHecBackpressureBehavior {
	return &e
}
func (e *OutputHumioHecBackpressureBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		fallthrough
	case "queue":
		*e = OutputHumioHecBackpressureBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputHumioHecBackpressureBehavior: %v", v)
	}
}

// OutputHumioHecCompression - Codec to use to compress the persisted data.
type OutputHumioHecCompression string

const (
	OutputHumioHecCompressionNone OutputHumioHecCompression = "none"
	OutputHumioHecCompressionGzip OutputHumioHecCompression = "gzip"
)

func (e OutputHumioHecCompression) ToPointer() *OutputHumioHecCompression {
	return &e
}
func (e *OutputHumioHecCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = OutputHumioHecCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputHumioHecCompression: %v", v)
	}
}

// OutputHumioHecQueueFullBehavior - Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
type OutputHumioHecQueueFullBehavior string

const (
	OutputHumioHecQueueFullBehaviorBlock OutputHumioHecQueueFullBehavior = "block"
	OutputHumioHecQueueFullBehaviorDrop  OutputHumioHecQueueFullBehavior = "drop"
)

func (e OutputHumioHecQueueFullBehavior) ToPointer() *OutputHumioHecQueueFullBehavior {
	return &e
}
func (e *OutputHumioHecQueueFullBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputHumioHecQueueFullBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputHumioHecQueueFullBehavior: %v", v)
	}
}

// OutputHumioHecMode - In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
type OutputHumioHecMode string

const (
	OutputHumioHecModeError        OutputHumioHecMode = "error"
	OutputHumioHecModeBackpressure OutputHumioHecMode = "backpressure"
	OutputHumioHecModeAlways       OutputHumioHecMode = "always"
)

func (e OutputHumioHecMode) ToPointer() *OutputHumioHecMode {
	return &e
}
func (e *OutputHumioHecMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "error":
		fallthrough
	case "backpressure":
		fallthrough
	case "always":
		*e = OutputHumioHecMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputHumioHecMode: %v", v)
	}
}

type OutputHumioHecPqControls struct {
}

type OutputHumioHec struct {
	// Unique ID for this output
	ID   *string             `json:"id,omitempty"`
	Type *OutputHumioHecType `json:"type,omitempty"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// URL to a CrowdStrike Falcon LogScale endpoint to send events to, e.g., https://cloud.us.humio.com/api/v1/ingest/hec for JSON and https://cloud.us.humio.com/api/v1/ingest/hec/raw for raw
	URL *string `default:"https://cloud.us.humio.com/api/v1/ingest/hec" json:"url"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `default:"5" json:"concurrency"`
	// Maximum size, in KB, of the request body
	MaxPayloadSizeKB *float64 `default:"4096" json:"maxPayloadSizeKB"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited).
	MaxPayloadEvents *float64 `default:"0" json:"maxPayloadEvents"`
	// Compress the payload body before sending
	Compress *bool `default:"true" json:"compress"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Defaults to Yes. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `default:"30" json:"timeoutSec"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Max body size.
	FlushPeriodSec *float64 `default:"1" json:"flushPeriodSec"`
	// Headers to add to all events.
	ExtraHTTPHeaders []OutputHumioHecExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// Enables round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `default:"true" json:"useRoundRobinDns"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *OutputHumioHecFailedRequestLoggingMode `default:"none" json:"failedRequestLoggingMode"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// When set to JSON, the event is automatically formatted with required fields before sending. When set to Raw, only the event's `_raw` value is sent.
	Format *RequestFormat `default:"JSON" json:"format"`
	// Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
	AuthType *OutputHumioHecAuthenticationMethod `default:"manual" json:"authType"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable).
	ResponseRetrySettings []OutputHumioHecResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *OutputHumioHecTimeoutRetrySettings   `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `default:"false" json:"responseHonorRetryAfterHeader"`
	// Whether to block, drop, or queue events when all receivers are exerting backpressure.
	OnBackpressure *OutputHumioHecBackpressureBehavior `default:"block" json:"onBackpressure"`
	Description    *string                             `json:"description,omitempty"`
	// CrowdStrike Falcon LogScale authentication token
	Token *string `json:"token,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.).
	PqMaxFileSize *string `default:"1 MB" json:"pqMaxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `default:"5GB" json:"pqMaxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `default:"\\$CRIBL_HOME/state/queues" json:"pqPath"`
	// Codec to use to compress the persisted data.
	PqCompress *OutputHumioHecCompression `default:"none" json:"pqCompress"`
	// Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *OutputHumioHecQueueFullBehavior `default:"block" json:"pqOnBackpressure"`
	// In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
	PqMode     *OutputHumioHecMode       `default:"error" json:"pqMode"`
	PqControls *OutputHumioHecPqControls `json:"pqControls,omitempty"`
	Status     *TFStatus                 `json:"status,omitempty"`
}

func (o OutputHumioHec) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputHumioHec) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *OutputHumioHec) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *OutputHumioHec) GetType() *OutputHumioHecType {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *OutputHumioHec) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputHumioHec) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputHumioHec) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputHumioHec) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputHumioHec) GetURL() *string {
	if o == nil {
		return nil
	}
	return o.URL
}

func (o *OutputHumioHec) GetConcurrency() *float64 {
	if o == nil {
		return nil
	}
	return o.Concurrency
}

func (o *OutputHumioHec) GetMaxPayloadSizeKB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadSizeKB
}

func (o *OutputHumioHec) GetMaxPayloadEvents() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadEvents
}

func (o *OutputHumioHec) GetCompress() *bool {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *OutputHumioHec) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputHumioHec) GetTimeoutSec() *float64 {
	if o == nil {
		return nil
	}
	return o.TimeoutSec
}

func (o *OutputHumioHec) GetFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushPeriodSec
}

func (o *OutputHumioHec) GetExtraHTTPHeaders() []OutputHumioHecExtraHTTPHeaders {
	if o == nil {
		return nil
	}
	return o.ExtraHTTPHeaders
}

func (o *OutputHumioHec) GetUseRoundRobinDNS() *bool {
	if o == nil {
		return nil
	}
	return o.UseRoundRobinDNS
}

func (o *OutputHumioHec) GetFailedRequestLoggingMode() *OutputHumioHecFailedRequestLoggingMode {
	if o == nil {
		return nil
	}
	return o.FailedRequestLoggingMode
}

func (o *OutputHumioHec) GetSafeHeaders() []string {
	if o == nil {
		return nil
	}
	return o.SafeHeaders
}

func (o *OutputHumioHec) GetFormat() *RequestFormat {
	if o == nil {
		return nil
	}
	return o.Format
}

func (o *OutputHumioHec) GetAuthType() *OutputHumioHecAuthenticationMethod {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *OutputHumioHec) GetResponseRetrySettings() []OutputHumioHecResponseRetrySettings {
	if o == nil {
		return nil
	}
	return o.ResponseRetrySettings
}

func (o *OutputHumioHec) GetTimeoutRetrySettings() *OutputHumioHecTimeoutRetrySettings {
	if o == nil {
		return nil
	}
	return o.TimeoutRetrySettings
}

func (o *OutputHumioHec) GetResponseHonorRetryAfterHeader() *bool {
	if o == nil {
		return nil
	}
	return o.ResponseHonorRetryAfterHeader
}

func (o *OutputHumioHec) GetOnBackpressure() *OutputHumioHecBackpressureBehavior {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputHumioHec) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputHumioHec) GetToken() *string {
	if o == nil {
		return nil
	}
	return o.Token
}

func (o *OutputHumioHec) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *OutputHumioHec) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputHumioHec) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputHumioHec) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputHumioHec) GetPqCompress() *OutputHumioHecCompression {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputHumioHec) GetPqOnBackpressure() *OutputHumioHecQueueFullBehavior {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputHumioHec) GetPqMode() *OutputHumioHecMode {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputHumioHec) GetPqControls() *OutputHumioHecPqControls {
	if o == nil {
		return nil
	}
	return o.PqControls
}

func (o *OutputHumioHec) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type OutputCriblHTTPType string

const (
	OutputCriblHTTPTypeCriblHTTP OutputCriblHTTPType = "cribl_http"
)

func (e OutputCriblHTTPType) ToPointer() *OutputCriblHTTPType {
	return &e
}
func (e *OutputCriblHTTPType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "cribl_http":
		*e = OutputCriblHTTPType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputCriblHTTPType: %v", v)
	}
}

// OutputCriblHTTPMinimumTLSVersion - Minimum TLS version to use when connecting
type OutputCriblHTTPMinimumTLSVersion string

const (
	OutputCriblHTTPMinimumTLSVersionTlSv1  OutputCriblHTTPMinimumTLSVersion = "TLSv1"
	OutputCriblHTTPMinimumTLSVersionTlSv11 OutputCriblHTTPMinimumTLSVersion = "TLSv1.1"
	OutputCriblHTTPMinimumTLSVersionTlSv12 OutputCriblHTTPMinimumTLSVersion = "TLSv1.2"
	OutputCriblHTTPMinimumTLSVersionTlSv13 OutputCriblHTTPMinimumTLSVersion = "TLSv1.3"
)

func (e OutputCriblHTTPMinimumTLSVersion) ToPointer() *OutputCriblHTTPMinimumTLSVersion {
	return &e
}
func (e *OutputCriblHTTPMinimumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = OutputCriblHTTPMinimumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputCriblHTTPMinimumTLSVersion: %v", v)
	}
}

// OutputCriblHTTPMaximumTLSVersion - Maximum TLS version to use when connecting
type OutputCriblHTTPMaximumTLSVersion string

const (
	OutputCriblHTTPMaximumTLSVersionTlSv1  OutputCriblHTTPMaximumTLSVersion = "TLSv1"
	OutputCriblHTTPMaximumTLSVersionTlSv11 OutputCriblHTTPMaximumTLSVersion = "TLSv1.1"
	OutputCriblHTTPMaximumTLSVersionTlSv12 OutputCriblHTTPMaximumTLSVersion = "TLSv1.2"
	OutputCriblHTTPMaximumTLSVersionTlSv13 OutputCriblHTTPMaximumTLSVersion = "TLSv1.3"
)

func (e OutputCriblHTTPMaximumTLSVersion) ToPointer() *OutputCriblHTTPMaximumTLSVersion {
	return &e
}
func (e *OutputCriblHTTPMaximumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = OutputCriblHTTPMaximumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputCriblHTTPMaximumTLSVersion: %v", v)
	}
}

type OutputCriblHTTPTLSSettingsClientSide struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Reject certs that are not authorized by a CA in the CA certificate path, or by another
	//                     trusted CA (e.g., the system's CA). Defaults to Yes. Overrides the toggle from Advanced Settings, when also present.
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.
	Servername *string `json:"servername,omitempty"`
	// The name of the predefined certificate.
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Passphrase to use to decrypt private key.
	Passphrase *string `json:"passphrase,omitempty"`
	// Minimum TLS version to use when connecting
	MinVersion *OutputCriblHTTPMinimumTLSVersion `json:"minVersion,omitempty"`
	// Maximum TLS version to use when connecting
	MaxVersion *OutputCriblHTTPMaximumTLSVersion `json:"maxVersion,omitempty"`
}

func (o OutputCriblHTTPTLSSettingsClientSide) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputCriblHTTPTLSSettingsClientSide) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputCriblHTTPTLSSettingsClientSide) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *OutputCriblHTTPTLSSettingsClientSide) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputCriblHTTPTLSSettingsClientSide) GetServername() *string {
	if o == nil {
		return nil
	}
	return o.Servername
}

func (o *OutputCriblHTTPTLSSettingsClientSide) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *OutputCriblHTTPTLSSettingsClientSide) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *OutputCriblHTTPTLSSettingsClientSide) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *OutputCriblHTTPTLSSettingsClientSide) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *OutputCriblHTTPTLSSettingsClientSide) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *OutputCriblHTTPTLSSettingsClientSide) GetMinVersion() *OutputCriblHTTPMinimumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *OutputCriblHTTPTLSSettingsClientSide) GetMaxVersion() *OutputCriblHTTPMaximumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

// OutputCriblHTTPCompression - Codec to use to compress the data before sending.
type OutputCriblHTTPCompression string

const (
	OutputCriblHTTPCompressionNone OutputCriblHTTPCompression = "none"
	OutputCriblHTTPCompressionGzip OutputCriblHTTPCompression = "gzip"
)

func (e OutputCriblHTTPCompression) ToPointer() *OutputCriblHTTPCompression {
	return &e
}
func (e *OutputCriblHTTPCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = OutputCriblHTTPCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputCriblHTTPCompression: %v", v)
	}
}

type OutputCriblHTTPExtraHTTPHeaders struct {
	// Field name
	Name *string `json:"name,omitempty"`
	// Field value
	Value string `json:"value"`
}

func (o *OutputCriblHTTPExtraHTTPHeaders) GetName() *string {
	if o == nil {
		return nil
	}
	return o.Name
}

func (o *OutputCriblHTTPExtraHTTPHeaders) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// OutputCriblHTTPFailedRequestLoggingMode - Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
type OutputCriblHTTPFailedRequestLoggingMode string

const (
	OutputCriblHTTPFailedRequestLoggingModePayload           OutputCriblHTTPFailedRequestLoggingMode = "payload"
	OutputCriblHTTPFailedRequestLoggingModePayloadAndHeaders OutputCriblHTTPFailedRequestLoggingMode = "payloadAndHeaders"
	OutputCriblHTTPFailedRequestLoggingModeNone              OutputCriblHTTPFailedRequestLoggingMode = "none"
)

func (e OutputCriblHTTPFailedRequestLoggingMode) ToPointer() *OutputCriblHTTPFailedRequestLoggingMode {
	return &e
}
func (e *OutputCriblHTTPFailedRequestLoggingMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "payload":
		fallthrough
	case "payloadAndHeaders":
		fallthrough
	case "none":
		*e = OutputCriblHTTPFailedRequestLoggingMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputCriblHTTPFailedRequestLoggingMode: %v", v)
	}
}

type OutputCriblHTTPResponseRetrySettings struct {
	// The HTTP response status code that will trigger retries
	HTTPStatus float64 `json:"httpStatus"`
	// How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"1000" json:"initialBackoff"`
	// Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackoff *float64 `default:"10000" json:"maxBackoff"`
}

func (o OutputCriblHTTPResponseRetrySettings) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputCriblHTTPResponseRetrySettings) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputCriblHTTPResponseRetrySettings) GetHTTPStatus() float64 {
	if o == nil {
		return 0.0
	}
	return o.HTTPStatus
}

func (o *OutputCriblHTTPResponseRetrySettings) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *OutputCriblHTTPResponseRetrySettings) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *OutputCriblHTTPResponseRetrySettings) GetMaxBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackoff
}

type OutputCriblHTTPTimeoutRetrySettings struct {
	// Enable to retry on request timeout
	TimeoutRetry *bool `default:"false" json:"timeoutRetry"`
	// How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"1000" json:"initialBackoff"`
	// Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackoff *float64 `default:"10000" json:"maxBackoff"`
}

func (o OutputCriblHTTPTimeoutRetrySettings) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputCriblHTTPTimeoutRetrySettings) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputCriblHTTPTimeoutRetrySettings) GetTimeoutRetry() *bool {
	if o == nil {
		return nil
	}
	return o.TimeoutRetry
}

func (o *OutputCriblHTTPTimeoutRetrySettings) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *OutputCriblHTTPTimeoutRetrySettings) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *OutputCriblHTTPTimeoutRetrySettings) GetMaxBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackoff
}

// OutputCriblHTTPBackpressureBehavior - Whether to block, drop, or queue events when all receivers are exerting backpressure.
type OutputCriblHTTPBackpressureBehavior string

const (
	OutputCriblHTTPBackpressureBehaviorBlock OutputCriblHTTPBackpressureBehavior = "block"
	OutputCriblHTTPBackpressureBehaviorDrop  OutputCriblHTTPBackpressureBehavior = "drop"
	OutputCriblHTTPBackpressureBehaviorQueue OutputCriblHTTPBackpressureBehavior = "queue"
)

func (e OutputCriblHTTPBackpressureBehavior) ToPointer() *OutputCriblHTTPBackpressureBehavior {
	return &e
}
func (e *OutputCriblHTTPBackpressureBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		fallthrough
	case "queue":
		*e = OutputCriblHTTPBackpressureBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputCriblHTTPBackpressureBehavior: %v", v)
	}
}

type OutputCriblHTTPUrls struct {
	// URL of a Cribl Worker to send events to, e.g., http://localhost:10200
	URL string `json:"url"`
	// Assign a weight (>0) to each endpoint to indicate its traffic-handling capability
	Weight *float64 `default:"1" json:"weight"`
}

func (o OutputCriblHTTPUrls) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputCriblHTTPUrls) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputCriblHTTPUrls) GetURL() string {
	if o == nil {
		return ""
	}
	return o.URL
}

func (o *OutputCriblHTTPUrls) GetWeight() *float64 {
	if o == nil {
		return nil
	}
	return o.Weight
}

// OutputCriblHTTPOutputCompression - Codec to use to compress the persisted data.
type OutputCriblHTTPOutputCompression string

const (
	OutputCriblHTTPOutputCompressionNone OutputCriblHTTPOutputCompression = "none"
	OutputCriblHTTPOutputCompressionGzip OutputCriblHTTPOutputCompression = "gzip"
)

func (e OutputCriblHTTPOutputCompression) ToPointer() *OutputCriblHTTPOutputCompression {
	return &e
}
func (e *OutputCriblHTTPOutputCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = OutputCriblHTTPOutputCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputCriblHTTPOutputCompression: %v", v)
	}
}

// OutputCriblHTTPQueueFullBehavior - Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
type OutputCriblHTTPQueueFullBehavior string

const (
	OutputCriblHTTPQueueFullBehaviorBlock OutputCriblHTTPQueueFullBehavior = "block"
	OutputCriblHTTPQueueFullBehaviorDrop  OutputCriblHTTPQueueFullBehavior = "drop"
)

func (e OutputCriblHTTPQueueFullBehavior) ToPointer() *OutputCriblHTTPQueueFullBehavior {
	return &e
}
func (e *OutputCriblHTTPQueueFullBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputCriblHTTPQueueFullBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputCriblHTTPQueueFullBehavior: %v", v)
	}
}

// OutputCriblHTTPMode - In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
type OutputCriblHTTPMode string

const (
	OutputCriblHTTPModeError        OutputCriblHTTPMode = "error"
	OutputCriblHTTPModeBackpressure OutputCriblHTTPMode = "backpressure"
	OutputCriblHTTPModeAlways       OutputCriblHTTPMode = "always"
)

func (e OutputCriblHTTPMode) ToPointer() *OutputCriblHTTPMode {
	return &e
}
func (e *OutputCriblHTTPMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "error":
		fallthrough
	case "backpressure":
		fallthrough
	case "always":
		*e = OutputCriblHTTPMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputCriblHTTPMode: %v", v)
	}
}

type OutputCriblHTTPPqControls struct {
}

type OutputCriblHTTP struct {
	Status *TFStatus `json:"status,omitempty"`
	// Unique ID for this output
	ID   string              `json:"id"`
	Type OutputCriblHTTPType `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// For optimal performance, enable load balancing even if you have one hostname, as it can expand to multiple IPs. If this setting is disabled, consider enabling round-robin DNS.
	LoadBalanced *bool                                 `default:"true" json:"loadBalanced"`
	TLS          *OutputCriblHTTPTLSSettingsClientSide `json:"tls,omitempty"`
	// The number of minutes before the internally generated authentication token expires, valid values between 1 and 60.
	TokenTTLMinutes *float64 `default:"60" json:"tokenTTLMinutes"`
	// Fields to exclude from the event. By default, all internal fields except `__output` are sent. E.g.: `cribl_pipe`, `c*`. Wildcards supported.
	ExcludeFields []string `json:"excludeFields,omitempty"`
	// Codec to use to compress the data before sending.
	Compression *OutputCriblHTTPCompression `default:"gzip" json:"compression"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `default:"5" json:"concurrency"`
	// Maximum size, in KB, of the request body
	MaxPayloadSizeKB *float64 `default:"4096" json:"maxPayloadSizeKB"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited).
	MaxPayloadEvents *float64 `default:"0" json:"maxPayloadEvents"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Defaults to Yes. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `default:"30" json:"timeoutSec"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Max body size.
	FlushPeriodSec *float64 `default:"1" json:"flushPeriodSec"`
	// Headers to add to all events.
	ExtraHTTPHeaders []OutputCriblHTTPExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *OutputCriblHTTPFailedRequestLoggingMode `default:"none" json:"failedRequestLoggingMode"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable).
	ResponseRetrySettings []OutputCriblHTTPResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *OutputCriblHTTPTimeoutRetrySettings   `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `default:"false" json:"responseHonorRetryAfterHeader"`
	// Whether to block, drop, or queue events when all receivers are exerting backpressure.
	OnBackpressure *OutputCriblHTTPBackpressureBehavior `default:"block" json:"onBackpressure"`
	Description    *string                              `json:"description,omitempty"`
	// URL of a Cribl Worker to send events to, e.g., http://localhost:10200
	URL *string `json:"url,omitempty"`
	// Enables round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `default:"false" json:"useRoundRobinDns"`
	// Exclude all IPs of the current host from the list of any resolved hostnames.
	ExcludeSelf *bool                 `default:"false" json:"excludeSelf"`
	Urls        []OutputCriblHTTPUrls `json:"urls,omitempty"`
	// Re-resolve any hostnames every this many seconds and pick up destinations from A records.
	DNSResolvePeriodSec *float64 `default:"600" json:"dnsResolvePeriodSec"`
	// How far back in time to keep traffic stats for load balancing purposes.
	LoadBalanceStatsPeriodSec *float64 `default:"300" json:"loadBalanceStatsPeriodSec"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.).
	PqMaxFileSize *string `default:"1 MB" json:"pqMaxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `default:"5GB" json:"pqMaxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `default:"\\$CRIBL_HOME/state/queues" json:"pqPath"`
	// Codec to use to compress the persisted data.
	PqCompress *OutputCriblHTTPOutputCompression `default:"none" json:"pqCompress"`
	// Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *OutputCriblHTTPQueueFullBehavior `default:"block" json:"pqOnBackpressure"`
	// In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
	PqMode     *OutputCriblHTTPMode       `default:"error" json:"pqMode"`
	PqControls *OutputCriblHTTPPqControls `json:"pqControls,omitempty"`
}

func (o OutputCriblHTTP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputCriblHTTP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *OutputCriblHTTP) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

func (o *OutputCriblHTTP) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *OutputCriblHTTP) GetType() OutputCriblHTTPType {
	if o == nil {
		return OutputCriblHTTPType("")
	}
	return o.Type
}

func (o *OutputCriblHTTP) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputCriblHTTP) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputCriblHTTP) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputCriblHTTP) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputCriblHTTP) GetLoadBalanced() *bool {
	if o == nil {
		return nil
	}
	return o.LoadBalanced
}

func (o *OutputCriblHTTP) GetTLS() *OutputCriblHTTPTLSSettingsClientSide {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *OutputCriblHTTP) GetTokenTTLMinutes() *float64 {
	if o == nil {
		return nil
	}
	return o.TokenTTLMinutes
}

func (o *OutputCriblHTTP) GetExcludeFields() []string {
	if o == nil {
		return nil
	}
	return o.ExcludeFields
}

func (o *OutputCriblHTTP) GetCompression() *OutputCriblHTTPCompression {
	if o == nil {
		return nil
	}
	return o.Compression
}

func (o *OutputCriblHTTP) GetConcurrency() *float64 {
	if o == nil {
		return nil
	}
	return o.Concurrency
}

func (o *OutputCriblHTTP) GetMaxPayloadSizeKB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadSizeKB
}

func (o *OutputCriblHTTP) GetMaxPayloadEvents() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadEvents
}

func (o *OutputCriblHTTP) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputCriblHTTP) GetTimeoutSec() *float64 {
	if o == nil {
		return nil
	}
	return o.TimeoutSec
}

func (o *OutputCriblHTTP) GetFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushPeriodSec
}

func (o *OutputCriblHTTP) GetExtraHTTPHeaders() []OutputCriblHTTPExtraHTTPHeaders {
	if o == nil {
		return nil
	}
	return o.ExtraHTTPHeaders
}

func (o *OutputCriblHTTP) GetFailedRequestLoggingMode() *OutputCriblHTTPFailedRequestLoggingMode {
	if o == nil {
		return nil
	}
	return o.FailedRequestLoggingMode
}

func (o *OutputCriblHTTP) GetSafeHeaders() []string {
	if o == nil {
		return nil
	}
	return o.SafeHeaders
}

func (o *OutputCriblHTTP) GetResponseRetrySettings() []OutputCriblHTTPResponseRetrySettings {
	if o == nil {
		return nil
	}
	return o.ResponseRetrySettings
}

func (o *OutputCriblHTTP) GetTimeoutRetrySettings() *OutputCriblHTTPTimeoutRetrySettings {
	if o == nil {
		return nil
	}
	return o.TimeoutRetrySettings
}

func (o *OutputCriblHTTP) GetResponseHonorRetryAfterHeader() *bool {
	if o == nil {
		return nil
	}
	return o.ResponseHonorRetryAfterHeader
}

func (o *OutputCriblHTTP) GetOnBackpressure() *OutputCriblHTTPBackpressureBehavior {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputCriblHTTP) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputCriblHTTP) GetURL() *string {
	if o == nil {
		return nil
	}
	return o.URL
}

func (o *OutputCriblHTTP) GetUseRoundRobinDNS() *bool {
	if o == nil {
		return nil
	}
	return o.UseRoundRobinDNS
}

func (o *OutputCriblHTTP) GetExcludeSelf() *bool {
	if o == nil {
		return nil
	}
	return o.ExcludeSelf
}

func (o *OutputCriblHTTP) GetUrls() []OutputCriblHTTPUrls {
	if o == nil {
		return nil
	}
	return o.Urls
}

func (o *OutputCriblHTTP) GetDNSResolvePeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.DNSResolvePeriodSec
}

func (o *OutputCriblHTTP) GetLoadBalanceStatsPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.LoadBalanceStatsPeriodSec
}

func (o *OutputCriblHTTP) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputCriblHTTP) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputCriblHTTP) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputCriblHTTP) GetPqCompress() *OutputCriblHTTPOutputCompression {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputCriblHTTP) GetPqOnBackpressure() *OutputCriblHTTPQueueFullBehavior {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputCriblHTTP) GetPqMode() *OutputCriblHTTPMode {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputCriblHTTP) GetPqControls() *OutputCriblHTTPPqControls {
	if o == nil {
		return nil
	}
	return o.PqControls
}

type OutputCriblTCPType string

const (
	OutputCriblTCPTypeCriblTCP OutputCriblTCPType = "cribl_tcp"
)

func (e OutputCriblTCPType) ToPointer() *OutputCriblTCPType {
	return &e
}
func (e *OutputCriblTCPType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "cribl_tcp":
		*e = OutputCriblTCPType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputCriblTCPType: %v", v)
	}
}

// OutputCriblTCPCompression - Codec to use to compress the data before sending
type OutputCriblTCPCompression string

const (
	OutputCriblTCPCompressionNone OutputCriblTCPCompression = "none"
	OutputCriblTCPCompressionGzip OutputCriblTCPCompression = "gzip"
)

func (e OutputCriblTCPCompression) ToPointer() *OutputCriblTCPCompression {
	return &e
}
func (e *OutputCriblTCPCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = OutputCriblTCPCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputCriblTCPCompression: %v", v)
	}
}

// OutputCriblTCPMinimumTLSVersion - Minimum TLS version to use when connecting
type OutputCriblTCPMinimumTLSVersion string

const (
	OutputCriblTCPMinimumTLSVersionTlSv1  OutputCriblTCPMinimumTLSVersion = "TLSv1"
	OutputCriblTCPMinimumTLSVersionTlSv11 OutputCriblTCPMinimumTLSVersion = "TLSv1.1"
	OutputCriblTCPMinimumTLSVersionTlSv12 OutputCriblTCPMinimumTLSVersion = "TLSv1.2"
	OutputCriblTCPMinimumTLSVersionTlSv13 OutputCriblTCPMinimumTLSVersion = "TLSv1.3"
)

func (e OutputCriblTCPMinimumTLSVersion) ToPointer() *OutputCriblTCPMinimumTLSVersion {
	return &e
}
func (e *OutputCriblTCPMinimumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = OutputCriblTCPMinimumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputCriblTCPMinimumTLSVersion: %v", v)
	}
}

// OutputCriblTCPMaximumTLSVersion - Maximum TLS version to use when connecting
type OutputCriblTCPMaximumTLSVersion string

const (
	OutputCriblTCPMaximumTLSVersionTlSv1  OutputCriblTCPMaximumTLSVersion = "TLSv1"
	OutputCriblTCPMaximumTLSVersionTlSv11 OutputCriblTCPMaximumTLSVersion = "TLSv1.1"
	OutputCriblTCPMaximumTLSVersionTlSv12 OutputCriblTCPMaximumTLSVersion = "TLSv1.2"
	OutputCriblTCPMaximumTLSVersionTlSv13 OutputCriblTCPMaximumTLSVersion = "TLSv1.3"
)

func (e OutputCriblTCPMaximumTLSVersion) ToPointer() *OutputCriblTCPMaximumTLSVersion {
	return &e
}
func (e *OutputCriblTCPMaximumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = OutputCriblTCPMaximumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputCriblTCPMaximumTLSVersion: %v", v)
	}
}

type OutputCriblTCPTLSSettingsClientSide struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Reject certs that are not authorized by a CA in the CA certificate path, or by another
	//                     trusted CA (e.g., the system's CA). Defaults to Yes. Overrides the toggle from Advanced Settings, when also present.
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.
	Servername *string `json:"servername,omitempty"`
	// The name of the predefined certificate.
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Passphrase to use to decrypt private key.
	Passphrase *string `json:"passphrase,omitempty"`
	// Minimum TLS version to use when connecting
	MinVersion *OutputCriblTCPMinimumTLSVersion `json:"minVersion,omitempty"`
	// Maximum TLS version to use when connecting
	MaxVersion *OutputCriblTCPMaximumTLSVersion `json:"maxVersion,omitempty"`
}

func (o OutputCriblTCPTLSSettingsClientSide) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputCriblTCPTLSSettingsClientSide) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputCriblTCPTLSSettingsClientSide) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *OutputCriblTCPTLSSettingsClientSide) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputCriblTCPTLSSettingsClientSide) GetServername() *string {
	if o == nil {
		return nil
	}
	return o.Servername
}

func (o *OutputCriblTCPTLSSettingsClientSide) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *OutputCriblTCPTLSSettingsClientSide) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *OutputCriblTCPTLSSettingsClientSide) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *OutputCriblTCPTLSSettingsClientSide) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *OutputCriblTCPTLSSettingsClientSide) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *OutputCriblTCPTLSSettingsClientSide) GetMinVersion() *OutputCriblTCPMinimumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *OutputCriblTCPTLSSettingsClientSide) GetMaxVersion() *OutputCriblTCPMaximumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

// OutputCriblTCPBackpressureBehavior - Whether to block, drop, or queue events when all receivers are exerting backpressure.
type OutputCriblTCPBackpressureBehavior string

const (
	OutputCriblTCPBackpressureBehaviorBlock OutputCriblTCPBackpressureBehavior = "block"
	OutputCriblTCPBackpressureBehaviorDrop  OutputCriblTCPBackpressureBehavior = "drop"
	OutputCriblTCPBackpressureBehaviorQueue OutputCriblTCPBackpressureBehavior = "queue"
)

func (e OutputCriblTCPBackpressureBehavior) ToPointer() *OutputCriblTCPBackpressureBehavior {
	return &e
}
func (e *OutputCriblTCPBackpressureBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		fallthrough
	case "queue":
		*e = OutputCriblTCPBackpressureBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputCriblTCPBackpressureBehavior: %v", v)
	}
}

// OutputCriblTCPTLS - Whether to inherit TLS configs from group setting or disable TLS.
type OutputCriblTCPTLS string

const (
	OutputCriblTCPTLSInherit OutputCriblTCPTLS = "inherit"
	OutputCriblTCPTLSFalse   OutputCriblTCPTLS = "false"
)

func (e OutputCriblTCPTLS) ToPointer() *OutputCriblTCPTLS {
	return &e
}
func (e *OutputCriblTCPTLS) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "inherit":
		fallthrough
	case "false":
		*e = OutputCriblTCPTLS(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputCriblTCPTLS: %v", v)
	}
}

type OutputCriblTCPHosts struct {
	// The hostname of the receiver.
	Host string `json:"host"`
	// The port to connect to on the provided host.
	Port *float64 `default:"10300" json:"port"`
	// Whether to inherit TLS configs from group setting or disable TLS.
	TLS *OutputCriblTCPTLS `default:"inherit" json:"tls"`
	// Servername to use if establishing a TLS connection. If not specified, defaults to connection host (iff not an IP); otherwise, to the global TLS settings.
	Servername *string `json:"servername,omitempty"`
	// Assign a weight (>0) to each endpoint to indicate its traffic-handling capability
	Weight *float64 `default:"1" json:"weight"`
}

func (o OutputCriblTCPHosts) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputCriblTCPHosts) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputCriblTCPHosts) GetHost() string {
	if o == nil {
		return ""
	}
	return o.Host
}

func (o *OutputCriblTCPHosts) GetPort() *float64 {
	if o == nil {
		return nil
	}
	return o.Port
}

func (o *OutputCriblTCPHosts) GetTLS() *OutputCriblTCPTLS {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *OutputCriblTCPHosts) GetServername() *string {
	if o == nil {
		return nil
	}
	return o.Servername
}

func (o *OutputCriblTCPHosts) GetWeight() *float64 {
	if o == nil {
		return nil
	}
	return o.Weight
}

// OutputCriblTCPOutputCompression - Codec to use to compress the persisted data.
type OutputCriblTCPOutputCompression string

const (
	OutputCriblTCPOutputCompressionNone OutputCriblTCPOutputCompression = "none"
	OutputCriblTCPOutputCompressionGzip OutputCriblTCPOutputCompression = "gzip"
)

func (e OutputCriblTCPOutputCompression) ToPointer() *OutputCriblTCPOutputCompression {
	return &e
}
func (e *OutputCriblTCPOutputCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = OutputCriblTCPOutputCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputCriblTCPOutputCompression: %v", v)
	}
}

// OutputCriblTCPQueueFullBehavior - Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
type OutputCriblTCPQueueFullBehavior string

const (
	OutputCriblTCPQueueFullBehaviorBlock OutputCriblTCPQueueFullBehavior = "block"
	OutputCriblTCPQueueFullBehaviorDrop  OutputCriblTCPQueueFullBehavior = "drop"
)

func (e OutputCriblTCPQueueFullBehavior) ToPointer() *OutputCriblTCPQueueFullBehavior {
	return &e
}
func (e *OutputCriblTCPQueueFullBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputCriblTCPQueueFullBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputCriblTCPQueueFullBehavior: %v", v)
	}
}

// OutputCriblTCPMode - In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
type OutputCriblTCPMode string

const (
	OutputCriblTCPModeError        OutputCriblTCPMode = "error"
	OutputCriblTCPModeBackpressure OutputCriblTCPMode = "backpressure"
	OutputCriblTCPModeAlways       OutputCriblTCPMode = "always"
)

func (e OutputCriblTCPMode) ToPointer() *OutputCriblTCPMode {
	return &e
}
func (e *OutputCriblTCPMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "error":
		fallthrough
	case "backpressure":
		fallthrough
	case "always":
		*e = OutputCriblTCPMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputCriblTCPMode: %v", v)
	}
}

type OutputCriblTCPPqControls struct {
}

type OutputCriblTCP struct {
	// Unique ID for this output
	ID   string             `json:"id"`
	Type OutputCriblTCPType `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Use load-balanced destinations
	LoadBalanced *bool `default:"true" json:"loadBalanced"`
	// Codec to use to compress the data before sending
	Compression *OutputCriblTCPCompression `default:"gzip" json:"compression"`
	// Use to troubleshoot issues with sending data
	LogFailedRequests *bool `default:"false" json:"logFailedRequests"`
	// Rate (in bytes per second) to throttle while writing to an output. Accepts values with multiple-byte units, such as KB, MB, and GB. (Example: 42 MB) Default value of 0 specifies no throttling.
	ThrottleRatePerSec *string                              `default:"0" json:"throttleRatePerSec"`
	TLS                *OutputCriblTCPTLSSettingsClientSide `json:"tls,omitempty"`
	// Amount of time (milliseconds) to wait for the connection to establish before retrying
	ConnectionTimeout *float64 `default:"10000" json:"connectionTimeout"`
	// Amount of time (milliseconds) to wait for a write to complete before assuming connection is dead
	WriteTimeout *float64 `default:"60000" json:"writeTimeout"`
	// The number of minutes before the internally generated authentication token expires, valid values between 1 and 60
	TokenTTLMinutes *float64 `default:"60" json:"tokenTTLMinutes"`
	// Fields to exclude from the event. By default, all internal fields except `__output` are sent. E.g.: `cribl_pipe`, `c*`. Wildcards supported.
	ExcludeFields []string `json:"excludeFields,omitempty"`
	// Whether to block, drop, or queue events when all receivers are exerting backpressure.
	OnBackpressure *OutputCriblTCPBackpressureBehavior `default:"block" json:"onBackpressure"`
	Description    *string                             `json:"description,omitempty"`
	// The hostname of the receiver
	Host *string `json:"host,omitempty"`
	// The port to connect to on the provided host
	Port *float64 `default:"10300" json:"port"`
	// Exclude all IPs of the current host from the list of any resolved hostnames.
	ExcludeSelf *bool `default:"false" json:"excludeSelf"`
	// Set of hosts to load-balance data to.
	Hosts []OutputCriblTCPHosts `json:"hosts,omitempty"`
	// Re-resolve any hostnames every this many seconds and pick up destinations from A records.
	DNSResolvePeriodSec *float64 `default:"600" json:"dnsResolvePeriodSec"`
	// How far back in time to keep traffic stats for load balancing purposes.
	LoadBalanceStatsPeriodSec *float64 `default:"300" json:"loadBalanceStatsPeriodSec"`
	// Maximum number of concurrent connections (per worker process). A random set of IPs will be picked on every DNS resolution period. Use 0 for unlimited.
	MaxConcurrentSenders *float64 `default:"0" json:"maxConcurrentSenders"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.).
	PqMaxFileSize *string `default:"1 MB" json:"pqMaxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `default:"5GB" json:"pqMaxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `default:"\\$CRIBL_HOME/state/queues" json:"pqPath"`
	// Codec to use to compress the persisted data.
	PqCompress *OutputCriblTCPOutputCompression `default:"none" json:"pqCompress"`
	// Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *OutputCriblTCPQueueFullBehavior `default:"block" json:"pqOnBackpressure"`
	// In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
	PqMode     *OutputCriblTCPMode       `default:"error" json:"pqMode"`
	PqControls *OutputCriblTCPPqControls `json:"pqControls,omitempty"`
	Status     *TFStatus                 `json:"status,omitempty"`
}

func (o OutputCriblTCP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputCriblTCP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *OutputCriblTCP) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *OutputCriblTCP) GetType() OutputCriblTCPType {
	if o == nil {
		return OutputCriblTCPType("")
	}
	return o.Type
}

func (o *OutputCriblTCP) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputCriblTCP) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputCriblTCP) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputCriblTCP) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputCriblTCP) GetLoadBalanced() *bool {
	if o == nil {
		return nil
	}
	return o.LoadBalanced
}

func (o *OutputCriblTCP) GetCompression() *OutputCriblTCPCompression {
	if o == nil {
		return nil
	}
	return o.Compression
}

func (o *OutputCriblTCP) GetLogFailedRequests() *bool {
	if o == nil {
		return nil
	}
	return o.LogFailedRequests
}

func (o *OutputCriblTCP) GetThrottleRatePerSec() *string {
	if o == nil {
		return nil
	}
	return o.ThrottleRatePerSec
}

func (o *OutputCriblTCP) GetTLS() *OutputCriblTCPTLSSettingsClientSide {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *OutputCriblTCP) GetConnectionTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.ConnectionTimeout
}

func (o *OutputCriblTCP) GetWriteTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.WriteTimeout
}

func (o *OutputCriblTCP) GetTokenTTLMinutes() *float64 {
	if o == nil {
		return nil
	}
	return o.TokenTTLMinutes
}

func (o *OutputCriblTCP) GetExcludeFields() []string {
	if o == nil {
		return nil
	}
	return o.ExcludeFields
}

func (o *OutputCriblTCP) GetOnBackpressure() *OutputCriblTCPBackpressureBehavior {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputCriblTCP) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputCriblTCP) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *OutputCriblTCP) GetPort() *float64 {
	if o == nil {
		return nil
	}
	return o.Port
}

func (o *OutputCriblTCP) GetExcludeSelf() *bool {
	if o == nil {
		return nil
	}
	return o.ExcludeSelf
}

func (o *OutputCriblTCP) GetHosts() []OutputCriblTCPHosts {
	if o == nil {
		return nil
	}
	return o.Hosts
}

func (o *OutputCriblTCP) GetDNSResolvePeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.DNSResolvePeriodSec
}

func (o *OutputCriblTCP) GetLoadBalanceStatsPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.LoadBalanceStatsPeriodSec
}

func (o *OutputCriblTCP) GetMaxConcurrentSenders() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxConcurrentSenders
}

func (o *OutputCriblTCP) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputCriblTCP) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputCriblTCP) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputCriblTCP) GetPqCompress() *OutputCriblTCPOutputCompression {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputCriblTCP) GetPqOnBackpressure() *OutputCriblTCPQueueFullBehavior {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputCriblTCP) GetPqMode() *OutputCriblTCPMode {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputCriblTCP) GetPqControls() *OutputCriblTCPPqControls {
	if o == nil {
		return nil
	}
	return o.PqControls
}

func (o *OutputCriblTCP) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type OutputDatasetType string

const (
	OutputDatasetTypeDataset OutputDatasetType = "dataset"
)

func (e OutputDatasetType) ToPointer() *OutputDatasetType {
	return &e
}
func (e *OutputDatasetType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "dataset":
		*e = OutputDatasetType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputDatasetType: %v", v)
	}
}

// OutputDatasetSeverity - Default value for event severity. If the `sev` or `__severity` fields are set on an event, the first one matching will override this value.
type OutputDatasetSeverity string

const (
	OutputDatasetSeverityFinest  OutputDatasetSeverity = "finest"
	OutputDatasetSeverityFiner   OutputDatasetSeverity = "finer"
	OutputDatasetSeverityFine    OutputDatasetSeverity = "fine"
	OutputDatasetSeverityInfo    OutputDatasetSeverity = "info"
	OutputDatasetSeverityWarning OutputDatasetSeverity = "warning"
	OutputDatasetSeverityError   OutputDatasetSeverity = "error"
	OutputDatasetSeverityFatal   OutputDatasetSeverity = "fatal"
)

func (e OutputDatasetSeverity) ToPointer() *OutputDatasetSeverity {
	return &e
}
func (e *OutputDatasetSeverity) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "finest":
		fallthrough
	case "finer":
		fallthrough
	case "fine":
		fallthrough
	case "info":
		fallthrough
	case "warning":
		fallthrough
	case "error":
		fallthrough
	case "fatal":
		*e = OutputDatasetSeverity(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputDatasetSeverity: %v", v)
	}
}

type OutputDatasetResponseRetrySettings struct {
	// The HTTP response status code that will trigger retries
	HTTPStatus float64 `json:"httpStatus"`
	// How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"1000" json:"initialBackoff"`
	// Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackoff *float64 `default:"10000" json:"maxBackoff"`
}

func (o OutputDatasetResponseRetrySettings) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputDatasetResponseRetrySettings) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputDatasetResponseRetrySettings) GetHTTPStatus() float64 {
	if o == nil {
		return 0.0
	}
	return o.HTTPStatus
}

func (o *OutputDatasetResponseRetrySettings) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *OutputDatasetResponseRetrySettings) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *OutputDatasetResponseRetrySettings) GetMaxBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackoff
}

type OutputDatasetTimeoutRetrySettings struct {
	// Enable to retry on request timeout
	TimeoutRetry *bool `default:"false" json:"timeoutRetry"`
	// How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"1000" json:"initialBackoff"`
	// Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackoff *float64 `default:"10000" json:"maxBackoff"`
}

func (o OutputDatasetTimeoutRetrySettings) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputDatasetTimeoutRetrySettings) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputDatasetTimeoutRetrySettings) GetTimeoutRetry() *bool {
	if o == nil {
		return nil
	}
	return o.TimeoutRetry
}

func (o *OutputDatasetTimeoutRetrySettings) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *OutputDatasetTimeoutRetrySettings) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *OutputDatasetTimeoutRetrySettings) GetMaxBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackoff
}

// DataSetSite - DataSet site to which events should be sent
type DataSetSite string

const (
	DataSetSiteUs     DataSetSite = "us"
	DataSetSiteEu     DataSetSite = "eu"
	DataSetSiteCustom DataSetSite = "custom"
)

func (e DataSetSite) ToPointer() *DataSetSite {
	return &e
}
func (e *DataSetSite) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "us":
		fallthrough
	case "eu":
		fallthrough
	case "custom":
		*e = DataSetSite(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DataSetSite: %v", v)
	}
}

type OutputDatasetExtraHTTPHeaders struct {
	// Field name
	Name *string `json:"name,omitempty"`
	// Field value
	Value string `json:"value"`
}

func (o *OutputDatasetExtraHTTPHeaders) GetName() *string {
	if o == nil {
		return nil
	}
	return o.Name
}

func (o *OutputDatasetExtraHTTPHeaders) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// OutputDatasetFailedRequestLoggingMode - Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
type OutputDatasetFailedRequestLoggingMode string

const (
	OutputDatasetFailedRequestLoggingModePayload           OutputDatasetFailedRequestLoggingMode = "payload"
	OutputDatasetFailedRequestLoggingModePayloadAndHeaders OutputDatasetFailedRequestLoggingMode = "payloadAndHeaders"
	OutputDatasetFailedRequestLoggingModeNone              OutputDatasetFailedRequestLoggingMode = "none"
)

func (e OutputDatasetFailedRequestLoggingMode) ToPointer() *OutputDatasetFailedRequestLoggingMode {
	return &e
}
func (e *OutputDatasetFailedRequestLoggingMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "payload":
		fallthrough
	case "payloadAndHeaders":
		fallthrough
	case "none":
		*e = OutputDatasetFailedRequestLoggingMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputDatasetFailedRequestLoggingMode: %v", v)
	}
}

// OutputDatasetBackpressureBehavior - Whether to block, drop, or queue events when all receivers are exerting backpressure.
type OutputDatasetBackpressureBehavior string

const (
	OutputDatasetBackpressureBehaviorBlock OutputDatasetBackpressureBehavior = "block"
	OutputDatasetBackpressureBehaviorDrop  OutputDatasetBackpressureBehavior = "drop"
	OutputDatasetBackpressureBehaviorQueue OutputDatasetBackpressureBehavior = "queue"
)

func (e OutputDatasetBackpressureBehavior) ToPointer() *OutputDatasetBackpressureBehavior {
	return &e
}
func (e *OutputDatasetBackpressureBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		fallthrough
	case "queue":
		*e = OutputDatasetBackpressureBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputDatasetBackpressureBehavior: %v", v)
	}
}

// OutputDatasetAuthenticationMethod - Enter API key directly, or select a stored secret
type OutputDatasetAuthenticationMethod string

const (
	OutputDatasetAuthenticationMethodManual OutputDatasetAuthenticationMethod = "manual"
	OutputDatasetAuthenticationMethodSecret OutputDatasetAuthenticationMethod = "secret"
)

func (e OutputDatasetAuthenticationMethod) ToPointer() *OutputDatasetAuthenticationMethod {
	return &e
}
func (e *OutputDatasetAuthenticationMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "manual":
		fallthrough
	case "secret":
		*e = OutputDatasetAuthenticationMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputDatasetAuthenticationMethod: %v", v)
	}
}

// OutputDatasetCompression - Codec to use to compress the persisted data.
type OutputDatasetCompression string

const (
	OutputDatasetCompressionNone OutputDatasetCompression = "none"
	OutputDatasetCompressionGzip OutputDatasetCompression = "gzip"
)

func (e OutputDatasetCompression) ToPointer() *OutputDatasetCompression {
	return &e
}
func (e *OutputDatasetCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = OutputDatasetCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputDatasetCompression: %v", v)
	}
}

// OutputDatasetQueueFullBehavior - Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
type OutputDatasetQueueFullBehavior string

const (
	OutputDatasetQueueFullBehaviorBlock OutputDatasetQueueFullBehavior = "block"
	OutputDatasetQueueFullBehaviorDrop  OutputDatasetQueueFullBehavior = "drop"
)

func (e OutputDatasetQueueFullBehavior) ToPointer() *OutputDatasetQueueFullBehavior {
	return &e
}
func (e *OutputDatasetQueueFullBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputDatasetQueueFullBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputDatasetQueueFullBehavior: %v", v)
	}
}

// OutputDatasetMode - In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
type OutputDatasetMode string

const (
	OutputDatasetModeError        OutputDatasetMode = "error"
	OutputDatasetModeBackpressure OutputDatasetMode = "backpressure"
	OutputDatasetModeAlways       OutputDatasetMode = "always"
)

func (e OutputDatasetMode) ToPointer() *OutputDatasetMode {
	return &e
}
func (e *OutputDatasetMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "error":
		fallthrough
	case "backpressure":
		fallthrough
	case "always":
		*e = OutputDatasetMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputDatasetMode: %v", v)
	}
}

type OutputDatasetPqControls struct {
}

type OutputDataset struct {
	// Unique ID for this output
	ID   string            `json:"id"`
	Type OutputDatasetType `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Name of the event field that contains the message or attributes to send. If not specified, all of the event's non-internal fields will be sent as attributes.
	MessageField *string `json:"messageField,omitempty"`
	// Fields to exclude from the event if the Message field is either unspecified or refers to an object. Ignored if the Message field is a string. If empty, we send all non-internal fields.
	ExcludeFields []string `json:"excludeFields,omitempty"`
	// Name of the event field that contains the `serverHost` identifier. If not specified, defaults to `cribl_<outputId>`.
	ServerHostField *string `json:"serverHostField,omitempty"`
	// Name of the event field that contains the timestamp. If not specified, defaults to `ts`, `_time`, or `Date.now()`, in that order.
	TimestampField *string `json:"timestampField,omitempty"`
	// Default value for event severity. If the `sev` or `__severity` fields are set on an event, the first one matching will override this value.
	DefaultSeverity *OutputDatasetSeverity `default:"info" json:"defaultSeverity"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable).
	ResponseRetrySettings []OutputDatasetResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *OutputDatasetTimeoutRetrySettings   `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `default:"false" json:"responseHonorRetryAfterHeader"`
	// DataSet site to which events should be sent
	Site *DataSetSite `default:"us" json:"site"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `default:"5" json:"concurrency"`
	// Maximum size, in KB, of the request body
	MaxPayloadSizeKB *float64 `default:"4096" json:"maxPayloadSizeKB"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited).
	MaxPayloadEvents *float64 `default:"0" json:"maxPayloadEvents"`
	// Compress the payload body before sending
	Compress *bool `default:"true" json:"compress"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Defaults to Yes. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `default:"30" json:"timeoutSec"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Max body size.
	FlushPeriodSec *float64 `default:"1" json:"flushPeriodSec"`
	// Headers to add to all events.
	ExtraHTTPHeaders []OutputDatasetExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// Enables round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `default:"false" json:"useRoundRobinDns"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *OutputDatasetFailedRequestLoggingMode `default:"none" json:"failedRequestLoggingMode"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// Whether to block, drop, or queue events when all receivers are exerting backpressure.
	OnBackpressure *OutputDatasetBackpressureBehavior `default:"block" json:"onBackpressure"`
	// Enter API key directly, or select a stored secret
	AuthType *OutputDatasetAuthenticationMethod `default:"manual" json:"authType"`
	// Maximum total size of the batches waiting to be sent. If left blank, defaults to 5 times the max body size (if set). If 0, no limit is enforced.
	TotalMemoryLimitKB *float64 `json:"totalMemoryLimitKB,omitempty"`
	Description        *string  `json:"description,omitempty"`
	CustomURL          *string  `json:"customUrl,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.).
	PqMaxFileSize *string `default:"1 MB" json:"pqMaxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `default:"5GB" json:"pqMaxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `default:"\\$CRIBL_HOME/state/queues" json:"pqPath"`
	// Codec to use to compress the persisted data.
	PqCompress *OutputDatasetCompression `default:"none" json:"pqCompress"`
	// Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *OutputDatasetQueueFullBehavior `default:"block" json:"pqOnBackpressure"`
	// In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
	PqMode     *OutputDatasetMode       `default:"error" json:"pqMode"`
	PqControls *OutputDatasetPqControls `json:"pqControls,omitempty"`
	// A 'Log Write Access' API key for the DataSet account
	APIKey *string `json:"apiKey,omitempty"`
	// Select or create a stored text secret
	TextSecret *string   `json:"textSecret,omitempty"`
	Status     *TFStatus `json:"status,omitempty"`
}

func (o OutputDataset) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputDataset) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *OutputDataset) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *OutputDataset) GetType() OutputDatasetType {
	if o == nil {
		return OutputDatasetType("")
	}
	return o.Type
}

func (o *OutputDataset) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputDataset) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputDataset) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputDataset) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputDataset) GetMessageField() *string {
	if o == nil {
		return nil
	}
	return o.MessageField
}

func (o *OutputDataset) GetExcludeFields() []string {
	if o == nil {
		return nil
	}
	return o.ExcludeFields
}

func (o *OutputDataset) GetServerHostField() *string {
	if o == nil {
		return nil
	}
	return o.ServerHostField
}

func (o *OutputDataset) GetTimestampField() *string {
	if o == nil {
		return nil
	}
	return o.TimestampField
}

func (o *OutputDataset) GetDefaultSeverity() *OutputDatasetSeverity {
	if o == nil {
		return nil
	}
	return o.DefaultSeverity
}

func (o *OutputDataset) GetResponseRetrySettings() []OutputDatasetResponseRetrySettings {
	if o == nil {
		return nil
	}
	return o.ResponseRetrySettings
}

func (o *OutputDataset) GetTimeoutRetrySettings() *OutputDatasetTimeoutRetrySettings {
	if o == nil {
		return nil
	}
	return o.TimeoutRetrySettings
}

func (o *OutputDataset) GetResponseHonorRetryAfterHeader() *bool {
	if o == nil {
		return nil
	}
	return o.ResponseHonorRetryAfterHeader
}

func (o *OutputDataset) GetSite() *DataSetSite {
	if o == nil {
		return nil
	}
	return o.Site
}

func (o *OutputDataset) GetConcurrency() *float64 {
	if o == nil {
		return nil
	}
	return o.Concurrency
}

func (o *OutputDataset) GetMaxPayloadSizeKB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadSizeKB
}

func (o *OutputDataset) GetMaxPayloadEvents() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadEvents
}

func (o *OutputDataset) GetCompress() *bool {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *OutputDataset) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputDataset) GetTimeoutSec() *float64 {
	if o == nil {
		return nil
	}
	return o.TimeoutSec
}

func (o *OutputDataset) GetFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushPeriodSec
}

func (o *OutputDataset) GetExtraHTTPHeaders() []OutputDatasetExtraHTTPHeaders {
	if o == nil {
		return nil
	}
	return o.ExtraHTTPHeaders
}

func (o *OutputDataset) GetUseRoundRobinDNS() *bool {
	if o == nil {
		return nil
	}
	return o.UseRoundRobinDNS
}

func (o *OutputDataset) GetFailedRequestLoggingMode() *OutputDatasetFailedRequestLoggingMode {
	if o == nil {
		return nil
	}
	return o.FailedRequestLoggingMode
}

func (o *OutputDataset) GetSafeHeaders() []string {
	if o == nil {
		return nil
	}
	return o.SafeHeaders
}

func (o *OutputDataset) GetOnBackpressure() *OutputDatasetBackpressureBehavior {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputDataset) GetAuthType() *OutputDatasetAuthenticationMethod {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *OutputDataset) GetTotalMemoryLimitKB() *float64 {
	if o == nil {
		return nil
	}
	return o.TotalMemoryLimitKB
}

func (o *OutputDataset) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputDataset) GetCustomURL() *string {
	if o == nil {
		return nil
	}
	return o.CustomURL
}

func (o *OutputDataset) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputDataset) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputDataset) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputDataset) GetPqCompress() *OutputDatasetCompression {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputDataset) GetPqOnBackpressure() *OutputDatasetQueueFullBehavior {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputDataset) GetPqMode() *OutputDatasetMode {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputDataset) GetPqControls() *OutputDatasetPqControls {
	if o == nil {
		return nil
	}
	return o.PqControls
}

func (o *OutputDataset) GetAPIKey() *string {
	if o == nil {
		return nil
	}
	return o.APIKey
}

func (o *OutputDataset) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *OutputDataset) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type OutputServiceNowType string

const (
	OutputServiceNowTypeServiceNow OutputServiceNowType = "service_now"
)

func (e OutputServiceNowType) ToPointer() *OutputServiceNowType {
	return &e
}
func (e *OutputServiceNowType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "service_now":
		*e = OutputServiceNowType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputServiceNowType: %v", v)
	}
}

// OutputServiceNowOTLPVersion - The version of OTLP Protobuf definitions to use when structuring data to send
type OutputServiceNowOTLPVersion string

const (
	OutputServiceNowOTLPVersionOneDot3Dot1 OutputServiceNowOTLPVersion = "1.3.1"
)

func (e OutputServiceNowOTLPVersion) ToPointer() *OutputServiceNowOTLPVersion {
	return &e
}
func (e *OutputServiceNowOTLPVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "1.3.1":
		*e = OutputServiceNowOTLPVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputServiceNowOTLPVersion: %v", v)
	}
}

// OutputServiceNowProtocol - Select a transport option for OpenTelemetry
type OutputServiceNowProtocol string

const (
	OutputServiceNowProtocolGrpc OutputServiceNowProtocol = "grpc"
	OutputServiceNowProtocolHTTP OutputServiceNowProtocol = "http"
)

func (e OutputServiceNowProtocol) ToPointer() *OutputServiceNowProtocol {
	return &e
}
func (e *OutputServiceNowProtocol) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "grpc":
		fallthrough
	case "http":
		*e = OutputServiceNowProtocol(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputServiceNowProtocol: %v", v)
	}
}

// OutputServiceNowCompression - Type of compression to apply to messages sent to the OpenTelemetry endpoint
type OutputServiceNowCompression string

const (
	OutputServiceNowCompressionNone    OutputServiceNowCompression = "none"
	OutputServiceNowCompressionDeflate OutputServiceNowCompression = "deflate"
	OutputServiceNowCompressionGzip    OutputServiceNowCompression = "gzip"
)

func (e OutputServiceNowCompression) ToPointer() *OutputServiceNowCompression {
	return &e
}
func (e *OutputServiceNowCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "deflate":
		fallthrough
	case "gzip":
		*e = OutputServiceNowCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputServiceNowCompression: %v", v)
	}
}

// OutputServiceNowOutputCompression - Type of compression to apply to messages sent to the OpenTelemetry endpoint
type OutputServiceNowOutputCompression string

const (
	OutputServiceNowOutputCompressionNone OutputServiceNowOutputCompression = "none"
	OutputServiceNowOutputCompressionGzip OutputServiceNowOutputCompression = "gzip"
)

func (e OutputServiceNowOutputCompression) ToPointer() *OutputServiceNowOutputCompression {
	return &e
}
func (e *OutputServiceNowOutputCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = OutputServiceNowOutputCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputServiceNowOutputCompression: %v", v)
	}
}

type OutputServiceNowMetadata struct {
	Key   *string `default:"" json:"key"`
	Value string  `json:"value"`
}

func (o OutputServiceNowMetadata) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputServiceNowMetadata) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputServiceNowMetadata) GetKey() *string {
	if o == nil {
		return nil
	}
	return o.Key
}

func (o *OutputServiceNowMetadata) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// OutputServiceNowFailedRequestLoggingMode - Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
type OutputServiceNowFailedRequestLoggingMode string

const (
	OutputServiceNowFailedRequestLoggingModePayload           OutputServiceNowFailedRequestLoggingMode = "payload"
	OutputServiceNowFailedRequestLoggingModePayloadAndHeaders OutputServiceNowFailedRequestLoggingMode = "payloadAndHeaders"
	OutputServiceNowFailedRequestLoggingModeNone              OutputServiceNowFailedRequestLoggingMode = "none"
)

func (e OutputServiceNowFailedRequestLoggingMode) ToPointer() *OutputServiceNowFailedRequestLoggingMode {
	return &e
}
func (e *OutputServiceNowFailedRequestLoggingMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "payload":
		fallthrough
	case "payloadAndHeaders":
		fallthrough
	case "none":
		*e = OutputServiceNowFailedRequestLoggingMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputServiceNowFailedRequestLoggingMode: %v", v)
	}
}

// OutputServiceNowBackpressureBehavior - Whether to block, drop, or queue events when all receivers are exerting backpressure.
type OutputServiceNowBackpressureBehavior string

const (
	OutputServiceNowBackpressureBehaviorBlock OutputServiceNowBackpressureBehavior = "block"
	OutputServiceNowBackpressureBehaviorDrop  OutputServiceNowBackpressureBehavior = "drop"
	OutputServiceNowBackpressureBehaviorQueue OutputServiceNowBackpressureBehavior = "queue"
)

func (e OutputServiceNowBackpressureBehavior) ToPointer() *OutputServiceNowBackpressureBehavior {
	return &e
}
func (e *OutputServiceNowBackpressureBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		fallthrough
	case "queue":
		*e = OutputServiceNowBackpressureBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputServiceNowBackpressureBehavior: %v", v)
	}
}

type OutputServiceNowExtraHTTPHeaders struct {
	// Field name
	Name *string `json:"name,omitempty"`
	// Field value
	Value string `json:"value"`
}

func (o *OutputServiceNowExtraHTTPHeaders) GetName() *string {
	if o == nil {
		return nil
	}
	return o.Name
}

func (o *OutputServiceNowExtraHTTPHeaders) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type OutputServiceNowResponseRetrySettings struct {
	// The HTTP response status code that will trigger retries
	HTTPStatus float64 `json:"httpStatus"`
	// How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"1000" json:"initialBackoff"`
	// Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackoff *float64 `default:"10000" json:"maxBackoff"`
}

func (o OutputServiceNowResponseRetrySettings) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputServiceNowResponseRetrySettings) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputServiceNowResponseRetrySettings) GetHTTPStatus() float64 {
	if o == nil {
		return 0.0
	}
	return o.HTTPStatus
}

func (o *OutputServiceNowResponseRetrySettings) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *OutputServiceNowResponseRetrySettings) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *OutputServiceNowResponseRetrySettings) GetMaxBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackoff
}

type OutputServiceNowTimeoutRetrySettings struct {
	// Enable to retry on request timeout
	TimeoutRetry *bool `default:"false" json:"timeoutRetry"`
	// How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"1000" json:"initialBackoff"`
	// Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackoff *float64 `default:"10000" json:"maxBackoff"`
}

func (o OutputServiceNowTimeoutRetrySettings) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputServiceNowTimeoutRetrySettings) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputServiceNowTimeoutRetrySettings) GetTimeoutRetry() *bool {
	if o == nil {
		return nil
	}
	return o.TimeoutRetry
}

func (o *OutputServiceNowTimeoutRetrySettings) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *OutputServiceNowTimeoutRetrySettings) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *OutputServiceNowTimeoutRetrySettings) GetMaxBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackoff
}

// OutputServiceNowMinimumTLSVersion - Minimum TLS version to use when connecting
type OutputServiceNowMinimumTLSVersion string

const (
	OutputServiceNowMinimumTLSVersionTlSv1  OutputServiceNowMinimumTLSVersion = "TLSv1"
	OutputServiceNowMinimumTLSVersionTlSv11 OutputServiceNowMinimumTLSVersion = "TLSv1.1"
	OutputServiceNowMinimumTLSVersionTlSv12 OutputServiceNowMinimumTLSVersion = "TLSv1.2"
	OutputServiceNowMinimumTLSVersionTlSv13 OutputServiceNowMinimumTLSVersion = "TLSv1.3"
)

func (e OutputServiceNowMinimumTLSVersion) ToPointer() *OutputServiceNowMinimumTLSVersion {
	return &e
}
func (e *OutputServiceNowMinimumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = OutputServiceNowMinimumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputServiceNowMinimumTLSVersion: %v", v)
	}
}

// OutputServiceNowMaximumTLSVersion - Maximum TLS version to use when connecting
type OutputServiceNowMaximumTLSVersion string

const (
	OutputServiceNowMaximumTLSVersionTlSv1  OutputServiceNowMaximumTLSVersion = "TLSv1"
	OutputServiceNowMaximumTLSVersionTlSv11 OutputServiceNowMaximumTLSVersion = "TLSv1.1"
	OutputServiceNowMaximumTLSVersionTlSv12 OutputServiceNowMaximumTLSVersion = "TLSv1.2"
	OutputServiceNowMaximumTLSVersionTlSv13 OutputServiceNowMaximumTLSVersion = "TLSv1.3"
)

func (e OutputServiceNowMaximumTLSVersion) ToPointer() *OutputServiceNowMaximumTLSVersion {
	return &e
}
func (e *OutputServiceNowMaximumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = OutputServiceNowMaximumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputServiceNowMaximumTLSVersion: %v", v)
	}
}

type OutputServiceNowTLSSettingsClientSide struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Reject certs that are not authorized by a CA in the CA certificate path, or by another
	//                     trusted CA (e.g., the system's CA). Defaults to Yes. Overrides the toggle from Advanced Settings, when also present.
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// The name of the predefined certificate.
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Passphrase to use to decrypt private key.
	Passphrase *string `json:"passphrase,omitempty"`
	// Minimum TLS version to use when connecting
	MinVersion *OutputServiceNowMinimumTLSVersion `json:"minVersion,omitempty"`
	// Maximum TLS version to use when connecting
	MaxVersion *OutputServiceNowMaximumTLSVersion `json:"maxVersion,omitempty"`
}

func (o OutputServiceNowTLSSettingsClientSide) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputServiceNowTLSSettingsClientSide) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputServiceNowTLSSettingsClientSide) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *OutputServiceNowTLSSettingsClientSide) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputServiceNowTLSSettingsClientSide) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *OutputServiceNowTLSSettingsClientSide) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *OutputServiceNowTLSSettingsClientSide) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *OutputServiceNowTLSSettingsClientSide) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *OutputServiceNowTLSSettingsClientSide) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *OutputServiceNowTLSSettingsClientSide) GetMinVersion() *OutputServiceNowMinimumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *OutputServiceNowTLSSettingsClientSide) GetMaxVersion() *OutputServiceNowMaximumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

// OutputServiceNowOutputPqCompressCompression - Codec to use to compress the persisted data.
type OutputServiceNowOutputPqCompressCompression string

const (
	OutputServiceNowOutputPqCompressCompressionNone OutputServiceNowOutputPqCompressCompression = "none"
	OutputServiceNowOutputPqCompressCompressionGzip OutputServiceNowOutputPqCompressCompression = "gzip"
)

func (e OutputServiceNowOutputPqCompressCompression) ToPointer() *OutputServiceNowOutputPqCompressCompression {
	return &e
}
func (e *OutputServiceNowOutputPqCompressCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = OutputServiceNowOutputPqCompressCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputServiceNowOutputPqCompressCompression: %v", v)
	}
}

// OutputServiceNowQueueFullBehavior - Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
type OutputServiceNowQueueFullBehavior string

const (
	OutputServiceNowQueueFullBehaviorBlock OutputServiceNowQueueFullBehavior = "block"
	OutputServiceNowQueueFullBehaviorDrop  OutputServiceNowQueueFullBehavior = "drop"
)

func (e OutputServiceNowQueueFullBehavior) ToPointer() *OutputServiceNowQueueFullBehavior {
	return &e
}
func (e *OutputServiceNowQueueFullBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputServiceNowQueueFullBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputServiceNowQueueFullBehavior: %v", v)
	}
}

// OutputServiceNowMode - In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
type OutputServiceNowMode string

const (
	OutputServiceNowModeError        OutputServiceNowMode = "error"
	OutputServiceNowModeBackpressure OutputServiceNowMode = "backpressure"
	OutputServiceNowModeAlways       OutputServiceNowMode = "always"
)

func (e OutputServiceNowMode) ToPointer() *OutputServiceNowMode {
	return &e
}
func (e *OutputServiceNowMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "error":
		fallthrough
	case "backpressure":
		fallthrough
	case "always":
		*e = OutputServiceNowMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputServiceNowMode: %v", v)
	}
}

type OutputServiceNowPqControls struct {
}

type OutputServiceNow struct {
	// Unique ID for this output
	ID   *string               `json:"id,omitempty"`
	Type *OutputServiceNowType `json:"type,omitempty"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// The endpoint where ServiceNow events will be sent. Enter any valid URL or an IP address (IPv4 or IPv6; enclose IPv6 addresses in square brackets)
	Endpoint *string `default:"ingest.lightstep.com:443" json:"endpoint"`
	// Select or create a stored text secret
	TokenSecret   string  `json:"tokenSecret"`
	AuthTokenName *string `default:"lightstep-access-token" json:"authTokenName"`
	// The version of OTLP Protobuf definitions to use when structuring data to send
	OtlpVersion *OutputServiceNowOTLPVersion `default:"1.3.1" json:"otlpVersion"`
	// Maximum size, in KB, of the request body
	MaxPayloadSizeKB *float64 `default:"2048" json:"maxPayloadSizeKB"`
	// Select a transport option for OpenTelemetry
	Protocol *OutputServiceNowProtocol `default:"grpc" json:"protocol"`
	// Type of compression to apply to messages sent to the OpenTelemetry endpoint
	Compress *OutputServiceNowCompression `default:"gzip" json:"compress"`
	// Type of compression to apply to messages sent to the OpenTelemetry endpoint
	HTTPCompress *OutputServiceNowOutputCompression `default:"gzip" json:"httpCompress"`
	// If you want to send traces to the default `{endpoint}/v1/traces` endpoint, leave this field empty; otherwise, specify the desired endpoint
	HTTPTracesEndpointOverride *string `json:"httpTracesEndpointOverride,omitempty"`
	// If you want to send metrics to the default `{endpoint}/v1/metrics` endpoint, leave this field empty; otherwise, specify the desired endpoint
	HTTPMetricsEndpointOverride *string `json:"httpMetricsEndpointOverride,omitempty"`
	// If you want to send logs to the default `{endpoint}/v1/logs` endpoint, leave this field empty; otherwise, specify the desired endpoint
	HTTPLogsEndpointOverride *string `json:"httpLogsEndpointOverride,omitempty"`
	// List of key-value pairs to send with each gRPC request. Value supports JavaScript expressions that are evaluated just once, when the destination gets started. To pass credentials as metadata, use 'C.Secret'.
	Metadata []OutputServiceNowMetadata `json:"metadata,omitempty"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `default:"5" json:"concurrency"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `default:"30" json:"timeoutSec"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Max body size.
	FlushPeriodSec *float64 `default:"1" json:"flushPeriodSec"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *OutputServiceNowFailedRequestLoggingMode `default:"none" json:"failedRequestLoggingMode"`
	// Amount of time (milliseconds) to wait for the connection to establish before retrying
	ConnectionTimeout *float64 `default:"10000" json:"connectionTimeout"`
	// How often the sender should ping the peer to keep the connection open
	KeepAliveTime *float64 `default:"30" json:"keepAliveTime"`
	// Disable to close the connection immediately after sending the outgoing request
	KeepAlive *bool `default:"true" json:"keepAlive"`
	// Whether to block, drop, or queue events when all receivers are exerting backpressure.
	OnBackpressure *OutputServiceNowBackpressureBehavior `default:"block" json:"onBackpressure"`
	Description    *string                               `json:"description,omitempty"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Defaults to Yes. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Enables round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `default:"false" json:"useRoundRobinDns"`
	// Headers to add to all events.
	ExtraHTTPHeaders []OutputServiceNowExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable).
	ResponseRetrySettings []OutputServiceNowResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *OutputServiceNowTimeoutRetrySettings   `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool                                  `default:"false" json:"responseHonorRetryAfterHeader"`
	TLS                           *OutputServiceNowTLSSettingsClientSide `json:"tls,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.).
	PqMaxFileSize *string `default:"1 MB" json:"pqMaxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `default:"5GB" json:"pqMaxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `default:"\\$CRIBL_HOME/state/queues" json:"pqPath"`
	// Codec to use to compress the persisted data.
	PqCompress *OutputServiceNowOutputPqCompressCompression `default:"none" json:"pqCompress"`
	// Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *OutputServiceNowQueueFullBehavior `default:"block" json:"pqOnBackpressure"`
	// In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
	PqMode     *OutputServiceNowMode       `default:"error" json:"pqMode"`
	PqControls *OutputServiceNowPqControls `json:"pqControls,omitempty"`
	Status     *TFStatus                   `json:"status,omitempty"`
}

func (o OutputServiceNow) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputServiceNow) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *OutputServiceNow) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *OutputServiceNow) GetType() *OutputServiceNowType {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *OutputServiceNow) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputServiceNow) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputServiceNow) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputServiceNow) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputServiceNow) GetEndpoint() *string {
	if o == nil {
		return nil
	}
	return o.Endpoint
}

func (o *OutputServiceNow) GetTokenSecret() string {
	if o == nil {
		return ""
	}
	return o.TokenSecret
}

func (o *OutputServiceNow) GetAuthTokenName() *string {
	if o == nil {
		return nil
	}
	return o.AuthTokenName
}

func (o *OutputServiceNow) GetOtlpVersion() *OutputServiceNowOTLPVersion {
	if o == nil {
		return nil
	}
	return o.OtlpVersion
}

func (o *OutputServiceNow) GetMaxPayloadSizeKB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadSizeKB
}

func (o *OutputServiceNow) GetProtocol() *OutputServiceNowProtocol {
	if o == nil {
		return nil
	}
	return o.Protocol
}

func (o *OutputServiceNow) GetCompress() *OutputServiceNowCompression {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *OutputServiceNow) GetHTTPCompress() *OutputServiceNowOutputCompression {
	if o == nil {
		return nil
	}
	return o.HTTPCompress
}

func (o *OutputServiceNow) GetHTTPTracesEndpointOverride() *string {
	if o == nil {
		return nil
	}
	return o.HTTPTracesEndpointOverride
}

func (o *OutputServiceNow) GetHTTPMetricsEndpointOverride() *string {
	if o == nil {
		return nil
	}
	return o.HTTPMetricsEndpointOverride
}

func (o *OutputServiceNow) GetHTTPLogsEndpointOverride() *string {
	if o == nil {
		return nil
	}
	return o.HTTPLogsEndpointOverride
}

func (o *OutputServiceNow) GetMetadata() []OutputServiceNowMetadata {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *OutputServiceNow) GetConcurrency() *float64 {
	if o == nil {
		return nil
	}
	return o.Concurrency
}

func (o *OutputServiceNow) GetTimeoutSec() *float64 {
	if o == nil {
		return nil
	}
	return o.TimeoutSec
}

func (o *OutputServiceNow) GetFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushPeriodSec
}

func (o *OutputServiceNow) GetFailedRequestLoggingMode() *OutputServiceNowFailedRequestLoggingMode {
	if o == nil {
		return nil
	}
	return o.FailedRequestLoggingMode
}

func (o *OutputServiceNow) GetConnectionTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.ConnectionTimeout
}

func (o *OutputServiceNow) GetKeepAliveTime() *float64 {
	if o == nil {
		return nil
	}
	return o.KeepAliveTime
}

func (o *OutputServiceNow) GetKeepAlive() *bool {
	if o == nil {
		return nil
	}
	return o.KeepAlive
}

func (o *OutputServiceNow) GetOnBackpressure() *OutputServiceNowBackpressureBehavior {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputServiceNow) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputServiceNow) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputServiceNow) GetUseRoundRobinDNS() *bool {
	if o == nil {
		return nil
	}
	return o.UseRoundRobinDNS
}

func (o *OutputServiceNow) GetExtraHTTPHeaders() []OutputServiceNowExtraHTTPHeaders {
	if o == nil {
		return nil
	}
	return o.ExtraHTTPHeaders
}

func (o *OutputServiceNow) GetSafeHeaders() []string {
	if o == nil {
		return nil
	}
	return o.SafeHeaders
}

func (o *OutputServiceNow) GetResponseRetrySettings() []OutputServiceNowResponseRetrySettings {
	if o == nil {
		return nil
	}
	return o.ResponseRetrySettings
}

func (o *OutputServiceNow) GetTimeoutRetrySettings() *OutputServiceNowTimeoutRetrySettings {
	if o == nil {
		return nil
	}
	return o.TimeoutRetrySettings
}

func (o *OutputServiceNow) GetResponseHonorRetryAfterHeader() *bool {
	if o == nil {
		return nil
	}
	return o.ResponseHonorRetryAfterHeader
}

func (o *OutputServiceNow) GetTLS() *OutputServiceNowTLSSettingsClientSide {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *OutputServiceNow) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputServiceNow) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputServiceNow) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputServiceNow) GetPqCompress() *OutputServiceNowOutputPqCompressCompression {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputServiceNow) GetPqOnBackpressure() *OutputServiceNowQueueFullBehavior {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputServiceNow) GetPqMode() *OutputServiceNowMode {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputServiceNow) GetPqControls() *OutputServiceNowPqControls {
	if o == nil {
		return nil
	}
	return o.PqControls
}

func (o *OutputServiceNow) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type OutputOpenTelemetryType string

const (
	OutputOpenTelemetryTypeOpenTelemetry OutputOpenTelemetryType = "open_telemetry"
)

func (e OutputOpenTelemetryType) ToPointer() *OutputOpenTelemetryType {
	return &e
}
func (e *OutputOpenTelemetryType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "open_telemetry":
		*e = OutputOpenTelemetryType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputOpenTelemetryType: %v", v)
	}
}

// OutputOpenTelemetryProtocol - Select a transport option for OpenTelemetry
type OutputOpenTelemetryProtocol string

const (
	OutputOpenTelemetryProtocolGrpc OutputOpenTelemetryProtocol = "grpc"
	OutputOpenTelemetryProtocolHTTP OutputOpenTelemetryProtocol = "http"
)

func (e OutputOpenTelemetryProtocol) ToPointer() *OutputOpenTelemetryProtocol {
	return &e
}
func (e *OutputOpenTelemetryProtocol) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "grpc":
		fallthrough
	case "http":
		*e = OutputOpenTelemetryProtocol(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputOpenTelemetryProtocol: %v", v)
	}
}

// OutputOpenTelemetryOTLPVersion - The version of OTLP Protobuf definitions to use when structuring data to send
type OutputOpenTelemetryOTLPVersion string

const (
	OutputOpenTelemetryOTLPVersionZeroDot10Dot0 OutputOpenTelemetryOTLPVersion = "0.10.0"
	OutputOpenTelemetryOTLPVersionOneDot3Dot1   OutputOpenTelemetryOTLPVersion = "1.3.1"
)

func (e OutputOpenTelemetryOTLPVersion) ToPointer() *OutputOpenTelemetryOTLPVersion {
	return &e
}
func (e *OutputOpenTelemetryOTLPVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "0.10.0":
		fallthrough
	case "1.3.1":
		*e = OutputOpenTelemetryOTLPVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputOpenTelemetryOTLPVersion: %v", v)
	}
}

// OutputOpenTelemetryCompression - Type of compression to apply to messages sent to the OpenTelemetry endpoint
type OutputOpenTelemetryCompression string

const (
	OutputOpenTelemetryCompressionNone    OutputOpenTelemetryCompression = "none"
	OutputOpenTelemetryCompressionDeflate OutputOpenTelemetryCompression = "deflate"
	OutputOpenTelemetryCompressionGzip    OutputOpenTelemetryCompression = "gzip"
)

func (e OutputOpenTelemetryCompression) ToPointer() *OutputOpenTelemetryCompression {
	return &e
}
func (e *OutputOpenTelemetryCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "deflate":
		fallthrough
	case "gzip":
		*e = OutputOpenTelemetryCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputOpenTelemetryCompression: %v", v)
	}
}

// OutputOpenTelemetryOutputCompression - Type of compression to apply to messages sent to the OpenTelemetry endpoint
type OutputOpenTelemetryOutputCompression string

const (
	OutputOpenTelemetryOutputCompressionNone OutputOpenTelemetryOutputCompression = "none"
	OutputOpenTelemetryOutputCompressionGzip OutputOpenTelemetryOutputCompression = "gzip"
)

func (e OutputOpenTelemetryOutputCompression) ToPointer() *OutputOpenTelemetryOutputCompression {
	return &e
}
func (e *OutputOpenTelemetryOutputCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = OutputOpenTelemetryOutputCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputOpenTelemetryOutputCompression: %v", v)
	}
}

// OutputOpenTelemetryAuthenticationType - OpenTelemetry authentication type
type OutputOpenTelemetryAuthenticationType string

const (
	OutputOpenTelemetryAuthenticationTypeNone              OutputOpenTelemetryAuthenticationType = "none"
	OutputOpenTelemetryAuthenticationTypeBasic             OutputOpenTelemetryAuthenticationType = "basic"
	OutputOpenTelemetryAuthenticationTypeCredentialsSecret OutputOpenTelemetryAuthenticationType = "credentialsSecret"
	OutputOpenTelemetryAuthenticationTypeToken             OutputOpenTelemetryAuthenticationType = "token"
	OutputOpenTelemetryAuthenticationTypeTextSecret        OutputOpenTelemetryAuthenticationType = "textSecret"
	OutputOpenTelemetryAuthenticationTypeOauth             OutputOpenTelemetryAuthenticationType = "oauth"
)

func (e OutputOpenTelemetryAuthenticationType) ToPointer() *OutputOpenTelemetryAuthenticationType {
	return &e
}
func (e *OutputOpenTelemetryAuthenticationType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "basic":
		fallthrough
	case "credentialsSecret":
		fallthrough
	case "token":
		fallthrough
	case "textSecret":
		fallthrough
	case "oauth":
		*e = OutputOpenTelemetryAuthenticationType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputOpenTelemetryAuthenticationType: %v", v)
	}
}

type OutputOpenTelemetryMetadata struct {
	Key   *string `default:"" json:"key"`
	Value string  `json:"value"`
}

func (o OutputOpenTelemetryMetadata) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputOpenTelemetryMetadata) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputOpenTelemetryMetadata) GetKey() *string {
	if o == nil {
		return nil
	}
	return o.Key
}

func (o *OutputOpenTelemetryMetadata) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// OutputOpenTelemetryFailedRequestLoggingMode - Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
type OutputOpenTelemetryFailedRequestLoggingMode string

const (
	OutputOpenTelemetryFailedRequestLoggingModePayload           OutputOpenTelemetryFailedRequestLoggingMode = "payload"
	OutputOpenTelemetryFailedRequestLoggingModePayloadAndHeaders OutputOpenTelemetryFailedRequestLoggingMode = "payloadAndHeaders"
	OutputOpenTelemetryFailedRequestLoggingModeNone              OutputOpenTelemetryFailedRequestLoggingMode = "none"
)

func (e OutputOpenTelemetryFailedRequestLoggingMode) ToPointer() *OutputOpenTelemetryFailedRequestLoggingMode {
	return &e
}
func (e *OutputOpenTelemetryFailedRequestLoggingMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "payload":
		fallthrough
	case "payloadAndHeaders":
		fallthrough
	case "none":
		*e = OutputOpenTelemetryFailedRequestLoggingMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputOpenTelemetryFailedRequestLoggingMode: %v", v)
	}
}

// OutputOpenTelemetryBackpressureBehavior - Whether to block, drop, or queue events when all receivers are exerting backpressure.
type OutputOpenTelemetryBackpressureBehavior string

const (
	OutputOpenTelemetryBackpressureBehaviorBlock OutputOpenTelemetryBackpressureBehavior = "block"
	OutputOpenTelemetryBackpressureBehaviorDrop  OutputOpenTelemetryBackpressureBehavior = "drop"
	OutputOpenTelemetryBackpressureBehaviorQueue OutputOpenTelemetryBackpressureBehavior = "queue"
)

func (e OutputOpenTelemetryBackpressureBehavior) ToPointer() *OutputOpenTelemetryBackpressureBehavior {
	return &e
}
func (e *OutputOpenTelemetryBackpressureBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		fallthrough
	case "queue":
		*e = OutputOpenTelemetryBackpressureBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputOpenTelemetryBackpressureBehavior: %v", v)
	}
}

type OutputOpenTelemetryOauthParams struct {
	// OAuth parameter name
	Name string `json:"name"`
	// OAuth parameter value
	Value string `json:"value"`
}

func (o *OutputOpenTelemetryOauthParams) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *OutputOpenTelemetryOauthParams) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type OutputOpenTelemetryOauthHeaders struct {
	// OAuth header name
	Name string `json:"name"`
	// OAuth header value
	Value string `json:"value"`
}

func (o *OutputOpenTelemetryOauthHeaders) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *OutputOpenTelemetryOauthHeaders) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type OutputOpenTelemetryExtraHTTPHeaders struct {
	// Field name
	Name *string `json:"name,omitempty"`
	// Field value
	Value string `json:"value"`
}

func (o *OutputOpenTelemetryExtraHTTPHeaders) GetName() *string {
	if o == nil {
		return nil
	}
	return o.Name
}

func (o *OutputOpenTelemetryExtraHTTPHeaders) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type OutputOpenTelemetryResponseRetrySettings struct {
	// The HTTP response status code that will trigger retries
	HTTPStatus float64 `json:"httpStatus"`
	// How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"1000" json:"initialBackoff"`
	// Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackoff *float64 `default:"10000" json:"maxBackoff"`
}

func (o OutputOpenTelemetryResponseRetrySettings) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputOpenTelemetryResponseRetrySettings) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputOpenTelemetryResponseRetrySettings) GetHTTPStatus() float64 {
	if o == nil {
		return 0.0
	}
	return o.HTTPStatus
}

func (o *OutputOpenTelemetryResponseRetrySettings) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *OutputOpenTelemetryResponseRetrySettings) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *OutputOpenTelemetryResponseRetrySettings) GetMaxBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackoff
}

type OutputOpenTelemetryTimeoutRetrySettings struct {
	// Enable to retry on request timeout
	TimeoutRetry *bool `default:"false" json:"timeoutRetry"`
	// How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"1000" json:"initialBackoff"`
	// Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackoff *float64 `default:"10000" json:"maxBackoff"`
}

func (o OutputOpenTelemetryTimeoutRetrySettings) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputOpenTelemetryTimeoutRetrySettings) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputOpenTelemetryTimeoutRetrySettings) GetTimeoutRetry() *bool {
	if o == nil {
		return nil
	}
	return o.TimeoutRetry
}

func (o *OutputOpenTelemetryTimeoutRetrySettings) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *OutputOpenTelemetryTimeoutRetrySettings) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *OutputOpenTelemetryTimeoutRetrySettings) GetMaxBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackoff
}

// OutputOpenTelemetryMinimumTLSVersion - Minimum TLS version to use when connecting
type OutputOpenTelemetryMinimumTLSVersion string

const (
	OutputOpenTelemetryMinimumTLSVersionTlSv1  OutputOpenTelemetryMinimumTLSVersion = "TLSv1"
	OutputOpenTelemetryMinimumTLSVersionTlSv11 OutputOpenTelemetryMinimumTLSVersion = "TLSv1.1"
	OutputOpenTelemetryMinimumTLSVersionTlSv12 OutputOpenTelemetryMinimumTLSVersion = "TLSv1.2"
	OutputOpenTelemetryMinimumTLSVersionTlSv13 OutputOpenTelemetryMinimumTLSVersion = "TLSv1.3"
)

func (e OutputOpenTelemetryMinimumTLSVersion) ToPointer() *OutputOpenTelemetryMinimumTLSVersion {
	return &e
}
func (e *OutputOpenTelemetryMinimumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = OutputOpenTelemetryMinimumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputOpenTelemetryMinimumTLSVersion: %v", v)
	}
}

// OutputOpenTelemetryMaximumTLSVersion - Maximum TLS version to use when connecting
type OutputOpenTelemetryMaximumTLSVersion string

const (
	OutputOpenTelemetryMaximumTLSVersionTlSv1  OutputOpenTelemetryMaximumTLSVersion = "TLSv1"
	OutputOpenTelemetryMaximumTLSVersionTlSv11 OutputOpenTelemetryMaximumTLSVersion = "TLSv1.1"
	OutputOpenTelemetryMaximumTLSVersionTlSv12 OutputOpenTelemetryMaximumTLSVersion = "TLSv1.2"
	OutputOpenTelemetryMaximumTLSVersionTlSv13 OutputOpenTelemetryMaximumTLSVersion = "TLSv1.3"
)

func (e OutputOpenTelemetryMaximumTLSVersion) ToPointer() *OutputOpenTelemetryMaximumTLSVersion {
	return &e
}
func (e *OutputOpenTelemetryMaximumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = OutputOpenTelemetryMaximumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputOpenTelemetryMaximumTLSVersion: %v", v)
	}
}

type OutputOpenTelemetryTLSSettingsClientSide struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Reject certs that are not authorized by a CA in the CA certificate path, or by another
	//                     trusted CA (e.g., the system's CA). Defaults to Yes. Overrides the toggle from Advanced Settings, when also present.
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// The name of the predefined certificate.
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Passphrase to use to decrypt private key.
	Passphrase *string `json:"passphrase,omitempty"`
	// Minimum TLS version to use when connecting
	MinVersion *OutputOpenTelemetryMinimumTLSVersion `json:"minVersion,omitempty"`
	// Maximum TLS version to use when connecting
	MaxVersion *OutputOpenTelemetryMaximumTLSVersion `json:"maxVersion,omitempty"`
}

func (o OutputOpenTelemetryTLSSettingsClientSide) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputOpenTelemetryTLSSettingsClientSide) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputOpenTelemetryTLSSettingsClientSide) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *OutputOpenTelemetryTLSSettingsClientSide) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputOpenTelemetryTLSSettingsClientSide) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *OutputOpenTelemetryTLSSettingsClientSide) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *OutputOpenTelemetryTLSSettingsClientSide) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *OutputOpenTelemetryTLSSettingsClientSide) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *OutputOpenTelemetryTLSSettingsClientSide) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *OutputOpenTelemetryTLSSettingsClientSide) GetMinVersion() *OutputOpenTelemetryMinimumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *OutputOpenTelemetryTLSSettingsClientSide) GetMaxVersion() *OutputOpenTelemetryMaximumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

// OutputOpenTelemetryOutputPqCompressCompression - Codec to use to compress the persisted data.
type OutputOpenTelemetryOutputPqCompressCompression string

const (
	OutputOpenTelemetryOutputPqCompressCompressionNone OutputOpenTelemetryOutputPqCompressCompression = "none"
	OutputOpenTelemetryOutputPqCompressCompressionGzip OutputOpenTelemetryOutputPqCompressCompression = "gzip"
)

func (e OutputOpenTelemetryOutputPqCompressCompression) ToPointer() *OutputOpenTelemetryOutputPqCompressCompression {
	return &e
}
func (e *OutputOpenTelemetryOutputPqCompressCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = OutputOpenTelemetryOutputPqCompressCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputOpenTelemetryOutputPqCompressCompression: %v", v)
	}
}

// OutputOpenTelemetryQueueFullBehavior - Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
type OutputOpenTelemetryQueueFullBehavior string

const (
	OutputOpenTelemetryQueueFullBehaviorBlock OutputOpenTelemetryQueueFullBehavior = "block"
	OutputOpenTelemetryQueueFullBehaviorDrop  OutputOpenTelemetryQueueFullBehavior = "drop"
)

func (e OutputOpenTelemetryQueueFullBehavior) ToPointer() *OutputOpenTelemetryQueueFullBehavior {
	return &e
}
func (e *OutputOpenTelemetryQueueFullBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputOpenTelemetryQueueFullBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputOpenTelemetryQueueFullBehavior: %v", v)
	}
}

// OutputOpenTelemetryMode - In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
type OutputOpenTelemetryMode string

const (
	OutputOpenTelemetryModeError        OutputOpenTelemetryMode = "error"
	OutputOpenTelemetryModeBackpressure OutputOpenTelemetryMode = "backpressure"
	OutputOpenTelemetryModeAlways       OutputOpenTelemetryMode = "always"
)

func (e OutputOpenTelemetryMode) ToPointer() *OutputOpenTelemetryMode {
	return &e
}
func (e *OutputOpenTelemetryMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "error":
		fallthrough
	case "backpressure":
		fallthrough
	case "always":
		*e = OutputOpenTelemetryMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputOpenTelemetryMode: %v", v)
	}
}

type OutputOpenTelemetryPqControls struct {
}

type OutputOpenTelemetry struct {
	// Unique ID for this output
	ID   *string                 `json:"id,omitempty"`
	Type OutputOpenTelemetryType `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Select a transport option for OpenTelemetry
	Protocol *OutputOpenTelemetryProtocol `default:"grpc" json:"protocol"`
	// The endpoint where OTel events will be sent. Enter any valid URL or an IP address (IPv4 or IPv6; enclose IPv6 addresses in square brackets). Unspecified ports will default to 4317, unless the endpoint is an HTTPS-based URL or TLS is enabled, in which case 443 will be used.
	Endpoint string `json:"endpoint"`
	// The version of OTLP Protobuf definitions to use when structuring data to send
	OtlpVersion *OutputOpenTelemetryOTLPVersion `default:"0.10.0" json:"otlpVersion"`
	// Type of compression to apply to messages sent to the OpenTelemetry endpoint
	Compress *OutputOpenTelemetryCompression `default:"gzip" json:"compress"`
	// Type of compression to apply to messages sent to the OpenTelemetry endpoint
	HTTPCompress *OutputOpenTelemetryOutputCompression `default:"gzip" json:"httpCompress"`
	// OpenTelemetry authentication type
	AuthType *OutputOpenTelemetryAuthenticationType `default:"none" json:"authType"`
	// If you want to send traces to the default `{endpoint}/v1/traces` endpoint, leave this field empty; otherwise, specify the desired endpoint
	HTTPTracesEndpointOverride *string `json:"httpTracesEndpointOverride,omitempty"`
	// If you want to send metrics to the default `{endpoint}/v1/metrics` endpoint, leave this field empty; otherwise, specify the desired endpoint
	HTTPMetricsEndpointOverride *string `json:"httpMetricsEndpointOverride,omitempty"`
	// If you want to send logs to the default `{endpoint}/v1/logs` endpoint, leave this field empty; otherwise, specify the desired endpoint
	HTTPLogsEndpointOverride *string `json:"httpLogsEndpointOverride,omitempty"`
	// List of key-value pairs to send with each gRPC request. Value supports JavaScript expressions that are evaluated just once, when the destination gets started. To pass credentials as metadata, use 'C.Secret'.
	Metadata []OutputOpenTelemetryMetadata `json:"metadata,omitempty"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `default:"5" json:"concurrency"`
	// Maximum size, in KB, of the request body
	MaxPayloadSizeKB *float64 `default:"4096" json:"maxPayloadSizeKB"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `default:"30" json:"timeoutSec"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Max body size.
	FlushPeriodSec *float64 `default:"1" json:"flushPeriodSec"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *OutputOpenTelemetryFailedRequestLoggingMode `default:"none" json:"failedRequestLoggingMode"`
	// Amount of time (milliseconds) to wait for the connection to establish before retrying
	ConnectionTimeout *float64 `default:"10000" json:"connectionTimeout"`
	// How often the sender should ping the peer to keep the connection open
	KeepAliveTime *float64 `default:"30" json:"keepAliveTime"`
	// Disable to close the connection immediately after sending the outgoing request
	KeepAlive *bool `default:"true" json:"keepAlive"`
	// Whether to block, drop, or queue events when all receivers are exerting backpressure.
	OnBackpressure *OutputOpenTelemetryBackpressureBehavior `default:"block" json:"onBackpressure"`
	Description    *string                                  `json:"description,omitempty"`
	Username       *string                                  `json:"username,omitempty"`
	Password       *string                                  `json:"password,omitempty"`
	// Bearer token to include in the authorization header
	Token *string `json:"token,omitempty"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// URL for OAuth
	LoginURL *string `json:"loginUrl,omitempty"`
	// Secret parameter name to pass in request body
	SecretParamName *string `json:"secretParamName,omitempty"`
	// Secret parameter value to pass in request body
	Secret *string `json:"secret,omitempty"`
	// Name of the auth token attribute in the OAuth response. Can be top-level (e.g., 'token'); or nested, using a period (e.g., 'data.token').
	TokenAttributeName *string `json:"tokenAttributeName,omitempty"`
	// JavaScript expression to compute the Authorization header value to pass in requests. The value `${token}` is used to reference the token obtained from authentication, e.g.: `Bearer ${token}`.
	AuthHeaderExpr *string `default:"Bearer \\${token}" json:"authHeaderExpr"`
	// How often the OAuth token should be refreshed.
	TokenTimeoutSecs *float64 `default:"3600" json:"tokenTimeoutSecs"`
	// Additional parameters to send in the OAuth login request. @{product} will combine the secret with these parameters, and will send the URL-encoded result in a POST request to the endpoint specified in the 'Login URL'. We'll automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthParams []OutputOpenTelemetryOauthParams `json:"oauthParams,omitempty"`
	// Additional headers to send in the OAuth login request. @{product} will automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthHeaders []OutputOpenTelemetryOauthHeaders `json:"oauthHeaders,omitempty"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Defaults to Yes. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Enables round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `default:"false" json:"useRoundRobinDns"`
	// Headers to add to all events.
	ExtraHTTPHeaders []OutputOpenTelemetryExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable).
	ResponseRetrySettings []OutputOpenTelemetryResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *OutputOpenTelemetryTimeoutRetrySettings   `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool                                     `default:"false" json:"responseHonorRetryAfterHeader"`
	TLS                           *OutputOpenTelemetryTLSSettingsClientSide `json:"tls,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.).
	PqMaxFileSize *string `default:"1 MB" json:"pqMaxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `default:"5GB" json:"pqMaxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `default:"\\$CRIBL_HOME/state/queues" json:"pqPath"`
	// Codec to use to compress the persisted data.
	PqCompress *OutputOpenTelemetryOutputPqCompressCompression `default:"none" json:"pqCompress"`
	// Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *OutputOpenTelemetryQueueFullBehavior `default:"block" json:"pqOnBackpressure"`
	// In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
	PqMode     *OutputOpenTelemetryMode       `default:"error" json:"pqMode"`
	PqControls *OutputOpenTelemetryPqControls `json:"pqControls,omitempty"`
	Status     *TFStatus                      `json:"status,omitempty"`
}

func (o OutputOpenTelemetry) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputOpenTelemetry) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *OutputOpenTelemetry) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *OutputOpenTelemetry) GetType() OutputOpenTelemetryType {
	if o == nil {
		return OutputOpenTelemetryType("")
	}
	return o.Type
}

func (o *OutputOpenTelemetry) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputOpenTelemetry) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputOpenTelemetry) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputOpenTelemetry) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputOpenTelemetry) GetProtocol() *OutputOpenTelemetryProtocol {
	if o == nil {
		return nil
	}
	return o.Protocol
}

func (o *OutputOpenTelemetry) GetEndpoint() string {
	if o == nil {
		return ""
	}
	return o.Endpoint
}

func (o *OutputOpenTelemetry) GetOtlpVersion() *OutputOpenTelemetryOTLPVersion {
	if o == nil {
		return nil
	}
	return o.OtlpVersion
}

func (o *OutputOpenTelemetry) GetCompress() *OutputOpenTelemetryCompression {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *OutputOpenTelemetry) GetHTTPCompress() *OutputOpenTelemetryOutputCompression {
	if o == nil {
		return nil
	}
	return o.HTTPCompress
}

func (o *OutputOpenTelemetry) GetAuthType() *OutputOpenTelemetryAuthenticationType {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *OutputOpenTelemetry) GetHTTPTracesEndpointOverride() *string {
	if o == nil {
		return nil
	}
	return o.HTTPTracesEndpointOverride
}

func (o *OutputOpenTelemetry) GetHTTPMetricsEndpointOverride() *string {
	if o == nil {
		return nil
	}
	return o.HTTPMetricsEndpointOverride
}

func (o *OutputOpenTelemetry) GetHTTPLogsEndpointOverride() *string {
	if o == nil {
		return nil
	}
	return o.HTTPLogsEndpointOverride
}

func (o *OutputOpenTelemetry) GetMetadata() []OutputOpenTelemetryMetadata {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *OutputOpenTelemetry) GetConcurrency() *float64 {
	if o == nil {
		return nil
	}
	return o.Concurrency
}

func (o *OutputOpenTelemetry) GetMaxPayloadSizeKB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadSizeKB
}

func (o *OutputOpenTelemetry) GetTimeoutSec() *float64 {
	if o == nil {
		return nil
	}
	return o.TimeoutSec
}

func (o *OutputOpenTelemetry) GetFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushPeriodSec
}

func (o *OutputOpenTelemetry) GetFailedRequestLoggingMode() *OutputOpenTelemetryFailedRequestLoggingMode {
	if o == nil {
		return nil
	}
	return o.FailedRequestLoggingMode
}

func (o *OutputOpenTelemetry) GetConnectionTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.ConnectionTimeout
}

func (o *OutputOpenTelemetry) GetKeepAliveTime() *float64 {
	if o == nil {
		return nil
	}
	return o.KeepAliveTime
}

func (o *OutputOpenTelemetry) GetKeepAlive() *bool {
	if o == nil {
		return nil
	}
	return o.KeepAlive
}

func (o *OutputOpenTelemetry) GetOnBackpressure() *OutputOpenTelemetryBackpressureBehavior {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputOpenTelemetry) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputOpenTelemetry) GetUsername() *string {
	if o == nil {
		return nil
	}
	return o.Username
}

func (o *OutputOpenTelemetry) GetPassword() *string {
	if o == nil {
		return nil
	}
	return o.Password
}

func (o *OutputOpenTelemetry) GetToken() *string {
	if o == nil {
		return nil
	}
	return o.Token
}

func (o *OutputOpenTelemetry) GetCredentialsSecret() *string {
	if o == nil {
		return nil
	}
	return o.CredentialsSecret
}

func (o *OutputOpenTelemetry) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *OutputOpenTelemetry) GetLoginURL() *string {
	if o == nil {
		return nil
	}
	return o.LoginURL
}

func (o *OutputOpenTelemetry) GetSecretParamName() *string {
	if o == nil {
		return nil
	}
	return o.SecretParamName
}

func (o *OutputOpenTelemetry) GetSecret() *string {
	if o == nil {
		return nil
	}
	return o.Secret
}

func (o *OutputOpenTelemetry) GetTokenAttributeName() *string {
	if o == nil {
		return nil
	}
	return o.TokenAttributeName
}

func (o *OutputOpenTelemetry) GetAuthHeaderExpr() *string {
	if o == nil {
		return nil
	}
	return o.AuthHeaderExpr
}

func (o *OutputOpenTelemetry) GetTokenTimeoutSecs() *float64 {
	if o == nil {
		return nil
	}
	return o.TokenTimeoutSecs
}

func (o *OutputOpenTelemetry) GetOauthParams() []OutputOpenTelemetryOauthParams {
	if o == nil {
		return nil
	}
	return o.OauthParams
}

func (o *OutputOpenTelemetry) GetOauthHeaders() []OutputOpenTelemetryOauthHeaders {
	if o == nil {
		return nil
	}
	return o.OauthHeaders
}

func (o *OutputOpenTelemetry) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputOpenTelemetry) GetUseRoundRobinDNS() *bool {
	if o == nil {
		return nil
	}
	return o.UseRoundRobinDNS
}

func (o *OutputOpenTelemetry) GetExtraHTTPHeaders() []OutputOpenTelemetryExtraHTTPHeaders {
	if o == nil {
		return nil
	}
	return o.ExtraHTTPHeaders
}

func (o *OutputOpenTelemetry) GetSafeHeaders() []string {
	if o == nil {
		return nil
	}
	return o.SafeHeaders
}

func (o *OutputOpenTelemetry) GetResponseRetrySettings() []OutputOpenTelemetryResponseRetrySettings {
	if o == nil {
		return nil
	}
	return o.ResponseRetrySettings
}

func (o *OutputOpenTelemetry) GetTimeoutRetrySettings() *OutputOpenTelemetryTimeoutRetrySettings {
	if o == nil {
		return nil
	}
	return o.TimeoutRetrySettings
}

func (o *OutputOpenTelemetry) GetResponseHonorRetryAfterHeader() *bool {
	if o == nil {
		return nil
	}
	return o.ResponseHonorRetryAfterHeader
}

func (o *OutputOpenTelemetry) GetTLS() *OutputOpenTelemetryTLSSettingsClientSide {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *OutputOpenTelemetry) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputOpenTelemetry) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputOpenTelemetry) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputOpenTelemetry) GetPqCompress() *OutputOpenTelemetryOutputPqCompressCompression {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputOpenTelemetry) GetPqOnBackpressure() *OutputOpenTelemetryQueueFullBehavior {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputOpenTelemetry) GetPqMode() *OutputOpenTelemetryMode {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputOpenTelemetry) GetPqControls() *OutputOpenTelemetryPqControls {
	if o == nil {
		return nil
	}
	return o.PqControls
}

func (o *OutputOpenTelemetry) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type OutputRingType string

const (
	OutputRingTypeRing OutputRingType = "ring"
)

func (e OutputRingType) ToPointer() *OutputRingType {
	return &e
}
func (e *OutputRingType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "ring":
		*e = OutputRingType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputRingType: %v", v)
	}
}

// OutputRingDataFormat - Format of the output data.
type OutputRingDataFormat string

const (
	OutputRingDataFormatJSON OutputRingDataFormat = "json"
	OutputRingDataFormatRaw  OutputRingDataFormat = "raw"
)

func (e OutputRingDataFormat) ToPointer() *OutputRingDataFormat {
	return &e
}
func (e *OutputRingDataFormat) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "json":
		fallthrough
	case "raw":
		*e = OutputRingDataFormat(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputRingDataFormat: %v", v)
	}
}

type DataCompressionFormat string

const (
	DataCompressionFormatNone DataCompressionFormat = "none"
	DataCompressionFormatGzip DataCompressionFormat = "gzip"
)

func (e DataCompressionFormat) ToPointer() *DataCompressionFormat {
	return &e
}
func (e *DataCompressionFormat) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = DataCompressionFormat(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DataCompressionFormat: %v", v)
	}
}

// OutputRingBackpressureBehavior - Whether to block or drop events when all receivers are exerting backpressure
type OutputRingBackpressureBehavior string

const (
	OutputRingBackpressureBehaviorBlock OutputRingBackpressureBehavior = "block"
	OutputRingBackpressureBehaviorDrop  OutputRingBackpressureBehavior = "drop"
)

func (e OutputRingBackpressureBehavior) ToPointer() *OutputRingBackpressureBehavior {
	return &e
}
func (e *OutputRingBackpressureBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputRingBackpressureBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputRingBackpressureBehavior: %v", v)
	}
}

type OutputRing struct {
	// Unique ID for this output
	ID   string         `json:"id"`
	Type OutputRingType `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Format of the output data.
	Format *OutputRingDataFormat `default:"json" json:"format"`
	// JS expression to define how files are partitioned and organized. If left blank, Cribl Stream will fallback on event.__partition.
	PartitionExpr *string `json:"partitionExpr,omitempty"`
	// Maximum disk space allowed to be consumed (examples: 420MB, 4GB). When limit is reached, older data will be deleted.
	MaxDataSize *string `default:"1GB" json:"maxDataSize"`
	// Maximum amount of time to retain data (examples: 2h, 4d). When limit is reached, older data will be deleted.
	MaxDataTime *string                `default:"24h" json:"maxDataTime"`
	Compress    *DataCompressionFormat `default:"gzip" json:"compress"`
	// Path to use to write metrics. Defaults to $CRIBL_HOME/state/<id>
	DestPath *string `json:"destPath,omitempty"`
	// Whether to block or drop events when all receivers are exerting backpressure
	OnBackpressure *OutputRingBackpressureBehavior `default:"block" json:"onBackpressure"`
	Description    *string                         `json:"description,omitempty"`
	Status         *TFStatus                       `json:"status,omitempty"`
}

func (o OutputRing) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputRing) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *OutputRing) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *OutputRing) GetType() OutputRingType {
	if o == nil {
		return OutputRingType("")
	}
	return o.Type
}

func (o *OutputRing) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputRing) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputRing) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputRing) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputRing) GetFormat() *OutputRingDataFormat {
	if o == nil {
		return nil
	}
	return o.Format
}

func (o *OutputRing) GetPartitionExpr() *string {
	if o == nil {
		return nil
	}
	return o.PartitionExpr
}

func (o *OutputRing) GetMaxDataSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxDataSize
}

func (o *OutputRing) GetMaxDataTime() *string {
	if o == nil {
		return nil
	}
	return o.MaxDataTime
}

func (o *OutputRing) GetCompress() *DataCompressionFormat {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *OutputRing) GetDestPath() *string {
	if o == nil {
		return nil
	}
	return o.DestPath
}

func (o *OutputRing) GetOnBackpressure() *OutputRingBackpressureBehavior {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputRing) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputRing) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type OutputPrometheusType string

const (
	OutputPrometheusTypePrometheus OutputPrometheusType = "prometheus"
)

func (e OutputPrometheusType) ToPointer() *OutputPrometheusType {
	return &e
}
func (e *OutputPrometheusType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "prometheus":
		*e = OutputPrometheusType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputPrometheusType: %v", v)
	}
}

type OutputPrometheusExtraHTTPHeaders struct {
	// Field name
	Name *string `json:"name,omitempty"`
	// Field value
	Value string `json:"value"`
}

func (o *OutputPrometheusExtraHTTPHeaders) GetName() *string {
	if o == nil {
		return nil
	}
	return o.Name
}

func (o *OutputPrometheusExtraHTTPHeaders) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// OutputPrometheusFailedRequestLoggingMode - Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
type OutputPrometheusFailedRequestLoggingMode string

const (
	OutputPrometheusFailedRequestLoggingModePayload           OutputPrometheusFailedRequestLoggingMode = "payload"
	OutputPrometheusFailedRequestLoggingModePayloadAndHeaders OutputPrometheusFailedRequestLoggingMode = "payloadAndHeaders"
	OutputPrometheusFailedRequestLoggingModeNone              OutputPrometheusFailedRequestLoggingMode = "none"
)

func (e OutputPrometheusFailedRequestLoggingMode) ToPointer() *OutputPrometheusFailedRequestLoggingMode {
	return &e
}
func (e *OutputPrometheusFailedRequestLoggingMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "payload":
		fallthrough
	case "payloadAndHeaders":
		fallthrough
	case "none":
		*e = OutputPrometheusFailedRequestLoggingMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputPrometheusFailedRequestLoggingMode: %v", v)
	}
}

type OutputPrometheusResponseRetrySettings struct {
	// The HTTP response status code that will trigger retries
	HTTPStatus float64 `json:"httpStatus"`
	// How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"1000" json:"initialBackoff"`
	// Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackoff *float64 `default:"10000" json:"maxBackoff"`
}

func (o OutputPrometheusResponseRetrySettings) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputPrometheusResponseRetrySettings) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputPrometheusResponseRetrySettings) GetHTTPStatus() float64 {
	if o == nil {
		return 0.0
	}
	return o.HTTPStatus
}

func (o *OutputPrometheusResponseRetrySettings) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *OutputPrometheusResponseRetrySettings) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *OutputPrometheusResponseRetrySettings) GetMaxBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackoff
}

type OutputPrometheusTimeoutRetrySettings struct {
	// Enable to retry on request timeout
	TimeoutRetry *bool `default:"false" json:"timeoutRetry"`
	// How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"1000" json:"initialBackoff"`
	// Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackoff *float64 `default:"10000" json:"maxBackoff"`
}

func (o OutputPrometheusTimeoutRetrySettings) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputPrometheusTimeoutRetrySettings) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputPrometheusTimeoutRetrySettings) GetTimeoutRetry() *bool {
	if o == nil {
		return nil
	}
	return o.TimeoutRetry
}

func (o *OutputPrometheusTimeoutRetrySettings) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *OutputPrometheusTimeoutRetrySettings) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *OutputPrometheusTimeoutRetrySettings) GetMaxBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackoff
}

// OutputPrometheusBackpressureBehavior - Whether to block, drop, or queue events when all receivers are exerting backpressure.
type OutputPrometheusBackpressureBehavior string

const (
	OutputPrometheusBackpressureBehaviorBlock OutputPrometheusBackpressureBehavior = "block"
	OutputPrometheusBackpressureBehaviorDrop  OutputPrometheusBackpressureBehavior = "drop"
	OutputPrometheusBackpressureBehaviorQueue OutputPrometheusBackpressureBehavior = "queue"
)

func (e OutputPrometheusBackpressureBehavior) ToPointer() *OutputPrometheusBackpressureBehavior {
	return &e
}
func (e *OutputPrometheusBackpressureBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		fallthrough
	case "queue":
		*e = OutputPrometheusBackpressureBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputPrometheusBackpressureBehavior: %v", v)
	}
}

// OutputPrometheusAuthenticationType - Remote Write authentication type
type OutputPrometheusAuthenticationType string

const (
	OutputPrometheusAuthenticationTypeNone              OutputPrometheusAuthenticationType = "none"
	OutputPrometheusAuthenticationTypeBasic             OutputPrometheusAuthenticationType = "basic"
	OutputPrometheusAuthenticationTypeCredentialsSecret OutputPrometheusAuthenticationType = "credentialsSecret"
	OutputPrometheusAuthenticationTypeToken             OutputPrometheusAuthenticationType = "token"
	OutputPrometheusAuthenticationTypeTextSecret        OutputPrometheusAuthenticationType = "textSecret"
	OutputPrometheusAuthenticationTypeOauth             OutputPrometheusAuthenticationType = "oauth"
)

func (e OutputPrometheusAuthenticationType) ToPointer() *OutputPrometheusAuthenticationType {
	return &e
}
func (e *OutputPrometheusAuthenticationType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "basic":
		fallthrough
	case "credentialsSecret":
		fallthrough
	case "token":
		fallthrough
	case "textSecret":
		fallthrough
	case "oauth":
		*e = OutputPrometheusAuthenticationType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputPrometheusAuthenticationType: %v", v)
	}
}

// OutputPrometheusCompression - Codec to use to compress the persisted data.
type OutputPrometheusCompression string

const (
	OutputPrometheusCompressionNone OutputPrometheusCompression = "none"
	OutputPrometheusCompressionGzip OutputPrometheusCompression = "gzip"
)

func (e OutputPrometheusCompression) ToPointer() *OutputPrometheusCompression {
	return &e
}
func (e *OutputPrometheusCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = OutputPrometheusCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputPrometheusCompression: %v", v)
	}
}

// OutputPrometheusQueueFullBehavior - Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
type OutputPrometheusQueueFullBehavior string

const (
	OutputPrometheusQueueFullBehaviorBlock OutputPrometheusQueueFullBehavior = "block"
	OutputPrometheusQueueFullBehaviorDrop  OutputPrometheusQueueFullBehavior = "drop"
)

func (e OutputPrometheusQueueFullBehavior) ToPointer() *OutputPrometheusQueueFullBehavior {
	return &e
}
func (e *OutputPrometheusQueueFullBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputPrometheusQueueFullBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputPrometheusQueueFullBehavior: %v", v)
	}
}

// OutputPrometheusMode - In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
type OutputPrometheusMode string

const (
	OutputPrometheusModeError        OutputPrometheusMode = "error"
	OutputPrometheusModeBackpressure OutputPrometheusMode = "backpressure"
	OutputPrometheusModeAlways       OutputPrometheusMode = "always"
)

func (e OutputPrometheusMode) ToPointer() *OutputPrometheusMode {
	return &e
}
func (e *OutputPrometheusMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "error":
		fallthrough
	case "backpressure":
		fallthrough
	case "always":
		*e = OutputPrometheusMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputPrometheusMode: %v", v)
	}
}

type OutputPrometheusPqControls struct {
}

type OutputPrometheusOauthParams struct {
	// OAuth parameter name
	Name string `json:"name"`
	// OAuth parameter value
	Value string `json:"value"`
}

func (o *OutputPrometheusOauthParams) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *OutputPrometheusOauthParams) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type OutputPrometheusOauthHeaders struct {
	// OAuth header name
	Name string `json:"name"`
	// OAuth header value
	Value string `json:"value"`
}

func (o *OutputPrometheusOauthHeaders) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *OutputPrometheusOauthHeaders) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type OutputPrometheus struct {
	// Unique ID for this output
	ID   *string              `json:"id,omitempty"`
	Type OutputPrometheusType `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards. These fields are added as dimensions to generated metrics.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// The endpoint to send metrics to.
	URL string `json:"url"`
	// A JS expression that can be used to rename metrics. E.g.: name.replace(/\./g, '_') will replace all '.' characters in a metric's name with the supported '_' character. Use the 'name' global variable to access the metric's name.  You can access event fields' values via __e.<fieldName>.
	MetricRenameExpr *string `default:"name.replace(/[^a-zA-Z0-9_]/g, '_')" json:"metricRenameExpr"`
	// Whether to generate and send metadata (`type` and `metricFamilyName`) requests.
	SendMetadata *bool `default:"true" json:"sendMetadata"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `default:"5" json:"concurrency"`
	// Maximum size, in KB, of the request body
	MaxPayloadSizeKB *float64 `default:"4096" json:"maxPayloadSizeKB"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited).
	MaxPayloadEvents *float64 `default:"0" json:"maxPayloadEvents"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Defaults to Yes. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `default:"30" json:"timeoutSec"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Max body size.
	FlushPeriodSec *float64 `default:"1" json:"flushPeriodSec"`
	// Headers to add to all events.
	ExtraHTTPHeaders []OutputPrometheusExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// Enables round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `default:"false" json:"useRoundRobinDns"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *OutputPrometheusFailedRequestLoggingMode `default:"none" json:"failedRequestLoggingMode"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable).
	ResponseRetrySettings []OutputPrometheusResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *OutputPrometheusTimeoutRetrySettings   `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `default:"false" json:"responseHonorRetryAfterHeader"`
	// Whether to block, drop, or queue events when all receivers are exerting backpressure.
	OnBackpressure *OutputPrometheusBackpressureBehavior `default:"block" json:"onBackpressure"`
	// Remote Write authentication type
	AuthType    *OutputPrometheusAuthenticationType `default:"none" json:"authType"`
	Description *string                             `json:"description,omitempty"`
	// How frequently metrics metadata is sent out. Value cannot be smaller than the base Flush period (sec) set above.
	MetricsFlushPeriodSec *float64 `default:"60" json:"metricsFlushPeriodSec"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.).
	PqMaxFileSize *string `default:"1 MB" json:"pqMaxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `default:"5GB" json:"pqMaxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `default:"\\$CRIBL_HOME/state/queues" json:"pqPath"`
	// Codec to use to compress the persisted data.
	PqCompress *OutputPrometheusCompression `default:"none" json:"pqCompress"`
	// Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *OutputPrometheusQueueFullBehavior `default:"block" json:"pqOnBackpressure"`
	// In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
	PqMode     *OutputPrometheusMode       `default:"error" json:"pqMode"`
	PqControls *OutputPrometheusPqControls `json:"pqControls,omitempty"`
	Username   *string                     `json:"username,omitempty"`
	Password   *string                     `json:"password,omitempty"`
	// Bearer token to include in the authorization header
	Token *string `json:"token,omitempty"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// URL for OAuth
	LoginURL *string `json:"loginUrl,omitempty"`
	// Secret parameter name to pass in request body
	SecretParamName *string `json:"secretParamName,omitempty"`
	// Secret parameter value to pass in request body
	Secret *string `json:"secret,omitempty"`
	// Name of the auth token attribute in the OAuth response. Can be top-level (e.g., 'token'); or nested, using a period (e.g., 'data.token').
	TokenAttributeName *string `json:"tokenAttributeName,omitempty"`
	// JavaScript expression to compute the Authorization header value to pass in requests. The value `${token}` is used to reference the token obtained from authentication, e.g.: `Bearer ${token}`.
	AuthHeaderExpr *string `default:"Bearer \\${token}" json:"authHeaderExpr"`
	// How often the OAuth token should be refreshed.
	TokenTimeoutSecs *float64 `default:"3600" json:"tokenTimeoutSecs"`
	// Additional parameters to send in the OAuth login request. @{product} will combine the secret with these parameters, and will send the URL-encoded result in a POST request to the endpoint specified in the 'Login URL'. We'll automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthParams []OutputPrometheusOauthParams `json:"oauthParams,omitempty"`
	// Additional headers to send in the OAuth login request. @{product} will automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthHeaders []OutputPrometheusOauthHeaders `json:"oauthHeaders,omitempty"`
	Status       *TFStatus                      `json:"status,omitempty"`
}

func (o OutputPrometheus) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputPrometheus) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *OutputPrometheus) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *OutputPrometheus) GetType() OutputPrometheusType {
	if o == nil {
		return OutputPrometheusType("")
	}
	return o.Type
}

func (o *OutputPrometheus) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputPrometheus) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputPrometheus) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputPrometheus) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputPrometheus) GetURL() string {
	if o == nil {
		return ""
	}
	return o.URL
}

func (o *OutputPrometheus) GetMetricRenameExpr() *string {
	if o == nil {
		return nil
	}
	return o.MetricRenameExpr
}

func (o *OutputPrometheus) GetSendMetadata() *bool {
	if o == nil {
		return nil
	}
	return o.SendMetadata
}

func (o *OutputPrometheus) GetConcurrency() *float64 {
	if o == nil {
		return nil
	}
	return o.Concurrency
}

func (o *OutputPrometheus) GetMaxPayloadSizeKB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadSizeKB
}

func (o *OutputPrometheus) GetMaxPayloadEvents() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadEvents
}

func (o *OutputPrometheus) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputPrometheus) GetTimeoutSec() *float64 {
	if o == nil {
		return nil
	}
	return o.TimeoutSec
}

func (o *OutputPrometheus) GetFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushPeriodSec
}

func (o *OutputPrometheus) GetExtraHTTPHeaders() []OutputPrometheusExtraHTTPHeaders {
	if o == nil {
		return nil
	}
	return o.ExtraHTTPHeaders
}

func (o *OutputPrometheus) GetUseRoundRobinDNS() *bool {
	if o == nil {
		return nil
	}
	return o.UseRoundRobinDNS
}

func (o *OutputPrometheus) GetFailedRequestLoggingMode() *OutputPrometheusFailedRequestLoggingMode {
	if o == nil {
		return nil
	}
	return o.FailedRequestLoggingMode
}

func (o *OutputPrometheus) GetSafeHeaders() []string {
	if o == nil {
		return nil
	}
	return o.SafeHeaders
}

func (o *OutputPrometheus) GetResponseRetrySettings() []OutputPrometheusResponseRetrySettings {
	if o == nil {
		return nil
	}
	return o.ResponseRetrySettings
}

func (o *OutputPrometheus) GetTimeoutRetrySettings() *OutputPrometheusTimeoutRetrySettings {
	if o == nil {
		return nil
	}
	return o.TimeoutRetrySettings
}

func (o *OutputPrometheus) GetResponseHonorRetryAfterHeader() *bool {
	if o == nil {
		return nil
	}
	return o.ResponseHonorRetryAfterHeader
}

func (o *OutputPrometheus) GetOnBackpressure() *OutputPrometheusBackpressureBehavior {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputPrometheus) GetAuthType() *OutputPrometheusAuthenticationType {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *OutputPrometheus) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputPrometheus) GetMetricsFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.MetricsFlushPeriodSec
}

func (o *OutputPrometheus) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputPrometheus) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputPrometheus) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputPrometheus) GetPqCompress() *OutputPrometheusCompression {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputPrometheus) GetPqOnBackpressure() *OutputPrometheusQueueFullBehavior {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputPrometheus) GetPqMode() *OutputPrometheusMode {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputPrometheus) GetPqControls() *OutputPrometheusPqControls {
	if o == nil {
		return nil
	}
	return o.PqControls
}

func (o *OutputPrometheus) GetUsername() *string {
	if o == nil {
		return nil
	}
	return o.Username
}

func (o *OutputPrometheus) GetPassword() *string {
	if o == nil {
		return nil
	}
	return o.Password
}

func (o *OutputPrometheus) GetToken() *string {
	if o == nil {
		return nil
	}
	return o.Token
}

func (o *OutputPrometheus) GetCredentialsSecret() *string {
	if o == nil {
		return nil
	}
	return o.CredentialsSecret
}

func (o *OutputPrometheus) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *OutputPrometheus) GetLoginURL() *string {
	if o == nil {
		return nil
	}
	return o.LoginURL
}

func (o *OutputPrometheus) GetSecretParamName() *string {
	if o == nil {
		return nil
	}
	return o.SecretParamName
}

func (o *OutputPrometheus) GetSecret() *string {
	if o == nil {
		return nil
	}
	return o.Secret
}

func (o *OutputPrometheus) GetTokenAttributeName() *string {
	if o == nil {
		return nil
	}
	return o.TokenAttributeName
}

func (o *OutputPrometheus) GetAuthHeaderExpr() *string {
	if o == nil {
		return nil
	}
	return o.AuthHeaderExpr
}

func (o *OutputPrometheus) GetTokenTimeoutSecs() *float64 {
	if o == nil {
		return nil
	}
	return o.TokenTimeoutSecs
}

func (o *OutputPrometheus) GetOauthParams() []OutputPrometheusOauthParams {
	if o == nil {
		return nil
	}
	return o.OauthParams
}

func (o *OutputPrometheus) GetOauthHeaders() []OutputPrometheusOauthHeaders {
	if o == nil {
		return nil
	}
	return o.OauthHeaders
}

func (o *OutputPrometheus) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type OutputLokiType string

const (
	OutputLokiTypeLoki OutputLokiType = "loki"
)

func (e OutputLokiType) ToPointer() *OutputLokiType {
	return &e
}
func (e *OutputLokiType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "loki":
		*e = OutputLokiType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputLokiType: %v", v)
	}
}

// OutputLokiMessageFormat - Which format to use when sending logs to Loki (Protobuf or JSON).  Defaults to Protobuf.
type OutputLokiMessageFormat string

const (
	OutputLokiMessageFormatProtobuf OutputLokiMessageFormat = "protobuf"
	OutputLokiMessageFormatJSON     OutputLokiMessageFormat = "json"
)

func (e OutputLokiMessageFormat) ToPointer() *OutputLokiMessageFormat {
	return &e
}
func (e *OutputLokiMessageFormat) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "protobuf":
		fallthrough
	case "json":
		*e = OutputLokiMessageFormat(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputLokiMessageFormat: %v", v)
	}
}

type Labels struct {
	// Name of the label.
	Name *string `default:"" json:"name"`
	// Value of the label.
	Value string `json:"value"`
}

func (l Labels) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(l, "", false)
}

func (l *Labels) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &l, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *Labels) GetName() *string {
	if o == nil {
		return nil
	}
	return o.Name
}

func (o *Labels) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// OutputLokiAuthenticationType - The authentication method to use for the HTTP requests
type OutputLokiAuthenticationType string

const (
	OutputLokiAuthenticationTypeNone              OutputLokiAuthenticationType = "none"
	OutputLokiAuthenticationTypeToken             OutputLokiAuthenticationType = "token"
	OutputLokiAuthenticationTypeTextSecret        OutputLokiAuthenticationType = "textSecret"
	OutputLokiAuthenticationTypeBasic             OutputLokiAuthenticationType = "basic"
	OutputLokiAuthenticationTypeCredentialsSecret OutputLokiAuthenticationType = "credentialsSecret"
)

func (e OutputLokiAuthenticationType) ToPointer() *OutputLokiAuthenticationType {
	return &e
}
func (e *OutputLokiAuthenticationType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "token":
		fallthrough
	case "textSecret":
		fallthrough
	case "basic":
		fallthrough
	case "credentialsSecret":
		*e = OutputLokiAuthenticationType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputLokiAuthenticationType: %v", v)
	}
}

type OutputLokiExtraHTTPHeaders struct {
	// Field name
	Name *string `json:"name,omitempty"`
	// Field value
	Value string `json:"value"`
}

func (o *OutputLokiExtraHTTPHeaders) GetName() *string {
	if o == nil {
		return nil
	}
	return o.Name
}

func (o *OutputLokiExtraHTTPHeaders) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// OutputLokiFailedRequestLoggingMode - Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
type OutputLokiFailedRequestLoggingMode string

const (
	OutputLokiFailedRequestLoggingModePayload           OutputLokiFailedRequestLoggingMode = "payload"
	OutputLokiFailedRequestLoggingModePayloadAndHeaders OutputLokiFailedRequestLoggingMode = "payloadAndHeaders"
	OutputLokiFailedRequestLoggingModeNone              OutputLokiFailedRequestLoggingMode = "none"
)

func (e OutputLokiFailedRequestLoggingMode) ToPointer() *OutputLokiFailedRequestLoggingMode {
	return &e
}
func (e *OutputLokiFailedRequestLoggingMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "payload":
		fallthrough
	case "payloadAndHeaders":
		fallthrough
	case "none":
		*e = OutputLokiFailedRequestLoggingMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputLokiFailedRequestLoggingMode: %v", v)
	}
}

type OutputLokiResponseRetrySettings struct {
	// The HTTP response status code that will trigger retries
	HTTPStatus float64 `json:"httpStatus"`
	// How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"1000" json:"initialBackoff"`
	// Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackoff *float64 `default:"10000" json:"maxBackoff"`
}

func (o OutputLokiResponseRetrySettings) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputLokiResponseRetrySettings) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputLokiResponseRetrySettings) GetHTTPStatus() float64 {
	if o == nil {
		return 0.0
	}
	return o.HTTPStatus
}

func (o *OutputLokiResponseRetrySettings) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *OutputLokiResponseRetrySettings) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *OutputLokiResponseRetrySettings) GetMaxBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackoff
}

type OutputLokiTimeoutRetrySettings struct {
	// Enable to retry on request timeout
	TimeoutRetry *bool `default:"false" json:"timeoutRetry"`
	// How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"1000" json:"initialBackoff"`
	// Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackoff *float64 `default:"10000" json:"maxBackoff"`
}

func (o OutputLokiTimeoutRetrySettings) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputLokiTimeoutRetrySettings) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputLokiTimeoutRetrySettings) GetTimeoutRetry() *bool {
	if o == nil {
		return nil
	}
	return o.TimeoutRetry
}

func (o *OutputLokiTimeoutRetrySettings) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *OutputLokiTimeoutRetrySettings) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *OutputLokiTimeoutRetrySettings) GetMaxBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackoff
}

// OutputLokiBackpressureBehavior - Whether to block, drop, or queue events when all receivers are exerting backpressure.
type OutputLokiBackpressureBehavior string

const (
	OutputLokiBackpressureBehaviorBlock OutputLokiBackpressureBehavior = "block"
	OutputLokiBackpressureBehaviorDrop  OutputLokiBackpressureBehavior = "drop"
	OutputLokiBackpressureBehaviorQueue OutputLokiBackpressureBehavior = "queue"
)

func (e OutputLokiBackpressureBehavior) ToPointer() *OutputLokiBackpressureBehavior {
	return &e
}
func (e *OutputLokiBackpressureBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		fallthrough
	case "queue":
		*e = OutputLokiBackpressureBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputLokiBackpressureBehavior: %v", v)
	}
}

// OutputLokiCompression - Codec to use to compress the persisted data.
type OutputLokiCompression string

const (
	OutputLokiCompressionNone OutputLokiCompression = "none"
	OutputLokiCompressionGzip OutputLokiCompression = "gzip"
)

func (e OutputLokiCompression) ToPointer() *OutputLokiCompression {
	return &e
}
func (e *OutputLokiCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = OutputLokiCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputLokiCompression: %v", v)
	}
}

// OutputLokiQueueFullBehavior - Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
type OutputLokiQueueFullBehavior string

const (
	OutputLokiQueueFullBehaviorBlock OutputLokiQueueFullBehavior = "block"
	OutputLokiQueueFullBehaviorDrop  OutputLokiQueueFullBehavior = "drop"
)

func (e OutputLokiQueueFullBehavior) ToPointer() *OutputLokiQueueFullBehavior {
	return &e
}
func (e *OutputLokiQueueFullBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputLokiQueueFullBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputLokiQueueFullBehavior: %v", v)
	}
}

// OutputLokiMode - In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
type OutputLokiMode string

const (
	OutputLokiModeError        OutputLokiMode = "error"
	OutputLokiModeBackpressure OutputLokiMode = "backpressure"
	OutputLokiModeAlways       OutputLokiMode = "always"
)

func (e OutputLokiMode) ToPointer() *OutputLokiMode {
	return &e
}
func (e *OutputLokiMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "error":
		fallthrough
	case "backpressure":
		fallthrough
	case "always":
		*e = OutputLokiMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputLokiMode: %v", v)
	}
}

type OutputLokiPqControls struct {
}

type OutputLoki struct {
	// Unique ID for this output
	ID   *string        `json:"id,omitempty"`
	Type OutputLokiType `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards. These fields are added as labels to generated logs.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// The endpoint to send logs to.
	URL string `json:"url"`
	// Name of the event field that contains the message to send. If not specified, Stream sends a JSON representation of the whole event.
	Message *string `json:"message,omitempty"`
	// Which format to use when sending logs to Loki (Protobuf or JSON).  Defaults to Protobuf.
	MessageFormat *OutputLokiMessageFormat `default:"protobuf" json:"messageFormat"`
	// List of labels to send with logs. Labels define Loki streams, so use static labels to avoid proliferating label value combinations and streams. Can be merged and/or overridden by the event's __labels field (e.g.: '__labels: {host: "cribl.io", level: "error"}').
	Labels []Labels `json:"labels,omitempty"`
	// The authentication method to use for the HTTP requests
	AuthType *OutputLokiAuthenticationType `default:"none" json:"authType"`
	// Maximum number of ongoing requests before blocking. Warning: Setting this value > 1 can cause Loki to complain about entries being delivered out of order.
	Concurrency *float64 `default:"1" json:"concurrency"`
	// Maximum size, in KB, of the request body. Warning: Setting this too low can increase the number of ongoing requests (depending on the value of 'Request concurrency'); this can cause Loki to complain about entries being delivered out of order.
	MaxPayloadSizeKB *float64 `default:"4096" json:"maxPayloadSizeKB"`
	// Maximum number of events to include in the request body. Defaults to 0 (unlimited). Warning: Setting this too low can increase the number of ongoing requests (depending on the value of 'Request concurrency'); this can cause Loki to complain about entries being delivered out of order.
	MaxPayloadEvents *float64 `default:"0" json:"maxPayloadEvents"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Defaults to Yes. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `default:"30" json:"timeoutSec"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Maximum time between requests. Small values can reduce the payload size below the configured 'Max record size' and 'Max events per request'. Warning: Setting this too low can increase the number of ongoing requests (depending on the value of 'Request concurrency'); this can cause Loki to complain about entries being delivered out of order.
	FlushPeriodSec *float64 `default:"15" json:"flushPeriodSec"`
	// Headers to add to all events.
	ExtraHTTPHeaders []OutputLokiExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// Enables round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `default:"false" json:"useRoundRobinDns"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *OutputLokiFailedRequestLoggingMode `default:"none" json:"failedRequestLoggingMode"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable).
	ResponseRetrySettings []OutputLokiResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *OutputLokiTimeoutRetrySettings   `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `default:"false" json:"responseHonorRetryAfterHeader"`
	// Whether to block, drop, or queue events when all receivers are exerting backpressure.
	OnBackpressure *OutputLokiBackpressureBehavior `default:"block" json:"onBackpressure"`
	// Maximum total size of the batches waiting to be sent. If left blank, defaults to 5 times the max body size (if set). If 0, no limit is enforced.
	TotalMemoryLimitKB *float64 `json:"totalMemoryLimitKB,omitempty"`
	Description        *string  `json:"description,omitempty"`
	// Whether to compress the payload body before sending.
	Compress *bool `default:"true" json:"compress"`
	// Bearer token to include in the authorization header. In Grafana Cloud, this is generally built by concatenating the username and the API key, separated by a colon. E.g.: <your-username>:<your-api-key>.
	Token *string `json:"token,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// Username for authentication
	Username *string `json:"username,omitempty"`
	// Password (a.k.a API key in Grafana Cloud domain) for authentication
	Password *string `json:"password,omitempty"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.).
	PqMaxFileSize *string `default:"1 MB" json:"pqMaxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `default:"5GB" json:"pqMaxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `default:"\\$CRIBL_HOME/state/queues" json:"pqPath"`
	// Codec to use to compress the persisted data.
	PqCompress *OutputLokiCompression `default:"none" json:"pqCompress"`
	// Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *OutputLokiQueueFullBehavior `default:"block" json:"pqOnBackpressure"`
	// In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
	PqMode     *OutputLokiMode       `default:"error" json:"pqMode"`
	PqControls *OutputLokiPqControls `json:"pqControls,omitempty"`
	Status     *TFStatus             `json:"status,omitempty"`
}

func (o OutputLoki) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputLoki) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *OutputLoki) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *OutputLoki) GetType() OutputLokiType {
	if o == nil {
		return OutputLokiType("")
	}
	return o.Type
}

func (o *OutputLoki) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputLoki) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputLoki) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputLoki) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputLoki) GetURL() string {
	if o == nil {
		return ""
	}
	return o.URL
}

func (o *OutputLoki) GetMessage() *string {
	if o == nil {
		return nil
	}
	return o.Message
}

func (o *OutputLoki) GetMessageFormat() *OutputLokiMessageFormat {
	if o == nil {
		return nil
	}
	return o.MessageFormat
}

func (o *OutputLoki) GetLabels() []Labels {
	if o == nil {
		return nil
	}
	return o.Labels
}

func (o *OutputLoki) GetAuthType() *OutputLokiAuthenticationType {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *OutputLoki) GetConcurrency() *float64 {
	if o == nil {
		return nil
	}
	return o.Concurrency
}

func (o *OutputLoki) GetMaxPayloadSizeKB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadSizeKB
}

func (o *OutputLoki) GetMaxPayloadEvents() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadEvents
}

func (o *OutputLoki) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputLoki) GetTimeoutSec() *float64 {
	if o == nil {
		return nil
	}
	return o.TimeoutSec
}

func (o *OutputLoki) GetFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushPeriodSec
}

func (o *OutputLoki) GetExtraHTTPHeaders() []OutputLokiExtraHTTPHeaders {
	if o == nil {
		return nil
	}
	return o.ExtraHTTPHeaders
}

func (o *OutputLoki) GetUseRoundRobinDNS() *bool {
	if o == nil {
		return nil
	}
	return o.UseRoundRobinDNS
}

func (o *OutputLoki) GetFailedRequestLoggingMode() *OutputLokiFailedRequestLoggingMode {
	if o == nil {
		return nil
	}
	return o.FailedRequestLoggingMode
}

func (o *OutputLoki) GetSafeHeaders() []string {
	if o == nil {
		return nil
	}
	return o.SafeHeaders
}

func (o *OutputLoki) GetResponseRetrySettings() []OutputLokiResponseRetrySettings {
	if o == nil {
		return nil
	}
	return o.ResponseRetrySettings
}

func (o *OutputLoki) GetTimeoutRetrySettings() *OutputLokiTimeoutRetrySettings {
	if o == nil {
		return nil
	}
	return o.TimeoutRetrySettings
}

func (o *OutputLoki) GetResponseHonorRetryAfterHeader() *bool {
	if o == nil {
		return nil
	}
	return o.ResponseHonorRetryAfterHeader
}

func (o *OutputLoki) GetOnBackpressure() *OutputLokiBackpressureBehavior {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputLoki) GetTotalMemoryLimitKB() *float64 {
	if o == nil {
		return nil
	}
	return o.TotalMemoryLimitKB
}

func (o *OutputLoki) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputLoki) GetCompress() *bool {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *OutputLoki) GetToken() *string {
	if o == nil {
		return nil
	}
	return o.Token
}

func (o *OutputLoki) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *OutputLoki) GetUsername() *string {
	if o == nil {
		return nil
	}
	return o.Username
}

func (o *OutputLoki) GetPassword() *string {
	if o == nil {
		return nil
	}
	return o.Password
}

func (o *OutputLoki) GetCredentialsSecret() *string {
	if o == nil {
		return nil
	}
	return o.CredentialsSecret
}

func (o *OutputLoki) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputLoki) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputLoki) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputLoki) GetPqCompress() *OutputLokiCompression {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputLoki) GetPqOnBackpressure() *OutputLokiQueueFullBehavior {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputLoki) GetPqMode() *OutputLokiMode {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputLoki) GetPqControls() *OutputLokiPqControls {
	if o == nil {
		return nil
	}
	return o.PqControls
}

func (o *OutputLoki) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type OutputOutputGrafanaCloudType string

const (
	OutputOutputGrafanaCloudTypeGrafanaCloud OutputOutputGrafanaCloudType = "grafana_cloud"
)

func (e OutputOutputGrafanaCloudType) ToPointer() *OutputOutputGrafanaCloudType {
	return &e
}
func (e *OutputOutputGrafanaCloudType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "grafana_cloud":
		*e = OutputOutputGrafanaCloudType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputOutputGrafanaCloudType: %v", v)
	}
}

// OutputOutputGrafanaCloudMessageFormat - Which format to use when sending logs to Loki (Protobuf or JSON).  Defaults to Protobuf.
type OutputOutputGrafanaCloudMessageFormat string

const (
	OutputOutputGrafanaCloudMessageFormatProtobuf OutputOutputGrafanaCloudMessageFormat = "protobuf"
	OutputOutputGrafanaCloudMessageFormatJSON     OutputOutputGrafanaCloudMessageFormat = "json"
)

func (e OutputOutputGrafanaCloudMessageFormat) ToPointer() *OutputOutputGrafanaCloudMessageFormat {
	return &e
}
func (e *OutputOutputGrafanaCloudMessageFormat) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "protobuf":
		fallthrough
	case "json":
		*e = OutputOutputGrafanaCloudMessageFormat(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputOutputGrafanaCloudMessageFormat: %v", v)
	}
}

type OutputGrafanaCloudLabels struct {
	// Name of the label.
	Name *string `default:"" json:"name"`
	// Value of the label.
	Value string `json:"value"`
}

func (o OutputGrafanaCloudLabels) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputGrafanaCloudLabels) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputGrafanaCloudLabels) GetName() *string {
	if o == nil {
		return nil
	}
	return o.Name
}

func (o *OutputGrafanaCloudLabels) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// OutputOutputGrafanaCloud2AuthenticationType - The authentication method to use for the HTTP requests
type OutputOutputGrafanaCloud2AuthenticationType string

const (
	OutputOutputGrafanaCloud2AuthenticationTypeNone              OutputOutputGrafanaCloud2AuthenticationType = "none"
	OutputOutputGrafanaCloud2AuthenticationTypeToken             OutputOutputGrafanaCloud2AuthenticationType = "token"
	OutputOutputGrafanaCloud2AuthenticationTypeTextSecret        OutputOutputGrafanaCloud2AuthenticationType = "textSecret"
	OutputOutputGrafanaCloud2AuthenticationTypeBasic             OutputOutputGrafanaCloud2AuthenticationType = "basic"
	OutputOutputGrafanaCloud2AuthenticationTypeCredentialsSecret OutputOutputGrafanaCloud2AuthenticationType = "credentialsSecret"
)

func (e OutputOutputGrafanaCloud2AuthenticationType) ToPointer() *OutputOutputGrafanaCloud2AuthenticationType {
	return &e
}
func (e *OutputOutputGrafanaCloud2AuthenticationType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "token":
		fallthrough
	case "textSecret":
		fallthrough
	case "basic":
		fallthrough
	case "credentialsSecret":
		*e = OutputOutputGrafanaCloud2AuthenticationType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputOutputGrafanaCloud2AuthenticationType: %v", v)
	}
}

type OutputOutputGrafanaCloudPrometheusAuth struct {
	// The authentication method to use for the HTTP requests
	AuthType *OutputOutputGrafanaCloud2AuthenticationType `default:"basic" json:"authType"`
	// Bearer token to include in the authorization header. In Grafana Cloud, this is generally built by concatenating the username and the API key, separated by a colon. E.g.: <your-username>:<your-api-key>.
	Token *string `json:"token,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// Username for authentication
	Username *string `json:"username,omitempty"`
	// Password (a.k.a API key in Grafana Cloud domain) for authentication
	Password *string `json:"password,omitempty"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
}

func (o OutputOutputGrafanaCloudPrometheusAuth) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputOutputGrafanaCloudPrometheusAuth) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputOutputGrafanaCloudPrometheusAuth) GetAuthType() *OutputOutputGrafanaCloud2AuthenticationType {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *OutputOutputGrafanaCloudPrometheusAuth) GetToken() *string {
	if o == nil {
		return nil
	}
	return o.Token
}

func (o *OutputOutputGrafanaCloudPrometheusAuth) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *OutputOutputGrafanaCloudPrometheusAuth) GetUsername() *string {
	if o == nil {
		return nil
	}
	return o.Username
}

func (o *OutputOutputGrafanaCloudPrometheusAuth) GetPassword() *string {
	if o == nil {
		return nil
	}
	return o.Password
}

func (o *OutputOutputGrafanaCloudPrometheusAuth) GetCredentialsSecret() *string {
	if o == nil {
		return nil
	}
	return o.CredentialsSecret
}

// OutputOutputGrafanaCloud2LokiAuthAuthenticationType - The authentication method to use for the HTTP requests
type OutputOutputGrafanaCloud2LokiAuthAuthenticationType string

const (
	OutputOutputGrafanaCloud2LokiAuthAuthenticationTypeNone              OutputOutputGrafanaCloud2LokiAuthAuthenticationType = "none"
	OutputOutputGrafanaCloud2LokiAuthAuthenticationTypeToken             OutputOutputGrafanaCloud2LokiAuthAuthenticationType = "token"
	OutputOutputGrafanaCloud2LokiAuthAuthenticationTypeTextSecret        OutputOutputGrafanaCloud2LokiAuthAuthenticationType = "textSecret"
	OutputOutputGrafanaCloud2LokiAuthAuthenticationTypeBasic             OutputOutputGrafanaCloud2LokiAuthAuthenticationType = "basic"
	OutputOutputGrafanaCloud2LokiAuthAuthenticationTypeCredentialsSecret OutputOutputGrafanaCloud2LokiAuthAuthenticationType = "credentialsSecret"
)

func (e OutputOutputGrafanaCloud2LokiAuthAuthenticationType) ToPointer() *OutputOutputGrafanaCloud2LokiAuthAuthenticationType {
	return &e
}
func (e *OutputOutputGrafanaCloud2LokiAuthAuthenticationType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "token":
		fallthrough
	case "textSecret":
		fallthrough
	case "basic":
		fallthrough
	case "credentialsSecret":
		*e = OutputOutputGrafanaCloud2LokiAuthAuthenticationType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputOutputGrafanaCloud2LokiAuthAuthenticationType: %v", v)
	}
}

type OutputOutputGrafanaCloudLokiAuth struct {
	// The authentication method to use for the HTTP requests
	AuthType *OutputOutputGrafanaCloud2LokiAuthAuthenticationType `default:"basic" json:"authType"`
	// Bearer token to include in the authorization header. In Grafana Cloud, this is generally built by concatenating the username and the API key, separated by a colon. E.g.: <your-username>:<your-api-key>.
	Token *string `json:"token,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// Username for authentication
	Username *string `json:"username,omitempty"`
	// Password (a.k.a API key in Grafana Cloud domain) for authentication
	Password *string `json:"password,omitempty"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
}

func (o OutputOutputGrafanaCloudLokiAuth) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputOutputGrafanaCloudLokiAuth) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputOutputGrafanaCloudLokiAuth) GetAuthType() *OutputOutputGrafanaCloud2LokiAuthAuthenticationType {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *OutputOutputGrafanaCloudLokiAuth) GetToken() *string {
	if o == nil {
		return nil
	}
	return o.Token
}

func (o *OutputOutputGrafanaCloudLokiAuth) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *OutputOutputGrafanaCloudLokiAuth) GetUsername() *string {
	if o == nil {
		return nil
	}
	return o.Username
}

func (o *OutputOutputGrafanaCloudLokiAuth) GetPassword() *string {
	if o == nil {
		return nil
	}
	return o.Password
}

func (o *OutputOutputGrafanaCloudLokiAuth) GetCredentialsSecret() *string {
	if o == nil {
		return nil
	}
	return o.CredentialsSecret
}

type OutputOutputGrafanaCloudExtraHTTPHeaders struct {
	// Field name
	Name *string `json:"name,omitempty"`
	// Field value
	Value string `json:"value"`
}

func (o *OutputOutputGrafanaCloudExtraHTTPHeaders) GetName() *string {
	if o == nil {
		return nil
	}
	return o.Name
}

func (o *OutputOutputGrafanaCloudExtraHTTPHeaders) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// OutputOutputGrafanaCloudFailedRequestLoggingMode - Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
type OutputOutputGrafanaCloudFailedRequestLoggingMode string

const (
	OutputOutputGrafanaCloudFailedRequestLoggingModePayload           OutputOutputGrafanaCloudFailedRequestLoggingMode = "payload"
	OutputOutputGrafanaCloudFailedRequestLoggingModePayloadAndHeaders OutputOutputGrafanaCloudFailedRequestLoggingMode = "payloadAndHeaders"
	OutputOutputGrafanaCloudFailedRequestLoggingModeNone              OutputOutputGrafanaCloudFailedRequestLoggingMode = "none"
)

func (e OutputOutputGrafanaCloudFailedRequestLoggingMode) ToPointer() *OutputOutputGrafanaCloudFailedRequestLoggingMode {
	return &e
}
func (e *OutputOutputGrafanaCloudFailedRequestLoggingMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "payload":
		fallthrough
	case "payloadAndHeaders":
		fallthrough
	case "none":
		*e = OutputOutputGrafanaCloudFailedRequestLoggingMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputOutputGrafanaCloudFailedRequestLoggingMode: %v", v)
	}
}

type OutputOutputGrafanaCloudResponseRetrySettings struct {
	// The HTTP response status code that will trigger retries
	HTTPStatus float64 `json:"httpStatus"`
	// How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"1000" json:"initialBackoff"`
	// Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackoff *float64 `default:"10000" json:"maxBackoff"`
}

func (o OutputOutputGrafanaCloudResponseRetrySettings) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputOutputGrafanaCloudResponseRetrySettings) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputOutputGrafanaCloudResponseRetrySettings) GetHTTPStatus() float64 {
	if o == nil {
		return 0.0
	}
	return o.HTTPStatus
}

func (o *OutputOutputGrafanaCloudResponseRetrySettings) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *OutputOutputGrafanaCloudResponseRetrySettings) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *OutputOutputGrafanaCloudResponseRetrySettings) GetMaxBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackoff
}

type OutputOutputGrafanaCloudTimeoutRetrySettings struct {
	// Enable to retry on request timeout
	TimeoutRetry *bool `default:"false" json:"timeoutRetry"`
	// How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"1000" json:"initialBackoff"`
	// Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackoff *float64 `default:"10000" json:"maxBackoff"`
}

func (o OutputOutputGrafanaCloudTimeoutRetrySettings) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputOutputGrafanaCloudTimeoutRetrySettings) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputOutputGrafanaCloudTimeoutRetrySettings) GetTimeoutRetry() *bool {
	if o == nil {
		return nil
	}
	return o.TimeoutRetry
}

func (o *OutputOutputGrafanaCloudTimeoutRetrySettings) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *OutputOutputGrafanaCloudTimeoutRetrySettings) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *OutputOutputGrafanaCloudTimeoutRetrySettings) GetMaxBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackoff
}

// OutputOutputGrafanaCloudBackpressureBehavior - Whether to block, drop, or queue events when all receivers are exerting backpressure.
type OutputOutputGrafanaCloudBackpressureBehavior string

const (
	OutputOutputGrafanaCloudBackpressureBehaviorBlock OutputOutputGrafanaCloudBackpressureBehavior = "block"
	OutputOutputGrafanaCloudBackpressureBehaviorDrop  OutputOutputGrafanaCloudBackpressureBehavior = "drop"
	OutputOutputGrafanaCloudBackpressureBehaviorQueue OutputOutputGrafanaCloudBackpressureBehavior = "queue"
)

func (e OutputOutputGrafanaCloudBackpressureBehavior) ToPointer() *OutputOutputGrafanaCloudBackpressureBehavior {
	return &e
}
func (e *OutputOutputGrafanaCloudBackpressureBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		fallthrough
	case "queue":
		*e = OutputOutputGrafanaCloudBackpressureBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputOutputGrafanaCloudBackpressureBehavior: %v", v)
	}
}

// OutputOutputGrafanaCloudCompression - Codec to use to compress the persisted data.
type OutputOutputGrafanaCloudCompression string

const (
	OutputOutputGrafanaCloudCompressionNone OutputOutputGrafanaCloudCompression = "none"
	OutputOutputGrafanaCloudCompressionGzip OutputOutputGrafanaCloudCompression = "gzip"
)

func (e OutputOutputGrafanaCloudCompression) ToPointer() *OutputOutputGrafanaCloudCompression {
	return &e
}
func (e *OutputOutputGrafanaCloudCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = OutputOutputGrafanaCloudCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputOutputGrafanaCloudCompression: %v", v)
	}
}

// OutputOutputGrafanaCloudQueueFullBehavior - Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
type OutputOutputGrafanaCloudQueueFullBehavior string

const (
	OutputOutputGrafanaCloudQueueFullBehaviorBlock OutputOutputGrafanaCloudQueueFullBehavior = "block"
	OutputOutputGrafanaCloudQueueFullBehaviorDrop  OutputOutputGrafanaCloudQueueFullBehavior = "drop"
)

func (e OutputOutputGrafanaCloudQueueFullBehavior) ToPointer() *OutputOutputGrafanaCloudQueueFullBehavior {
	return &e
}
func (e *OutputOutputGrafanaCloudQueueFullBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputOutputGrafanaCloudQueueFullBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputOutputGrafanaCloudQueueFullBehavior: %v", v)
	}
}

// OutputOutputGrafanaCloudMode - In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
type OutputOutputGrafanaCloudMode string

const (
	OutputOutputGrafanaCloudModeError        OutputOutputGrafanaCloudMode = "error"
	OutputOutputGrafanaCloudModeBackpressure OutputOutputGrafanaCloudMode = "backpressure"
	OutputOutputGrafanaCloudModeAlways       OutputOutputGrafanaCloudMode = "always"
)

func (e OutputOutputGrafanaCloudMode) ToPointer() *OutputOutputGrafanaCloudMode {
	return &e
}
func (e *OutputOutputGrafanaCloudMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "error":
		fallthrough
	case "backpressure":
		fallthrough
	case "always":
		*e = OutputOutputGrafanaCloudMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputOutputGrafanaCloudMode: %v", v)
	}
}

type OutputOutputGrafanaCloudPqControls struct {
}

type OutputGrafanaCloud2 struct {
	// Unique ID for this output
	ID   string                       `json:"id"`
	Type OutputOutputGrafanaCloudType `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards. These fields are added as dimensions and labels to generated metrics and logs, respectively.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// The endpoint to send logs to, e.g.: https://logs-prod-us-central1.grafana.net
	LokiURL *string `json:"lokiUrl,omitempty"`
	// The remote_write endpoint to send Prometheus metrics to, e.g.: https://prometheus-blocks-prod-us-central1.grafana.net/api/prom/push
	PrometheusURL string `json:"prometheusUrl"`
	// Name of the event field that contains the message to send. If not specified, Stream sends a JSON representation of the whole event.
	Message *string `json:"message,omitempty"`
	// Which format to use when sending logs to Loki (Protobuf or JSON).  Defaults to Protobuf.
	MessageFormat *OutputOutputGrafanaCloudMessageFormat `default:"protobuf" json:"messageFormat"`
	// List of labels to send with logs. Labels define Loki streams, so use static labels to avoid proliferating label value combinations and streams. Can be merged and/or overridden by the event's __labels field (e.g.: '__labels: {host: "cribl.io", level: "error"}').
	Labels []OutputGrafanaCloudLabels `json:"labels,omitempty"`
	// A JS expression that can be used to rename metrics. E.g.: name.replace(/\./g, '_') will replace all '.' characters in a metric's name with the supported '_' character. Use the 'name' global variable to access the metric's name.  You can access event fields' values via __e.<fieldName>.
	MetricRenameExpr *string                                 `default:"name.replace(/[^a-zA-Z0-9_]/g, '_')" json:"metricRenameExpr"`
	PrometheusAuth   *OutputOutputGrafanaCloudPrometheusAuth `json:"prometheusAuth,omitempty"`
	LokiAuth         *OutputOutputGrafanaCloudLokiAuth       `json:"lokiAuth,omitempty"`
	// Maximum number of ongoing requests before blocking. Warning: Setting this value > 1 can cause Loki and Prometheus to complain about entries being delivered out of order.
	Concurrency *float64 `default:"1" json:"concurrency"`
	// Maximum size, in KB, of the request body. Warning: Setting this too low can increase the number of ongoing requests (depending on the value of 'Request concurrency'); this can cause Loki and Prometheus to complain about entries being delivered out of order.
	MaxPayloadSizeKB *float64 `default:"4096" json:"maxPayloadSizeKB"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited). Warning: Setting this too low can increase the number of ongoing requests (depending on the value of 'Request concurrency'); this can cause Loki and Prometheus to complain about entries being delivered out of order.
	MaxPayloadEvents *float64 `default:"0" json:"maxPayloadEvents"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Defaults to Yes. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `default:"30" json:"timeoutSec"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Maximum time between requests. Small values can reduce the payload size below the configured 'Max record size' and 'Max events per request'. Warning: Setting this too low can increase the number of ongoing requests (depending on the value of 'Request concurrency'); this can cause Loki and Prometheus to complain about entries being delivered out of order.
	FlushPeriodSec *float64 `default:"15" json:"flushPeriodSec"`
	// Headers to add to all events.
	ExtraHTTPHeaders []OutputOutputGrafanaCloudExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// Enables round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `default:"false" json:"useRoundRobinDns"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *OutputOutputGrafanaCloudFailedRequestLoggingMode `default:"none" json:"failedRequestLoggingMode"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable).
	ResponseRetrySettings []OutputOutputGrafanaCloudResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *OutputOutputGrafanaCloudTimeoutRetrySettings   `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `default:"false" json:"responseHonorRetryAfterHeader"`
	// Whether to block, drop, or queue events when all receivers are exerting backpressure.
	OnBackpressure *OutputOutputGrafanaCloudBackpressureBehavior `default:"block" json:"onBackpressure"`
	Description    *string                                       `json:"description,omitempty"`
	// Whether to compress the payload body before sending. Applies only to Loki's JSON payloads, as both Prometheus' and Loki's Protobuf variant are snappy-compressed by default.
	Compress *bool `default:"true" json:"compress"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.).
	PqMaxFileSize *string `default:"1 MB" json:"pqMaxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `default:"5GB" json:"pqMaxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `default:"\\$CRIBL_HOME/state/queues" json:"pqPath"`
	// Codec to use to compress the persisted data.
	PqCompress *OutputOutputGrafanaCloudCompression `default:"none" json:"pqCompress"`
	// Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *OutputOutputGrafanaCloudQueueFullBehavior `default:"block" json:"pqOnBackpressure"`
	// In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
	PqMode     *OutputOutputGrafanaCloudMode       `default:"error" json:"pqMode"`
	PqControls *OutputOutputGrafanaCloudPqControls `json:"pqControls,omitempty"`
	Status     *TFStatus                           `json:"status,omitempty"`
}

func (o OutputGrafanaCloud2) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputGrafanaCloud2) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *OutputGrafanaCloud2) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *OutputGrafanaCloud2) GetType() OutputOutputGrafanaCloudType {
	if o == nil {
		return OutputOutputGrafanaCloudType("")
	}
	return o.Type
}

func (o *OutputGrafanaCloud2) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputGrafanaCloud2) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputGrafanaCloud2) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputGrafanaCloud2) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputGrafanaCloud2) GetLokiURL() *string {
	if o == nil {
		return nil
	}
	return o.LokiURL
}

func (o *OutputGrafanaCloud2) GetPrometheusURL() string {
	if o == nil {
		return ""
	}
	return o.PrometheusURL
}

func (o *OutputGrafanaCloud2) GetMessage() *string {
	if o == nil {
		return nil
	}
	return o.Message
}

func (o *OutputGrafanaCloud2) GetMessageFormat() *OutputOutputGrafanaCloudMessageFormat {
	if o == nil {
		return nil
	}
	return o.MessageFormat
}

func (o *OutputGrafanaCloud2) GetLabels() []OutputGrafanaCloudLabels {
	if o == nil {
		return nil
	}
	return o.Labels
}

func (o *OutputGrafanaCloud2) GetMetricRenameExpr() *string {
	if o == nil {
		return nil
	}
	return o.MetricRenameExpr
}

func (o *OutputGrafanaCloud2) GetPrometheusAuth() *OutputOutputGrafanaCloudPrometheusAuth {
	if o == nil {
		return nil
	}
	return o.PrometheusAuth
}

func (o *OutputGrafanaCloud2) GetLokiAuth() *OutputOutputGrafanaCloudLokiAuth {
	if o == nil {
		return nil
	}
	return o.LokiAuth
}

func (o *OutputGrafanaCloud2) GetConcurrency() *float64 {
	if o == nil {
		return nil
	}
	return o.Concurrency
}

func (o *OutputGrafanaCloud2) GetMaxPayloadSizeKB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadSizeKB
}

func (o *OutputGrafanaCloud2) GetMaxPayloadEvents() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadEvents
}

func (o *OutputGrafanaCloud2) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputGrafanaCloud2) GetTimeoutSec() *float64 {
	if o == nil {
		return nil
	}
	return o.TimeoutSec
}

func (o *OutputGrafanaCloud2) GetFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushPeriodSec
}

func (o *OutputGrafanaCloud2) GetExtraHTTPHeaders() []OutputOutputGrafanaCloudExtraHTTPHeaders {
	if o == nil {
		return nil
	}
	return o.ExtraHTTPHeaders
}

func (o *OutputGrafanaCloud2) GetUseRoundRobinDNS() *bool {
	if o == nil {
		return nil
	}
	return o.UseRoundRobinDNS
}

func (o *OutputGrafanaCloud2) GetFailedRequestLoggingMode() *OutputOutputGrafanaCloudFailedRequestLoggingMode {
	if o == nil {
		return nil
	}
	return o.FailedRequestLoggingMode
}

func (o *OutputGrafanaCloud2) GetSafeHeaders() []string {
	if o == nil {
		return nil
	}
	return o.SafeHeaders
}

func (o *OutputGrafanaCloud2) GetResponseRetrySettings() []OutputOutputGrafanaCloudResponseRetrySettings {
	if o == nil {
		return nil
	}
	return o.ResponseRetrySettings
}

func (o *OutputGrafanaCloud2) GetTimeoutRetrySettings() *OutputOutputGrafanaCloudTimeoutRetrySettings {
	if o == nil {
		return nil
	}
	return o.TimeoutRetrySettings
}

func (o *OutputGrafanaCloud2) GetResponseHonorRetryAfterHeader() *bool {
	if o == nil {
		return nil
	}
	return o.ResponseHonorRetryAfterHeader
}

func (o *OutputGrafanaCloud2) GetOnBackpressure() *OutputOutputGrafanaCloudBackpressureBehavior {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputGrafanaCloud2) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputGrafanaCloud2) GetCompress() *bool {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *OutputGrafanaCloud2) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputGrafanaCloud2) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputGrafanaCloud2) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputGrafanaCloud2) GetPqCompress() *OutputOutputGrafanaCloudCompression {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputGrafanaCloud2) GetPqOnBackpressure() *OutputOutputGrafanaCloudQueueFullBehavior {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputGrafanaCloud2) GetPqMode() *OutputOutputGrafanaCloudMode {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputGrafanaCloud2) GetPqControls() *OutputOutputGrafanaCloudPqControls {
	if o == nil {
		return nil
	}
	return o.PqControls
}

func (o *OutputGrafanaCloud2) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type OutputGrafanaCloudType string

const (
	OutputGrafanaCloudTypeGrafanaCloud OutputGrafanaCloudType = "grafana_cloud"
)

func (e OutputGrafanaCloudType) ToPointer() *OutputGrafanaCloudType {
	return &e
}
func (e *OutputGrafanaCloudType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "grafana_cloud":
		*e = OutputGrafanaCloudType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputGrafanaCloudType: %v", v)
	}
}

// OutputGrafanaCloudMessageFormat - Which format to use when sending logs to Loki (Protobuf or JSON).  Defaults to Protobuf.
type OutputGrafanaCloudMessageFormat string

const (
	OutputGrafanaCloudMessageFormatProtobuf OutputGrafanaCloudMessageFormat = "protobuf"
	OutputGrafanaCloudMessageFormatJSON     OutputGrafanaCloudMessageFormat = "json"
)

func (e OutputGrafanaCloudMessageFormat) ToPointer() *OutputGrafanaCloudMessageFormat {
	return &e
}
func (e *OutputGrafanaCloudMessageFormat) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "protobuf":
		fallthrough
	case "json":
		*e = OutputGrafanaCloudMessageFormat(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputGrafanaCloudMessageFormat: %v", v)
	}
}

type OutputOutputGrafanaCloudLabels struct {
	// Name of the label.
	Name *string `default:"" json:"name"`
	// Value of the label.
	Value string `json:"value"`
}

func (o OutputOutputGrafanaCloudLabels) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputOutputGrafanaCloudLabels) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputOutputGrafanaCloudLabels) GetName() *string {
	if o == nil {
		return nil
	}
	return o.Name
}

func (o *OutputOutputGrafanaCloudLabels) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// OutputGrafanaCloudAuthenticationType - The authentication method to use for the HTTP requests
type OutputGrafanaCloudAuthenticationType string

const (
	OutputGrafanaCloudAuthenticationTypeNone              OutputGrafanaCloudAuthenticationType = "none"
	OutputGrafanaCloudAuthenticationTypeToken             OutputGrafanaCloudAuthenticationType = "token"
	OutputGrafanaCloudAuthenticationTypeTextSecret        OutputGrafanaCloudAuthenticationType = "textSecret"
	OutputGrafanaCloudAuthenticationTypeBasic             OutputGrafanaCloudAuthenticationType = "basic"
	OutputGrafanaCloudAuthenticationTypeCredentialsSecret OutputGrafanaCloudAuthenticationType = "credentialsSecret"
)

func (e OutputGrafanaCloudAuthenticationType) ToPointer() *OutputGrafanaCloudAuthenticationType {
	return &e
}
func (e *OutputGrafanaCloudAuthenticationType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "token":
		fallthrough
	case "textSecret":
		fallthrough
	case "basic":
		fallthrough
	case "credentialsSecret":
		*e = OutputGrafanaCloudAuthenticationType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputGrafanaCloudAuthenticationType: %v", v)
	}
}

type OutputGrafanaCloudPrometheusAuth struct {
	// The authentication method to use for the HTTP requests
	AuthType *OutputGrafanaCloudAuthenticationType `default:"basic" json:"authType"`
	// Bearer token to include in the authorization header. In Grafana Cloud, this is generally built by concatenating the username and the API key, separated by a colon. E.g.: <your-username>:<your-api-key>.
	Token *string `json:"token,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// Username for authentication
	Username *string `json:"username,omitempty"`
	// Password (a.k.a API key in Grafana Cloud domain) for authentication
	Password *string `json:"password,omitempty"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
}

func (o OutputGrafanaCloudPrometheusAuth) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputGrafanaCloudPrometheusAuth) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputGrafanaCloudPrometheusAuth) GetAuthType() *OutputGrafanaCloudAuthenticationType {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *OutputGrafanaCloudPrometheusAuth) GetToken() *string {
	if o == nil {
		return nil
	}
	return o.Token
}

func (o *OutputGrafanaCloudPrometheusAuth) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *OutputGrafanaCloudPrometheusAuth) GetUsername() *string {
	if o == nil {
		return nil
	}
	return o.Username
}

func (o *OutputGrafanaCloudPrometheusAuth) GetPassword() *string {
	if o == nil {
		return nil
	}
	return o.Password
}

func (o *OutputGrafanaCloudPrometheusAuth) GetCredentialsSecret() *string {
	if o == nil {
		return nil
	}
	return o.CredentialsSecret
}

// OutputOutputGrafanaCloudAuthenticationType - The authentication method to use for the HTTP requests
type OutputOutputGrafanaCloudAuthenticationType string

const (
	OutputOutputGrafanaCloudAuthenticationTypeNone              OutputOutputGrafanaCloudAuthenticationType = "none"
	OutputOutputGrafanaCloudAuthenticationTypeToken             OutputOutputGrafanaCloudAuthenticationType = "token"
	OutputOutputGrafanaCloudAuthenticationTypeTextSecret        OutputOutputGrafanaCloudAuthenticationType = "textSecret"
	OutputOutputGrafanaCloudAuthenticationTypeBasic             OutputOutputGrafanaCloudAuthenticationType = "basic"
	OutputOutputGrafanaCloudAuthenticationTypeCredentialsSecret OutputOutputGrafanaCloudAuthenticationType = "credentialsSecret"
)

func (e OutputOutputGrafanaCloudAuthenticationType) ToPointer() *OutputOutputGrafanaCloudAuthenticationType {
	return &e
}
func (e *OutputOutputGrafanaCloudAuthenticationType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "token":
		fallthrough
	case "textSecret":
		fallthrough
	case "basic":
		fallthrough
	case "credentialsSecret":
		*e = OutputOutputGrafanaCloudAuthenticationType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputOutputGrafanaCloudAuthenticationType: %v", v)
	}
}

type OutputGrafanaCloudLokiAuth struct {
	// The authentication method to use for the HTTP requests
	AuthType *OutputOutputGrafanaCloudAuthenticationType `default:"basic" json:"authType"`
	// Bearer token to include in the authorization header. In Grafana Cloud, this is generally built by concatenating the username and the API key, separated by a colon. E.g.: <your-username>:<your-api-key>.
	Token *string `json:"token,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// Username for authentication
	Username *string `json:"username,omitempty"`
	// Password (a.k.a API key in Grafana Cloud domain) for authentication
	Password *string `json:"password,omitempty"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
}

func (o OutputGrafanaCloudLokiAuth) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputGrafanaCloudLokiAuth) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputGrafanaCloudLokiAuth) GetAuthType() *OutputOutputGrafanaCloudAuthenticationType {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *OutputGrafanaCloudLokiAuth) GetToken() *string {
	if o == nil {
		return nil
	}
	return o.Token
}

func (o *OutputGrafanaCloudLokiAuth) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *OutputGrafanaCloudLokiAuth) GetUsername() *string {
	if o == nil {
		return nil
	}
	return o.Username
}

func (o *OutputGrafanaCloudLokiAuth) GetPassword() *string {
	if o == nil {
		return nil
	}
	return o.Password
}

func (o *OutputGrafanaCloudLokiAuth) GetCredentialsSecret() *string {
	if o == nil {
		return nil
	}
	return o.CredentialsSecret
}

type OutputGrafanaCloudExtraHTTPHeaders struct {
	// Field name
	Name *string `json:"name,omitempty"`
	// Field value
	Value string `json:"value"`
}

func (o *OutputGrafanaCloudExtraHTTPHeaders) GetName() *string {
	if o == nil {
		return nil
	}
	return o.Name
}

func (o *OutputGrafanaCloudExtraHTTPHeaders) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// OutputGrafanaCloudFailedRequestLoggingMode - Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
type OutputGrafanaCloudFailedRequestLoggingMode string

const (
	OutputGrafanaCloudFailedRequestLoggingModePayload           OutputGrafanaCloudFailedRequestLoggingMode = "payload"
	OutputGrafanaCloudFailedRequestLoggingModePayloadAndHeaders OutputGrafanaCloudFailedRequestLoggingMode = "payloadAndHeaders"
	OutputGrafanaCloudFailedRequestLoggingModeNone              OutputGrafanaCloudFailedRequestLoggingMode = "none"
)

func (e OutputGrafanaCloudFailedRequestLoggingMode) ToPointer() *OutputGrafanaCloudFailedRequestLoggingMode {
	return &e
}
func (e *OutputGrafanaCloudFailedRequestLoggingMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "payload":
		fallthrough
	case "payloadAndHeaders":
		fallthrough
	case "none":
		*e = OutputGrafanaCloudFailedRequestLoggingMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputGrafanaCloudFailedRequestLoggingMode: %v", v)
	}
}

type OutputGrafanaCloudResponseRetrySettings struct {
	// The HTTP response status code that will trigger retries
	HTTPStatus float64 `json:"httpStatus"`
	// How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"1000" json:"initialBackoff"`
	// Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackoff *float64 `default:"10000" json:"maxBackoff"`
}

func (o OutputGrafanaCloudResponseRetrySettings) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputGrafanaCloudResponseRetrySettings) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputGrafanaCloudResponseRetrySettings) GetHTTPStatus() float64 {
	if o == nil {
		return 0.0
	}
	return o.HTTPStatus
}

func (o *OutputGrafanaCloudResponseRetrySettings) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *OutputGrafanaCloudResponseRetrySettings) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *OutputGrafanaCloudResponseRetrySettings) GetMaxBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackoff
}

type OutputGrafanaCloudTimeoutRetrySettings struct {
	// Enable to retry on request timeout
	TimeoutRetry *bool `default:"false" json:"timeoutRetry"`
	// How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"1000" json:"initialBackoff"`
	// Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackoff *float64 `default:"10000" json:"maxBackoff"`
}

func (o OutputGrafanaCloudTimeoutRetrySettings) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputGrafanaCloudTimeoutRetrySettings) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputGrafanaCloudTimeoutRetrySettings) GetTimeoutRetry() *bool {
	if o == nil {
		return nil
	}
	return o.TimeoutRetry
}

func (o *OutputGrafanaCloudTimeoutRetrySettings) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *OutputGrafanaCloudTimeoutRetrySettings) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *OutputGrafanaCloudTimeoutRetrySettings) GetMaxBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackoff
}

// OutputGrafanaCloudBackpressureBehavior - Whether to block, drop, or queue events when all receivers are exerting backpressure.
type OutputGrafanaCloudBackpressureBehavior string

const (
	OutputGrafanaCloudBackpressureBehaviorBlock OutputGrafanaCloudBackpressureBehavior = "block"
	OutputGrafanaCloudBackpressureBehaviorDrop  OutputGrafanaCloudBackpressureBehavior = "drop"
	OutputGrafanaCloudBackpressureBehaviorQueue OutputGrafanaCloudBackpressureBehavior = "queue"
)

func (e OutputGrafanaCloudBackpressureBehavior) ToPointer() *OutputGrafanaCloudBackpressureBehavior {
	return &e
}
func (e *OutputGrafanaCloudBackpressureBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		fallthrough
	case "queue":
		*e = OutputGrafanaCloudBackpressureBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputGrafanaCloudBackpressureBehavior: %v", v)
	}
}

// OutputGrafanaCloudCompression - Codec to use to compress the persisted data.
type OutputGrafanaCloudCompression string

const (
	OutputGrafanaCloudCompressionNone OutputGrafanaCloudCompression = "none"
	OutputGrafanaCloudCompressionGzip OutputGrafanaCloudCompression = "gzip"
)

func (e OutputGrafanaCloudCompression) ToPointer() *OutputGrafanaCloudCompression {
	return &e
}
func (e *OutputGrafanaCloudCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = OutputGrafanaCloudCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputGrafanaCloudCompression: %v", v)
	}
}

// OutputGrafanaCloudQueueFullBehavior - Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
type OutputGrafanaCloudQueueFullBehavior string

const (
	OutputGrafanaCloudQueueFullBehaviorBlock OutputGrafanaCloudQueueFullBehavior = "block"
	OutputGrafanaCloudQueueFullBehaviorDrop  OutputGrafanaCloudQueueFullBehavior = "drop"
)

func (e OutputGrafanaCloudQueueFullBehavior) ToPointer() *OutputGrafanaCloudQueueFullBehavior {
	return &e
}
func (e *OutputGrafanaCloudQueueFullBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputGrafanaCloudQueueFullBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputGrafanaCloudQueueFullBehavior: %v", v)
	}
}

// OutputGrafanaCloudMode - In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
type OutputGrafanaCloudMode string

const (
	OutputGrafanaCloudModeError        OutputGrafanaCloudMode = "error"
	OutputGrafanaCloudModeBackpressure OutputGrafanaCloudMode = "backpressure"
	OutputGrafanaCloudModeAlways       OutputGrafanaCloudMode = "always"
)

func (e OutputGrafanaCloudMode) ToPointer() *OutputGrafanaCloudMode {
	return &e
}
func (e *OutputGrafanaCloudMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "error":
		fallthrough
	case "backpressure":
		fallthrough
	case "always":
		*e = OutputGrafanaCloudMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputGrafanaCloudMode: %v", v)
	}
}

type OutputGrafanaCloudPqControls struct {
}

type OutputGrafanaCloud1 struct {
	// Unique ID for this output
	ID   string                 `json:"id"`
	Type OutputGrafanaCloudType `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards. These fields are added as dimensions and labels to generated metrics and logs, respectively.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// The endpoint to send logs to, e.g.: https://logs-prod-us-central1.grafana.net
	LokiURL string `json:"lokiUrl"`
	// The remote_write endpoint to send Prometheus metrics to, e.g.: https://prometheus-blocks-prod-us-central1.grafana.net/api/prom/push
	PrometheusURL *string `json:"prometheusUrl,omitempty"`
	// Name of the event field that contains the message to send. If not specified, Stream sends a JSON representation of the whole event.
	Message *string `json:"message,omitempty"`
	// Which format to use when sending logs to Loki (Protobuf or JSON).  Defaults to Protobuf.
	MessageFormat *OutputGrafanaCloudMessageFormat `default:"protobuf" json:"messageFormat"`
	// List of labels to send with logs. Labels define Loki streams, so use static labels to avoid proliferating label value combinations and streams. Can be merged and/or overridden by the event's __labels field (e.g.: '__labels: {host: "cribl.io", level: "error"}').
	Labels []OutputOutputGrafanaCloudLabels `json:"labels,omitempty"`
	// A JS expression that can be used to rename metrics. E.g.: name.replace(/\./g, '_') will replace all '.' characters in a metric's name with the supported '_' character. Use the 'name' global variable to access the metric's name.  You can access event fields' values via __e.<fieldName>.
	MetricRenameExpr *string                           `default:"name.replace(/[^a-zA-Z0-9_]/g, '_')" json:"metricRenameExpr"`
	PrometheusAuth   *OutputGrafanaCloudPrometheusAuth `json:"prometheusAuth,omitempty"`
	LokiAuth         *OutputGrafanaCloudLokiAuth       `json:"lokiAuth,omitempty"`
	// Maximum number of ongoing requests before blocking. Warning: Setting this value > 1 can cause Loki and Prometheus to complain about entries being delivered out of order.
	Concurrency *float64 `default:"1" json:"concurrency"`
	// Maximum size, in KB, of the request body. Warning: Setting this too low can increase the number of ongoing requests (depending on the value of 'Request concurrency'); this can cause Loki and Prometheus to complain about entries being delivered out of order.
	MaxPayloadSizeKB *float64 `default:"4096" json:"maxPayloadSizeKB"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited). Warning: Setting this too low can increase the number of ongoing requests (depending on the value of 'Request concurrency'); this can cause Loki and Prometheus to complain about entries being delivered out of order.
	MaxPayloadEvents *float64 `default:"0" json:"maxPayloadEvents"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Defaults to Yes. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `default:"30" json:"timeoutSec"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Maximum time between requests. Small values can reduce the payload size below the configured 'Max record size' and 'Max events per request'. Warning: Setting this too low can increase the number of ongoing requests (depending on the value of 'Request concurrency'); this can cause Loki and Prometheus to complain about entries being delivered out of order.
	FlushPeriodSec *float64 `default:"15" json:"flushPeriodSec"`
	// Headers to add to all events.
	ExtraHTTPHeaders []OutputGrafanaCloudExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// Enables round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `default:"false" json:"useRoundRobinDns"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *OutputGrafanaCloudFailedRequestLoggingMode `default:"none" json:"failedRequestLoggingMode"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable).
	ResponseRetrySettings []OutputGrafanaCloudResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *OutputGrafanaCloudTimeoutRetrySettings   `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `default:"false" json:"responseHonorRetryAfterHeader"`
	// Whether to block, drop, or queue events when all receivers are exerting backpressure.
	OnBackpressure *OutputGrafanaCloudBackpressureBehavior `default:"block" json:"onBackpressure"`
	Description    *string                                 `json:"description,omitempty"`
	// Whether to compress the payload body before sending. Applies only to Loki's JSON payloads, as both Prometheus' and Loki's Protobuf variant are snappy-compressed by default.
	Compress *bool `default:"true" json:"compress"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.).
	PqMaxFileSize *string `default:"1 MB" json:"pqMaxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `default:"5GB" json:"pqMaxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `default:"\\$CRIBL_HOME/state/queues" json:"pqPath"`
	// Codec to use to compress the persisted data.
	PqCompress *OutputGrafanaCloudCompression `default:"none" json:"pqCompress"`
	// Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *OutputGrafanaCloudQueueFullBehavior `default:"block" json:"pqOnBackpressure"`
	// In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
	PqMode     *OutputGrafanaCloudMode       `default:"error" json:"pqMode"`
	PqControls *OutputGrafanaCloudPqControls `json:"pqControls,omitempty"`
	Status     *TFStatus                     `json:"status,omitempty"`
}

func (o OutputGrafanaCloud1) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputGrafanaCloud1) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *OutputGrafanaCloud1) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *OutputGrafanaCloud1) GetType() OutputGrafanaCloudType {
	if o == nil {
		return OutputGrafanaCloudType("")
	}
	return o.Type
}

func (o *OutputGrafanaCloud1) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputGrafanaCloud1) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputGrafanaCloud1) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputGrafanaCloud1) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputGrafanaCloud1) GetLokiURL() string {
	if o == nil {
		return ""
	}
	return o.LokiURL
}

func (o *OutputGrafanaCloud1) GetPrometheusURL() *string {
	if o == nil {
		return nil
	}
	return o.PrometheusURL
}

func (o *OutputGrafanaCloud1) GetMessage() *string {
	if o == nil {
		return nil
	}
	return o.Message
}

func (o *OutputGrafanaCloud1) GetMessageFormat() *OutputGrafanaCloudMessageFormat {
	if o == nil {
		return nil
	}
	return o.MessageFormat
}

func (o *OutputGrafanaCloud1) GetLabels() []OutputOutputGrafanaCloudLabels {
	if o == nil {
		return nil
	}
	return o.Labels
}

func (o *OutputGrafanaCloud1) GetMetricRenameExpr() *string {
	if o == nil {
		return nil
	}
	return o.MetricRenameExpr
}

func (o *OutputGrafanaCloud1) GetPrometheusAuth() *OutputGrafanaCloudPrometheusAuth {
	if o == nil {
		return nil
	}
	return o.PrometheusAuth
}

func (o *OutputGrafanaCloud1) GetLokiAuth() *OutputGrafanaCloudLokiAuth {
	if o == nil {
		return nil
	}
	return o.LokiAuth
}

func (o *OutputGrafanaCloud1) GetConcurrency() *float64 {
	if o == nil {
		return nil
	}
	return o.Concurrency
}

func (o *OutputGrafanaCloud1) GetMaxPayloadSizeKB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadSizeKB
}

func (o *OutputGrafanaCloud1) GetMaxPayloadEvents() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadEvents
}

func (o *OutputGrafanaCloud1) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputGrafanaCloud1) GetTimeoutSec() *float64 {
	if o == nil {
		return nil
	}
	return o.TimeoutSec
}

func (o *OutputGrafanaCloud1) GetFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushPeriodSec
}

func (o *OutputGrafanaCloud1) GetExtraHTTPHeaders() []OutputGrafanaCloudExtraHTTPHeaders {
	if o == nil {
		return nil
	}
	return o.ExtraHTTPHeaders
}

func (o *OutputGrafanaCloud1) GetUseRoundRobinDNS() *bool {
	if o == nil {
		return nil
	}
	return o.UseRoundRobinDNS
}

func (o *OutputGrafanaCloud1) GetFailedRequestLoggingMode() *OutputGrafanaCloudFailedRequestLoggingMode {
	if o == nil {
		return nil
	}
	return o.FailedRequestLoggingMode
}

func (o *OutputGrafanaCloud1) GetSafeHeaders() []string {
	if o == nil {
		return nil
	}
	return o.SafeHeaders
}

func (o *OutputGrafanaCloud1) GetResponseRetrySettings() []OutputGrafanaCloudResponseRetrySettings {
	if o == nil {
		return nil
	}
	return o.ResponseRetrySettings
}

func (o *OutputGrafanaCloud1) GetTimeoutRetrySettings() *OutputGrafanaCloudTimeoutRetrySettings {
	if o == nil {
		return nil
	}
	return o.TimeoutRetrySettings
}

func (o *OutputGrafanaCloud1) GetResponseHonorRetryAfterHeader() *bool {
	if o == nil {
		return nil
	}
	return o.ResponseHonorRetryAfterHeader
}

func (o *OutputGrafanaCloud1) GetOnBackpressure() *OutputGrafanaCloudBackpressureBehavior {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputGrafanaCloud1) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputGrafanaCloud1) GetCompress() *bool {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *OutputGrafanaCloud1) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputGrafanaCloud1) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputGrafanaCloud1) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputGrafanaCloud1) GetPqCompress() *OutputGrafanaCloudCompression {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputGrafanaCloud1) GetPqOnBackpressure() *OutputGrafanaCloudQueueFullBehavior {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputGrafanaCloud1) GetPqMode() *OutputGrafanaCloudMode {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputGrafanaCloud1) GetPqControls() *OutputGrafanaCloudPqControls {
	if o == nil {
		return nil
	}
	return o.PqControls
}

func (o *OutputGrafanaCloud1) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type OutputGrafanaCloudUnionType string

const (
	OutputGrafanaCloudUnionTypeOutputGrafanaCloud1 OutputGrafanaCloudUnionType = "OutputGrafanaCloud_1"
	OutputGrafanaCloudUnionTypeOutputGrafanaCloud2 OutputGrafanaCloudUnionType = "OutputGrafanaCloud_2"
)

type OutputGrafanaCloud struct {
	OutputGrafanaCloud1 *OutputGrafanaCloud1 `queryParam:"inline"`
	OutputGrafanaCloud2 *OutputGrafanaCloud2 `queryParam:"inline"`

	Type OutputGrafanaCloudUnionType
}

func CreateOutputGrafanaCloudOutputGrafanaCloud1(outputGrafanaCloud1 OutputGrafanaCloud1) OutputGrafanaCloud {
	typ := OutputGrafanaCloudUnionTypeOutputGrafanaCloud1

	return OutputGrafanaCloud{
		OutputGrafanaCloud1: &outputGrafanaCloud1,
		Type:                typ,
	}
}

func CreateOutputGrafanaCloudOutputGrafanaCloud2(outputGrafanaCloud2 OutputGrafanaCloud2) OutputGrafanaCloud {
	typ := OutputGrafanaCloudUnionTypeOutputGrafanaCloud2

	return OutputGrafanaCloud{
		OutputGrafanaCloud2: &outputGrafanaCloud2,
		Type:                typ,
	}
}

func (u *OutputGrafanaCloud) UnmarshalJSON(data []byte) error {

	var outputGrafanaCloud1 OutputGrafanaCloud1 = OutputGrafanaCloud1{}
	if err := utils.UnmarshalJSON(data, &outputGrafanaCloud1, "", true, true); err == nil {
		u.OutputGrafanaCloud1 = &outputGrafanaCloud1
		u.Type = OutputGrafanaCloudUnionTypeOutputGrafanaCloud1
		return nil
	}

	var outputGrafanaCloud2 OutputGrafanaCloud2 = OutputGrafanaCloud2{}
	if err := utils.UnmarshalJSON(data, &outputGrafanaCloud2, "", true, true); err == nil {
		u.OutputGrafanaCloud2 = &outputGrafanaCloud2
		u.Type = OutputGrafanaCloudUnionTypeOutputGrafanaCloud2
		return nil
	}

	return fmt.Errorf("could not unmarshal `%s` into any supported union types for OutputGrafanaCloud", string(data))
}

func (u OutputGrafanaCloud) MarshalJSON() ([]byte, error) {
	if u.OutputGrafanaCloud1 != nil {
		return utils.MarshalJSON(u.OutputGrafanaCloud1, "", true)
	}

	if u.OutputGrafanaCloud2 != nil {
		return utils.MarshalJSON(u.OutputGrafanaCloud2, "", true)
	}

	return nil, errors.New("could not marshal union type OutputGrafanaCloud: all fields are null")
}

type OutputDatadogType string

const (
	OutputDatadogTypeDatadog OutputDatadogType = "datadog"
)

func (e OutputDatadogType) ToPointer() *OutputDatadogType {
	return &e
}
func (e *OutputDatadogType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "datadog":
		*e = OutputDatadogType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputDatadogType: %v", v)
	}
}

// SendLogsAs - The content type to use when sending logs.
type SendLogsAs string

const (
	SendLogsAsText SendLogsAs = "text"
	SendLogsAsJSON SendLogsAs = "json"
)

func (e SendLogsAs) ToPointer() *SendLogsAs {
	return &e
}
func (e *SendLogsAs) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "text":
		fallthrough
	case "json":
		*e = SendLogsAs(v)
		return nil
	default:
		return fmt.Errorf("invalid value for SendLogsAs: %v", v)
	}
}

// OutputDatadogSeverity - Default value for message severity. When you send logs as JSON objects, the event's '__severity' field (if set) will override this value.
type OutputDatadogSeverity string

const (
	OutputDatadogSeverityEmergency OutputDatadogSeverity = "emergency"
	OutputDatadogSeverityAlert     OutputDatadogSeverity = "alert"
	OutputDatadogSeverityCritical  OutputDatadogSeverity = "critical"
	OutputDatadogSeverityError     OutputDatadogSeverity = "error"
	OutputDatadogSeverityWarning   OutputDatadogSeverity = "warning"
	OutputDatadogSeverityNotice    OutputDatadogSeverity = "notice"
	OutputDatadogSeverityInfo      OutputDatadogSeverity = "info"
	OutputDatadogSeverityDebug     OutputDatadogSeverity = "debug"
)

func (e OutputDatadogSeverity) ToPointer() *OutputDatadogSeverity {
	return &e
}
func (e *OutputDatadogSeverity) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "emergency":
		fallthrough
	case "alert":
		fallthrough
	case "critical":
		fallthrough
	case "error":
		fallthrough
	case "warning":
		fallthrough
	case "notice":
		fallthrough
	case "info":
		fallthrough
	case "debug":
		*e = OutputDatadogSeverity(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputDatadogSeverity: %v", v)
	}
}

// DatadogSite - Datadog site to which events should be sent
type DatadogSite string

const (
	DatadogSiteUs     DatadogSite = "us"
	DatadogSiteUs3    DatadogSite = "us3"
	DatadogSiteUs5    DatadogSite = "us5"
	DatadogSiteEu     DatadogSite = "eu"
	DatadogSiteFed1   DatadogSite = "fed1"
	DatadogSiteAp1    DatadogSite = "ap1"
	DatadogSiteCustom DatadogSite = "custom"
)

func (e DatadogSite) ToPointer() *DatadogSite {
	return &e
}
func (e *DatadogSite) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "us":
		fallthrough
	case "us3":
		fallthrough
	case "us5":
		fallthrough
	case "eu":
		fallthrough
	case "fed1":
		fallthrough
	case "ap1":
		fallthrough
	case "custom":
		*e = DatadogSite(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DatadogSite: %v", v)
	}
}

type OutputDatadogExtraHTTPHeaders struct {
	// Field name
	Name *string `json:"name,omitempty"`
	// Field value
	Value string `json:"value"`
}

func (o *OutputDatadogExtraHTTPHeaders) GetName() *string {
	if o == nil {
		return nil
	}
	return o.Name
}

func (o *OutputDatadogExtraHTTPHeaders) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// OutputDatadogFailedRequestLoggingMode - Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
type OutputDatadogFailedRequestLoggingMode string

const (
	OutputDatadogFailedRequestLoggingModePayload           OutputDatadogFailedRequestLoggingMode = "payload"
	OutputDatadogFailedRequestLoggingModePayloadAndHeaders OutputDatadogFailedRequestLoggingMode = "payloadAndHeaders"
	OutputDatadogFailedRequestLoggingModeNone              OutputDatadogFailedRequestLoggingMode = "none"
)

func (e OutputDatadogFailedRequestLoggingMode) ToPointer() *OutputDatadogFailedRequestLoggingMode {
	return &e
}
func (e *OutputDatadogFailedRequestLoggingMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "payload":
		fallthrough
	case "payloadAndHeaders":
		fallthrough
	case "none":
		*e = OutputDatadogFailedRequestLoggingMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputDatadogFailedRequestLoggingMode: %v", v)
	}
}

type OutputDatadogResponseRetrySettings struct {
	// The HTTP response status code that will trigger retries
	HTTPStatus float64 `json:"httpStatus"`
	// How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"1000" json:"initialBackoff"`
	// Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackoff *float64 `default:"10000" json:"maxBackoff"`
}

func (o OutputDatadogResponseRetrySettings) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputDatadogResponseRetrySettings) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputDatadogResponseRetrySettings) GetHTTPStatus() float64 {
	if o == nil {
		return 0.0
	}
	return o.HTTPStatus
}

func (o *OutputDatadogResponseRetrySettings) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *OutputDatadogResponseRetrySettings) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *OutputDatadogResponseRetrySettings) GetMaxBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackoff
}

type OutputDatadogTimeoutRetrySettings struct {
	// Enable to retry on request timeout
	TimeoutRetry *bool `default:"false" json:"timeoutRetry"`
	// How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"1000" json:"initialBackoff"`
	// Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackoff *float64 `default:"10000" json:"maxBackoff"`
}

func (o OutputDatadogTimeoutRetrySettings) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputDatadogTimeoutRetrySettings) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputDatadogTimeoutRetrySettings) GetTimeoutRetry() *bool {
	if o == nil {
		return nil
	}
	return o.TimeoutRetry
}

func (o *OutputDatadogTimeoutRetrySettings) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *OutputDatadogTimeoutRetrySettings) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *OutputDatadogTimeoutRetrySettings) GetMaxBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackoff
}

// OutputDatadogBackpressureBehavior - Whether to block, drop, or queue events when all receivers are exerting backpressure.
type OutputDatadogBackpressureBehavior string

const (
	OutputDatadogBackpressureBehaviorBlock OutputDatadogBackpressureBehavior = "block"
	OutputDatadogBackpressureBehaviorDrop  OutputDatadogBackpressureBehavior = "drop"
	OutputDatadogBackpressureBehaviorQueue OutputDatadogBackpressureBehavior = "queue"
)

func (e OutputDatadogBackpressureBehavior) ToPointer() *OutputDatadogBackpressureBehavior {
	return &e
}
func (e *OutputDatadogBackpressureBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		fallthrough
	case "queue":
		*e = OutputDatadogBackpressureBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputDatadogBackpressureBehavior: %v", v)
	}
}

// OutputDatadogAuthenticationMethod - Enter API key directly, or select a stored secret
type OutputDatadogAuthenticationMethod string

const (
	OutputDatadogAuthenticationMethodManual OutputDatadogAuthenticationMethod = "manual"
	OutputDatadogAuthenticationMethodSecret OutputDatadogAuthenticationMethod = "secret"
)

func (e OutputDatadogAuthenticationMethod) ToPointer() *OutputDatadogAuthenticationMethod {
	return &e
}
func (e *OutputDatadogAuthenticationMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "manual":
		fallthrough
	case "secret":
		*e = OutputDatadogAuthenticationMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputDatadogAuthenticationMethod: %v", v)
	}
}

// OutputDatadogCompression - Codec to use to compress the persisted data.
type OutputDatadogCompression string

const (
	OutputDatadogCompressionNone OutputDatadogCompression = "none"
	OutputDatadogCompressionGzip OutputDatadogCompression = "gzip"
)

func (e OutputDatadogCompression) ToPointer() *OutputDatadogCompression {
	return &e
}
func (e *OutputDatadogCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = OutputDatadogCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputDatadogCompression: %v", v)
	}
}

// OutputDatadogQueueFullBehavior - Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
type OutputDatadogQueueFullBehavior string

const (
	OutputDatadogQueueFullBehaviorBlock OutputDatadogQueueFullBehavior = "block"
	OutputDatadogQueueFullBehaviorDrop  OutputDatadogQueueFullBehavior = "drop"
)

func (e OutputDatadogQueueFullBehavior) ToPointer() *OutputDatadogQueueFullBehavior {
	return &e
}
func (e *OutputDatadogQueueFullBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputDatadogQueueFullBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputDatadogQueueFullBehavior: %v", v)
	}
}

// OutputDatadogMode - In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
type OutputDatadogMode string

const (
	OutputDatadogModeError        OutputDatadogMode = "error"
	OutputDatadogModeBackpressure OutputDatadogMode = "backpressure"
	OutputDatadogModeAlways       OutputDatadogMode = "always"
)

func (e OutputDatadogMode) ToPointer() *OutputDatadogMode {
	return &e
}
func (e *OutputDatadogMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "error":
		fallthrough
	case "backpressure":
		fallthrough
	case "always":
		*e = OutputDatadogMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputDatadogMode: %v", v)
	}
}

type OutputDatadogPqControls struct {
}

type OutputDatadog struct {
	// Unique ID for this output
	ID   string            `json:"id"`
	Type OutputDatadogType `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// The content type to use when sending logs.
	ContentType *SendLogsAs `default:"json" json:"contentType"`
	// Name of the event field that contains the message to send. If not specified, Stream sends a JSON representation of the whole event.
	Message *string `json:"message,omitempty"`
	// Name of the source to send with logs. When you send logs as JSON objects, the event's 'source' field (if set) will override this value.
	Source *string `json:"source,omitempty"`
	// Name of the host to send with logs. When you send logs as JSON objects, the event's 'host' field (if set) will override this value.
	Host *string `json:"host,omitempty"`
	// Name of the service to send with logs. When you send logs as JSON objects, the event's '__service' field (if set) will override this value.
	Service *string `json:"service,omitempty"`
	// List of tags to send with logs (e.g., 'env:prod', 'env_staging:east').
	Tags []string `json:"tags,omitempty"`
	// When enabled, batches events by API key and the ddtags field on the event. When disabled, batches events only by API key. If incoming events have high cardinality in the ddtags field, disabling this setting may improve Destination performance.
	BatchByTags *bool `default:"true" json:"batchByTags"`
	// If enabled, the API key can be set from the event's '__agent_api_key' field.
	AllowAPIKeyFromEvents *bool `default:"false" json:"allowApiKeyFromEvents"`
	// Default value for message severity. When you send logs as JSON objects, the event's '__severity' field (if set) will override this value.
	Severity *OutputDatadogSeverity `json:"severity,omitempty"`
	// Datadog site to which events should be sent
	Site *DatadogSite `default:"us" json:"site"`
	// If not enabled, Datadog will transform 'counter' metrics to 'gauge'. [Learn more about Datadog metrics types.](https://docs.datadoghq.com/metrics/types/?tab=count)
	SendCountersAsCount *bool `default:"false" json:"sendCountersAsCount"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `default:"5" json:"concurrency"`
	// Maximum size, in KB, of the request body
	MaxPayloadSizeKB *float64 `default:"4096" json:"maxPayloadSizeKB"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited).
	MaxPayloadEvents *float64 `default:"0" json:"maxPayloadEvents"`
	// Compress the payload body before sending
	Compress *bool `default:"true" json:"compress"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Defaults to Yes. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `default:"30" json:"timeoutSec"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Max body size.
	FlushPeriodSec *float64 `default:"1" json:"flushPeriodSec"`
	// Headers to add to all events.
	ExtraHTTPHeaders []OutputDatadogExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// Enables round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `default:"false" json:"useRoundRobinDns"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *OutputDatadogFailedRequestLoggingMode `default:"none" json:"failedRequestLoggingMode"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable).
	ResponseRetrySettings []OutputDatadogResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *OutputDatadogTimeoutRetrySettings   `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `default:"false" json:"responseHonorRetryAfterHeader"`
	// Whether to block, drop, or queue events when all receivers are exerting backpressure.
	OnBackpressure *OutputDatadogBackpressureBehavior `default:"block" json:"onBackpressure"`
	// Enter API key directly, or select a stored secret
	AuthType *OutputDatadogAuthenticationMethod `default:"manual" json:"authType"`
	// Maximum total size of the batches waiting to be sent. If left blank, defaults to 5 times the max body size (if set). If 0, no limit is enforced.
	TotalMemoryLimitKB *float64 `json:"totalMemoryLimitKB,omitempty"`
	Description        *string  `json:"description,omitempty"`
	CustomURL          *string  `json:"customUrl,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.).
	PqMaxFileSize *string `default:"1 MB" json:"pqMaxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `default:"5GB" json:"pqMaxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `default:"\\$CRIBL_HOME/state/queues" json:"pqPath"`
	// Codec to use to compress the persisted data.
	PqCompress *OutputDatadogCompression `default:"none" json:"pqCompress"`
	// Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *OutputDatadogQueueFullBehavior `default:"block" json:"pqOnBackpressure"`
	// In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
	PqMode     *OutputDatadogMode       `default:"error" json:"pqMode"`
	PqControls *OutputDatadogPqControls `json:"pqControls,omitempty"`
	// Organization's API key in Datadog
	APIKey *string `json:"apiKey,omitempty"`
	// Select or create a stored text secret
	TextSecret *string   `json:"textSecret,omitempty"`
	Status     *TFStatus `json:"status,omitempty"`
}

func (o OutputDatadog) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputDatadog) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *OutputDatadog) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *OutputDatadog) GetType() OutputDatadogType {
	if o == nil {
		return OutputDatadogType("")
	}
	return o.Type
}

func (o *OutputDatadog) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputDatadog) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputDatadog) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputDatadog) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputDatadog) GetContentType() *SendLogsAs {
	if o == nil {
		return nil
	}
	return o.ContentType
}

func (o *OutputDatadog) GetMessage() *string {
	if o == nil {
		return nil
	}
	return o.Message
}

func (o *OutputDatadog) GetSource() *string {
	if o == nil {
		return nil
	}
	return o.Source
}

func (o *OutputDatadog) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *OutputDatadog) GetService() *string {
	if o == nil {
		return nil
	}
	return o.Service
}

func (o *OutputDatadog) GetTags() []string {
	if o == nil {
		return nil
	}
	return o.Tags
}

func (o *OutputDatadog) GetBatchByTags() *bool {
	if o == nil {
		return nil
	}
	return o.BatchByTags
}

func (o *OutputDatadog) GetAllowAPIKeyFromEvents() *bool {
	if o == nil {
		return nil
	}
	return o.AllowAPIKeyFromEvents
}

func (o *OutputDatadog) GetSeverity() *OutputDatadogSeverity {
	if o == nil {
		return nil
	}
	return o.Severity
}

func (o *OutputDatadog) GetSite() *DatadogSite {
	if o == nil {
		return nil
	}
	return o.Site
}

func (o *OutputDatadog) GetSendCountersAsCount() *bool {
	if o == nil {
		return nil
	}
	return o.SendCountersAsCount
}

func (o *OutputDatadog) GetConcurrency() *float64 {
	if o == nil {
		return nil
	}
	return o.Concurrency
}

func (o *OutputDatadog) GetMaxPayloadSizeKB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadSizeKB
}

func (o *OutputDatadog) GetMaxPayloadEvents() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadEvents
}

func (o *OutputDatadog) GetCompress() *bool {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *OutputDatadog) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputDatadog) GetTimeoutSec() *float64 {
	if o == nil {
		return nil
	}
	return o.TimeoutSec
}

func (o *OutputDatadog) GetFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushPeriodSec
}

func (o *OutputDatadog) GetExtraHTTPHeaders() []OutputDatadogExtraHTTPHeaders {
	if o == nil {
		return nil
	}
	return o.ExtraHTTPHeaders
}

func (o *OutputDatadog) GetUseRoundRobinDNS() *bool {
	if o == nil {
		return nil
	}
	return o.UseRoundRobinDNS
}

func (o *OutputDatadog) GetFailedRequestLoggingMode() *OutputDatadogFailedRequestLoggingMode {
	if o == nil {
		return nil
	}
	return o.FailedRequestLoggingMode
}

func (o *OutputDatadog) GetSafeHeaders() []string {
	if o == nil {
		return nil
	}
	return o.SafeHeaders
}

func (o *OutputDatadog) GetResponseRetrySettings() []OutputDatadogResponseRetrySettings {
	if o == nil {
		return nil
	}
	return o.ResponseRetrySettings
}

func (o *OutputDatadog) GetTimeoutRetrySettings() *OutputDatadogTimeoutRetrySettings {
	if o == nil {
		return nil
	}
	return o.TimeoutRetrySettings
}

func (o *OutputDatadog) GetResponseHonorRetryAfterHeader() *bool {
	if o == nil {
		return nil
	}
	return o.ResponseHonorRetryAfterHeader
}

func (o *OutputDatadog) GetOnBackpressure() *OutputDatadogBackpressureBehavior {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputDatadog) GetAuthType() *OutputDatadogAuthenticationMethod {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *OutputDatadog) GetTotalMemoryLimitKB() *float64 {
	if o == nil {
		return nil
	}
	return o.TotalMemoryLimitKB
}

func (o *OutputDatadog) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputDatadog) GetCustomURL() *string {
	if o == nil {
		return nil
	}
	return o.CustomURL
}

func (o *OutputDatadog) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputDatadog) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputDatadog) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputDatadog) GetPqCompress() *OutputDatadogCompression {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputDatadog) GetPqOnBackpressure() *OutputDatadogQueueFullBehavior {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputDatadog) GetPqMode() *OutputDatadogMode {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputDatadog) GetPqControls() *OutputDatadogPqControls {
	if o == nil {
		return nil
	}
	return o.PqControls
}

func (o *OutputDatadog) GetAPIKey() *string {
	if o == nil {
		return nil
	}
	return o.APIKey
}

func (o *OutputDatadog) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *OutputDatadog) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type OutputSumoLogicType string

const (
	OutputSumoLogicTypeSumoLogic OutputSumoLogicType = "sumo_logic"
)

func (e OutputSumoLogicType) ToPointer() *OutputSumoLogicType {
	return &e
}
func (e *OutputSumoLogicType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "sumo_logic":
		*e = OutputSumoLogicType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSumoLogicType: %v", v)
	}
}

// OutputSumoLogicDataFormat - Optionally, preserve the raw event format instead of json-ifying it.
type OutputSumoLogicDataFormat string

const (
	OutputSumoLogicDataFormatJSON OutputSumoLogicDataFormat = "json"
	OutputSumoLogicDataFormatRaw  OutputSumoLogicDataFormat = "raw"
)

func (e OutputSumoLogicDataFormat) ToPointer() *OutputSumoLogicDataFormat {
	return &e
}
func (e *OutputSumoLogicDataFormat) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "json":
		fallthrough
	case "raw":
		*e = OutputSumoLogicDataFormat(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSumoLogicDataFormat: %v", v)
	}
}

type OutputSumoLogicExtraHTTPHeaders struct {
	// Field name
	Name *string `json:"name,omitempty"`
	// Field value
	Value string `json:"value"`
}

func (o *OutputSumoLogicExtraHTTPHeaders) GetName() *string {
	if o == nil {
		return nil
	}
	return o.Name
}

func (o *OutputSumoLogicExtraHTTPHeaders) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// OutputSumoLogicFailedRequestLoggingMode - Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
type OutputSumoLogicFailedRequestLoggingMode string

const (
	OutputSumoLogicFailedRequestLoggingModePayload           OutputSumoLogicFailedRequestLoggingMode = "payload"
	OutputSumoLogicFailedRequestLoggingModePayloadAndHeaders OutputSumoLogicFailedRequestLoggingMode = "payloadAndHeaders"
	OutputSumoLogicFailedRequestLoggingModeNone              OutputSumoLogicFailedRequestLoggingMode = "none"
)

func (e OutputSumoLogicFailedRequestLoggingMode) ToPointer() *OutputSumoLogicFailedRequestLoggingMode {
	return &e
}
func (e *OutputSumoLogicFailedRequestLoggingMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "payload":
		fallthrough
	case "payloadAndHeaders":
		fallthrough
	case "none":
		*e = OutputSumoLogicFailedRequestLoggingMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSumoLogicFailedRequestLoggingMode: %v", v)
	}
}

type OutputSumoLogicResponseRetrySettings struct {
	// The HTTP response status code that will trigger retries
	HTTPStatus float64 `json:"httpStatus"`
	// How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"1000" json:"initialBackoff"`
	// Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackoff *float64 `default:"10000" json:"maxBackoff"`
}

func (o OutputSumoLogicResponseRetrySettings) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputSumoLogicResponseRetrySettings) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputSumoLogicResponseRetrySettings) GetHTTPStatus() float64 {
	if o == nil {
		return 0.0
	}
	return o.HTTPStatus
}

func (o *OutputSumoLogicResponseRetrySettings) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *OutputSumoLogicResponseRetrySettings) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *OutputSumoLogicResponseRetrySettings) GetMaxBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackoff
}

type OutputSumoLogicTimeoutRetrySettings struct {
	// Enable to retry on request timeout
	TimeoutRetry *bool `default:"false" json:"timeoutRetry"`
	// How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"1000" json:"initialBackoff"`
	// Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackoff *float64 `default:"10000" json:"maxBackoff"`
}

func (o OutputSumoLogicTimeoutRetrySettings) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputSumoLogicTimeoutRetrySettings) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputSumoLogicTimeoutRetrySettings) GetTimeoutRetry() *bool {
	if o == nil {
		return nil
	}
	return o.TimeoutRetry
}

func (o *OutputSumoLogicTimeoutRetrySettings) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *OutputSumoLogicTimeoutRetrySettings) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *OutputSumoLogicTimeoutRetrySettings) GetMaxBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackoff
}

// OutputSumoLogicBackpressureBehavior - Whether to block, drop, or queue events when all receivers are exerting backpressure.
type OutputSumoLogicBackpressureBehavior string

const (
	OutputSumoLogicBackpressureBehaviorBlock OutputSumoLogicBackpressureBehavior = "block"
	OutputSumoLogicBackpressureBehaviorDrop  OutputSumoLogicBackpressureBehavior = "drop"
	OutputSumoLogicBackpressureBehaviorQueue OutputSumoLogicBackpressureBehavior = "queue"
)

func (e OutputSumoLogicBackpressureBehavior) ToPointer() *OutputSumoLogicBackpressureBehavior {
	return &e
}
func (e *OutputSumoLogicBackpressureBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		fallthrough
	case "queue":
		*e = OutputSumoLogicBackpressureBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSumoLogicBackpressureBehavior: %v", v)
	}
}

// OutputSumoLogicCompression - Codec to use to compress the persisted data.
type OutputSumoLogicCompression string

const (
	OutputSumoLogicCompressionNone OutputSumoLogicCompression = "none"
	OutputSumoLogicCompressionGzip OutputSumoLogicCompression = "gzip"
)

func (e OutputSumoLogicCompression) ToPointer() *OutputSumoLogicCompression {
	return &e
}
func (e *OutputSumoLogicCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = OutputSumoLogicCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSumoLogicCompression: %v", v)
	}
}

// OutputSumoLogicQueueFullBehavior - Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
type OutputSumoLogicQueueFullBehavior string

const (
	OutputSumoLogicQueueFullBehaviorBlock OutputSumoLogicQueueFullBehavior = "block"
	OutputSumoLogicQueueFullBehaviorDrop  OutputSumoLogicQueueFullBehavior = "drop"
)

func (e OutputSumoLogicQueueFullBehavior) ToPointer() *OutputSumoLogicQueueFullBehavior {
	return &e
}
func (e *OutputSumoLogicQueueFullBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputSumoLogicQueueFullBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSumoLogicQueueFullBehavior: %v", v)
	}
}

// OutputSumoLogicMode - In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
type OutputSumoLogicMode string

const (
	OutputSumoLogicModeError        OutputSumoLogicMode = "error"
	OutputSumoLogicModeBackpressure OutputSumoLogicMode = "backpressure"
	OutputSumoLogicModeAlways       OutputSumoLogicMode = "always"
)

func (e OutputSumoLogicMode) ToPointer() *OutputSumoLogicMode {
	return &e
}
func (e *OutputSumoLogicMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "error":
		fallthrough
	case "backpressure":
		fallthrough
	case "always":
		*e = OutputSumoLogicMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSumoLogicMode: %v", v)
	}
}

type OutputSumoLogicPqControls struct {
}

type OutputSumoLogic struct {
	// Unique ID for this output
	ID   *string             `json:"id,omitempty"`
	Type OutputSumoLogicType `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Sumo Logic HTTP collector URL to which events should be sent.
	URL string `json:"url"`
	// Optionally, override the source name configured on the Sumo Logic HTTP collector. This can also be overridden at the event level with the __sourceName field.
	CustomSource *string `json:"customSource,omitempty"`
	// Optionally, override the source category configured on the Sumo Logic HTTP collector. This can also be overridden at the event level with the __sourceCategory field.
	CustomCategory *string `json:"customCategory,omitempty"`
	// Optionally, preserve the raw event format instead of json-ifying it.
	Format *OutputSumoLogicDataFormat `default:"json" json:"format"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `default:"5" json:"concurrency"`
	// Maximum size, in KB, of the request body
	MaxPayloadSizeKB *float64 `default:"1024" json:"maxPayloadSizeKB"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited).
	MaxPayloadEvents *float64 `default:"0" json:"maxPayloadEvents"`
	// Compress the payload body before sending
	Compress *bool `default:"true" json:"compress"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Defaults to Yes. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `default:"30" json:"timeoutSec"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Max body size.
	FlushPeriodSec *float64 `default:"1" json:"flushPeriodSec"`
	// Headers to add to all events.
	ExtraHTTPHeaders []OutputSumoLogicExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// Enables round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `default:"false" json:"useRoundRobinDns"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *OutputSumoLogicFailedRequestLoggingMode `default:"none" json:"failedRequestLoggingMode"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable).
	ResponseRetrySettings []OutputSumoLogicResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *OutputSumoLogicTimeoutRetrySettings   `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `default:"false" json:"responseHonorRetryAfterHeader"`
	// Whether to block, drop, or queue events when all receivers are exerting backpressure.
	OnBackpressure *OutputSumoLogicBackpressureBehavior `default:"block" json:"onBackpressure"`
	// Maximum total size of the batches waiting to be sent. If left blank, defaults to 5 times the max body size (if set). If 0, no limit is enforced.
	TotalMemoryLimitKB *float64 `json:"totalMemoryLimitKB,omitempty"`
	Description        *string  `json:"description,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.).
	PqMaxFileSize *string `default:"1 MB" json:"pqMaxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `default:"5GB" json:"pqMaxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `default:"\\$CRIBL_HOME/state/queues" json:"pqPath"`
	// Codec to use to compress the persisted data.
	PqCompress *OutputSumoLogicCompression `default:"none" json:"pqCompress"`
	// Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *OutputSumoLogicQueueFullBehavior `default:"block" json:"pqOnBackpressure"`
	// In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
	PqMode     *OutputSumoLogicMode       `default:"error" json:"pqMode"`
	PqControls *OutputSumoLogicPqControls `json:"pqControls,omitempty"`
	Status     *TFStatus                  `json:"status,omitempty"`
}

func (o OutputSumoLogic) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputSumoLogic) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *OutputSumoLogic) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *OutputSumoLogic) GetType() OutputSumoLogicType {
	if o == nil {
		return OutputSumoLogicType("")
	}
	return o.Type
}

func (o *OutputSumoLogic) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputSumoLogic) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputSumoLogic) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputSumoLogic) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputSumoLogic) GetURL() string {
	if o == nil {
		return ""
	}
	return o.URL
}

func (o *OutputSumoLogic) GetCustomSource() *string {
	if o == nil {
		return nil
	}
	return o.CustomSource
}

func (o *OutputSumoLogic) GetCustomCategory() *string {
	if o == nil {
		return nil
	}
	return o.CustomCategory
}

func (o *OutputSumoLogic) GetFormat() *OutputSumoLogicDataFormat {
	if o == nil {
		return nil
	}
	return o.Format
}

func (o *OutputSumoLogic) GetConcurrency() *float64 {
	if o == nil {
		return nil
	}
	return o.Concurrency
}

func (o *OutputSumoLogic) GetMaxPayloadSizeKB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadSizeKB
}

func (o *OutputSumoLogic) GetMaxPayloadEvents() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadEvents
}

func (o *OutputSumoLogic) GetCompress() *bool {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *OutputSumoLogic) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputSumoLogic) GetTimeoutSec() *float64 {
	if o == nil {
		return nil
	}
	return o.TimeoutSec
}

func (o *OutputSumoLogic) GetFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushPeriodSec
}

func (o *OutputSumoLogic) GetExtraHTTPHeaders() []OutputSumoLogicExtraHTTPHeaders {
	if o == nil {
		return nil
	}
	return o.ExtraHTTPHeaders
}

func (o *OutputSumoLogic) GetUseRoundRobinDNS() *bool {
	if o == nil {
		return nil
	}
	return o.UseRoundRobinDNS
}

func (o *OutputSumoLogic) GetFailedRequestLoggingMode() *OutputSumoLogicFailedRequestLoggingMode {
	if o == nil {
		return nil
	}
	return o.FailedRequestLoggingMode
}

func (o *OutputSumoLogic) GetSafeHeaders() []string {
	if o == nil {
		return nil
	}
	return o.SafeHeaders
}

func (o *OutputSumoLogic) GetResponseRetrySettings() []OutputSumoLogicResponseRetrySettings {
	if o == nil {
		return nil
	}
	return o.ResponseRetrySettings
}

func (o *OutputSumoLogic) GetTimeoutRetrySettings() *OutputSumoLogicTimeoutRetrySettings {
	if o == nil {
		return nil
	}
	return o.TimeoutRetrySettings
}

func (o *OutputSumoLogic) GetResponseHonorRetryAfterHeader() *bool {
	if o == nil {
		return nil
	}
	return o.ResponseHonorRetryAfterHeader
}

func (o *OutputSumoLogic) GetOnBackpressure() *OutputSumoLogicBackpressureBehavior {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputSumoLogic) GetTotalMemoryLimitKB() *float64 {
	if o == nil {
		return nil
	}
	return o.TotalMemoryLimitKB
}

func (o *OutputSumoLogic) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputSumoLogic) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputSumoLogic) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputSumoLogic) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputSumoLogic) GetPqCompress() *OutputSumoLogicCompression {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputSumoLogic) GetPqOnBackpressure() *OutputSumoLogicQueueFullBehavior {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputSumoLogic) GetPqMode() *OutputSumoLogicMode {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputSumoLogic) GetPqControls() *OutputSumoLogicPqControls {
	if o == nil {
		return nil
	}
	return o.PqControls
}

func (o *OutputSumoLogic) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type OutputSnmpType string

const (
	OutputSnmpTypeSnmp OutputSnmpType = "snmp"
)

func (e OutputSnmpType) ToPointer() *OutputSnmpType {
	return &e
}
func (e *OutputSnmpType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "snmp":
		*e = OutputSnmpType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSnmpType: %v", v)
	}
}

type OutputSnmpHosts struct {
	// Destination host
	Host string `json:"host"`
	// Destination port, default is 162
	Port *float64 `default:"162" json:"port"`
}

func (o OutputSnmpHosts) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputSnmpHosts) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputSnmpHosts) GetHost() string {
	if o == nil {
		return ""
	}
	return o.Host
}

func (o *OutputSnmpHosts) GetPort() *float64 {
	if o == nil {
		return nil
	}
	return o.Port
}

type OutputSnmp struct {
	// Unique ID for this output
	ID   *string        `json:"id,omitempty"`
	Type OutputSnmpType `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// One or more SNMP destinations to forward traps to
	Hosts []OutputSnmpHosts `json:"hosts"`
	// How often to resolve the destination hostname to an IP address. Ignored if all destinations are IP addresses. A value of 0 means every trap sent will incur a DNS lookup.
	DNSResolvePeriodSec *float64  `default:"0" json:"dnsResolvePeriodSec"`
	Description         *string   `json:"description,omitempty"`
	Status              *TFStatus `json:"status,omitempty"`
}

func (o OutputSnmp) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputSnmp) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *OutputSnmp) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *OutputSnmp) GetType() OutputSnmpType {
	if o == nil {
		return OutputSnmpType("")
	}
	return o.Type
}

func (o *OutputSnmp) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputSnmp) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputSnmp) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputSnmp) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputSnmp) GetHosts() []OutputSnmpHosts {
	if o == nil {
		return []OutputSnmpHosts{}
	}
	return o.Hosts
}

func (o *OutputSnmp) GetDNSResolvePeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.DNSResolvePeriodSec
}

func (o *OutputSnmp) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputSnmp) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type OutputSqsType string

const (
	OutputSqsTypeSqs OutputSqsType = "sqs"
)

func (e OutputSqsType) ToPointer() *OutputSqsType {
	return &e
}
func (e *OutputSqsType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "sqs":
		*e = OutputSqsType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSqsType: %v", v)
	}
}

// OutputSqsQueueType - The queue type used (or created). Defaults to Standard.
type OutputSqsQueueType string

const (
	OutputSqsQueueTypeStandard OutputSqsQueueType = "standard"
	OutputSqsQueueTypeFifo     OutputSqsQueueType = "fifo"
)

func (e OutputSqsQueueType) ToPointer() *OutputSqsQueueType {
	return &e
}
func (e *OutputSqsQueueType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "standard":
		fallthrough
	case "fifo":
		*e = OutputSqsQueueType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSqsQueueType: %v", v)
	}
}

// OutputSqsAuthenticationMethod - AWS authentication method. Choose Auto to use IAM roles.
type OutputSqsAuthenticationMethod string

const (
	OutputSqsAuthenticationMethodAuto   OutputSqsAuthenticationMethod = "auto"
	OutputSqsAuthenticationMethodManual OutputSqsAuthenticationMethod = "manual"
	OutputSqsAuthenticationMethodSecret OutputSqsAuthenticationMethod = "secret"
)

func (e OutputSqsAuthenticationMethod) ToPointer() *OutputSqsAuthenticationMethod {
	return &e
}
func (e *OutputSqsAuthenticationMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "auto":
		fallthrough
	case "manual":
		fallthrough
	case "secret":
		*e = OutputSqsAuthenticationMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSqsAuthenticationMethod: %v", v)
	}
}

// OutputSqsSignatureVersion - Signature version to use for signing SQS requests
type OutputSqsSignatureVersion string

const (
	OutputSqsSignatureVersionV2 OutputSqsSignatureVersion = "v2"
	OutputSqsSignatureVersionV4 OutputSqsSignatureVersion = "v4"
)

func (e OutputSqsSignatureVersion) ToPointer() *OutputSqsSignatureVersion {
	return &e
}
func (e *OutputSqsSignatureVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "v2":
		fallthrough
	case "v4":
		*e = OutputSqsSignatureVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSqsSignatureVersion: %v", v)
	}
}

// OutputSqsBackpressureBehavior - Whether to block, drop, or queue events when all receivers are exerting backpressure.
type OutputSqsBackpressureBehavior string

const (
	OutputSqsBackpressureBehaviorBlock OutputSqsBackpressureBehavior = "block"
	OutputSqsBackpressureBehaviorDrop  OutputSqsBackpressureBehavior = "drop"
	OutputSqsBackpressureBehaviorQueue OutputSqsBackpressureBehavior = "queue"
)

func (e OutputSqsBackpressureBehavior) ToPointer() *OutputSqsBackpressureBehavior {
	return &e
}
func (e *OutputSqsBackpressureBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		fallthrough
	case "queue":
		*e = OutputSqsBackpressureBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSqsBackpressureBehavior: %v", v)
	}
}

// OutputSqsCompression - Codec to use to compress the persisted data.
type OutputSqsCompression string

const (
	OutputSqsCompressionNone OutputSqsCompression = "none"
	OutputSqsCompressionGzip OutputSqsCompression = "gzip"
)

func (e OutputSqsCompression) ToPointer() *OutputSqsCompression {
	return &e
}
func (e *OutputSqsCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = OutputSqsCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSqsCompression: %v", v)
	}
}

// OutputSqsQueueFullBehavior - Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
type OutputSqsQueueFullBehavior string

const (
	OutputSqsQueueFullBehaviorBlock OutputSqsQueueFullBehavior = "block"
	OutputSqsQueueFullBehaviorDrop  OutputSqsQueueFullBehavior = "drop"
)

func (e OutputSqsQueueFullBehavior) ToPointer() *OutputSqsQueueFullBehavior {
	return &e
}
func (e *OutputSqsQueueFullBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputSqsQueueFullBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSqsQueueFullBehavior: %v", v)
	}
}

// OutputSqsMode - In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
type OutputSqsMode string

const (
	OutputSqsModeError        OutputSqsMode = "error"
	OutputSqsModeBackpressure OutputSqsMode = "backpressure"
	OutputSqsModeAlways       OutputSqsMode = "always"
)

func (e OutputSqsMode) ToPointer() *OutputSqsMode {
	return &e
}
func (e *OutputSqsMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "error":
		fallthrough
	case "backpressure":
		fallthrough
	case "always":
		*e = OutputSqsMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSqsMode: %v", v)
	}
}

type OutputSqsPqControls struct {
}

type OutputSqs struct {
	// Unique ID for this output
	ID   *string        `json:"id,omitempty"`
	Type *OutputSqsType `json:"type,omitempty"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// The name, URL, or ARN of the SQS queue to send events to. When a non-AWS URL is specified, format must be: '{url}/myQueueName'. Example: 'https://host:port/myQueueName'. Must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at init time. Example referencing a Global Variable: `https://host:port/myQueue-${C.vars.myVar}`.
	QueueName string `json:"queueName"`
	// The queue type used (or created). Defaults to Standard.
	QueueType *OutputSqsQueueType `default:"standard" json:"queueType"`
	// SQS queue owner's AWS account ID. Leave empty if SQS queue is in same AWS account.
	AwsAccountID *string `json:"awsAccountId,omitempty"`
	// This parameter applies only to FIFO queues. The tag that specifies that a message belongs to a specific message group. Messages that belong to the same message group are processed in a FIFO manner. Use event field __messageGroupId to override this value.
	MessageGroupID *string `default:"cribl" json:"messageGroupId"`
	// Create queue if it does not exist.
	CreateQueue *bool `default:"true" json:"createQueue"`
	// AWS authentication method. Choose Auto to use IAM roles.
	AwsAuthenticationMethod *OutputSqsAuthenticationMethod `default:"auto" json:"awsAuthenticationMethod"`
	AwsSecretKey            *string                        `json:"awsSecretKey,omitempty"`
	// AWS Region where the SQS queue is located. Required, unless the Queue entry is a URL or ARN that includes a Region.
	Region *string `json:"region,omitempty"`
	// SQS service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to SQS-compatible endpoint.
	Endpoint *string `json:"endpoint,omitempty"`
	// Signature version to use for signing SQS requests
	SignatureVersion *OutputSqsSignatureVersion `default:"v4" json:"signatureVersion"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `default:"true" json:"reuseConnections"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Use Assume Role credentials to access SQS
	EnableAssumeRole *bool `default:"false" json:"enableAssumeRole"`
	// Amazon Resource Name (ARN) of the role to assume
	AssumeRoleArn *string `json:"assumeRoleArn,omitempty"`
	// External ID to use when assuming role
	AssumeRoleExternalID *string `json:"assumeRoleExternalId,omitempty"`
	// Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
	DurationSeconds *float64 `default:"3600" json:"durationSeconds"`
	// Maximum number of queued batches before blocking.
	MaxQueueSize *float64 `default:"100" json:"maxQueueSize"`
	// Maximum size (KB) of batches to send. Per the SQS spec, the max allowed value is 256 KB.
	MaxRecordSizeKB *float64 `default:"256" json:"maxRecordSizeKB"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Max record size.
	FlushPeriodSec *float64 `default:"1" json:"flushPeriodSec"`
	// The maximum number of in-progress API requests before backpressure is applied.
	MaxInProgress *float64 `default:"10" json:"maxInProgress"`
	// Whether to block, drop, or queue events when all receivers are exerting backpressure.
	OnBackpressure *OutputSqsBackpressureBehavior `default:"block" json:"onBackpressure"`
	Description    *string                        `json:"description,omitempty"`
	AwsAPIKey      *string                        `json:"awsApiKey,omitempty"`
	// Select or create a stored secret that references your access key and secret key
	AwsSecret *string `json:"awsSecret,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.).
	PqMaxFileSize *string `default:"1 MB" json:"pqMaxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `default:"5GB" json:"pqMaxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `default:"\\$CRIBL_HOME/state/queues" json:"pqPath"`
	// Codec to use to compress the persisted data.
	PqCompress *OutputSqsCompression `default:"none" json:"pqCompress"`
	// Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *OutputSqsQueueFullBehavior `default:"block" json:"pqOnBackpressure"`
	// In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
	PqMode     *OutputSqsMode       `default:"error" json:"pqMode"`
	PqControls *OutputSqsPqControls `json:"pqControls,omitempty"`
	Status     *TFStatus            `json:"status,omitempty"`
}

func (o OutputSqs) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputSqs) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *OutputSqs) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *OutputSqs) GetType() *OutputSqsType {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *OutputSqs) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputSqs) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputSqs) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputSqs) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputSqs) GetQueueName() string {
	if o == nil {
		return ""
	}
	return o.QueueName
}

func (o *OutputSqs) GetQueueType() *OutputSqsQueueType {
	if o == nil {
		return nil
	}
	return o.QueueType
}

func (o *OutputSqs) GetAwsAccountID() *string {
	if o == nil {
		return nil
	}
	return o.AwsAccountID
}

func (o *OutputSqs) GetMessageGroupID() *string {
	if o == nil {
		return nil
	}
	return o.MessageGroupID
}

func (o *OutputSqs) GetCreateQueue() *bool {
	if o == nil {
		return nil
	}
	return o.CreateQueue
}

func (o *OutputSqs) GetAwsAuthenticationMethod() *OutputSqsAuthenticationMethod {
	if o == nil {
		return nil
	}
	return o.AwsAuthenticationMethod
}

func (o *OutputSqs) GetAwsSecretKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecretKey
}

func (o *OutputSqs) GetRegion() *string {
	if o == nil {
		return nil
	}
	return o.Region
}

func (o *OutputSqs) GetEndpoint() *string {
	if o == nil {
		return nil
	}
	return o.Endpoint
}

func (o *OutputSqs) GetSignatureVersion() *OutputSqsSignatureVersion {
	if o == nil {
		return nil
	}
	return o.SignatureVersion
}

func (o *OutputSqs) GetReuseConnections() *bool {
	if o == nil {
		return nil
	}
	return o.ReuseConnections
}

func (o *OutputSqs) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputSqs) GetEnableAssumeRole() *bool {
	if o == nil {
		return nil
	}
	return o.EnableAssumeRole
}

func (o *OutputSqs) GetAssumeRoleArn() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleArn
}

func (o *OutputSqs) GetAssumeRoleExternalID() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleExternalID
}

func (o *OutputSqs) GetDurationSeconds() *float64 {
	if o == nil {
		return nil
	}
	return o.DurationSeconds
}

func (o *OutputSqs) GetMaxQueueSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxQueueSize
}

func (o *OutputSqs) GetMaxRecordSizeKB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxRecordSizeKB
}

func (o *OutputSqs) GetFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushPeriodSec
}

func (o *OutputSqs) GetMaxInProgress() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxInProgress
}

func (o *OutputSqs) GetOnBackpressure() *OutputSqsBackpressureBehavior {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputSqs) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputSqs) GetAwsAPIKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsAPIKey
}

func (o *OutputSqs) GetAwsSecret() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecret
}

func (o *OutputSqs) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputSqs) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputSqs) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputSqs) GetPqCompress() *OutputSqsCompression {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputSqs) GetPqOnBackpressure() *OutputSqsQueueFullBehavior {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputSqs) GetPqMode() *OutputSqsMode {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputSqs) GetPqControls() *OutputSqsPqControls {
	if o == nil {
		return nil
	}
	return o.PqControls
}

func (o *OutputSqs) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type OutputSnsType string

const (
	OutputSnsTypeSns OutputSnsType = "sns"
)

func (e OutputSnsType) ToPointer() *OutputSnsType {
	return &e
}
func (e *OutputSnsType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "sns":
		*e = OutputSnsType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSnsType: %v", v)
	}
}

// OutputSnsAuthenticationMethod - AWS authentication method. Choose Auto to use IAM roles.
type OutputSnsAuthenticationMethod string

const (
	OutputSnsAuthenticationMethodAuto   OutputSnsAuthenticationMethod = "auto"
	OutputSnsAuthenticationMethodManual OutputSnsAuthenticationMethod = "manual"
	OutputSnsAuthenticationMethodSecret OutputSnsAuthenticationMethod = "secret"
)

func (e OutputSnsAuthenticationMethod) ToPointer() *OutputSnsAuthenticationMethod {
	return &e
}
func (e *OutputSnsAuthenticationMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "auto":
		fallthrough
	case "manual":
		fallthrough
	case "secret":
		*e = OutputSnsAuthenticationMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSnsAuthenticationMethod: %v", v)
	}
}

// OutputSnsSignatureVersion - Signature version to use for signing SNS requests
type OutputSnsSignatureVersion string

const (
	OutputSnsSignatureVersionV2 OutputSnsSignatureVersion = "v2"
	OutputSnsSignatureVersionV4 OutputSnsSignatureVersion = "v4"
)

func (e OutputSnsSignatureVersion) ToPointer() *OutputSnsSignatureVersion {
	return &e
}
func (e *OutputSnsSignatureVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "v2":
		fallthrough
	case "v4":
		*e = OutputSnsSignatureVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSnsSignatureVersion: %v", v)
	}
}

// OutputSnsBackpressureBehavior - Whether to block, drop, or queue events when all receivers are exerting backpressure.
type OutputSnsBackpressureBehavior string

const (
	OutputSnsBackpressureBehaviorBlock OutputSnsBackpressureBehavior = "block"
	OutputSnsBackpressureBehaviorDrop  OutputSnsBackpressureBehavior = "drop"
	OutputSnsBackpressureBehaviorQueue OutputSnsBackpressureBehavior = "queue"
)

func (e OutputSnsBackpressureBehavior) ToPointer() *OutputSnsBackpressureBehavior {
	return &e
}
func (e *OutputSnsBackpressureBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		fallthrough
	case "queue":
		*e = OutputSnsBackpressureBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSnsBackpressureBehavior: %v", v)
	}
}

// OutputSnsCompression - Codec to use to compress the persisted data.
type OutputSnsCompression string

const (
	OutputSnsCompressionNone OutputSnsCompression = "none"
	OutputSnsCompressionGzip OutputSnsCompression = "gzip"
)

func (e OutputSnsCompression) ToPointer() *OutputSnsCompression {
	return &e
}
func (e *OutputSnsCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = OutputSnsCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSnsCompression: %v", v)
	}
}

// OutputSnsQueueFullBehavior - Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
type OutputSnsQueueFullBehavior string

const (
	OutputSnsQueueFullBehaviorBlock OutputSnsQueueFullBehavior = "block"
	OutputSnsQueueFullBehaviorDrop  OutputSnsQueueFullBehavior = "drop"
)

func (e OutputSnsQueueFullBehavior) ToPointer() *OutputSnsQueueFullBehavior {
	return &e
}
func (e *OutputSnsQueueFullBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputSnsQueueFullBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSnsQueueFullBehavior: %v", v)
	}
}

// OutputSnsMode - In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
type OutputSnsMode string

const (
	OutputSnsModeError        OutputSnsMode = "error"
	OutputSnsModeBackpressure OutputSnsMode = "backpressure"
	OutputSnsModeAlways       OutputSnsMode = "always"
)

func (e OutputSnsMode) ToPointer() *OutputSnsMode {
	return &e
}
func (e *OutputSnsMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "error":
		fallthrough
	case "backpressure":
		fallthrough
	case "always":
		*e = OutputSnsMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSnsMode: %v", v)
	}
}

type OutputSnsPqControls struct {
}

type OutputSns struct {
	// Unique ID for this output
	ID   *string        `json:"id,omitempty"`
	Type *OutputSnsType `json:"type,omitempty"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// The ARN of the SNS topic to send events to. When a non-AWS URL is specified, format must be: '{url}/myQueueName'. E.g., 'https://host:port/myQueueName'. Must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at init time. E.g., referencing a Global Variable: `https://host:port/myQueue-${C.vars.myVar}`.
	TopicArn string `json:"topicArn"`
	// Messages in the same group are processed in a FIFO manner. Must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at init time. Example referencing a Global Variable: `https://host:port/myQueue-${C.vars.myVar}`.
	MessageGroupID string `json:"messageGroupId"`
	// Maximum number of retries before the output returns an error. Note that not all errors are retryable. The retries use an exponential backoff policy.
	MaxRetries *float64 `json:"maxRetries,omitempty"`
	// AWS authentication method. Choose Auto to use IAM roles.
	AwsAuthenticationMethod *OutputSnsAuthenticationMethod `default:"auto" json:"awsAuthenticationMethod"`
	AwsSecretKey            *string                        `json:"awsSecretKey,omitempty"`
	// Region where the SNS is located
	Region *string `json:"region,omitempty"`
	// SNS service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to SNS-compatible endpoint.
	Endpoint *string `json:"endpoint,omitempty"`
	// Signature version to use for signing SNS requests
	SignatureVersion *OutputSnsSignatureVersion `default:"v4" json:"signatureVersion"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `default:"true" json:"reuseConnections"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Use Assume Role credentials to access SNS
	EnableAssumeRole *bool `default:"false" json:"enableAssumeRole"`
	// Amazon Resource Name (ARN) of the role to assume
	AssumeRoleArn *string `json:"assumeRoleArn,omitempty"`
	// External ID to use when assuming role
	AssumeRoleExternalID *string `json:"assumeRoleExternalId,omitempty"`
	// Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
	DurationSeconds *float64 `default:"3600" json:"durationSeconds"`
	// Whether to block, drop, or queue events when all receivers are exerting backpressure.
	OnBackpressure *OutputSnsBackpressureBehavior `default:"block" json:"onBackpressure"`
	Description    *string                        `json:"description,omitempty"`
	AwsAPIKey      *string                        `json:"awsApiKey,omitempty"`
	// Select or create a stored secret that references your access key and secret key
	AwsSecret *string `json:"awsSecret,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.).
	PqMaxFileSize *string `default:"1 MB" json:"pqMaxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `default:"5GB" json:"pqMaxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `default:"\\$CRIBL_HOME/state/queues" json:"pqPath"`
	// Codec to use to compress the persisted data.
	PqCompress *OutputSnsCompression `default:"none" json:"pqCompress"`
	// Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *OutputSnsQueueFullBehavior `default:"block" json:"pqOnBackpressure"`
	// In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
	PqMode     *OutputSnsMode       `default:"error" json:"pqMode"`
	PqControls *OutputSnsPqControls `json:"pqControls,omitempty"`
	Status     *TFStatus            `json:"status,omitempty"`
}

func (o OutputSns) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputSns) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *OutputSns) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *OutputSns) GetType() *OutputSnsType {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *OutputSns) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputSns) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputSns) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputSns) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputSns) GetTopicArn() string {
	if o == nil {
		return ""
	}
	return o.TopicArn
}

func (o *OutputSns) GetMessageGroupID() string {
	if o == nil {
		return ""
	}
	return o.MessageGroupID
}

func (o *OutputSns) GetMaxRetries() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxRetries
}

func (o *OutputSns) GetAwsAuthenticationMethod() *OutputSnsAuthenticationMethod {
	if o == nil {
		return nil
	}
	return o.AwsAuthenticationMethod
}

func (o *OutputSns) GetAwsSecretKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecretKey
}

func (o *OutputSns) GetRegion() *string {
	if o == nil {
		return nil
	}
	return o.Region
}

func (o *OutputSns) GetEndpoint() *string {
	if o == nil {
		return nil
	}
	return o.Endpoint
}

func (o *OutputSns) GetSignatureVersion() *OutputSnsSignatureVersion {
	if o == nil {
		return nil
	}
	return o.SignatureVersion
}

func (o *OutputSns) GetReuseConnections() *bool {
	if o == nil {
		return nil
	}
	return o.ReuseConnections
}

func (o *OutputSns) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputSns) GetEnableAssumeRole() *bool {
	if o == nil {
		return nil
	}
	return o.EnableAssumeRole
}

func (o *OutputSns) GetAssumeRoleArn() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleArn
}

func (o *OutputSns) GetAssumeRoleExternalID() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleExternalID
}

func (o *OutputSns) GetDurationSeconds() *float64 {
	if o == nil {
		return nil
	}
	return o.DurationSeconds
}

func (o *OutputSns) GetOnBackpressure() *OutputSnsBackpressureBehavior {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputSns) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputSns) GetAwsAPIKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsAPIKey
}

func (o *OutputSns) GetAwsSecret() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecret
}

func (o *OutputSns) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputSns) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputSns) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputSns) GetPqCompress() *OutputSnsCompression {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputSns) GetPqOnBackpressure() *OutputSnsQueueFullBehavior {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputSns) GetPqMode() *OutputSnsMode {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputSns) GetPqControls() *OutputSnsPqControls {
	if o == nil {
		return nil
	}
	return o.PqControls
}

func (o *OutputSns) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type OutputRouterType string

const (
	OutputRouterTypeRouter OutputRouterType = "router"
)

func (e OutputRouterType) ToPointer() *OutputRouterType {
	return &e
}
func (e *OutputRouterType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "router":
		*e = OutputRouterType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputRouterType: %v", v)
	}
}

type OutputRouterRules struct {
	// JavaScript expression to select events to send to output
	Filter string `json:"filter"`
	// Output to send matching events to
	Output string `json:"output"`
	// Description of this rule's purpose
	Description *string `json:"description,omitempty"`
	// Flag to control whether to stop the event from being checked against other rules
	Final *bool `default:"true" json:"final"`
}

func (o OutputRouterRules) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputRouterRules) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputRouterRules) GetFilter() string {
	if o == nil {
		return ""
	}
	return o.Filter
}

func (o *OutputRouterRules) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

func (o *OutputRouterRules) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputRouterRules) GetFinal() *bool {
	if o == nil {
		return nil
	}
	return o.Final
}

type OutputRouter struct {
	// Unique ID for this output
	ID   *string          `json:"id,omitempty"`
	Type OutputRouterType `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Event routing rules
	Rules       []OutputRouterRules `json:"rules"`
	Description *string             `json:"description,omitempty"`
	Status      *TFStatus           `json:"status,omitempty"`
}

func (o *OutputRouter) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *OutputRouter) GetType() OutputRouterType {
	if o == nil {
		return OutputRouterType("")
	}
	return o.Type
}

func (o *OutputRouter) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputRouter) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputRouter) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputRouter) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputRouter) GetRules() []OutputRouterRules {
	if o == nil {
		return []OutputRouterRules{}
	}
	return o.Rules
}

func (o *OutputRouter) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputRouter) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type OutputGraphiteType string

const (
	OutputGraphiteTypeGraphite OutputGraphiteType = "graphite"
)

func (e OutputGraphiteType) ToPointer() *OutputGraphiteType {
	return &e
}
func (e *OutputGraphiteType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "graphite":
		*e = OutputGraphiteType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputGraphiteType: %v", v)
	}
}

// OutputGraphiteDestinationProtocol - Protocol to use when communicating with the destination.
type OutputGraphiteDestinationProtocol string

const (
	OutputGraphiteDestinationProtocolUDP OutputGraphiteDestinationProtocol = "udp"
	OutputGraphiteDestinationProtocolTCP OutputGraphiteDestinationProtocol = "tcp"
)

func (e OutputGraphiteDestinationProtocol) ToPointer() *OutputGraphiteDestinationProtocol {
	return &e
}
func (e *OutputGraphiteDestinationProtocol) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "udp":
		fallthrough
	case "tcp":
		*e = OutputGraphiteDestinationProtocol(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputGraphiteDestinationProtocol: %v", v)
	}
}

// OutputGraphiteBackpressureBehavior - Whether to block, drop, or queue events when all receivers are exerting backpressure.
type OutputGraphiteBackpressureBehavior string

const (
	OutputGraphiteBackpressureBehaviorBlock OutputGraphiteBackpressureBehavior = "block"
	OutputGraphiteBackpressureBehaviorDrop  OutputGraphiteBackpressureBehavior = "drop"
	OutputGraphiteBackpressureBehaviorQueue OutputGraphiteBackpressureBehavior = "queue"
)

func (e OutputGraphiteBackpressureBehavior) ToPointer() *OutputGraphiteBackpressureBehavior {
	return &e
}
func (e *OutputGraphiteBackpressureBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		fallthrough
	case "queue":
		*e = OutputGraphiteBackpressureBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputGraphiteBackpressureBehavior: %v", v)
	}
}

// OutputGraphiteCompression - Codec to use to compress the persisted data.
type OutputGraphiteCompression string

const (
	OutputGraphiteCompressionNone OutputGraphiteCompression = "none"
	OutputGraphiteCompressionGzip OutputGraphiteCompression = "gzip"
)

func (e OutputGraphiteCompression) ToPointer() *OutputGraphiteCompression {
	return &e
}
func (e *OutputGraphiteCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = OutputGraphiteCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputGraphiteCompression: %v", v)
	}
}

// OutputGraphiteQueueFullBehavior - Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
type OutputGraphiteQueueFullBehavior string

const (
	OutputGraphiteQueueFullBehaviorBlock OutputGraphiteQueueFullBehavior = "block"
	OutputGraphiteQueueFullBehaviorDrop  OutputGraphiteQueueFullBehavior = "drop"
)

func (e OutputGraphiteQueueFullBehavior) ToPointer() *OutputGraphiteQueueFullBehavior {
	return &e
}
func (e *OutputGraphiteQueueFullBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputGraphiteQueueFullBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputGraphiteQueueFullBehavior: %v", v)
	}
}

// OutputGraphiteMode - In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
type OutputGraphiteMode string

const (
	OutputGraphiteModeError        OutputGraphiteMode = "error"
	OutputGraphiteModeBackpressure OutputGraphiteMode = "backpressure"
	OutputGraphiteModeAlways       OutputGraphiteMode = "always"
)

func (e OutputGraphiteMode) ToPointer() *OutputGraphiteMode {
	return &e
}
func (e *OutputGraphiteMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "error":
		fallthrough
	case "backpressure":
		fallthrough
	case "always":
		*e = OutputGraphiteMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputGraphiteMode: %v", v)
	}
}

type OutputGraphitePqControls struct {
}

type OutputGraphite struct {
	// Unique ID for this output
	ID   *string             `json:"id,omitempty"`
	Type *OutputGraphiteType `json:"type,omitempty"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Protocol to use when communicating with the destination.
	Protocol *OutputGraphiteDestinationProtocol `default:"udp" json:"protocol"`
	// The hostname of the destination.
	Host string `json:"host"`
	// Destination port.
	Port *float64 `default:"8125" json:"port"`
	// When protocol is UDP, specifies the maximum size of packets sent to the destination. Also known as the MTU for the network path to the destination system.
	Mtu *float64 `default:"512" json:"mtu"`
	// When protocol is TCP, specifies how often buffers should be flushed, resulting in records sent to the destination.
	FlushPeriodSec *float64 `default:"1" json:"flushPeriodSec"`
	// How often to resolve the destination hostname to an IP address. Ignored if the destination is an IP address. A value of 0 means every batch sent will incur a DNS lookup.
	DNSResolvePeriodSec *float64 `default:"0" json:"dnsResolvePeriodSec"`
	Description         *string  `json:"description,omitempty"`
	// Rate (in bytes per second) to throttle while writing to an output. Accepts values with multiple-byte units, such as KB, MB, and GB. (Example: 42 MB) Default value of 0 specifies no throttling.
	ThrottleRatePerSec *string `default:"0" json:"throttleRatePerSec"`
	// Amount of time (milliseconds) to wait for the connection to establish before retrying
	ConnectionTimeout *float64 `default:"10000" json:"connectionTimeout"`
	// Amount of time (milliseconds) to wait for a write to complete before assuming connection is dead
	WriteTimeout *float64 `default:"60000" json:"writeTimeout"`
	// Whether to block, drop, or queue events when all receivers are exerting backpressure.
	OnBackpressure *OutputGraphiteBackpressureBehavior `default:"block" json:"onBackpressure"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.).
	PqMaxFileSize *string `default:"1 MB" json:"pqMaxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `default:"5GB" json:"pqMaxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `default:"\\$CRIBL_HOME/state/queues" json:"pqPath"`
	// Codec to use to compress the persisted data.
	PqCompress *OutputGraphiteCompression `default:"none" json:"pqCompress"`
	// Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *OutputGraphiteQueueFullBehavior `default:"block" json:"pqOnBackpressure"`
	// In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
	PqMode     *OutputGraphiteMode       `default:"error" json:"pqMode"`
	PqControls *OutputGraphitePqControls `json:"pqControls,omitempty"`
	Status     *TFStatus                 `json:"status,omitempty"`
}

func (o OutputGraphite) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputGraphite) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *OutputGraphite) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *OutputGraphite) GetType() *OutputGraphiteType {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *OutputGraphite) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputGraphite) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputGraphite) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputGraphite) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputGraphite) GetProtocol() *OutputGraphiteDestinationProtocol {
	if o == nil {
		return nil
	}
	return o.Protocol
}

func (o *OutputGraphite) GetHost() string {
	if o == nil {
		return ""
	}
	return o.Host
}

func (o *OutputGraphite) GetPort() *float64 {
	if o == nil {
		return nil
	}
	return o.Port
}

func (o *OutputGraphite) GetMtu() *float64 {
	if o == nil {
		return nil
	}
	return o.Mtu
}

func (o *OutputGraphite) GetFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushPeriodSec
}

func (o *OutputGraphite) GetDNSResolvePeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.DNSResolvePeriodSec
}

func (o *OutputGraphite) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputGraphite) GetThrottleRatePerSec() *string {
	if o == nil {
		return nil
	}
	return o.ThrottleRatePerSec
}

func (o *OutputGraphite) GetConnectionTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.ConnectionTimeout
}

func (o *OutputGraphite) GetWriteTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.WriteTimeout
}

func (o *OutputGraphite) GetOnBackpressure() *OutputGraphiteBackpressureBehavior {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputGraphite) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputGraphite) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputGraphite) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputGraphite) GetPqCompress() *OutputGraphiteCompression {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputGraphite) GetPqOnBackpressure() *OutputGraphiteQueueFullBehavior {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputGraphite) GetPqMode() *OutputGraphiteMode {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputGraphite) GetPqControls() *OutputGraphitePqControls {
	if o == nil {
		return nil
	}
	return o.PqControls
}

func (o *OutputGraphite) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type OutputStatsdExtType string

const (
	OutputStatsdExtTypeStatsdExt OutputStatsdExtType = "statsd_ext"
)

func (e OutputStatsdExtType) ToPointer() *OutputStatsdExtType {
	return &e
}
func (e *OutputStatsdExtType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "statsd_ext":
		*e = OutputStatsdExtType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputStatsdExtType: %v", v)
	}
}

// OutputStatsdExtDestinationProtocol - Protocol to use when communicating with the destination.
type OutputStatsdExtDestinationProtocol string

const (
	OutputStatsdExtDestinationProtocolUDP OutputStatsdExtDestinationProtocol = "udp"
	OutputStatsdExtDestinationProtocolTCP OutputStatsdExtDestinationProtocol = "tcp"
)

func (e OutputStatsdExtDestinationProtocol) ToPointer() *OutputStatsdExtDestinationProtocol {
	return &e
}
func (e *OutputStatsdExtDestinationProtocol) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "udp":
		fallthrough
	case "tcp":
		*e = OutputStatsdExtDestinationProtocol(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputStatsdExtDestinationProtocol: %v", v)
	}
}

// OutputStatsdExtBackpressureBehavior - Whether to block, drop, or queue events when all receivers are exerting backpressure.
type OutputStatsdExtBackpressureBehavior string

const (
	OutputStatsdExtBackpressureBehaviorBlock OutputStatsdExtBackpressureBehavior = "block"
	OutputStatsdExtBackpressureBehaviorDrop  OutputStatsdExtBackpressureBehavior = "drop"
	OutputStatsdExtBackpressureBehaviorQueue OutputStatsdExtBackpressureBehavior = "queue"
)

func (e OutputStatsdExtBackpressureBehavior) ToPointer() *OutputStatsdExtBackpressureBehavior {
	return &e
}
func (e *OutputStatsdExtBackpressureBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		fallthrough
	case "queue":
		*e = OutputStatsdExtBackpressureBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputStatsdExtBackpressureBehavior: %v", v)
	}
}

// OutputStatsdExtCompression - Codec to use to compress the persisted data.
type OutputStatsdExtCompression string

const (
	OutputStatsdExtCompressionNone OutputStatsdExtCompression = "none"
	OutputStatsdExtCompressionGzip OutputStatsdExtCompression = "gzip"
)

func (e OutputStatsdExtCompression) ToPointer() *OutputStatsdExtCompression {
	return &e
}
func (e *OutputStatsdExtCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = OutputStatsdExtCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputStatsdExtCompression: %v", v)
	}
}

// OutputStatsdExtQueueFullBehavior - Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
type OutputStatsdExtQueueFullBehavior string

const (
	OutputStatsdExtQueueFullBehaviorBlock OutputStatsdExtQueueFullBehavior = "block"
	OutputStatsdExtQueueFullBehaviorDrop  OutputStatsdExtQueueFullBehavior = "drop"
)

func (e OutputStatsdExtQueueFullBehavior) ToPointer() *OutputStatsdExtQueueFullBehavior {
	return &e
}
func (e *OutputStatsdExtQueueFullBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputStatsdExtQueueFullBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputStatsdExtQueueFullBehavior: %v", v)
	}
}

// OutputStatsdExtMode - In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
type OutputStatsdExtMode string

const (
	OutputStatsdExtModeError        OutputStatsdExtMode = "error"
	OutputStatsdExtModeBackpressure OutputStatsdExtMode = "backpressure"
	OutputStatsdExtModeAlways       OutputStatsdExtMode = "always"
)

func (e OutputStatsdExtMode) ToPointer() *OutputStatsdExtMode {
	return &e
}
func (e *OutputStatsdExtMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "error":
		fallthrough
	case "backpressure":
		fallthrough
	case "always":
		*e = OutputStatsdExtMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputStatsdExtMode: %v", v)
	}
}

type OutputStatsdExtPqControls struct {
}

type OutputStatsdExt struct {
	// Unique ID for this output
	ID   *string              `json:"id,omitempty"`
	Type *OutputStatsdExtType `json:"type,omitempty"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Protocol to use when communicating with the destination.
	Protocol *OutputStatsdExtDestinationProtocol `default:"udp" json:"protocol"`
	// The hostname of the destination.
	Host string `json:"host"`
	// Destination port.
	Port *float64 `default:"8125" json:"port"`
	// When protocol is UDP, specifies the maximum size of packets sent to the destination. Also known as the MTU for the network path to the destination system.
	Mtu *float64 `default:"512" json:"mtu"`
	// When protocol is TCP, specifies how often buffers should be flushed, resulting in records sent to the destination.
	FlushPeriodSec *float64 `default:"1" json:"flushPeriodSec"`
	// How often to resolve the destination hostname to an IP address. Ignored if the destination is an IP address. A value of 0 means every batch sent will incur a DNS lookup.
	DNSResolvePeriodSec *float64 `default:"0" json:"dnsResolvePeriodSec"`
	Description         *string  `json:"description,omitempty"`
	// Rate (in bytes per second) to throttle while writing to an output. Accepts values with multiple-byte units, such as KB, MB, and GB. (Example: 42 MB) Default value of 0 specifies no throttling.
	ThrottleRatePerSec *string `default:"0" json:"throttleRatePerSec"`
	// Amount of time (milliseconds) to wait for the connection to establish before retrying
	ConnectionTimeout *float64 `default:"10000" json:"connectionTimeout"`
	// Amount of time (milliseconds) to wait for a write to complete before assuming connection is dead
	WriteTimeout *float64 `default:"60000" json:"writeTimeout"`
	// Whether to block, drop, or queue events when all receivers are exerting backpressure.
	OnBackpressure *OutputStatsdExtBackpressureBehavior `default:"block" json:"onBackpressure"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.).
	PqMaxFileSize *string `default:"1 MB" json:"pqMaxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `default:"5GB" json:"pqMaxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `default:"\\$CRIBL_HOME/state/queues" json:"pqPath"`
	// Codec to use to compress the persisted data.
	PqCompress *OutputStatsdExtCompression `default:"none" json:"pqCompress"`
	// Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *OutputStatsdExtQueueFullBehavior `default:"block" json:"pqOnBackpressure"`
	// In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
	PqMode     *OutputStatsdExtMode       `default:"error" json:"pqMode"`
	PqControls *OutputStatsdExtPqControls `json:"pqControls,omitempty"`
	Status     *TFStatus                  `json:"status,omitempty"`
}

func (o OutputStatsdExt) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputStatsdExt) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *OutputStatsdExt) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *OutputStatsdExt) GetType() *OutputStatsdExtType {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *OutputStatsdExt) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputStatsdExt) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputStatsdExt) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputStatsdExt) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputStatsdExt) GetProtocol() *OutputStatsdExtDestinationProtocol {
	if o == nil {
		return nil
	}
	return o.Protocol
}

func (o *OutputStatsdExt) GetHost() string {
	if o == nil {
		return ""
	}
	return o.Host
}

func (o *OutputStatsdExt) GetPort() *float64 {
	if o == nil {
		return nil
	}
	return o.Port
}

func (o *OutputStatsdExt) GetMtu() *float64 {
	if o == nil {
		return nil
	}
	return o.Mtu
}

func (o *OutputStatsdExt) GetFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushPeriodSec
}

func (o *OutputStatsdExt) GetDNSResolvePeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.DNSResolvePeriodSec
}

func (o *OutputStatsdExt) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputStatsdExt) GetThrottleRatePerSec() *string {
	if o == nil {
		return nil
	}
	return o.ThrottleRatePerSec
}

func (o *OutputStatsdExt) GetConnectionTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.ConnectionTimeout
}

func (o *OutputStatsdExt) GetWriteTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.WriteTimeout
}

func (o *OutputStatsdExt) GetOnBackpressure() *OutputStatsdExtBackpressureBehavior {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputStatsdExt) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputStatsdExt) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputStatsdExt) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputStatsdExt) GetPqCompress() *OutputStatsdExtCompression {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputStatsdExt) GetPqOnBackpressure() *OutputStatsdExtQueueFullBehavior {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputStatsdExt) GetPqMode() *OutputStatsdExtMode {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputStatsdExt) GetPqControls() *OutputStatsdExtPqControls {
	if o == nil {
		return nil
	}
	return o.PqControls
}

func (o *OutputStatsdExt) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type OutputStatsdType string

const (
	OutputStatsdTypeStatsd OutputStatsdType = "statsd"
)

func (e OutputStatsdType) ToPointer() *OutputStatsdType {
	return &e
}
func (e *OutputStatsdType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "statsd":
		*e = OutputStatsdType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputStatsdType: %v", v)
	}
}

// DestinationProtocol - Protocol to use when communicating with the destination.
type DestinationProtocol string

const (
	DestinationProtocolUDP DestinationProtocol = "udp"
	DestinationProtocolTCP DestinationProtocol = "tcp"
)

func (e DestinationProtocol) ToPointer() *DestinationProtocol {
	return &e
}
func (e *DestinationProtocol) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "udp":
		fallthrough
	case "tcp":
		*e = DestinationProtocol(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationProtocol: %v", v)
	}
}

// OutputStatsdBackpressureBehavior - Whether to block, drop, or queue events when all receivers are exerting backpressure.
type OutputStatsdBackpressureBehavior string

const (
	OutputStatsdBackpressureBehaviorBlock OutputStatsdBackpressureBehavior = "block"
	OutputStatsdBackpressureBehaviorDrop  OutputStatsdBackpressureBehavior = "drop"
	OutputStatsdBackpressureBehaviorQueue OutputStatsdBackpressureBehavior = "queue"
)

func (e OutputStatsdBackpressureBehavior) ToPointer() *OutputStatsdBackpressureBehavior {
	return &e
}
func (e *OutputStatsdBackpressureBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		fallthrough
	case "queue":
		*e = OutputStatsdBackpressureBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputStatsdBackpressureBehavior: %v", v)
	}
}

// OutputStatsdCompression - Codec to use to compress the persisted data.
type OutputStatsdCompression string

const (
	OutputStatsdCompressionNone OutputStatsdCompression = "none"
	OutputStatsdCompressionGzip OutputStatsdCompression = "gzip"
)

func (e OutputStatsdCompression) ToPointer() *OutputStatsdCompression {
	return &e
}
func (e *OutputStatsdCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = OutputStatsdCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputStatsdCompression: %v", v)
	}
}

// OutputStatsdQueueFullBehavior - Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
type OutputStatsdQueueFullBehavior string

const (
	OutputStatsdQueueFullBehaviorBlock OutputStatsdQueueFullBehavior = "block"
	OutputStatsdQueueFullBehaviorDrop  OutputStatsdQueueFullBehavior = "drop"
)

func (e OutputStatsdQueueFullBehavior) ToPointer() *OutputStatsdQueueFullBehavior {
	return &e
}
func (e *OutputStatsdQueueFullBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputStatsdQueueFullBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputStatsdQueueFullBehavior: %v", v)
	}
}

// OutputStatsdMode - In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
type OutputStatsdMode string

const (
	OutputStatsdModeError        OutputStatsdMode = "error"
	OutputStatsdModeBackpressure OutputStatsdMode = "backpressure"
	OutputStatsdModeAlways       OutputStatsdMode = "always"
)

func (e OutputStatsdMode) ToPointer() *OutputStatsdMode {
	return &e
}
func (e *OutputStatsdMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "error":
		fallthrough
	case "backpressure":
		fallthrough
	case "always":
		*e = OutputStatsdMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputStatsdMode: %v", v)
	}
}

type OutputStatsdPqControls struct {
}

type OutputStatsd struct {
	// Unique ID for this output
	ID   *string           `json:"id,omitempty"`
	Type *OutputStatsdType `json:"type,omitempty"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Protocol to use when communicating with the destination.
	Protocol *DestinationProtocol `default:"udp" json:"protocol"`
	// The hostname of the destination.
	Host string `json:"host"`
	// Destination port.
	Port *float64 `default:"8125" json:"port"`
	// When protocol is UDP, specifies the maximum size of packets sent to the destination. Also known as the MTU for the network path to the destination system.
	Mtu *float64 `default:"512" json:"mtu"`
	// When protocol is TCP, specifies how often buffers should be flushed, resulting in records sent to the destination.
	FlushPeriodSec *float64 `default:"1" json:"flushPeriodSec"`
	// How often to resolve the destination hostname to an IP address. Ignored if the destination is an IP address. A value of 0 means every batch sent will incur a DNS lookup.
	DNSResolvePeriodSec *float64 `default:"0" json:"dnsResolvePeriodSec"`
	Description         *string  `json:"description,omitempty"`
	// Rate (in bytes per second) to throttle while writing to an output. Accepts values with multiple-byte units, such as KB, MB, and GB. (Example: 42 MB) Default value of 0 specifies no throttling.
	ThrottleRatePerSec *string `default:"0" json:"throttleRatePerSec"`
	// Amount of time (milliseconds) to wait for the connection to establish before retrying
	ConnectionTimeout *float64 `default:"10000" json:"connectionTimeout"`
	// Amount of time (milliseconds) to wait for a write to complete before assuming connection is dead
	WriteTimeout *float64 `default:"60000" json:"writeTimeout"`
	// Whether to block, drop, or queue events when all receivers are exerting backpressure.
	OnBackpressure *OutputStatsdBackpressureBehavior `default:"block" json:"onBackpressure"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.).
	PqMaxFileSize *string `default:"1 MB" json:"pqMaxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `default:"5GB" json:"pqMaxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `default:"\\$CRIBL_HOME/state/queues" json:"pqPath"`
	// Codec to use to compress the persisted data.
	PqCompress *OutputStatsdCompression `default:"none" json:"pqCompress"`
	// Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *OutputStatsdQueueFullBehavior `default:"block" json:"pqOnBackpressure"`
	// In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
	PqMode     *OutputStatsdMode       `default:"error" json:"pqMode"`
	PqControls *OutputStatsdPqControls `json:"pqControls,omitempty"`
	Status     *TFStatus               `json:"status,omitempty"`
}

func (o OutputStatsd) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputStatsd) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *OutputStatsd) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *OutputStatsd) GetType() *OutputStatsdType {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *OutputStatsd) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputStatsd) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputStatsd) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputStatsd) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputStatsd) GetProtocol() *DestinationProtocol {
	if o == nil {
		return nil
	}
	return o.Protocol
}

func (o *OutputStatsd) GetHost() string {
	if o == nil {
		return ""
	}
	return o.Host
}

func (o *OutputStatsd) GetPort() *float64 {
	if o == nil {
		return nil
	}
	return o.Port
}

func (o *OutputStatsd) GetMtu() *float64 {
	if o == nil {
		return nil
	}
	return o.Mtu
}

func (o *OutputStatsd) GetFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushPeriodSec
}

func (o *OutputStatsd) GetDNSResolvePeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.DNSResolvePeriodSec
}

func (o *OutputStatsd) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputStatsd) GetThrottleRatePerSec() *string {
	if o == nil {
		return nil
	}
	return o.ThrottleRatePerSec
}

func (o *OutputStatsd) GetConnectionTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.ConnectionTimeout
}

func (o *OutputStatsd) GetWriteTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.WriteTimeout
}

func (o *OutputStatsd) GetOnBackpressure() *OutputStatsdBackpressureBehavior {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputStatsd) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputStatsd) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputStatsd) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputStatsd) GetPqCompress() *OutputStatsdCompression {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputStatsd) GetPqOnBackpressure() *OutputStatsdQueueFullBehavior {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputStatsd) GetPqMode() *OutputStatsdMode {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputStatsd) GetPqControls() *OutputStatsdPqControls {
	if o == nil {
		return nil
	}
	return o.PqControls
}

func (o *OutputStatsd) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type OutputMinioType string

const (
	OutputMinioTypeMinio OutputMinioType = "minio"
)

func (e OutputMinioType) ToPointer() *OutputMinioType {
	return &e
}
func (e *OutputMinioType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "minio":
		*e = OutputMinioType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputMinioType: %v", v)
	}
}

// OutputMinioAuthenticationMethod - AWS authentication method. Choose Auto to use IAM roles.
type OutputMinioAuthenticationMethod string

const (
	OutputMinioAuthenticationMethodAuto   OutputMinioAuthenticationMethod = "auto"
	OutputMinioAuthenticationMethodManual OutputMinioAuthenticationMethod = "manual"
	OutputMinioAuthenticationMethodSecret OutputMinioAuthenticationMethod = "secret"
)

func (e OutputMinioAuthenticationMethod) ToPointer() *OutputMinioAuthenticationMethod {
	return &e
}
func (e *OutputMinioAuthenticationMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "auto":
		fallthrough
	case "manual":
		fallthrough
	case "secret":
		*e = OutputMinioAuthenticationMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputMinioAuthenticationMethod: %v", v)
	}
}

// OutputMinioSignatureVersion - Signature version to use for signing MinIO requests.
type OutputMinioSignatureVersion string

const (
	OutputMinioSignatureVersionV2 OutputMinioSignatureVersion = "v2"
	OutputMinioSignatureVersionV4 OutputMinioSignatureVersion = "v4"
)

func (e OutputMinioSignatureVersion) ToPointer() *OutputMinioSignatureVersion {
	return &e
}
func (e *OutputMinioSignatureVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "v2":
		fallthrough
	case "v4":
		*e = OutputMinioSignatureVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputMinioSignatureVersion: %v", v)
	}
}

// OutputMinioObjectACL - Object ACL to assign to uploaded objects.
type OutputMinioObjectACL string

const (
	OutputMinioObjectACLPrivate                OutputMinioObjectACL = "private"
	OutputMinioObjectACLPublicRead             OutputMinioObjectACL = "public-read"
	OutputMinioObjectACLPublicReadWrite        OutputMinioObjectACL = "public-read-write"
	OutputMinioObjectACLAuthenticatedRead      OutputMinioObjectACL = "authenticated-read"
	OutputMinioObjectACLAwsExecRead            OutputMinioObjectACL = "aws-exec-read"
	OutputMinioObjectACLBucketOwnerRead        OutputMinioObjectACL = "bucket-owner-read"
	OutputMinioObjectACLBucketOwnerFullControl OutputMinioObjectACL = "bucket-owner-full-control"
)

func (e OutputMinioObjectACL) ToPointer() *OutputMinioObjectACL {
	return &e
}
func (e *OutputMinioObjectACL) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "private":
		fallthrough
	case "public-read":
		fallthrough
	case "public-read-write":
		fallthrough
	case "authenticated-read":
		fallthrough
	case "aws-exec-read":
		fallthrough
	case "bucket-owner-read":
		fallthrough
	case "bucket-owner-full-control":
		*e = OutputMinioObjectACL(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputMinioObjectACL: %v", v)
	}
}

// OutputMinioStorageClass - Storage class to select for uploaded objects.
type OutputMinioStorageClass string

const (
	OutputMinioStorageClassStandard          OutputMinioStorageClass = "STANDARD"
	OutputMinioStorageClassReducedRedundancy OutputMinioStorageClass = "REDUCED_REDUNDANCY"
)

func (e OutputMinioStorageClass) ToPointer() *OutputMinioStorageClass {
	return &e
}
func (e *OutputMinioStorageClass) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "STANDARD":
		fallthrough
	case "REDUCED_REDUNDANCY":
		*e = OutputMinioStorageClass(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputMinioStorageClass: %v", v)
	}
}

// OutputMinioServerSideEncryption - Server-side encryption for uploaded objects.
type OutputMinioServerSideEncryption string

const (
	OutputMinioServerSideEncryptionAes256 OutputMinioServerSideEncryption = "AES256"
)

func (e OutputMinioServerSideEncryption) ToPointer() *OutputMinioServerSideEncryption {
	return &e
}
func (e *OutputMinioServerSideEncryption) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "AES256":
		*e = OutputMinioServerSideEncryption(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputMinioServerSideEncryption: %v", v)
	}
}

// OutputMinioDataFormat - Format of the output data
type OutputMinioDataFormat string

const (
	OutputMinioDataFormatJSON    OutputMinioDataFormat = "json"
	OutputMinioDataFormatRaw     OutputMinioDataFormat = "raw"
	OutputMinioDataFormatParquet OutputMinioDataFormat = "parquet"
)

func (e OutputMinioDataFormat) ToPointer() *OutputMinioDataFormat {
	return &e
}
func (e *OutputMinioDataFormat) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "json":
		fallthrough
	case "raw":
		fallthrough
	case "parquet":
		*e = OutputMinioDataFormat(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputMinioDataFormat: %v", v)
	}
}

// OutputMinioBackpressureBehavior - Whether to block or drop events when all receivers are exerting backpressure
type OutputMinioBackpressureBehavior string

const (
	OutputMinioBackpressureBehaviorBlock OutputMinioBackpressureBehavior = "block"
	OutputMinioBackpressureBehaviorDrop  OutputMinioBackpressureBehavior = "drop"
)

func (e OutputMinioBackpressureBehavior) ToPointer() *OutputMinioBackpressureBehavior {
	return &e
}
func (e *OutputMinioBackpressureBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputMinioBackpressureBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputMinioBackpressureBehavior: %v", v)
	}
}

// OutputMinioDiskSpaceProtection - Whether to block or drop events when disk space is below the global 'Min free disk space' limit
type OutputMinioDiskSpaceProtection string

const (
	OutputMinioDiskSpaceProtectionBlock OutputMinioDiskSpaceProtection = "block"
	OutputMinioDiskSpaceProtectionDrop  OutputMinioDiskSpaceProtection = "drop"
)

func (e OutputMinioDiskSpaceProtection) ToPointer() *OutputMinioDiskSpaceProtection {
	return &e
}
func (e *OutputMinioDiskSpaceProtection) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputMinioDiskSpaceProtection(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputMinioDiskSpaceProtection: %v", v)
	}
}

// OutputMinioCompress - Choose data compression format to apply before moving files to final destination
type OutputMinioCompress string

const (
	OutputMinioCompressNone OutputMinioCompress = "none"
	OutputMinioCompressGzip OutputMinioCompress = "gzip"
)

func (e OutputMinioCompress) ToPointer() *OutputMinioCompress {
	return &e
}
func (e *OutputMinioCompress) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = OutputMinioCompress(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputMinioCompress: %v", v)
	}
}

// OutputMinioCompressionLevel - Compression level to apply before moving files to final destination
type OutputMinioCompressionLevel string

const (
	OutputMinioCompressionLevelBestSpeed       OutputMinioCompressionLevel = "best_speed"
	OutputMinioCompressionLevelNormal          OutputMinioCompressionLevel = "normal"
	OutputMinioCompressionLevelBestCompression OutputMinioCompressionLevel = "best_compression"
)

func (e OutputMinioCompressionLevel) ToPointer() *OutputMinioCompressionLevel {
	return &e
}
func (e *OutputMinioCompressionLevel) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "best_speed":
		fallthrough
	case "normal":
		fallthrough
	case "best_compression":
		*e = OutputMinioCompressionLevel(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputMinioCompressionLevel: %v", v)
	}
}

// OutputMinioParquetVersion - Determines which data types are supported and how they are represented
type OutputMinioParquetVersion string

const (
	OutputMinioParquetVersionParquet10 OutputMinioParquetVersion = "PARQUET_1_0"
	OutputMinioParquetVersionParquet24 OutputMinioParquetVersion = "PARQUET_2_4"
	OutputMinioParquetVersionParquet26 OutputMinioParquetVersion = "PARQUET_2_6"
)

func (e OutputMinioParquetVersion) ToPointer() *OutputMinioParquetVersion {
	return &e
}
func (e *OutputMinioParquetVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "PARQUET_1_0":
		fallthrough
	case "PARQUET_2_4":
		fallthrough
	case "PARQUET_2_6":
		*e = OutputMinioParquetVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputMinioParquetVersion: %v", v)
	}
}

// OutputMinioDataPageVersion - Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
type OutputMinioDataPageVersion string

const (
	OutputMinioDataPageVersionDataPageV1 OutputMinioDataPageVersion = "DATA_PAGE_V1"
	OutputMinioDataPageVersionDataPageV2 OutputMinioDataPageVersion = "DATA_PAGE_V2"
)

func (e OutputMinioDataPageVersion) ToPointer() *OutputMinioDataPageVersion {
	return &e
}
func (e *OutputMinioDataPageVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "DATA_PAGE_V1":
		fallthrough
	case "DATA_PAGE_V2":
		*e = OutputMinioDataPageVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputMinioDataPageVersion: %v", v)
	}
}

type OutputMinioKeyValueMetadata struct {
	Key   *string `default:"" json:"key"`
	Value string  `json:"value"`
}

func (o OutputMinioKeyValueMetadata) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputMinioKeyValueMetadata) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputMinioKeyValueMetadata) GetKey() *string {
	if o == nil {
		return nil
	}
	return o.Key
}

func (o *OutputMinioKeyValueMetadata) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type OutputMinio struct {
	// Unique ID for this output
	ID   *string          `json:"id,omitempty"`
	Type *OutputMinioType `json:"type,omitempty"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// MinIO service url (e.g. http://minioHost:9000)
	Endpoint string `json:"endpoint"`
	// Name of the destination MinIO bucket. This value can be a constant or a JavaScript expression that can only be evaluated at init time. E.g. referencing a Global Variable: `myBucket-${C.vars.myVar}`.
	Bucket string `json:"bucket"`
	// AWS authentication method. Choose Auto to use IAM roles.
	AwsAuthenticationMethod *OutputMinioAuthenticationMethod `default:"auto" json:"awsAuthenticationMethod"`
	// Secret key. This value can be a constant or a JavaScript expression(e.g., `${C.env.SOME_SECRET}`).
	AwsSecretKey *string `json:"awsSecretKey,omitempty"`
	// Region where the MinIO service/cluster is located
	Region *string `json:"region,omitempty"`
	// Filesystem location in which to buffer files, before compressing and moving to final destination. Use performant stable storage.
	StagePath *string `default:"\\$CRIBL_HOME/state/outputs/staging" json:"stagePath"`
	// Append output's ID to staging location
	AddIDToStagePath *bool `default:"true" json:"addIdToStagePath"`
	// Root directory to prepend to path before uploading. Enter a constant, or a JS expression enclosed in quotes or backticks.
	DestPath *string `json:"destPath,omitempty"`
	// Signature version to use for signing MinIO requests.
	SignatureVersion *OutputMinioSignatureVersion `default:"v4" json:"signatureVersion"`
	// Object ACL to assign to uploaded objects.
	ObjectACL *OutputMinioObjectACL `default:"private" json:"objectACL"`
	// Storage class to select for uploaded objects.
	StorageClass *OutputMinioStorageClass `json:"storageClass,omitempty"`
	// Server-side encryption for uploaded objects.
	ServerSideEncryption *OutputMinioServerSideEncryption `json:"serverSideEncryption,omitempty"`
	// Whether to reuse connections between requests, which can improve performance.
	ReuseConnections *bool `default:"true" json:"reuseConnections"`
	// Whether to reject certificates that cannot be verified against a valid CA (e.g., self-signed certificates).
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Disable if you can access files within the bucket but not the bucket itself.
	VerifyPermissions *bool `default:"true" json:"verifyPermissions"`
	// Remove empty staging directories after moving files
	RemoveEmptyDirs *bool `default:"true" json:"removeEmptyDirs"`
	// JavaScript expression defining how files are partitioned and organized. Default is date-based. If blank, Stream will fall back to the event's __partition field value  if present  otherwise to each location's root directory.
	PartitionExpr *string `default:"C.Time.strftime(_time ? _time : Date.now()/1000, '%Y/%m/%d')" json:"partitionExpr"`
	// Format of the output data
	Format *OutputMinioDataFormat `default:"json" json:"format"`
	// JavaScript expression to define the output filename prefix (can be constant)
	BaseFileName *string `default:"CriblOut" json:"baseFileName"`
	// JavaScript expression to define the output filename suffix (can be constant).  The `__format` variable refers to the value of the `Data format` field (`json` or `raw`).  The `__compression` field refers to the kind of compression being used (`none` or `gzip`).
	FileNameSuffix *string `default:".\\${C.env[\"CRIBL_WORKER_ID\"]}.\\${__format}\\${__compression === \"gzip\" ? \".gz\" : \"\"}" json:"fileNameSuffix"`
	// Maximum uncompressed output file size. Files of this size will be closed and moved to final output location.
	MaxFileSizeMB *float64 `default:"32" json:"maxFileSizeMB"`
	// Maximum number of files to keep open concurrently. When exceeded, @{product} will close the oldest open files and move them to the final output location.
	MaxOpenFiles *float64 `default:"100" json:"maxOpenFiles"`
	// If set, this line will be written to the beginning of each output file
	HeaderLine *string `default:"" json:"headerLine"`
	// Buffer size used to write to a file
	WriteHighWaterMark *float64 `default:"64" json:"writeHighWaterMark"`
	// Whether to block or drop events when all receivers are exerting backpressure
	OnBackpressure *OutputMinioBackpressureBehavior `default:"block" json:"onBackpressure"`
	// If a file fails to move to its final destination after the maximum number of retries, dead-letter it to prevent further errors.
	DeadletterEnabled *bool `default:"false" json:"deadletterEnabled"`
	// Whether to block or drop events when disk space is below the global 'Min free disk space' limit
	OnDiskFullBackpressure *OutputMinioDiskSpaceProtection `default:"block" json:"onDiskFullBackpressure"`
	// Maximum amount of time to write to a file. Files open for longer than this will be closed and moved to final output location.
	MaxFileOpenTimeSec *float64 `default:"300" json:"maxFileOpenTimeSec"`
	// Maximum amount of time to keep inactive files open. Files open for longer than this will be closed and moved to final output location.
	MaxFileIdleTimeSec *float64 `default:"30" json:"maxFileIdleTimeSec"`
	// Maximum number of parts to upload in parallel per file. Minimum part size is 5MB.
	MaxConcurrentFileParts *float64 `default:"4" json:"maxConcurrentFileParts"`
	Description            *string  `json:"description,omitempty"`
	// This value can be a constant or a JavaScript expression (`${C.env.SOME_ACCESS_KEY}`)
	AwsAPIKey *string `json:"awsApiKey,omitempty"`
	// Select or create a stored secret that references your access key and secret key
	AwsSecret *string `json:"awsSecret,omitempty"`
	// Choose data compression format to apply before moving files to final destination
	Compress *OutputMinioCompress `default:"gzip" json:"compress"`
	// Compression level to apply before moving files to final destination
	CompressionLevel *OutputMinioCompressionLevel `default:"best_speed" json:"compressionLevel"`
	// Automatically calculate the schema based on the events of each Parquet file generated
	AutomaticSchema *bool `default:"false" json:"automaticSchema"`
	// Determines which data types are supported and how they are represented
	ParquetVersion *OutputMinioParquetVersion `default:"PARQUET_2_6" json:"parquetVersion"`
	// Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
	ParquetDataPageVersion *OutputMinioDataPageVersion `default:"DATA_PAGE_V2" json:"parquetDataPageVersion"`
	// The number of rows that every group will contain. The final group can contain a smaller number of rows.
	ParquetRowGroupLength *float64 `default:"10000" json:"parquetRowGroupLength"`
	// Target memory size for page segments, such as 1MB or 128MB. Generally, lower values improve reading speed, while higher values improve compression.
	ParquetPageSize *string `default:"1MB" json:"parquetPageSize"`
	// Log up to 3 rows that @{product} skips due to data mismatch
	ShouldLogInvalidRows *bool `json:"shouldLogInvalidRows,omitempty"`
	// The metadata of files the Destination writes will include the properties you add here as key-value pairs. Useful for tagging, e.g., "key":"OCSF Event Class", "value":"9001".
	KeyValueMetadata []OutputMinioKeyValueMetadata `json:"keyValueMetadata,omitempty"`
	// Statistics profile an entire file in terms of minimum/maximum values within data, numbers of nulls, etc. You can use Parquet tools to view statistics.
	EnableStatistics *bool `default:"true" json:"enableStatistics"`
	// One page index contains statistics for one data page. Parquet readers use statistics to enable page skipping.
	EnableWritePageIndex *bool `default:"true" json:"enableWritePageIndex"`
	// Parquet tools can use the checksum of a Parquet page to verify data integrity
	EnablePageChecksum *bool `default:"false" json:"enablePageChecksum"`
	// How frequently, in seconds, to clean up empty directories when 'Remove empty staging dirs' is enabled
	EmptyDirCleanupSec *float64 `default:"300" json:"emptyDirCleanupSec"`
	// Storage location for files that fail to reach their final destination after maximum retries are exceeded
	DeadletterPath *string `default:"\\$CRIBL_HOME/state/outputs/dead-letter" json:"deadletterPath"`
	// The maximum number of times a file will attempt to move to its final destination before being dead-lettered
	MaxRetryNum *float64  `default:"20" json:"maxRetryNum"`
	Status      *TFStatus `json:"status,omitempty"`
}

func (o OutputMinio) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputMinio) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *OutputMinio) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *OutputMinio) GetType() *OutputMinioType {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *OutputMinio) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputMinio) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputMinio) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputMinio) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputMinio) GetEndpoint() string {
	if o == nil {
		return ""
	}
	return o.Endpoint
}

func (o *OutputMinio) GetBucket() string {
	if o == nil {
		return ""
	}
	return o.Bucket
}

func (o *OutputMinio) GetAwsAuthenticationMethod() *OutputMinioAuthenticationMethod {
	if o == nil {
		return nil
	}
	return o.AwsAuthenticationMethod
}

func (o *OutputMinio) GetAwsSecretKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecretKey
}

func (o *OutputMinio) GetRegion() *string {
	if o == nil {
		return nil
	}
	return o.Region
}

func (o *OutputMinio) GetStagePath() *string {
	if o == nil {
		return nil
	}
	return o.StagePath
}

func (o *OutputMinio) GetAddIDToStagePath() *bool {
	if o == nil {
		return nil
	}
	return o.AddIDToStagePath
}

func (o *OutputMinio) GetDestPath() *string {
	if o == nil {
		return nil
	}
	return o.DestPath
}

func (o *OutputMinio) GetSignatureVersion() *OutputMinioSignatureVersion {
	if o == nil {
		return nil
	}
	return o.SignatureVersion
}

func (o *OutputMinio) GetObjectACL() *OutputMinioObjectACL {
	if o == nil {
		return nil
	}
	return o.ObjectACL
}

func (o *OutputMinio) GetStorageClass() *OutputMinioStorageClass {
	if o == nil {
		return nil
	}
	return o.StorageClass
}

func (o *OutputMinio) GetServerSideEncryption() *OutputMinioServerSideEncryption {
	if o == nil {
		return nil
	}
	return o.ServerSideEncryption
}

func (o *OutputMinio) GetReuseConnections() *bool {
	if o == nil {
		return nil
	}
	return o.ReuseConnections
}

func (o *OutputMinio) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputMinio) GetVerifyPermissions() *bool {
	if o == nil {
		return nil
	}
	return o.VerifyPermissions
}

func (o *OutputMinio) GetRemoveEmptyDirs() *bool {
	if o == nil {
		return nil
	}
	return o.RemoveEmptyDirs
}

func (o *OutputMinio) GetPartitionExpr() *string {
	if o == nil {
		return nil
	}
	return o.PartitionExpr
}

func (o *OutputMinio) GetFormat() *OutputMinioDataFormat {
	if o == nil {
		return nil
	}
	return o.Format
}

func (o *OutputMinio) GetBaseFileName() *string {
	if o == nil {
		return nil
	}
	return o.BaseFileName
}

func (o *OutputMinio) GetFileNameSuffix() *string {
	if o == nil {
		return nil
	}
	return o.FileNameSuffix
}

func (o *OutputMinio) GetMaxFileSizeMB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxFileSizeMB
}

func (o *OutputMinio) GetMaxOpenFiles() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxOpenFiles
}

func (o *OutputMinio) GetHeaderLine() *string {
	if o == nil {
		return nil
	}
	return o.HeaderLine
}

func (o *OutputMinio) GetWriteHighWaterMark() *float64 {
	if o == nil {
		return nil
	}
	return o.WriteHighWaterMark
}

func (o *OutputMinio) GetOnBackpressure() *OutputMinioBackpressureBehavior {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputMinio) GetDeadletterEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.DeadletterEnabled
}

func (o *OutputMinio) GetOnDiskFullBackpressure() *OutputMinioDiskSpaceProtection {
	if o == nil {
		return nil
	}
	return o.OnDiskFullBackpressure
}

func (o *OutputMinio) GetMaxFileOpenTimeSec() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxFileOpenTimeSec
}

func (o *OutputMinio) GetMaxFileIdleTimeSec() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxFileIdleTimeSec
}

func (o *OutputMinio) GetMaxConcurrentFileParts() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxConcurrentFileParts
}

func (o *OutputMinio) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputMinio) GetAwsAPIKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsAPIKey
}

func (o *OutputMinio) GetAwsSecret() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecret
}

func (o *OutputMinio) GetCompress() *OutputMinioCompress {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *OutputMinio) GetCompressionLevel() *OutputMinioCompressionLevel {
	if o == nil {
		return nil
	}
	return o.CompressionLevel
}

func (o *OutputMinio) GetAutomaticSchema() *bool {
	if o == nil {
		return nil
	}
	return o.AutomaticSchema
}

func (o *OutputMinio) GetParquetVersion() *OutputMinioParquetVersion {
	if o == nil {
		return nil
	}
	return o.ParquetVersion
}

func (o *OutputMinio) GetParquetDataPageVersion() *OutputMinioDataPageVersion {
	if o == nil {
		return nil
	}
	return o.ParquetDataPageVersion
}

func (o *OutputMinio) GetParquetRowGroupLength() *float64 {
	if o == nil {
		return nil
	}
	return o.ParquetRowGroupLength
}

func (o *OutputMinio) GetParquetPageSize() *string {
	if o == nil {
		return nil
	}
	return o.ParquetPageSize
}

func (o *OutputMinio) GetShouldLogInvalidRows() *bool {
	if o == nil {
		return nil
	}
	return o.ShouldLogInvalidRows
}

func (o *OutputMinio) GetKeyValueMetadata() []OutputMinioKeyValueMetadata {
	if o == nil {
		return nil
	}
	return o.KeyValueMetadata
}

func (o *OutputMinio) GetEnableStatistics() *bool {
	if o == nil {
		return nil
	}
	return o.EnableStatistics
}

func (o *OutputMinio) GetEnableWritePageIndex() *bool {
	if o == nil {
		return nil
	}
	return o.EnableWritePageIndex
}

func (o *OutputMinio) GetEnablePageChecksum() *bool {
	if o == nil {
		return nil
	}
	return o.EnablePageChecksum
}

func (o *OutputMinio) GetEmptyDirCleanupSec() *float64 {
	if o == nil {
		return nil
	}
	return o.EmptyDirCleanupSec
}

func (o *OutputMinio) GetDeadletterPath() *string {
	if o == nil {
		return nil
	}
	return o.DeadletterPath
}

func (o *OutputMinio) GetMaxRetryNum() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxRetryNum
}

func (o *OutputMinio) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type OutputCloudwatchType string

const (
	OutputCloudwatchTypeCloudwatch OutputCloudwatchType = "cloudwatch"
)

func (e OutputCloudwatchType) ToPointer() *OutputCloudwatchType {
	return &e
}
func (e *OutputCloudwatchType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "cloudwatch":
		*e = OutputCloudwatchType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputCloudwatchType: %v", v)
	}
}

// OutputCloudwatchAuthenticationMethod - AWS authentication method. Choose Auto to use IAM roles.
type OutputCloudwatchAuthenticationMethod string

const (
	OutputCloudwatchAuthenticationMethodAuto   OutputCloudwatchAuthenticationMethod = "auto"
	OutputCloudwatchAuthenticationMethodManual OutputCloudwatchAuthenticationMethod = "manual"
	OutputCloudwatchAuthenticationMethodSecret OutputCloudwatchAuthenticationMethod = "secret"
)

func (e OutputCloudwatchAuthenticationMethod) ToPointer() *OutputCloudwatchAuthenticationMethod {
	return &e
}
func (e *OutputCloudwatchAuthenticationMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "auto":
		fallthrough
	case "manual":
		fallthrough
	case "secret":
		*e = OutputCloudwatchAuthenticationMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputCloudwatchAuthenticationMethod: %v", v)
	}
}

// OutputCloudwatchBackpressureBehavior - Whether to block, drop, or queue events when all receivers are exerting backpressure.
type OutputCloudwatchBackpressureBehavior string

const (
	OutputCloudwatchBackpressureBehaviorBlock OutputCloudwatchBackpressureBehavior = "block"
	OutputCloudwatchBackpressureBehaviorDrop  OutputCloudwatchBackpressureBehavior = "drop"
	OutputCloudwatchBackpressureBehaviorQueue OutputCloudwatchBackpressureBehavior = "queue"
)

func (e OutputCloudwatchBackpressureBehavior) ToPointer() *OutputCloudwatchBackpressureBehavior {
	return &e
}
func (e *OutputCloudwatchBackpressureBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		fallthrough
	case "queue":
		*e = OutputCloudwatchBackpressureBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputCloudwatchBackpressureBehavior: %v", v)
	}
}

// OutputCloudwatchCompression - Codec to use to compress the persisted data.
type OutputCloudwatchCompression string

const (
	OutputCloudwatchCompressionNone OutputCloudwatchCompression = "none"
	OutputCloudwatchCompressionGzip OutputCloudwatchCompression = "gzip"
)

func (e OutputCloudwatchCompression) ToPointer() *OutputCloudwatchCompression {
	return &e
}
func (e *OutputCloudwatchCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = OutputCloudwatchCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputCloudwatchCompression: %v", v)
	}
}

// OutputCloudwatchQueueFullBehavior - Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
type OutputCloudwatchQueueFullBehavior string

const (
	OutputCloudwatchQueueFullBehaviorBlock OutputCloudwatchQueueFullBehavior = "block"
	OutputCloudwatchQueueFullBehaviorDrop  OutputCloudwatchQueueFullBehavior = "drop"
)

func (e OutputCloudwatchQueueFullBehavior) ToPointer() *OutputCloudwatchQueueFullBehavior {
	return &e
}
func (e *OutputCloudwatchQueueFullBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputCloudwatchQueueFullBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputCloudwatchQueueFullBehavior: %v", v)
	}
}

// OutputCloudwatchMode - In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
type OutputCloudwatchMode string

const (
	OutputCloudwatchModeError        OutputCloudwatchMode = "error"
	OutputCloudwatchModeBackpressure OutputCloudwatchMode = "backpressure"
	OutputCloudwatchModeAlways       OutputCloudwatchMode = "always"
)

func (e OutputCloudwatchMode) ToPointer() *OutputCloudwatchMode {
	return &e
}
func (e *OutputCloudwatchMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "error":
		fallthrough
	case "backpressure":
		fallthrough
	case "always":
		*e = OutputCloudwatchMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputCloudwatchMode: %v", v)
	}
}

type OutputCloudwatchPqControls struct {
}

type OutputCloudwatch struct {
	// Unique ID for this output
	ID   *string               `json:"id,omitempty"`
	Type *OutputCloudwatchType `json:"type,omitempty"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// CloudWatch log group to associate events with
	LogGroupName string `json:"logGroupName"`
	// Prefix for CloudWatch log stream name. This prefix will be used to generate a unique log stream name per cribl instance, for example: myStream_myHost_myOutputId
	LogStreamName string `json:"logStreamName"`
	// AWS authentication method. Choose Auto to use IAM roles.
	AwsAuthenticationMethod *OutputCloudwatchAuthenticationMethod `default:"auto" json:"awsAuthenticationMethod"`
	AwsSecretKey            *string                               `json:"awsSecretKey,omitempty"`
	// Region where the CloudWatchLogs is located
	Region string `json:"region"`
	// CloudWatchLogs service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to CloudWatchLogs-compatible endpoint.
	Endpoint *string `json:"endpoint,omitempty"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `default:"true" json:"reuseConnections"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Use Assume Role credentials to access CloudWatchLogs
	EnableAssumeRole *bool `default:"false" json:"enableAssumeRole"`
	// Amazon Resource Name (ARN) of the role to assume
	AssumeRoleArn *string `json:"assumeRoleArn,omitempty"`
	// External ID to use when assuming role
	AssumeRoleExternalID *string `json:"assumeRoleExternalId,omitempty"`
	// Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
	DurationSeconds *float64 `default:"3600" json:"durationSeconds"`
	// Maximum number of queued batches before blocking
	MaxQueueSize *float64 `default:"5" json:"maxQueueSize"`
	// Maximum size (KB) of each individual record before compression. For non compressible data 1MB is the max recommended size
	MaxRecordSizeKB *float64 `default:"1024" json:"maxRecordSizeKB"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Max record size.
	FlushPeriodSec *float64 `default:"1" json:"flushPeriodSec"`
	// Whether to block, drop, or queue events when all receivers are exerting backpressure.
	OnBackpressure *OutputCloudwatchBackpressureBehavior `default:"block" json:"onBackpressure"`
	Description    *string                               `json:"description,omitempty"`
	AwsAPIKey      *string                               `json:"awsApiKey,omitempty"`
	// Select or create a stored secret that references your access key and secret key
	AwsSecret *string `json:"awsSecret,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.).
	PqMaxFileSize *string `default:"1 MB" json:"pqMaxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `default:"5GB" json:"pqMaxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `default:"\\$CRIBL_HOME/state/queues" json:"pqPath"`
	// Codec to use to compress the persisted data.
	PqCompress *OutputCloudwatchCompression `default:"none" json:"pqCompress"`
	// Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *OutputCloudwatchQueueFullBehavior `default:"block" json:"pqOnBackpressure"`
	// In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
	PqMode     *OutputCloudwatchMode       `default:"error" json:"pqMode"`
	PqControls *OutputCloudwatchPqControls `json:"pqControls,omitempty"`
	Status     *TFStatus                   `json:"status,omitempty"`
}

func (o OutputCloudwatch) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputCloudwatch) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *OutputCloudwatch) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *OutputCloudwatch) GetType() *OutputCloudwatchType {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *OutputCloudwatch) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputCloudwatch) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputCloudwatch) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputCloudwatch) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputCloudwatch) GetLogGroupName() string {
	if o == nil {
		return ""
	}
	return o.LogGroupName
}

func (o *OutputCloudwatch) GetLogStreamName() string {
	if o == nil {
		return ""
	}
	return o.LogStreamName
}

func (o *OutputCloudwatch) GetAwsAuthenticationMethod() *OutputCloudwatchAuthenticationMethod {
	if o == nil {
		return nil
	}
	return o.AwsAuthenticationMethod
}

func (o *OutputCloudwatch) GetAwsSecretKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecretKey
}

func (o *OutputCloudwatch) GetRegion() string {
	if o == nil {
		return ""
	}
	return o.Region
}

func (o *OutputCloudwatch) GetEndpoint() *string {
	if o == nil {
		return nil
	}
	return o.Endpoint
}

func (o *OutputCloudwatch) GetReuseConnections() *bool {
	if o == nil {
		return nil
	}
	return o.ReuseConnections
}

func (o *OutputCloudwatch) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputCloudwatch) GetEnableAssumeRole() *bool {
	if o == nil {
		return nil
	}
	return o.EnableAssumeRole
}

func (o *OutputCloudwatch) GetAssumeRoleArn() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleArn
}

func (o *OutputCloudwatch) GetAssumeRoleExternalID() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleExternalID
}

func (o *OutputCloudwatch) GetDurationSeconds() *float64 {
	if o == nil {
		return nil
	}
	return o.DurationSeconds
}

func (o *OutputCloudwatch) GetMaxQueueSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxQueueSize
}

func (o *OutputCloudwatch) GetMaxRecordSizeKB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxRecordSizeKB
}

func (o *OutputCloudwatch) GetFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushPeriodSec
}

func (o *OutputCloudwatch) GetOnBackpressure() *OutputCloudwatchBackpressureBehavior {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputCloudwatch) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputCloudwatch) GetAwsAPIKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsAPIKey
}

func (o *OutputCloudwatch) GetAwsSecret() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecret
}

func (o *OutputCloudwatch) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputCloudwatch) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputCloudwatch) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputCloudwatch) GetPqCompress() *OutputCloudwatchCompression {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputCloudwatch) GetPqOnBackpressure() *OutputCloudwatchQueueFullBehavior {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputCloudwatch) GetPqMode() *OutputCloudwatchMode {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputCloudwatch) GetPqControls() *OutputCloudwatchPqControls {
	if o == nil {
		return nil
	}
	return o.PqControls
}

func (o *OutputCloudwatch) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type OutputInfluxdbType string

const (
	OutputInfluxdbTypeInfluxdb OutputInfluxdbType = "influxdb"
)

func (e OutputInfluxdbType) ToPointer() *OutputInfluxdbType {
	return &e
}
func (e *OutputInfluxdbType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "influxdb":
		*e = OutputInfluxdbType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputInfluxdbType: %v", v)
	}
}

// TimestampPrecision - Sets the precision for the supplied Unix time values. Defaults to milliseconds.
type TimestampPrecision string

const (
	TimestampPrecisionNs TimestampPrecision = "ns"
	TimestampPrecisionU  TimestampPrecision = "u"
	TimestampPrecisionMs TimestampPrecision = "ms"
	TimestampPrecisionS  TimestampPrecision = "s"
	TimestampPrecisionM  TimestampPrecision = "m"
	TimestampPrecisionH  TimestampPrecision = "h"
)

func (e TimestampPrecision) ToPointer() *TimestampPrecision {
	return &e
}
func (e *TimestampPrecision) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "ns":
		fallthrough
	case "u":
		fallthrough
	case "ms":
		fallthrough
	case "s":
		fallthrough
	case "m":
		fallthrough
	case "h":
		*e = TimestampPrecision(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TimestampPrecision: %v", v)
	}
}

type OutputInfluxdbExtraHTTPHeaders struct {
	// Field name
	Name *string `json:"name,omitempty"`
	// Field value
	Value string `json:"value"`
}

func (o *OutputInfluxdbExtraHTTPHeaders) GetName() *string {
	if o == nil {
		return nil
	}
	return o.Name
}

func (o *OutputInfluxdbExtraHTTPHeaders) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// OutputInfluxdbFailedRequestLoggingMode - Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
type OutputInfluxdbFailedRequestLoggingMode string

const (
	OutputInfluxdbFailedRequestLoggingModePayload           OutputInfluxdbFailedRequestLoggingMode = "payload"
	OutputInfluxdbFailedRequestLoggingModePayloadAndHeaders OutputInfluxdbFailedRequestLoggingMode = "payloadAndHeaders"
	OutputInfluxdbFailedRequestLoggingModeNone              OutputInfluxdbFailedRequestLoggingMode = "none"
)

func (e OutputInfluxdbFailedRequestLoggingMode) ToPointer() *OutputInfluxdbFailedRequestLoggingMode {
	return &e
}
func (e *OutputInfluxdbFailedRequestLoggingMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "payload":
		fallthrough
	case "payloadAndHeaders":
		fallthrough
	case "none":
		*e = OutputInfluxdbFailedRequestLoggingMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputInfluxdbFailedRequestLoggingMode: %v", v)
	}
}

type OutputInfluxdbResponseRetrySettings struct {
	// The HTTP response status code that will trigger retries
	HTTPStatus float64 `json:"httpStatus"`
	// How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"1000" json:"initialBackoff"`
	// Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackoff *float64 `default:"10000" json:"maxBackoff"`
}

func (o OutputInfluxdbResponseRetrySettings) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputInfluxdbResponseRetrySettings) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputInfluxdbResponseRetrySettings) GetHTTPStatus() float64 {
	if o == nil {
		return 0.0
	}
	return o.HTTPStatus
}

func (o *OutputInfluxdbResponseRetrySettings) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *OutputInfluxdbResponseRetrySettings) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *OutputInfluxdbResponseRetrySettings) GetMaxBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackoff
}

type OutputInfluxdbTimeoutRetrySettings struct {
	// Enable to retry on request timeout
	TimeoutRetry *bool `default:"false" json:"timeoutRetry"`
	// How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"1000" json:"initialBackoff"`
	// Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackoff *float64 `default:"10000" json:"maxBackoff"`
}

func (o OutputInfluxdbTimeoutRetrySettings) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputInfluxdbTimeoutRetrySettings) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputInfluxdbTimeoutRetrySettings) GetTimeoutRetry() *bool {
	if o == nil {
		return nil
	}
	return o.TimeoutRetry
}

func (o *OutputInfluxdbTimeoutRetrySettings) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *OutputInfluxdbTimeoutRetrySettings) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *OutputInfluxdbTimeoutRetrySettings) GetMaxBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackoff
}

// OutputInfluxdbBackpressureBehavior - Whether to block, drop, or queue events when all receivers are exerting backpressure.
type OutputInfluxdbBackpressureBehavior string

const (
	OutputInfluxdbBackpressureBehaviorBlock OutputInfluxdbBackpressureBehavior = "block"
	OutputInfluxdbBackpressureBehaviorDrop  OutputInfluxdbBackpressureBehavior = "drop"
	OutputInfluxdbBackpressureBehaviorQueue OutputInfluxdbBackpressureBehavior = "queue"
)

func (e OutputInfluxdbBackpressureBehavior) ToPointer() *OutputInfluxdbBackpressureBehavior {
	return &e
}
func (e *OutputInfluxdbBackpressureBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		fallthrough
	case "queue":
		*e = OutputInfluxdbBackpressureBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputInfluxdbBackpressureBehavior: %v", v)
	}
}

// OutputInfluxdbAuthenticationType - InfluxDB authentication type
type OutputInfluxdbAuthenticationType string

const (
	OutputInfluxdbAuthenticationTypeNone              OutputInfluxdbAuthenticationType = "none"
	OutputInfluxdbAuthenticationTypeBasic             OutputInfluxdbAuthenticationType = "basic"
	OutputInfluxdbAuthenticationTypeCredentialsSecret OutputInfluxdbAuthenticationType = "credentialsSecret"
	OutputInfluxdbAuthenticationTypeToken             OutputInfluxdbAuthenticationType = "token"
	OutputInfluxdbAuthenticationTypeTextSecret        OutputInfluxdbAuthenticationType = "textSecret"
	OutputInfluxdbAuthenticationTypeOauth             OutputInfluxdbAuthenticationType = "oauth"
)

func (e OutputInfluxdbAuthenticationType) ToPointer() *OutputInfluxdbAuthenticationType {
	return &e
}
func (e *OutputInfluxdbAuthenticationType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "basic":
		fallthrough
	case "credentialsSecret":
		fallthrough
	case "token":
		fallthrough
	case "textSecret":
		fallthrough
	case "oauth":
		*e = OutputInfluxdbAuthenticationType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputInfluxdbAuthenticationType: %v", v)
	}
}

// OutputInfluxdbCompression - Codec to use to compress the persisted data.
type OutputInfluxdbCompression string

const (
	OutputInfluxdbCompressionNone OutputInfluxdbCompression = "none"
	OutputInfluxdbCompressionGzip OutputInfluxdbCompression = "gzip"
)

func (e OutputInfluxdbCompression) ToPointer() *OutputInfluxdbCompression {
	return &e
}
func (e *OutputInfluxdbCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = OutputInfluxdbCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputInfluxdbCompression: %v", v)
	}
}

// OutputInfluxdbQueueFullBehavior - Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
type OutputInfluxdbQueueFullBehavior string

const (
	OutputInfluxdbQueueFullBehaviorBlock OutputInfluxdbQueueFullBehavior = "block"
	OutputInfluxdbQueueFullBehaviorDrop  OutputInfluxdbQueueFullBehavior = "drop"
)

func (e OutputInfluxdbQueueFullBehavior) ToPointer() *OutputInfluxdbQueueFullBehavior {
	return &e
}
func (e *OutputInfluxdbQueueFullBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputInfluxdbQueueFullBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputInfluxdbQueueFullBehavior: %v", v)
	}
}

// OutputInfluxdbMode - In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
type OutputInfluxdbMode string

const (
	OutputInfluxdbModeError        OutputInfluxdbMode = "error"
	OutputInfluxdbModeBackpressure OutputInfluxdbMode = "backpressure"
	OutputInfluxdbModeAlways       OutputInfluxdbMode = "always"
)

func (e OutputInfluxdbMode) ToPointer() *OutputInfluxdbMode {
	return &e
}
func (e *OutputInfluxdbMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "error":
		fallthrough
	case "backpressure":
		fallthrough
	case "always":
		*e = OutputInfluxdbMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputInfluxdbMode: %v", v)
	}
}

type OutputInfluxdbPqControls struct {
}

type OutputInfluxdbOauthParams struct {
	// OAuth parameter name
	Name string `json:"name"`
	// OAuth parameter value
	Value string `json:"value"`
}

func (o *OutputInfluxdbOauthParams) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *OutputInfluxdbOauthParams) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type OutputInfluxdbOauthHeaders struct {
	// OAuth header name
	Name string `json:"name"`
	// OAuth header value
	Value string `json:"value"`
}

func (o *OutputInfluxdbOauthHeaders) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *OutputInfluxdbOauthHeaders) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type OutputInfluxdb struct {
	// Unique ID for this output
	ID   *string            `json:"id,omitempty"`
	Type OutputInfluxdbType `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// URL of an InfluxDB cluster to send events to, e.g., http://localhost:8086/write
	URL string `json:"url"`
	// The v2 API can be enabled with InfluxDB versions 1.8 and later.
	UseV2API *bool `default:"false" json:"useV2API"`
	// Sets the precision for the supplied Unix time values. Defaults to milliseconds.
	TimestampPrecision *TimestampPrecision `default:"ms" json:"timestampPrecision"`
	// Enabling this will pull the value field from the metric name. E,g, 'db.query.user' will use 'db.query' as the measurement and 'user' as the value field.
	DynamicValueFieldName *bool `default:"true" json:"dynamicValueFieldName"`
	// Name of the field in which to store the metric when sending to InfluxDB. If dynamic generation is enabled and fails, this will be used as a fallback.
	ValueFieldName *string `default:"value" json:"valueFieldName"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `default:"5" json:"concurrency"`
	// Maximum size, in KB, of the request body
	MaxPayloadSizeKB *float64 `default:"4096" json:"maxPayloadSizeKB"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited).
	MaxPayloadEvents *float64 `default:"0" json:"maxPayloadEvents"`
	// Compress the payload body before sending
	Compress *bool `default:"true" json:"compress"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Defaults to Yes. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `default:"30" json:"timeoutSec"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Max body size.
	FlushPeriodSec *float64 `default:"1" json:"flushPeriodSec"`
	// Headers to add to all events.
	ExtraHTTPHeaders []OutputInfluxdbExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// Enables round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `default:"false" json:"useRoundRobinDns"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *OutputInfluxdbFailedRequestLoggingMode `default:"none" json:"failedRequestLoggingMode"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable).
	ResponseRetrySettings []OutputInfluxdbResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *OutputInfluxdbTimeoutRetrySettings   `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `default:"false" json:"responseHonorRetryAfterHeader"`
	// Whether to block, drop, or queue events when all receivers are exerting backpressure.
	OnBackpressure *OutputInfluxdbBackpressureBehavior `default:"block" json:"onBackpressure"`
	// InfluxDB authentication type
	AuthType    *OutputInfluxdbAuthenticationType `default:"none" json:"authType"`
	Description *string                           `json:"description,omitempty"`
	// Database to write to.
	Database *string `json:"database,omitempty"`
	// Bucket to write to.
	Bucket *string `json:"bucket,omitempty"`
	// Organization ID for this bucket.
	Org *string `json:"org,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.).
	PqMaxFileSize *string `default:"1 MB" json:"pqMaxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `default:"5GB" json:"pqMaxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `default:"\\$CRIBL_HOME/state/queues" json:"pqPath"`
	// Codec to use to compress the persisted data.
	PqCompress *OutputInfluxdbCompression `default:"none" json:"pqCompress"`
	// Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *OutputInfluxdbQueueFullBehavior `default:"block" json:"pqOnBackpressure"`
	// In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
	PqMode     *OutputInfluxdbMode       `default:"error" json:"pqMode"`
	PqControls *OutputInfluxdbPqControls `json:"pqControls,omitempty"`
	Username   *string                   `json:"username,omitempty"`
	Password   *string                   `json:"password,omitempty"`
	// Bearer token to include in the authorization header
	Token *string `json:"token,omitempty"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// URL for OAuth
	LoginURL *string `json:"loginUrl,omitempty"`
	// Secret parameter name to pass in request body
	SecretParamName *string `json:"secretParamName,omitempty"`
	// Secret parameter value to pass in request body
	Secret *string `json:"secret,omitempty"`
	// Name of the auth token attribute in the OAuth response. Can be top-level (e.g., 'token'); or nested, using a period (e.g., 'data.token').
	TokenAttributeName *string `json:"tokenAttributeName,omitempty"`
	// JavaScript expression to compute the Authorization header value to pass in requests. The value `${token}` is used to reference the token obtained from authentication, e.g.: `Bearer ${token}`.
	AuthHeaderExpr *string `default:"Bearer \\${token}" json:"authHeaderExpr"`
	// How often the OAuth token should be refreshed.
	TokenTimeoutSecs *float64 `default:"3600" json:"tokenTimeoutSecs"`
	// Additional parameters to send in the OAuth login request. @{product} will combine the secret with these parameters, and will send the URL-encoded result in a POST request to the endpoint specified in the 'Login URL'. We'll automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthParams []OutputInfluxdbOauthParams `json:"oauthParams,omitempty"`
	// Additional headers to send in the OAuth login request. @{product} will automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthHeaders []OutputInfluxdbOauthHeaders `json:"oauthHeaders,omitempty"`
	Status       *TFStatus                    `json:"status,omitempty"`
}

func (o OutputInfluxdb) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputInfluxdb) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *OutputInfluxdb) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *OutputInfluxdb) GetType() OutputInfluxdbType {
	if o == nil {
		return OutputInfluxdbType("")
	}
	return o.Type
}

func (o *OutputInfluxdb) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputInfluxdb) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputInfluxdb) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputInfluxdb) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputInfluxdb) GetURL() string {
	if o == nil {
		return ""
	}
	return o.URL
}

func (o *OutputInfluxdb) GetUseV2API() *bool {
	if o == nil {
		return nil
	}
	return o.UseV2API
}

func (o *OutputInfluxdb) GetTimestampPrecision() *TimestampPrecision {
	if o == nil {
		return nil
	}
	return o.TimestampPrecision
}

func (o *OutputInfluxdb) GetDynamicValueFieldName() *bool {
	if o == nil {
		return nil
	}
	return o.DynamicValueFieldName
}

func (o *OutputInfluxdb) GetValueFieldName() *string {
	if o == nil {
		return nil
	}
	return o.ValueFieldName
}

func (o *OutputInfluxdb) GetConcurrency() *float64 {
	if o == nil {
		return nil
	}
	return o.Concurrency
}

func (o *OutputInfluxdb) GetMaxPayloadSizeKB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadSizeKB
}

func (o *OutputInfluxdb) GetMaxPayloadEvents() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadEvents
}

func (o *OutputInfluxdb) GetCompress() *bool {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *OutputInfluxdb) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputInfluxdb) GetTimeoutSec() *float64 {
	if o == nil {
		return nil
	}
	return o.TimeoutSec
}

func (o *OutputInfluxdb) GetFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushPeriodSec
}

func (o *OutputInfluxdb) GetExtraHTTPHeaders() []OutputInfluxdbExtraHTTPHeaders {
	if o == nil {
		return nil
	}
	return o.ExtraHTTPHeaders
}

func (o *OutputInfluxdb) GetUseRoundRobinDNS() *bool {
	if o == nil {
		return nil
	}
	return o.UseRoundRobinDNS
}

func (o *OutputInfluxdb) GetFailedRequestLoggingMode() *OutputInfluxdbFailedRequestLoggingMode {
	if o == nil {
		return nil
	}
	return o.FailedRequestLoggingMode
}

func (o *OutputInfluxdb) GetSafeHeaders() []string {
	if o == nil {
		return nil
	}
	return o.SafeHeaders
}

func (o *OutputInfluxdb) GetResponseRetrySettings() []OutputInfluxdbResponseRetrySettings {
	if o == nil {
		return nil
	}
	return o.ResponseRetrySettings
}

func (o *OutputInfluxdb) GetTimeoutRetrySettings() *OutputInfluxdbTimeoutRetrySettings {
	if o == nil {
		return nil
	}
	return o.TimeoutRetrySettings
}

func (o *OutputInfluxdb) GetResponseHonorRetryAfterHeader() *bool {
	if o == nil {
		return nil
	}
	return o.ResponseHonorRetryAfterHeader
}

func (o *OutputInfluxdb) GetOnBackpressure() *OutputInfluxdbBackpressureBehavior {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputInfluxdb) GetAuthType() *OutputInfluxdbAuthenticationType {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *OutputInfluxdb) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputInfluxdb) GetDatabase() *string {
	if o == nil {
		return nil
	}
	return o.Database
}

func (o *OutputInfluxdb) GetBucket() *string {
	if o == nil {
		return nil
	}
	return o.Bucket
}

func (o *OutputInfluxdb) GetOrg() *string {
	if o == nil {
		return nil
	}
	return o.Org
}

func (o *OutputInfluxdb) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputInfluxdb) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputInfluxdb) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputInfluxdb) GetPqCompress() *OutputInfluxdbCompression {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputInfluxdb) GetPqOnBackpressure() *OutputInfluxdbQueueFullBehavior {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputInfluxdb) GetPqMode() *OutputInfluxdbMode {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputInfluxdb) GetPqControls() *OutputInfluxdbPqControls {
	if o == nil {
		return nil
	}
	return o.PqControls
}

func (o *OutputInfluxdb) GetUsername() *string {
	if o == nil {
		return nil
	}
	return o.Username
}

func (o *OutputInfluxdb) GetPassword() *string {
	if o == nil {
		return nil
	}
	return o.Password
}

func (o *OutputInfluxdb) GetToken() *string {
	if o == nil {
		return nil
	}
	return o.Token
}

func (o *OutputInfluxdb) GetCredentialsSecret() *string {
	if o == nil {
		return nil
	}
	return o.CredentialsSecret
}

func (o *OutputInfluxdb) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *OutputInfluxdb) GetLoginURL() *string {
	if o == nil {
		return nil
	}
	return o.LoginURL
}

func (o *OutputInfluxdb) GetSecretParamName() *string {
	if o == nil {
		return nil
	}
	return o.SecretParamName
}

func (o *OutputInfluxdb) GetSecret() *string {
	if o == nil {
		return nil
	}
	return o.Secret
}

func (o *OutputInfluxdb) GetTokenAttributeName() *string {
	if o == nil {
		return nil
	}
	return o.TokenAttributeName
}

func (o *OutputInfluxdb) GetAuthHeaderExpr() *string {
	if o == nil {
		return nil
	}
	return o.AuthHeaderExpr
}

func (o *OutputInfluxdb) GetTokenTimeoutSecs() *float64 {
	if o == nil {
		return nil
	}
	return o.TokenTimeoutSecs
}

func (o *OutputInfluxdb) GetOauthParams() []OutputInfluxdbOauthParams {
	if o == nil {
		return nil
	}
	return o.OauthParams
}

func (o *OutputInfluxdb) GetOauthHeaders() []OutputInfluxdbOauthHeaders {
	if o == nil {
		return nil
	}
	return o.OauthHeaders
}

func (o *OutputInfluxdb) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type OutputNewrelicEventsType string

const (
	OutputNewrelicEventsTypeNewrelicEvents OutputNewrelicEventsType = "newrelic_events"
)

func (e OutputNewrelicEventsType) ToPointer() *OutputNewrelicEventsType {
	return &e
}
func (e *OutputNewrelicEventsType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "newrelic_events":
		*e = OutputNewrelicEventsType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputNewrelicEventsType: %v", v)
	}
}

// OutputNewrelicEventsRegion - Which New Relic region endpoint to use.
type OutputNewrelicEventsRegion string

const (
	OutputNewrelicEventsRegionUs     OutputNewrelicEventsRegion = "US"
	OutputNewrelicEventsRegionEu     OutputNewrelicEventsRegion = "EU"
	OutputNewrelicEventsRegionCustom OutputNewrelicEventsRegion = "Custom"
)

func (e OutputNewrelicEventsRegion) ToPointer() *OutputNewrelicEventsRegion {
	return &e
}
func (e *OutputNewrelicEventsRegion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "US":
		fallthrough
	case "EU":
		fallthrough
	case "Custom":
		*e = OutputNewrelicEventsRegion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputNewrelicEventsRegion: %v", v)
	}
}

type OutputNewrelicEventsExtraHTTPHeaders struct {
	// Field name
	Name *string `json:"name,omitempty"`
	// Field value
	Value string `json:"value"`
}

func (o *OutputNewrelicEventsExtraHTTPHeaders) GetName() *string {
	if o == nil {
		return nil
	}
	return o.Name
}

func (o *OutputNewrelicEventsExtraHTTPHeaders) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// OutputNewrelicEventsFailedRequestLoggingMode - Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
type OutputNewrelicEventsFailedRequestLoggingMode string

const (
	OutputNewrelicEventsFailedRequestLoggingModePayload           OutputNewrelicEventsFailedRequestLoggingMode = "payload"
	OutputNewrelicEventsFailedRequestLoggingModePayloadAndHeaders OutputNewrelicEventsFailedRequestLoggingMode = "payloadAndHeaders"
	OutputNewrelicEventsFailedRequestLoggingModeNone              OutputNewrelicEventsFailedRequestLoggingMode = "none"
)

func (e OutputNewrelicEventsFailedRequestLoggingMode) ToPointer() *OutputNewrelicEventsFailedRequestLoggingMode {
	return &e
}
func (e *OutputNewrelicEventsFailedRequestLoggingMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "payload":
		fallthrough
	case "payloadAndHeaders":
		fallthrough
	case "none":
		*e = OutputNewrelicEventsFailedRequestLoggingMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputNewrelicEventsFailedRequestLoggingMode: %v", v)
	}
}

type OutputNewrelicEventsResponseRetrySettings struct {
	// The HTTP response status code that will trigger retries
	HTTPStatus float64 `json:"httpStatus"`
	// How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"1000" json:"initialBackoff"`
	// Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackoff *float64 `default:"10000" json:"maxBackoff"`
}

func (o OutputNewrelicEventsResponseRetrySettings) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputNewrelicEventsResponseRetrySettings) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputNewrelicEventsResponseRetrySettings) GetHTTPStatus() float64 {
	if o == nil {
		return 0.0
	}
	return o.HTTPStatus
}

func (o *OutputNewrelicEventsResponseRetrySettings) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *OutputNewrelicEventsResponseRetrySettings) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *OutputNewrelicEventsResponseRetrySettings) GetMaxBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackoff
}

type OutputNewrelicEventsTimeoutRetrySettings struct {
	// Enable to retry on request timeout
	TimeoutRetry *bool `default:"false" json:"timeoutRetry"`
	// How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"1000" json:"initialBackoff"`
	// Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackoff *float64 `default:"10000" json:"maxBackoff"`
}

func (o OutputNewrelicEventsTimeoutRetrySettings) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputNewrelicEventsTimeoutRetrySettings) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputNewrelicEventsTimeoutRetrySettings) GetTimeoutRetry() *bool {
	if o == nil {
		return nil
	}
	return o.TimeoutRetry
}

func (o *OutputNewrelicEventsTimeoutRetrySettings) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *OutputNewrelicEventsTimeoutRetrySettings) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *OutputNewrelicEventsTimeoutRetrySettings) GetMaxBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackoff
}

// OutputNewrelicEventsBackpressureBehavior - Whether to block, drop, or queue events when all receivers are exerting backpressure.
type OutputNewrelicEventsBackpressureBehavior string

const (
	OutputNewrelicEventsBackpressureBehaviorBlock OutputNewrelicEventsBackpressureBehavior = "block"
	OutputNewrelicEventsBackpressureBehaviorDrop  OutputNewrelicEventsBackpressureBehavior = "drop"
	OutputNewrelicEventsBackpressureBehaviorQueue OutputNewrelicEventsBackpressureBehavior = "queue"
)

func (e OutputNewrelicEventsBackpressureBehavior) ToPointer() *OutputNewrelicEventsBackpressureBehavior {
	return &e
}
func (e *OutputNewrelicEventsBackpressureBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		fallthrough
	case "queue":
		*e = OutputNewrelicEventsBackpressureBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputNewrelicEventsBackpressureBehavior: %v", v)
	}
}

// OutputNewrelicEventsAuthenticationMethod - Enter API key directly, or select a stored secret
type OutputNewrelicEventsAuthenticationMethod string

const (
	OutputNewrelicEventsAuthenticationMethodManual OutputNewrelicEventsAuthenticationMethod = "manual"
	OutputNewrelicEventsAuthenticationMethodSecret OutputNewrelicEventsAuthenticationMethod = "secret"
)

func (e OutputNewrelicEventsAuthenticationMethod) ToPointer() *OutputNewrelicEventsAuthenticationMethod {
	return &e
}
func (e *OutputNewrelicEventsAuthenticationMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "manual":
		fallthrough
	case "secret":
		*e = OutputNewrelicEventsAuthenticationMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputNewrelicEventsAuthenticationMethod: %v", v)
	}
}

// OutputNewrelicEventsCompression - Codec to use to compress the persisted data.
type OutputNewrelicEventsCompression string

const (
	OutputNewrelicEventsCompressionNone OutputNewrelicEventsCompression = "none"
	OutputNewrelicEventsCompressionGzip OutputNewrelicEventsCompression = "gzip"
)

func (e OutputNewrelicEventsCompression) ToPointer() *OutputNewrelicEventsCompression {
	return &e
}
func (e *OutputNewrelicEventsCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = OutputNewrelicEventsCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputNewrelicEventsCompression: %v", v)
	}
}

// OutputNewrelicEventsQueueFullBehavior - Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
type OutputNewrelicEventsQueueFullBehavior string

const (
	OutputNewrelicEventsQueueFullBehaviorBlock OutputNewrelicEventsQueueFullBehavior = "block"
	OutputNewrelicEventsQueueFullBehaviorDrop  OutputNewrelicEventsQueueFullBehavior = "drop"
)

func (e OutputNewrelicEventsQueueFullBehavior) ToPointer() *OutputNewrelicEventsQueueFullBehavior {
	return &e
}
func (e *OutputNewrelicEventsQueueFullBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputNewrelicEventsQueueFullBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputNewrelicEventsQueueFullBehavior: %v", v)
	}
}

// OutputNewrelicEventsMode - In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
type OutputNewrelicEventsMode string

const (
	OutputNewrelicEventsModeError        OutputNewrelicEventsMode = "error"
	OutputNewrelicEventsModeBackpressure OutputNewrelicEventsMode = "backpressure"
	OutputNewrelicEventsModeAlways       OutputNewrelicEventsMode = "always"
)

func (e OutputNewrelicEventsMode) ToPointer() *OutputNewrelicEventsMode {
	return &e
}
func (e *OutputNewrelicEventsMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "error":
		fallthrough
	case "backpressure":
		fallthrough
	case "always":
		*e = OutputNewrelicEventsMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputNewrelicEventsMode: %v", v)
	}
}

type OutputNewrelicEventsPqControls struct {
}

type OutputNewrelicEvents struct {
	// Unique ID for this output
	ID   *string                   `json:"id,omitempty"`
	Type *OutputNewrelicEventsType `json:"type,omitempty"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Which New Relic region endpoint to use.
	Region *OutputNewrelicEventsRegion `default:"US" json:"region"`
	// New Relic account ID
	AccountID string `json:"accountId"`
	// Default eventType to use when not present in an event. For more information, see [here](https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/data-requirements-limits-custom-event-data/#reserved-words).
	EventType string `json:"eventType"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `default:"5" json:"concurrency"`
	// Maximum size, in KB, of the request body
	MaxPayloadSizeKB *float64 `default:"1024" json:"maxPayloadSizeKB"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited).
	MaxPayloadEvents *float64 `default:"0" json:"maxPayloadEvents"`
	// Compress the payload body before sending
	Compress *bool `default:"true" json:"compress"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Defaults to Yes. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `default:"30" json:"timeoutSec"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Max body size.
	FlushPeriodSec *float64 `default:"1" json:"flushPeriodSec"`
	// Headers to add to all events.
	ExtraHTTPHeaders []OutputNewrelicEventsExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// Enables round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `default:"false" json:"useRoundRobinDns"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *OutputNewrelicEventsFailedRequestLoggingMode `default:"none" json:"failedRequestLoggingMode"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable).
	ResponseRetrySettings []OutputNewrelicEventsResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *OutputNewrelicEventsTimeoutRetrySettings   `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `default:"false" json:"responseHonorRetryAfterHeader"`
	// Whether to block, drop, or queue events when all receivers are exerting backpressure.
	OnBackpressure *OutputNewrelicEventsBackpressureBehavior `default:"block" json:"onBackpressure"`
	// Enter API key directly, or select a stored secret
	AuthType    *OutputNewrelicEventsAuthenticationMethod `default:"manual" json:"authType"`
	Description *string                                   `json:"description,omitempty"`
	CustomURL   *string                                   `json:"customUrl,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.).
	PqMaxFileSize *string `default:"1 MB" json:"pqMaxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `default:"5GB" json:"pqMaxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `default:"\\$CRIBL_HOME/state/queues" json:"pqPath"`
	// Codec to use to compress the persisted data.
	PqCompress *OutputNewrelicEventsCompression `default:"none" json:"pqCompress"`
	// Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *OutputNewrelicEventsQueueFullBehavior `default:"block" json:"pqOnBackpressure"`
	// In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
	PqMode     *OutputNewrelicEventsMode       `default:"error" json:"pqMode"`
	PqControls *OutputNewrelicEventsPqControls `json:"pqControls,omitempty"`
	// New Relic API key. Can be overridden using __newRelic_apiKey field.
	APIKey *string `json:"apiKey,omitempty"`
	// Select or create a stored text secret
	TextSecret *string   `json:"textSecret,omitempty"`
	Status     *TFStatus `json:"status,omitempty"`
}

func (o OutputNewrelicEvents) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputNewrelicEvents) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *OutputNewrelicEvents) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *OutputNewrelicEvents) GetType() *OutputNewrelicEventsType {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *OutputNewrelicEvents) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputNewrelicEvents) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputNewrelicEvents) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputNewrelicEvents) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputNewrelicEvents) GetRegion() *OutputNewrelicEventsRegion {
	if o == nil {
		return nil
	}
	return o.Region
}

func (o *OutputNewrelicEvents) GetAccountID() string {
	if o == nil {
		return ""
	}
	return o.AccountID
}

func (o *OutputNewrelicEvents) GetEventType() string {
	if o == nil {
		return ""
	}
	return o.EventType
}

func (o *OutputNewrelicEvents) GetConcurrency() *float64 {
	if o == nil {
		return nil
	}
	return o.Concurrency
}

func (o *OutputNewrelicEvents) GetMaxPayloadSizeKB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadSizeKB
}

func (o *OutputNewrelicEvents) GetMaxPayloadEvents() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadEvents
}

func (o *OutputNewrelicEvents) GetCompress() *bool {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *OutputNewrelicEvents) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputNewrelicEvents) GetTimeoutSec() *float64 {
	if o == nil {
		return nil
	}
	return o.TimeoutSec
}

func (o *OutputNewrelicEvents) GetFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushPeriodSec
}

func (o *OutputNewrelicEvents) GetExtraHTTPHeaders() []OutputNewrelicEventsExtraHTTPHeaders {
	if o == nil {
		return nil
	}
	return o.ExtraHTTPHeaders
}

func (o *OutputNewrelicEvents) GetUseRoundRobinDNS() *bool {
	if o == nil {
		return nil
	}
	return o.UseRoundRobinDNS
}

func (o *OutputNewrelicEvents) GetFailedRequestLoggingMode() *OutputNewrelicEventsFailedRequestLoggingMode {
	if o == nil {
		return nil
	}
	return o.FailedRequestLoggingMode
}

func (o *OutputNewrelicEvents) GetSafeHeaders() []string {
	if o == nil {
		return nil
	}
	return o.SafeHeaders
}

func (o *OutputNewrelicEvents) GetResponseRetrySettings() []OutputNewrelicEventsResponseRetrySettings {
	if o == nil {
		return nil
	}
	return o.ResponseRetrySettings
}

func (o *OutputNewrelicEvents) GetTimeoutRetrySettings() *OutputNewrelicEventsTimeoutRetrySettings {
	if o == nil {
		return nil
	}
	return o.TimeoutRetrySettings
}

func (o *OutputNewrelicEvents) GetResponseHonorRetryAfterHeader() *bool {
	if o == nil {
		return nil
	}
	return o.ResponseHonorRetryAfterHeader
}

func (o *OutputNewrelicEvents) GetOnBackpressure() *OutputNewrelicEventsBackpressureBehavior {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputNewrelicEvents) GetAuthType() *OutputNewrelicEventsAuthenticationMethod {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *OutputNewrelicEvents) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputNewrelicEvents) GetCustomURL() *string {
	if o == nil {
		return nil
	}
	return o.CustomURL
}

func (o *OutputNewrelicEvents) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputNewrelicEvents) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputNewrelicEvents) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputNewrelicEvents) GetPqCompress() *OutputNewrelicEventsCompression {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputNewrelicEvents) GetPqOnBackpressure() *OutputNewrelicEventsQueueFullBehavior {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputNewrelicEvents) GetPqMode() *OutputNewrelicEventsMode {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputNewrelicEvents) GetPqControls() *OutputNewrelicEventsPqControls {
	if o == nil {
		return nil
	}
	return o.PqControls
}

func (o *OutputNewrelicEvents) GetAPIKey() *string {
	if o == nil {
		return nil
	}
	return o.APIKey
}

func (o *OutputNewrelicEvents) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *OutputNewrelicEvents) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type OutputNewrelicType string

const (
	OutputNewrelicTypeNewrelic OutputNewrelicType = "newrelic"
)

func (e OutputNewrelicType) ToPointer() *OutputNewrelicType {
	return &e
}
func (e *OutputNewrelicType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "newrelic":
		*e = OutputNewrelicType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputNewrelicType: %v", v)
	}
}

// OutputNewrelicRegion - Which New Relic region endpoint to use.
type OutputNewrelicRegion string

const (
	OutputNewrelicRegionUs     OutputNewrelicRegion = "US"
	OutputNewrelicRegionEu     OutputNewrelicRegion = "EU"
	OutputNewrelicRegionCustom OutputNewrelicRegion = "Custom"
)

func (e OutputNewrelicRegion) ToPointer() *OutputNewrelicRegion {
	return &e
}
func (e *OutputNewrelicRegion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "US":
		fallthrough
	case "EU":
		fallthrough
	case "Custom":
		*e = OutputNewrelicRegion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputNewrelicRegion: %v", v)
	}
}

type FieldName string

const (
	FieldNameService   FieldName = "service"
	FieldNameHostname  FieldName = "hostname"
	FieldNameTimestamp FieldName = "timestamp"
	FieldNameAuditID   FieldName = "auditId"
)

func (e FieldName) ToPointer() *FieldName {
	return &e
}
func (e *FieldName) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "service":
		fallthrough
	case "hostname":
		fallthrough
	case "timestamp":
		fallthrough
	case "auditId":
		*e = FieldName(v)
		return nil
	default:
		return fmt.Errorf("invalid value for FieldName: %v", v)
	}
}

type OutputNewrelicMetadata struct {
	Name FieldName `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *OutputNewrelicMetadata) GetName() FieldName {
	if o == nil {
		return FieldName("")
	}
	return o.Name
}

func (o *OutputNewrelicMetadata) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type OutputNewrelicExtraHTTPHeaders struct {
	// Field name
	Name *string `json:"name,omitempty"`
	// Field value
	Value string `json:"value"`
}

func (o *OutputNewrelicExtraHTTPHeaders) GetName() *string {
	if o == nil {
		return nil
	}
	return o.Name
}

func (o *OutputNewrelicExtraHTTPHeaders) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// OutputNewrelicFailedRequestLoggingMode - Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
type OutputNewrelicFailedRequestLoggingMode string

const (
	OutputNewrelicFailedRequestLoggingModePayload           OutputNewrelicFailedRequestLoggingMode = "payload"
	OutputNewrelicFailedRequestLoggingModePayloadAndHeaders OutputNewrelicFailedRequestLoggingMode = "payloadAndHeaders"
	OutputNewrelicFailedRequestLoggingModeNone              OutputNewrelicFailedRequestLoggingMode = "none"
)

func (e OutputNewrelicFailedRequestLoggingMode) ToPointer() *OutputNewrelicFailedRequestLoggingMode {
	return &e
}
func (e *OutputNewrelicFailedRequestLoggingMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "payload":
		fallthrough
	case "payloadAndHeaders":
		fallthrough
	case "none":
		*e = OutputNewrelicFailedRequestLoggingMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputNewrelicFailedRequestLoggingMode: %v", v)
	}
}

type OutputNewrelicResponseRetrySettings struct {
	// The HTTP response status code that will trigger retries
	HTTPStatus float64 `json:"httpStatus"`
	// How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"1000" json:"initialBackoff"`
	// Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackoff *float64 `default:"10000" json:"maxBackoff"`
}

func (o OutputNewrelicResponseRetrySettings) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputNewrelicResponseRetrySettings) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputNewrelicResponseRetrySettings) GetHTTPStatus() float64 {
	if o == nil {
		return 0.0
	}
	return o.HTTPStatus
}

func (o *OutputNewrelicResponseRetrySettings) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *OutputNewrelicResponseRetrySettings) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *OutputNewrelicResponseRetrySettings) GetMaxBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackoff
}

type OutputNewrelicTimeoutRetrySettings struct {
	// Enable to retry on request timeout
	TimeoutRetry *bool `default:"false" json:"timeoutRetry"`
	// How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"1000" json:"initialBackoff"`
	// Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackoff *float64 `default:"10000" json:"maxBackoff"`
}

func (o OutputNewrelicTimeoutRetrySettings) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputNewrelicTimeoutRetrySettings) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputNewrelicTimeoutRetrySettings) GetTimeoutRetry() *bool {
	if o == nil {
		return nil
	}
	return o.TimeoutRetry
}

func (o *OutputNewrelicTimeoutRetrySettings) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *OutputNewrelicTimeoutRetrySettings) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *OutputNewrelicTimeoutRetrySettings) GetMaxBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackoff
}

// OutputNewrelicBackpressureBehavior - Whether to block, drop, or queue events when all receivers are exerting backpressure.
type OutputNewrelicBackpressureBehavior string

const (
	OutputNewrelicBackpressureBehaviorBlock OutputNewrelicBackpressureBehavior = "block"
	OutputNewrelicBackpressureBehaviorDrop  OutputNewrelicBackpressureBehavior = "drop"
	OutputNewrelicBackpressureBehaviorQueue OutputNewrelicBackpressureBehavior = "queue"
)

func (e OutputNewrelicBackpressureBehavior) ToPointer() *OutputNewrelicBackpressureBehavior {
	return &e
}
func (e *OutputNewrelicBackpressureBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		fallthrough
	case "queue":
		*e = OutputNewrelicBackpressureBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputNewrelicBackpressureBehavior: %v", v)
	}
}

// OutputNewrelicAuthenticationMethod - Enter API key directly, or select a stored secret
type OutputNewrelicAuthenticationMethod string

const (
	OutputNewrelicAuthenticationMethodManual OutputNewrelicAuthenticationMethod = "manual"
	OutputNewrelicAuthenticationMethodSecret OutputNewrelicAuthenticationMethod = "secret"
)

func (e OutputNewrelicAuthenticationMethod) ToPointer() *OutputNewrelicAuthenticationMethod {
	return &e
}
func (e *OutputNewrelicAuthenticationMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "manual":
		fallthrough
	case "secret":
		*e = OutputNewrelicAuthenticationMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputNewrelicAuthenticationMethod: %v", v)
	}
}

// OutputNewrelicCompression - Codec to use to compress the persisted data.
type OutputNewrelicCompression string

const (
	OutputNewrelicCompressionNone OutputNewrelicCompression = "none"
	OutputNewrelicCompressionGzip OutputNewrelicCompression = "gzip"
)

func (e OutputNewrelicCompression) ToPointer() *OutputNewrelicCompression {
	return &e
}
func (e *OutputNewrelicCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = OutputNewrelicCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputNewrelicCompression: %v", v)
	}
}

// OutputNewrelicQueueFullBehavior - Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
type OutputNewrelicQueueFullBehavior string

const (
	OutputNewrelicQueueFullBehaviorBlock OutputNewrelicQueueFullBehavior = "block"
	OutputNewrelicQueueFullBehaviorDrop  OutputNewrelicQueueFullBehavior = "drop"
)

func (e OutputNewrelicQueueFullBehavior) ToPointer() *OutputNewrelicQueueFullBehavior {
	return &e
}
func (e *OutputNewrelicQueueFullBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputNewrelicQueueFullBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputNewrelicQueueFullBehavior: %v", v)
	}
}

// OutputNewrelicMode - In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
type OutputNewrelicMode string

const (
	OutputNewrelicModeError        OutputNewrelicMode = "error"
	OutputNewrelicModeBackpressure OutputNewrelicMode = "backpressure"
	OutputNewrelicModeAlways       OutputNewrelicMode = "always"
)

func (e OutputNewrelicMode) ToPointer() *OutputNewrelicMode {
	return &e
}
func (e *OutputNewrelicMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "error":
		fallthrough
	case "backpressure":
		fallthrough
	case "always":
		*e = OutputNewrelicMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputNewrelicMode: %v", v)
	}
}

type OutputNewrelicPqControls struct {
}

type OutputNewrelic struct {
	// Unique ID for this output
	ID   string             `json:"id"`
	Type OutputNewrelicType `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Which New Relic region endpoint to use.
	Region *OutputNewrelicRegion `default:"US" json:"region"`
	// Name of the logtype to send with events, e.g.: observability, access_log. The event's 'sourcetype' field (if set) will override this value.
	LogType *string `default:"" json:"logType"`
	// Name of field to send as log message value. If not present, event will be serialized and sent as JSON.
	MessageField *string `default:"" json:"messageField"`
	// Fields to add to events from this input
	Metadata []OutputNewrelicMetadata `json:"metadata,omitempty"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `default:"5" json:"concurrency"`
	// Maximum size, in KB, of the request body
	MaxPayloadSizeKB *float64 `default:"1024" json:"maxPayloadSizeKB"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited).
	MaxPayloadEvents *float64 `default:"0" json:"maxPayloadEvents"`
	// Compress the payload body before sending
	Compress *bool `default:"true" json:"compress"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Defaults to Yes. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `default:"30" json:"timeoutSec"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Max body size.
	FlushPeriodSec *float64 `default:"1" json:"flushPeriodSec"`
	// Headers to add to all events.
	ExtraHTTPHeaders []OutputNewrelicExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// Enables round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `default:"false" json:"useRoundRobinDns"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *OutputNewrelicFailedRequestLoggingMode `default:"none" json:"failedRequestLoggingMode"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable).
	ResponseRetrySettings []OutputNewrelicResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *OutputNewrelicTimeoutRetrySettings   `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `default:"false" json:"responseHonorRetryAfterHeader"`
	// Whether to block, drop, or queue events when all receivers are exerting backpressure.
	OnBackpressure *OutputNewrelicBackpressureBehavior `default:"block" json:"onBackpressure"`
	// Enter API key directly, or select a stored secret
	AuthType *OutputNewrelicAuthenticationMethod `default:"manual" json:"authType"`
	// Maximum total size of the batches waiting to be sent. If left blank, defaults to 5 times the max body size (if set). If 0, no limit is enforced.
	TotalMemoryLimitKB *float64 `json:"totalMemoryLimitKB,omitempty"`
	Description        *string  `json:"description,omitempty"`
	CustomURL          *string  `json:"customUrl,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.).
	PqMaxFileSize *string `default:"1 MB" json:"pqMaxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `default:"5GB" json:"pqMaxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `default:"\\$CRIBL_HOME/state/queues" json:"pqPath"`
	// Codec to use to compress the persisted data.
	PqCompress *OutputNewrelicCompression `default:"none" json:"pqCompress"`
	// Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *OutputNewrelicQueueFullBehavior `default:"block" json:"pqOnBackpressure"`
	// In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
	PqMode     *OutputNewrelicMode       `default:"error" json:"pqMode"`
	PqControls *OutputNewrelicPqControls `json:"pqControls,omitempty"`
	// New Relic API key. Can be overridden using __newRelic_apiKey field.
	APIKey *string `json:"apiKey,omitempty"`
	// Select or create a stored text secret
	TextSecret *string   `json:"textSecret,omitempty"`
	Status     *TFStatus `json:"status,omitempty"`
}

func (o OutputNewrelic) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputNewrelic) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *OutputNewrelic) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *OutputNewrelic) GetType() OutputNewrelicType {
	if o == nil {
		return OutputNewrelicType("")
	}
	return o.Type
}

func (o *OutputNewrelic) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputNewrelic) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputNewrelic) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputNewrelic) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputNewrelic) GetRegion() *OutputNewrelicRegion {
	if o == nil {
		return nil
	}
	return o.Region
}

func (o *OutputNewrelic) GetLogType() *string {
	if o == nil {
		return nil
	}
	return o.LogType
}

func (o *OutputNewrelic) GetMessageField() *string {
	if o == nil {
		return nil
	}
	return o.MessageField
}

func (o *OutputNewrelic) GetMetadata() []OutputNewrelicMetadata {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *OutputNewrelic) GetConcurrency() *float64 {
	if o == nil {
		return nil
	}
	return o.Concurrency
}

func (o *OutputNewrelic) GetMaxPayloadSizeKB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadSizeKB
}

func (o *OutputNewrelic) GetMaxPayloadEvents() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadEvents
}

func (o *OutputNewrelic) GetCompress() *bool {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *OutputNewrelic) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputNewrelic) GetTimeoutSec() *float64 {
	if o == nil {
		return nil
	}
	return o.TimeoutSec
}

func (o *OutputNewrelic) GetFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushPeriodSec
}

func (o *OutputNewrelic) GetExtraHTTPHeaders() []OutputNewrelicExtraHTTPHeaders {
	if o == nil {
		return nil
	}
	return o.ExtraHTTPHeaders
}

func (o *OutputNewrelic) GetUseRoundRobinDNS() *bool {
	if o == nil {
		return nil
	}
	return o.UseRoundRobinDNS
}

func (o *OutputNewrelic) GetFailedRequestLoggingMode() *OutputNewrelicFailedRequestLoggingMode {
	if o == nil {
		return nil
	}
	return o.FailedRequestLoggingMode
}

func (o *OutputNewrelic) GetSafeHeaders() []string {
	if o == nil {
		return nil
	}
	return o.SafeHeaders
}

func (o *OutputNewrelic) GetResponseRetrySettings() []OutputNewrelicResponseRetrySettings {
	if o == nil {
		return nil
	}
	return o.ResponseRetrySettings
}

func (o *OutputNewrelic) GetTimeoutRetrySettings() *OutputNewrelicTimeoutRetrySettings {
	if o == nil {
		return nil
	}
	return o.TimeoutRetrySettings
}

func (o *OutputNewrelic) GetResponseHonorRetryAfterHeader() *bool {
	if o == nil {
		return nil
	}
	return o.ResponseHonorRetryAfterHeader
}

func (o *OutputNewrelic) GetOnBackpressure() *OutputNewrelicBackpressureBehavior {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputNewrelic) GetAuthType() *OutputNewrelicAuthenticationMethod {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *OutputNewrelic) GetTotalMemoryLimitKB() *float64 {
	if o == nil {
		return nil
	}
	return o.TotalMemoryLimitKB
}

func (o *OutputNewrelic) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputNewrelic) GetCustomURL() *string {
	if o == nil {
		return nil
	}
	return o.CustomURL
}

func (o *OutputNewrelic) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputNewrelic) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputNewrelic) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputNewrelic) GetPqCompress() *OutputNewrelicCompression {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputNewrelic) GetPqOnBackpressure() *OutputNewrelicQueueFullBehavior {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputNewrelic) GetPqMode() *OutputNewrelicMode {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputNewrelic) GetPqControls() *OutputNewrelicPqControls {
	if o == nil {
		return nil
	}
	return o.PqControls
}

func (o *OutputNewrelic) GetAPIKey() *string {
	if o == nil {
		return nil
	}
	return o.APIKey
}

func (o *OutputNewrelic) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *OutputNewrelic) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type OutputElasticCloudType string

const (
	OutputElasticCloudTypeElasticCloud OutputElasticCloudType = "elastic_cloud"
)

func (e OutputElasticCloudType) ToPointer() *OutputElasticCloudType {
	return &e
}
func (e *OutputElasticCloudType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "elastic_cloud":
		*e = OutputElasticCloudType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputElasticCloudType: %v", v)
	}
}

type OutputElasticCloudExtraHTTPHeaders struct {
	// Field name
	Name *string `json:"name,omitempty"`
	// Field value
	Value string `json:"value"`
}

func (o *OutputElasticCloudExtraHTTPHeaders) GetName() *string {
	if o == nil {
		return nil
	}
	return o.Name
}

func (o *OutputElasticCloudExtraHTTPHeaders) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// OutputElasticCloudFailedRequestLoggingMode - Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
type OutputElasticCloudFailedRequestLoggingMode string

const (
	OutputElasticCloudFailedRequestLoggingModePayload           OutputElasticCloudFailedRequestLoggingMode = "payload"
	OutputElasticCloudFailedRequestLoggingModePayloadAndHeaders OutputElasticCloudFailedRequestLoggingMode = "payloadAndHeaders"
	OutputElasticCloudFailedRequestLoggingModeNone              OutputElasticCloudFailedRequestLoggingMode = "none"
)

func (e OutputElasticCloudFailedRequestLoggingMode) ToPointer() *OutputElasticCloudFailedRequestLoggingMode {
	return &e
}
func (e *OutputElasticCloudFailedRequestLoggingMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "payload":
		fallthrough
	case "payloadAndHeaders":
		fallthrough
	case "none":
		*e = OutputElasticCloudFailedRequestLoggingMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputElasticCloudFailedRequestLoggingMode: %v", v)
	}
}

type OutputElasticCloudExtraParams struct {
	// Field name
	Name string `json:"name"`
	// Field value
	Value string `json:"value"`
}

func (o *OutputElasticCloudExtraParams) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *OutputElasticCloudExtraParams) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// OutputElasticCloudAuthenticationMethod - Enter credentials directly, or select a stored secret
type OutputElasticCloudAuthenticationMethod string

const (
	OutputElasticCloudAuthenticationMethodManual       OutputElasticCloudAuthenticationMethod = "manual"
	OutputElasticCloudAuthenticationMethodSecret       OutputElasticCloudAuthenticationMethod = "secret"
	OutputElasticCloudAuthenticationMethodManualAPIKey OutputElasticCloudAuthenticationMethod = "manualAPIKey"
	OutputElasticCloudAuthenticationMethodTextSecret   OutputElasticCloudAuthenticationMethod = "textSecret"
)

func (e OutputElasticCloudAuthenticationMethod) ToPointer() *OutputElasticCloudAuthenticationMethod {
	return &e
}
func (e *OutputElasticCloudAuthenticationMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "manual":
		fallthrough
	case "secret":
		fallthrough
	case "manualAPIKey":
		fallthrough
	case "textSecret":
		*e = OutputElasticCloudAuthenticationMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputElasticCloudAuthenticationMethod: %v", v)
	}
}

type OutputElasticCloudAuth struct {
	Disabled *bool `default:"false" json:"disabled"`
	// Enter credentials directly, or select a stored secret
	AuthType *OutputElasticCloudAuthenticationMethod `default:"manual" json:"authType"`
}

func (o OutputElasticCloudAuth) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputElasticCloudAuth) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputElasticCloudAuth) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *OutputElasticCloudAuth) GetAuthType() *OutputElasticCloudAuthenticationMethod {
	if o == nil {
		return nil
	}
	return o.AuthType
}

type OutputElasticCloudResponseRetrySettings struct {
	// The HTTP response status code that will trigger retries
	HTTPStatus float64 `json:"httpStatus"`
	// How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"1000" json:"initialBackoff"`
	// Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackoff *float64 `default:"10000" json:"maxBackoff"`
}

func (o OutputElasticCloudResponseRetrySettings) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputElasticCloudResponseRetrySettings) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputElasticCloudResponseRetrySettings) GetHTTPStatus() float64 {
	if o == nil {
		return 0.0
	}
	return o.HTTPStatus
}

func (o *OutputElasticCloudResponseRetrySettings) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *OutputElasticCloudResponseRetrySettings) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *OutputElasticCloudResponseRetrySettings) GetMaxBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackoff
}

type OutputElasticCloudTimeoutRetrySettings struct {
	// Enable to retry on request timeout
	TimeoutRetry *bool `default:"false" json:"timeoutRetry"`
	// How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"1000" json:"initialBackoff"`
	// Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackoff *float64 `default:"10000" json:"maxBackoff"`
}

func (o OutputElasticCloudTimeoutRetrySettings) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputElasticCloudTimeoutRetrySettings) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputElasticCloudTimeoutRetrySettings) GetTimeoutRetry() *bool {
	if o == nil {
		return nil
	}
	return o.TimeoutRetry
}

func (o *OutputElasticCloudTimeoutRetrySettings) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *OutputElasticCloudTimeoutRetrySettings) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *OutputElasticCloudTimeoutRetrySettings) GetMaxBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackoff
}

// OutputElasticCloudBackpressureBehavior - Whether to block, drop, or queue events when all receivers are exerting backpressure.
type OutputElasticCloudBackpressureBehavior string

const (
	OutputElasticCloudBackpressureBehaviorBlock OutputElasticCloudBackpressureBehavior = "block"
	OutputElasticCloudBackpressureBehaviorDrop  OutputElasticCloudBackpressureBehavior = "drop"
	OutputElasticCloudBackpressureBehaviorQueue OutputElasticCloudBackpressureBehavior = "queue"
)

func (e OutputElasticCloudBackpressureBehavior) ToPointer() *OutputElasticCloudBackpressureBehavior {
	return &e
}
func (e *OutputElasticCloudBackpressureBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		fallthrough
	case "queue":
		*e = OutputElasticCloudBackpressureBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputElasticCloudBackpressureBehavior: %v", v)
	}
}

// OutputElasticCloudCompression - Codec to use to compress the persisted data.
type OutputElasticCloudCompression string

const (
	OutputElasticCloudCompressionNone OutputElasticCloudCompression = "none"
	OutputElasticCloudCompressionGzip OutputElasticCloudCompression = "gzip"
)

func (e OutputElasticCloudCompression) ToPointer() *OutputElasticCloudCompression {
	return &e
}
func (e *OutputElasticCloudCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = OutputElasticCloudCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputElasticCloudCompression: %v", v)
	}
}

// OutputElasticCloudQueueFullBehavior - Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
type OutputElasticCloudQueueFullBehavior string

const (
	OutputElasticCloudQueueFullBehaviorBlock OutputElasticCloudQueueFullBehavior = "block"
	OutputElasticCloudQueueFullBehaviorDrop  OutputElasticCloudQueueFullBehavior = "drop"
)

func (e OutputElasticCloudQueueFullBehavior) ToPointer() *OutputElasticCloudQueueFullBehavior {
	return &e
}
func (e *OutputElasticCloudQueueFullBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputElasticCloudQueueFullBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputElasticCloudQueueFullBehavior: %v", v)
	}
}

// OutputElasticCloudMode - In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
type OutputElasticCloudMode string

const (
	OutputElasticCloudModeError        OutputElasticCloudMode = "error"
	OutputElasticCloudModeBackpressure OutputElasticCloudMode = "backpressure"
	OutputElasticCloudModeAlways       OutputElasticCloudMode = "always"
)

func (e OutputElasticCloudMode) ToPointer() *OutputElasticCloudMode {
	return &e
}
func (e *OutputElasticCloudMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "error":
		fallthrough
	case "backpressure":
		fallthrough
	case "always":
		*e = OutputElasticCloudMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputElasticCloudMode: %v", v)
	}
}

type OutputElasticCloudPqControls struct {
}

type OutputElasticCloud struct {
	// Unique ID for this output
	ID   *string                 `json:"id,omitempty"`
	Type *OutputElasticCloudType `json:"type,omitempty"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Enter Cloud ID of the Elastic Cloud environment to send events to
	URL string `json:"url"`
	// Data stream or index to send events to. Must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be overwritten by an event's __index field
	Index string `json:"index"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `default:"5" json:"concurrency"`
	// Maximum size, in KB, of the request body
	MaxPayloadSizeKB *float64 `default:"4096" json:"maxPayloadSizeKB"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited).
	MaxPayloadEvents *float64 `default:"0" json:"maxPayloadEvents"`
	// Compress the payload body before sending
	Compress *bool `default:"true" json:"compress"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Defaults to Yes. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `default:"30" json:"timeoutSec"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Max body size.
	FlushPeriodSec *float64 `default:"1" json:"flushPeriodSec"`
	// Headers to add to all events.
	ExtraHTTPHeaders []OutputElasticCloudExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *OutputElasticCloudFailedRequestLoggingMode `default:"none" json:"failedRequestLoggingMode"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// Extra parameters to use in HTTP requests
	ExtraParams []OutputElasticCloudExtraParams `json:"extraParams,omitempty"`
	Auth        *OutputElasticCloudAuth         `json:"auth,omitempty"`
	// Optional Elastic Cloud Destination pipeline
	ElasticPipeline *string `json:"elasticPipeline,omitempty"`
	// Toggle to No when sending events to an Elastic TSDS (time series data stream)
	IncludeDocID *bool `default:"true" json:"includeDocId"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable).
	ResponseRetrySettings []OutputElasticCloudResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *OutputElasticCloudTimeoutRetrySettings   `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `default:"false" json:"responseHonorRetryAfterHeader"`
	// Whether to block, drop, or queue events when all receivers are exerting backpressure.
	OnBackpressure *OutputElasticCloudBackpressureBehavior `default:"block" json:"onBackpressure"`
	Description    *string                                 `json:"description,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.).
	PqMaxFileSize *string `default:"1 MB" json:"pqMaxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `default:"5GB" json:"pqMaxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `default:"\\$CRIBL_HOME/state/queues" json:"pqPath"`
	// Codec to use to compress the persisted data.
	PqCompress *OutputElasticCloudCompression `default:"none" json:"pqCompress"`
	// Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *OutputElasticCloudQueueFullBehavior `default:"block" json:"pqOnBackpressure"`
	// In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
	PqMode     *OutputElasticCloudMode       `default:"error" json:"pqMode"`
	PqControls *OutputElasticCloudPqControls `json:"pqControls,omitempty"`
	Status     *TFStatus                     `json:"status,omitempty"`
}

func (o OutputElasticCloud) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputElasticCloud) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *OutputElasticCloud) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *OutputElasticCloud) GetType() *OutputElasticCloudType {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *OutputElasticCloud) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputElasticCloud) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputElasticCloud) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputElasticCloud) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputElasticCloud) GetURL() string {
	if o == nil {
		return ""
	}
	return o.URL
}

func (o *OutputElasticCloud) GetIndex() string {
	if o == nil {
		return ""
	}
	return o.Index
}

func (o *OutputElasticCloud) GetConcurrency() *float64 {
	if o == nil {
		return nil
	}
	return o.Concurrency
}

func (o *OutputElasticCloud) GetMaxPayloadSizeKB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadSizeKB
}

func (o *OutputElasticCloud) GetMaxPayloadEvents() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadEvents
}

func (o *OutputElasticCloud) GetCompress() *bool {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *OutputElasticCloud) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputElasticCloud) GetTimeoutSec() *float64 {
	if o == nil {
		return nil
	}
	return o.TimeoutSec
}

func (o *OutputElasticCloud) GetFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushPeriodSec
}

func (o *OutputElasticCloud) GetExtraHTTPHeaders() []OutputElasticCloudExtraHTTPHeaders {
	if o == nil {
		return nil
	}
	return o.ExtraHTTPHeaders
}

func (o *OutputElasticCloud) GetFailedRequestLoggingMode() *OutputElasticCloudFailedRequestLoggingMode {
	if o == nil {
		return nil
	}
	return o.FailedRequestLoggingMode
}

func (o *OutputElasticCloud) GetSafeHeaders() []string {
	if o == nil {
		return nil
	}
	return o.SafeHeaders
}

func (o *OutputElasticCloud) GetExtraParams() []OutputElasticCloudExtraParams {
	if o == nil {
		return nil
	}
	return o.ExtraParams
}

func (o *OutputElasticCloud) GetAuth() *OutputElasticCloudAuth {
	if o == nil {
		return nil
	}
	return o.Auth
}

func (o *OutputElasticCloud) GetElasticPipeline() *string {
	if o == nil {
		return nil
	}
	return o.ElasticPipeline
}

func (o *OutputElasticCloud) GetIncludeDocID() *bool {
	if o == nil {
		return nil
	}
	return o.IncludeDocID
}

func (o *OutputElasticCloud) GetResponseRetrySettings() []OutputElasticCloudResponseRetrySettings {
	if o == nil {
		return nil
	}
	return o.ResponseRetrySettings
}

func (o *OutputElasticCloud) GetTimeoutRetrySettings() *OutputElasticCloudTimeoutRetrySettings {
	if o == nil {
		return nil
	}
	return o.TimeoutRetrySettings
}

func (o *OutputElasticCloud) GetResponseHonorRetryAfterHeader() *bool {
	if o == nil {
		return nil
	}
	return o.ResponseHonorRetryAfterHeader
}

func (o *OutputElasticCloud) GetOnBackpressure() *OutputElasticCloudBackpressureBehavior {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputElasticCloud) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputElasticCloud) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputElasticCloud) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputElasticCloud) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputElasticCloud) GetPqCompress() *OutputElasticCloudCompression {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputElasticCloud) GetPqOnBackpressure() *OutputElasticCloudQueueFullBehavior {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputElasticCloud) GetPqMode() *OutputElasticCloudMode {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputElasticCloud) GetPqControls() *OutputElasticCloudPqControls {
	if o == nil {
		return nil
	}
	return o.PqControls
}

func (o *OutputElasticCloud) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type OutputElasticType string

const (
	OutputElasticTypeElastic OutputElasticType = "elastic"
)

func (e OutputElasticType) ToPointer() *OutputElasticType {
	return &e
}
func (e *OutputElasticType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "elastic":
		*e = OutputElasticType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputElasticType: %v", v)
	}
}

type OutputElasticExtraHTTPHeaders struct {
	// Field name
	Name *string `json:"name,omitempty"`
	// Field value
	Value string `json:"value"`
}

func (o *OutputElasticExtraHTTPHeaders) GetName() *string {
	if o == nil {
		return nil
	}
	return o.Name
}

func (o *OutputElasticExtraHTTPHeaders) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// OutputElasticFailedRequestLoggingMode - Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
type OutputElasticFailedRequestLoggingMode string

const (
	OutputElasticFailedRequestLoggingModePayload           OutputElasticFailedRequestLoggingMode = "payload"
	OutputElasticFailedRequestLoggingModePayloadAndHeaders OutputElasticFailedRequestLoggingMode = "payloadAndHeaders"
	OutputElasticFailedRequestLoggingModeNone              OutputElasticFailedRequestLoggingMode = "none"
)

func (e OutputElasticFailedRequestLoggingMode) ToPointer() *OutputElasticFailedRequestLoggingMode {
	return &e
}
func (e *OutputElasticFailedRequestLoggingMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "payload":
		fallthrough
	case "payloadAndHeaders":
		fallthrough
	case "none":
		*e = OutputElasticFailedRequestLoggingMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputElasticFailedRequestLoggingMode: %v", v)
	}
}

type OutputElasticResponseRetrySettings struct {
	// The HTTP response status code that will trigger retries
	HTTPStatus float64 `json:"httpStatus"`
	// How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"1000" json:"initialBackoff"`
	// Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackoff *float64 `default:"10000" json:"maxBackoff"`
}

func (o OutputElasticResponseRetrySettings) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputElasticResponseRetrySettings) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputElasticResponseRetrySettings) GetHTTPStatus() float64 {
	if o == nil {
		return 0.0
	}
	return o.HTTPStatus
}

func (o *OutputElasticResponseRetrySettings) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *OutputElasticResponseRetrySettings) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *OutputElasticResponseRetrySettings) GetMaxBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackoff
}

type OutputElasticTimeoutRetrySettings struct {
	// Enable to retry on request timeout
	TimeoutRetry *bool `default:"false" json:"timeoutRetry"`
	// How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"1000" json:"initialBackoff"`
	// Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackoff *float64 `default:"10000" json:"maxBackoff"`
}

func (o OutputElasticTimeoutRetrySettings) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputElasticTimeoutRetrySettings) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputElasticTimeoutRetrySettings) GetTimeoutRetry() *bool {
	if o == nil {
		return nil
	}
	return o.TimeoutRetry
}

func (o *OutputElasticTimeoutRetrySettings) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *OutputElasticTimeoutRetrySettings) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *OutputElasticTimeoutRetrySettings) GetMaxBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackoff
}

type ExtraParams struct {
	// Field name
	Name string `json:"name"`
	// Field value
	Value string `json:"value"`
}

func (o *ExtraParams) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *ExtraParams) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// OutputElasticAuthenticationMethod - Enter credentials directly, or select a stored secret
type OutputElasticAuthenticationMethod string

const (
	OutputElasticAuthenticationMethodManual       OutputElasticAuthenticationMethod = "manual"
	OutputElasticAuthenticationMethodSecret       OutputElasticAuthenticationMethod = "secret"
	OutputElasticAuthenticationMethodManualAPIKey OutputElasticAuthenticationMethod = "manualAPIKey"
	OutputElasticAuthenticationMethodTextSecret   OutputElasticAuthenticationMethod = "textSecret"
)

func (e OutputElasticAuthenticationMethod) ToPointer() *OutputElasticAuthenticationMethod {
	return &e
}
func (e *OutputElasticAuthenticationMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "manual":
		fallthrough
	case "secret":
		fallthrough
	case "manualAPIKey":
		fallthrough
	case "textSecret":
		*e = OutputElasticAuthenticationMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputElasticAuthenticationMethod: %v", v)
	}
}

type OutputElasticAuth struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Enter credentials directly, or select a stored secret
	AuthType *OutputElasticAuthenticationMethod `default:"manual" json:"authType"`
}

func (o OutputElasticAuth) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputElasticAuth) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputElasticAuth) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *OutputElasticAuth) GetAuthType() *OutputElasticAuthenticationMethod {
	if o == nil {
		return nil
	}
	return o.AuthType
}

// ElasticVersion - Optional Elasticsearch version, used to format events. If not specified, will auto-discover version.
type ElasticVersion string

const (
	ElasticVersionAuto  ElasticVersion = "auto"
	ElasticVersionSix   ElasticVersion = "6"
	ElasticVersionSeven ElasticVersion = "7"
)

func (e ElasticVersion) ToPointer() *ElasticVersion {
	return &e
}
func (e *ElasticVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "auto":
		fallthrough
	case "6":
		fallthrough
	case "7":
		*e = ElasticVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ElasticVersion: %v", v)
	}
}

// WriteAction - Action to use when writing events. Must be set to `Create` when writing to a data stream.
type WriteAction string

const (
	WriteActionIndex  WriteAction = "index"
	WriteActionCreate WriteAction = "create"
)

func (e WriteAction) ToPointer() *WriteAction {
	return &e
}
func (e *WriteAction) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "index":
		fallthrough
	case "create":
		*e = WriteAction(v)
		return nil
	default:
		return fmt.Errorf("invalid value for WriteAction: %v", v)
	}
}

// OutputElasticBackpressureBehavior - Whether to block, drop, or queue events when all receivers are exerting backpressure.
type OutputElasticBackpressureBehavior string

const (
	OutputElasticBackpressureBehaviorBlock OutputElasticBackpressureBehavior = "block"
	OutputElasticBackpressureBehaviorDrop  OutputElasticBackpressureBehavior = "drop"
	OutputElasticBackpressureBehaviorQueue OutputElasticBackpressureBehavior = "queue"
)

func (e OutputElasticBackpressureBehavior) ToPointer() *OutputElasticBackpressureBehavior {
	return &e
}
func (e *OutputElasticBackpressureBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		fallthrough
	case "queue":
		*e = OutputElasticBackpressureBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputElasticBackpressureBehavior: %v", v)
	}
}

type OutputElasticUrls struct {
	// The URL to an Elastic node to send events to. Example: http://elastic:9200/_bulk
	URL string `json:"url"`
	// Assign a weight (>0) to each endpoint to indicate its traffic-handling capability
	Weight *float64 `default:"1" json:"weight"`
}

func (o OutputElasticUrls) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputElasticUrls) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputElasticUrls) GetURL() string {
	if o == nil {
		return ""
	}
	return o.URL
}

func (o *OutputElasticUrls) GetWeight() *float64 {
	if o == nil {
		return nil
	}
	return o.Weight
}

// OutputElasticCompression - Codec to use to compress the persisted data.
type OutputElasticCompression string

const (
	OutputElasticCompressionNone OutputElasticCompression = "none"
	OutputElasticCompressionGzip OutputElasticCompression = "gzip"
)

func (e OutputElasticCompression) ToPointer() *OutputElasticCompression {
	return &e
}
func (e *OutputElasticCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = OutputElasticCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputElasticCompression: %v", v)
	}
}

// OutputElasticQueueFullBehavior - Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
type OutputElasticQueueFullBehavior string

const (
	OutputElasticQueueFullBehaviorBlock OutputElasticQueueFullBehavior = "block"
	OutputElasticQueueFullBehaviorDrop  OutputElasticQueueFullBehavior = "drop"
)

func (e OutputElasticQueueFullBehavior) ToPointer() *OutputElasticQueueFullBehavior {
	return &e
}
func (e *OutputElasticQueueFullBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputElasticQueueFullBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputElasticQueueFullBehavior: %v", v)
	}
}

// OutputElasticMode - In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
type OutputElasticMode string

const (
	OutputElasticModeError        OutputElasticMode = "error"
	OutputElasticModeBackpressure OutputElasticMode = "backpressure"
	OutputElasticModeAlways       OutputElasticMode = "always"
)

func (e OutputElasticMode) ToPointer() *OutputElasticMode {
	return &e
}
func (e *OutputElasticMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "error":
		fallthrough
	case "backpressure":
		fallthrough
	case "always":
		*e = OutputElasticMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputElasticMode: %v", v)
	}
}

type OutputElasticPqControls struct {
}

type OutputElastic struct {
	// Unique ID for this output
	ID   *string           `json:"id,omitempty"`
	Type OutputElasticType `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Enable for optimal performance. Even if you have one hostname, it can expand to multiple IPs. If disabled, consider enabling round-robin DNS.
	LoadBalanced *bool `default:"true" json:"loadBalanced"`
	// Index or data stream to send events to. Must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be overwritten by an event's __index field.
	Index string `json:"index"`
	// Document type to use for events. Can be overwritten by an event's __type field
	DocType *string `json:"docType,omitempty"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `default:"5" json:"concurrency"`
	// Maximum size, in KB, of the request body
	MaxPayloadSizeKB *float64 `default:"4096" json:"maxPayloadSizeKB"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited).
	MaxPayloadEvents *float64 `default:"0" json:"maxPayloadEvents"`
	// Compress the payload body before sending
	Compress *bool `default:"true" json:"compress"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Defaults to Yes. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `default:"30" json:"timeoutSec"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Max body size.
	FlushPeriodSec *float64 `default:"1" json:"flushPeriodSec"`
	// Headers to add to all events.
	ExtraHTTPHeaders []OutputElasticExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *OutputElasticFailedRequestLoggingMode `default:"none" json:"failedRequestLoggingMode"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable).
	ResponseRetrySettings []OutputElasticResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *OutputElasticTimeoutRetrySettings   `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `default:"false" json:"responseHonorRetryAfterHeader"`
	// Extra Parameters.
	ExtraParams []ExtraParams      `json:"extraParams,omitempty"`
	Auth        *OutputElasticAuth `json:"auth,omitempty"`
	// Optional Elasticsearch version, used to format events. If not specified, will auto-discover version.
	ElasticVersion *ElasticVersion `default:"auto" json:"elasticVersion"`
	// Optional Elasticsearch destination pipeline
	ElasticPipeline *string `json:"elasticPipeline,omitempty"`
	// Toggle this off when sending events to an Elastic TSDS (time series data stream) or to allow Elastic to generate document IDs
	IncludeDocID *bool `default:"false" json:"includeDocId"`
	// Action to use when writing events. Must be set to `Create` when writing to a data stream.
	WriteAction *WriteAction `default:"create" json:"writeAction"`
	// Retry failed events when a bulk request to Elastic is successful, but the response body returns an error for one or more events in the batch
	RetryPartialErrors *bool `default:"false" json:"retryPartialErrors"`
	// Whether to block, drop, or queue events when all receivers are exerting backpressure.
	OnBackpressure *OutputElasticBackpressureBehavior `default:"block" json:"onBackpressure"`
	Description    *string                            `json:"description,omitempty"`
	// The Cloud ID or URL to an Elastic cluster to send events to. Example: http://elastic:9200/_bulk
	URL *string `json:"url,omitempty"`
	// Enables round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `default:"false" json:"useRoundRobinDns"`
	// Exclude all IPs of the current host from the list of any resolved hostnames.
	ExcludeSelf *bool               `default:"false" json:"excludeSelf"`
	Urls        []OutputElasticUrls `json:"urls,omitempty"`
	// Re-resolve any hostnames every this many seconds and pick up destinations from A records.
	DNSResolvePeriodSec *float64 `default:"600" json:"dnsResolvePeriodSec"`
	// How far back in time to keep traffic stats for load balancing purposes.
	LoadBalanceStatsPeriodSec *float64 `default:"300" json:"loadBalanceStatsPeriodSec"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.).
	PqMaxFileSize *string `default:"1 MB" json:"pqMaxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `default:"5GB" json:"pqMaxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `default:"\\$CRIBL_HOME/state/queues" json:"pqPath"`
	// Codec to use to compress the persisted data.
	PqCompress *OutputElasticCompression `default:"none" json:"pqCompress"`
	// Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *OutputElasticQueueFullBehavior `default:"block" json:"pqOnBackpressure"`
	// In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
	PqMode     *OutputElasticMode       `default:"error" json:"pqMode"`
	PqControls *OutputElasticPqControls `json:"pqControls,omitempty"`
	Status     *TFStatus                `json:"status,omitempty"`
}

func (o OutputElastic) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputElastic) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *OutputElastic) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *OutputElastic) GetType() OutputElasticType {
	if o == nil {
		return OutputElasticType("")
	}
	return o.Type
}

func (o *OutputElastic) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputElastic) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputElastic) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputElastic) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputElastic) GetLoadBalanced() *bool {
	if o == nil {
		return nil
	}
	return o.LoadBalanced
}

func (o *OutputElastic) GetIndex() string {
	if o == nil {
		return ""
	}
	return o.Index
}

func (o *OutputElastic) GetDocType() *string {
	if o == nil {
		return nil
	}
	return o.DocType
}

func (o *OutputElastic) GetConcurrency() *float64 {
	if o == nil {
		return nil
	}
	return o.Concurrency
}

func (o *OutputElastic) GetMaxPayloadSizeKB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadSizeKB
}

func (o *OutputElastic) GetMaxPayloadEvents() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadEvents
}

func (o *OutputElastic) GetCompress() *bool {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *OutputElastic) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputElastic) GetTimeoutSec() *float64 {
	if o == nil {
		return nil
	}
	return o.TimeoutSec
}

func (o *OutputElastic) GetFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushPeriodSec
}

func (o *OutputElastic) GetExtraHTTPHeaders() []OutputElasticExtraHTTPHeaders {
	if o == nil {
		return nil
	}
	return o.ExtraHTTPHeaders
}

func (o *OutputElastic) GetFailedRequestLoggingMode() *OutputElasticFailedRequestLoggingMode {
	if o == nil {
		return nil
	}
	return o.FailedRequestLoggingMode
}

func (o *OutputElastic) GetSafeHeaders() []string {
	if o == nil {
		return nil
	}
	return o.SafeHeaders
}

func (o *OutputElastic) GetResponseRetrySettings() []OutputElasticResponseRetrySettings {
	if o == nil {
		return nil
	}
	return o.ResponseRetrySettings
}

func (o *OutputElastic) GetTimeoutRetrySettings() *OutputElasticTimeoutRetrySettings {
	if o == nil {
		return nil
	}
	return o.TimeoutRetrySettings
}

func (o *OutputElastic) GetResponseHonorRetryAfterHeader() *bool {
	if o == nil {
		return nil
	}
	return o.ResponseHonorRetryAfterHeader
}

func (o *OutputElastic) GetExtraParams() []ExtraParams {
	if o == nil {
		return nil
	}
	return o.ExtraParams
}

func (o *OutputElastic) GetAuth() *OutputElasticAuth {
	if o == nil {
		return nil
	}
	return o.Auth
}

func (o *OutputElastic) GetElasticVersion() *ElasticVersion {
	if o == nil {
		return nil
	}
	return o.ElasticVersion
}

func (o *OutputElastic) GetElasticPipeline() *string {
	if o == nil {
		return nil
	}
	return o.ElasticPipeline
}

func (o *OutputElastic) GetIncludeDocID() *bool {
	if o == nil {
		return nil
	}
	return o.IncludeDocID
}

func (o *OutputElastic) GetWriteAction() *WriteAction {
	if o == nil {
		return nil
	}
	return o.WriteAction
}

func (o *OutputElastic) GetRetryPartialErrors() *bool {
	if o == nil {
		return nil
	}
	return o.RetryPartialErrors
}

func (o *OutputElastic) GetOnBackpressure() *OutputElasticBackpressureBehavior {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputElastic) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputElastic) GetURL() *string {
	if o == nil {
		return nil
	}
	return o.URL
}

func (o *OutputElastic) GetUseRoundRobinDNS() *bool {
	if o == nil {
		return nil
	}
	return o.UseRoundRobinDNS
}

func (o *OutputElastic) GetExcludeSelf() *bool {
	if o == nil {
		return nil
	}
	return o.ExcludeSelf
}

func (o *OutputElastic) GetUrls() []OutputElasticUrls {
	if o == nil {
		return nil
	}
	return o.Urls
}

func (o *OutputElastic) GetDNSResolvePeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.DNSResolvePeriodSec
}

func (o *OutputElastic) GetLoadBalanceStatsPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.LoadBalanceStatsPeriodSec
}

func (o *OutputElastic) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputElastic) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputElastic) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputElastic) GetPqCompress() *OutputElasticCompression {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputElastic) GetPqOnBackpressure() *OutputElasticQueueFullBehavior {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputElastic) GetPqMode() *OutputElasticMode {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputElastic) GetPqControls() *OutputElasticPqControls {
	if o == nil {
		return nil
	}
	return o.PqControls
}

func (o *OutputElastic) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type OutputMskType string

const (
	OutputMskTypeMsk OutputMskType = "msk"
)

func (e OutputMskType) ToPointer() *OutputMskType {
	return &e
}
func (e *OutputMskType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "msk":
		*e = OutputMskType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputMskType: %v", v)
	}
}

// OutputMskAcknowledgments - Control the number of required acknowledgments.
type OutputMskAcknowledgments int64

const (
	OutputMskAcknowledgmentsOne    OutputMskAcknowledgments = 1
	OutputMskAcknowledgmentsZero   OutputMskAcknowledgments = 0
	OutputMskAcknowledgmentsMinus1 OutputMskAcknowledgments = -1
)

func (e OutputMskAcknowledgments) ToPointer() *OutputMskAcknowledgments {
	return &e
}
func (e *OutputMskAcknowledgments) UnmarshalJSON(data []byte) error {
	var v int64
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case 1:
		fallthrough
	case 0:
		fallthrough
	case -1:
		*e = OutputMskAcknowledgments(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputMskAcknowledgments: %v", v)
	}
}

// OutputMskRecordDataFormat - Format to use to serialize events before writing to Kafka.
type OutputMskRecordDataFormat string

const (
	OutputMskRecordDataFormatJSON     OutputMskRecordDataFormat = "json"
	OutputMskRecordDataFormatRaw      OutputMskRecordDataFormat = "raw"
	OutputMskRecordDataFormatProtobuf OutputMskRecordDataFormat = "protobuf"
)

func (e OutputMskRecordDataFormat) ToPointer() *OutputMskRecordDataFormat {
	return &e
}
func (e *OutputMskRecordDataFormat) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "json":
		fallthrough
	case "raw":
		fallthrough
	case "protobuf":
		*e = OutputMskRecordDataFormat(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputMskRecordDataFormat: %v", v)
	}
}

// OutputMskCompression - Codec to use to compress the data before sending to Kafka
type OutputMskCompression string

const (
	OutputMskCompressionNone   OutputMskCompression = "none"
	OutputMskCompressionGzip   OutputMskCompression = "gzip"
	OutputMskCompressionSnappy OutputMskCompression = "snappy"
	OutputMskCompressionLz4    OutputMskCompression = "lz4"
)

func (e OutputMskCompression) ToPointer() *OutputMskCompression {
	return &e
}
func (e *OutputMskCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		fallthrough
	case "snappy":
		fallthrough
	case "lz4":
		*e = OutputMskCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputMskCompression: %v", v)
	}
}

// OutputMskAuth - Credentials to use when authenticating with the schema registry using basic HTTP authentication
type OutputMskAuth struct {
	// Enable authentication
	Disabled *bool `default:"true" json:"disabled"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
}

func (o OutputMskAuth) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputMskAuth) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputMskAuth) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *OutputMskAuth) GetCredentialsSecret() *string {
	if o == nil {
		return nil
	}
	return o.CredentialsSecret
}

// OutputMskOutputMinimumTLSVersion - Minimum TLS version to use when connecting
type OutputMskOutputMinimumTLSVersion string

const (
	OutputMskOutputMinimumTLSVersionTlSv1  OutputMskOutputMinimumTLSVersion = "TLSv1"
	OutputMskOutputMinimumTLSVersionTlSv11 OutputMskOutputMinimumTLSVersion = "TLSv1.1"
	OutputMskOutputMinimumTLSVersionTlSv12 OutputMskOutputMinimumTLSVersion = "TLSv1.2"
	OutputMskOutputMinimumTLSVersionTlSv13 OutputMskOutputMinimumTLSVersion = "TLSv1.3"
)

func (e OutputMskOutputMinimumTLSVersion) ToPointer() *OutputMskOutputMinimumTLSVersion {
	return &e
}
func (e *OutputMskOutputMinimumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = OutputMskOutputMinimumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputMskOutputMinimumTLSVersion: %v", v)
	}
}

// OutputMskOutputMaximumTLSVersion - Maximum TLS version to use when connecting
type OutputMskOutputMaximumTLSVersion string

const (
	OutputMskOutputMaximumTLSVersionTlSv1  OutputMskOutputMaximumTLSVersion = "TLSv1"
	OutputMskOutputMaximumTLSVersionTlSv11 OutputMskOutputMaximumTLSVersion = "TLSv1.1"
	OutputMskOutputMaximumTLSVersionTlSv12 OutputMskOutputMaximumTLSVersion = "TLSv1.2"
	OutputMskOutputMaximumTLSVersionTlSv13 OutputMskOutputMaximumTLSVersion = "TLSv1.3"
)

func (e OutputMskOutputMaximumTLSVersion) ToPointer() *OutputMskOutputMaximumTLSVersion {
	return &e
}
func (e *OutputMskOutputMaximumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = OutputMskOutputMaximumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputMskOutputMaximumTLSVersion: %v", v)
	}
}

type OutputMskOutputTLSSettingsClientSide struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Reject certs that are not authorized by a CA in the CA certificate path, or by another
	//                     trusted CA (e.g., the system's CA). Defaults to Yes. Overrides the toggle from Advanced Settings, when also present.
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.
	Servername *string `json:"servername,omitempty"`
	// The name of the predefined certificate.
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Passphrase to use to decrypt private key.
	Passphrase *string `json:"passphrase,omitempty"`
	// Minimum TLS version to use when connecting
	MinVersion *OutputMskOutputMinimumTLSVersion `json:"minVersion,omitempty"`
	// Maximum TLS version to use when connecting
	MaxVersion *OutputMskOutputMaximumTLSVersion `json:"maxVersion,omitempty"`
}

func (o OutputMskOutputTLSSettingsClientSide) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputMskOutputTLSSettingsClientSide) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputMskOutputTLSSettingsClientSide) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *OutputMskOutputTLSSettingsClientSide) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputMskOutputTLSSettingsClientSide) GetServername() *string {
	if o == nil {
		return nil
	}
	return o.Servername
}

func (o *OutputMskOutputTLSSettingsClientSide) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *OutputMskOutputTLSSettingsClientSide) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *OutputMskOutputTLSSettingsClientSide) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *OutputMskOutputTLSSettingsClientSide) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *OutputMskOutputTLSSettingsClientSide) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *OutputMskOutputTLSSettingsClientSide) GetMinVersion() *OutputMskOutputMinimumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *OutputMskOutputTLSSettingsClientSide) GetMaxVersion() *OutputMskOutputMaximumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

type OutputMskKafkaSchemaRegistryAuthentication struct {
	// Enable Schema Registry
	Disabled *bool `default:"true" json:"disabled"`
	// URL for accessing the Confluent Schema Registry. Example: http://localhost:8081. To connect over TLS, use https instead of http.
	SchemaRegistryURL *string `default:"http://localhost:8081" json:"schemaRegistryURL"`
	// Maximum time to wait for a Schema Registry connection to complete successfully
	ConnectionTimeout *float64 `default:"30000" json:"connectionTimeout"`
	// Maximum time to wait for the Schema Registry to respond to a request
	RequestTimeout *float64 `default:"30000" json:"requestTimeout"`
	// Maximum number of times to try fetching schemas from the Schema Registry
	MaxRetries *float64 `default:"1" json:"maxRetries"`
	// Credentials to use when authenticating with the schema registry using basic HTTP authentication
	Auth *OutputMskAuth                        `json:"auth,omitempty"`
	TLS  *OutputMskOutputTLSSettingsClientSide `json:"tls,omitempty"`
	// Used when __keySchemaIdOut is not present, to transform key values, leave blank if key transformation is not required by default.
	DefaultKeySchemaID *float64 `json:"defaultKeySchemaId,omitempty"`
	// Used when __valueSchemaIdOut is not present, to transform _raw, leave blank if value transformation is not required by default.
	DefaultValueSchemaID *float64 `json:"defaultValueSchemaId,omitempty"`
}

func (o OutputMskKafkaSchemaRegistryAuthentication) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputMskKafkaSchemaRegistryAuthentication) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputMskKafkaSchemaRegistryAuthentication) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *OutputMskKafkaSchemaRegistryAuthentication) GetSchemaRegistryURL() *string {
	if o == nil {
		return nil
	}
	return o.SchemaRegistryURL
}

func (o *OutputMskKafkaSchemaRegistryAuthentication) GetConnectionTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.ConnectionTimeout
}

func (o *OutputMskKafkaSchemaRegistryAuthentication) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *OutputMskKafkaSchemaRegistryAuthentication) GetMaxRetries() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxRetries
}

func (o *OutputMskKafkaSchemaRegistryAuthentication) GetAuth() *OutputMskAuth {
	if o == nil {
		return nil
	}
	return o.Auth
}

func (o *OutputMskKafkaSchemaRegistryAuthentication) GetTLS() *OutputMskOutputTLSSettingsClientSide {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *OutputMskKafkaSchemaRegistryAuthentication) GetDefaultKeySchemaID() *float64 {
	if o == nil {
		return nil
	}
	return o.DefaultKeySchemaID
}

func (o *OutputMskKafkaSchemaRegistryAuthentication) GetDefaultValueSchemaID() *float64 {
	if o == nil {
		return nil
	}
	return o.DefaultValueSchemaID
}

// OutputMskAuthenticationMethod - AWS authentication method. Choose Auto to use IAM roles.
type OutputMskAuthenticationMethod string

const (
	OutputMskAuthenticationMethodAuto   OutputMskAuthenticationMethod = "auto"
	OutputMskAuthenticationMethodManual OutputMskAuthenticationMethod = "manual"
	OutputMskAuthenticationMethodSecret OutputMskAuthenticationMethod = "secret"
)

func (e OutputMskAuthenticationMethod) ToPointer() *OutputMskAuthenticationMethod {
	return &e
}
func (e *OutputMskAuthenticationMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "auto":
		fallthrough
	case "manual":
		fallthrough
	case "secret":
		*e = OutputMskAuthenticationMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputMskAuthenticationMethod: %v", v)
	}
}

// OutputMskSignatureVersion - Signature version to use for signing MSK cluster requests
type OutputMskSignatureVersion string

const (
	OutputMskSignatureVersionV2 OutputMskSignatureVersion = "v2"
	OutputMskSignatureVersionV4 OutputMskSignatureVersion = "v4"
)

func (e OutputMskSignatureVersion) ToPointer() *OutputMskSignatureVersion {
	return &e
}
func (e *OutputMskSignatureVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "v2":
		fallthrough
	case "v4":
		*e = OutputMskSignatureVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputMskSignatureVersion: %v", v)
	}
}

// OutputMskMinimumTLSVersion - Minimum TLS version to use when connecting
type OutputMskMinimumTLSVersion string

const (
	OutputMskMinimumTLSVersionTlSv1  OutputMskMinimumTLSVersion = "TLSv1"
	OutputMskMinimumTLSVersionTlSv11 OutputMskMinimumTLSVersion = "TLSv1.1"
	OutputMskMinimumTLSVersionTlSv12 OutputMskMinimumTLSVersion = "TLSv1.2"
	OutputMskMinimumTLSVersionTlSv13 OutputMskMinimumTLSVersion = "TLSv1.3"
)

func (e OutputMskMinimumTLSVersion) ToPointer() *OutputMskMinimumTLSVersion {
	return &e
}
func (e *OutputMskMinimumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = OutputMskMinimumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputMskMinimumTLSVersion: %v", v)
	}
}

// OutputMskMaximumTLSVersion - Maximum TLS version to use when connecting
type OutputMskMaximumTLSVersion string

const (
	OutputMskMaximumTLSVersionTlSv1  OutputMskMaximumTLSVersion = "TLSv1"
	OutputMskMaximumTLSVersionTlSv11 OutputMskMaximumTLSVersion = "TLSv1.1"
	OutputMskMaximumTLSVersionTlSv12 OutputMskMaximumTLSVersion = "TLSv1.2"
	OutputMskMaximumTLSVersionTlSv13 OutputMskMaximumTLSVersion = "TLSv1.3"
)

func (e OutputMskMaximumTLSVersion) ToPointer() *OutputMskMaximumTLSVersion {
	return &e
}
func (e *OutputMskMaximumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = OutputMskMaximumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputMskMaximumTLSVersion: %v", v)
	}
}

type OutputMskTLSSettingsClientSide struct {
	Disabled *bool `default:"false" json:"disabled"`
	// Reject certs that are not authorized by a CA in the CA certificate path, or by another
	//                     trusted CA (e.g., the system's CA). Defaults to Yes. Overrides the toggle from Advanced Settings, when also present.
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.
	Servername *string `json:"servername,omitempty"`
	// The name of the predefined certificate.
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Passphrase to use to decrypt private key.
	Passphrase *string `json:"passphrase,omitempty"`
	// Minimum TLS version to use when connecting
	MinVersion *OutputMskMinimumTLSVersion `json:"minVersion,omitempty"`
	// Maximum TLS version to use when connecting
	MaxVersion *OutputMskMaximumTLSVersion `json:"maxVersion,omitempty"`
}

func (o OutputMskTLSSettingsClientSide) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputMskTLSSettingsClientSide) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputMskTLSSettingsClientSide) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *OutputMskTLSSettingsClientSide) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputMskTLSSettingsClientSide) GetServername() *string {
	if o == nil {
		return nil
	}
	return o.Servername
}

func (o *OutputMskTLSSettingsClientSide) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *OutputMskTLSSettingsClientSide) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *OutputMskTLSSettingsClientSide) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *OutputMskTLSSettingsClientSide) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *OutputMskTLSSettingsClientSide) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *OutputMskTLSSettingsClientSide) GetMinVersion() *OutputMskMinimumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *OutputMskTLSSettingsClientSide) GetMaxVersion() *OutputMskMaximumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

// OutputMskBackpressureBehavior - Whether to block, drop, or queue events when all receivers are exerting backpressure.
type OutputMskBackpressureBehavior string

const (
	OutputMskBackpressureBehaviorBlock OutputMskBackpressureBehavior = "block"
	OutputMskBackpressureBehaviorDrop  OutputMskBackpressureBehavior = "drop"
	OutputMskBackpressureBehaviorQueue OutputMskBackpressureBehavior = "queue"
)

func (e OutputMskBackpressureBehavior) ToPointer() *OutputMskBackpressureBehavior {
	return &e
}
func (e *OutputMskBackpressureBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		fallthrough
	case "queue":
		*e = OutputMskBackpressureBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputMskBackpressureBehavior: %v", v)
	}
}

// OutputMskOutputCompression - Codec to use to compress the persisted data.
type OutputMskOutputCompression string

const (
	OutputMskOutputCompressionNone OutputMskOutputCompression = "none"
	OutputMskOutputCompressionGzip OutputMskOutputCompression = "gzip"
)

func (e OutputMskOutputCompression) ToPointer() *OutputMskOutputCompression {
	return &e
}
func (e *OutputMskOutputCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = OutputMskOutputCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputMskOutputCompression: %v", v)
	}
}

// OutputMskQueueFullBehavior - Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
type OutputMskQueueFullBehavior string

const (
	OutputMskQueueFullBehaviorBlock OutputMskQueueFullBehavior = "block"
	OutputMskQueueFullBehaviorDrop  OutputMskQueueFullBehavior = "drop"
)

func (e OutputMskQueueFullBehavior) ToPointer() *OutputMskQueueFullBehavior {
	return &e
}
func (e *OutputMskQueueFullBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputMskQueueFullBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputMskQueueFullBehavior: %v", v)
	}
}

// OutputMskMode - In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
type OutputMskMode string

const (
	OutputMskModeError        OutputMskMode = "error"
	OutputMskModeBackpressure OutputMskMode = "backpressure"
	OutputMskModeAlways       OutputMskMode = "always"
)

func (e OutputMskMode) ToPointer() *OutputMskMode {
	return &e
}
func (e *OutputMskMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "error":
		fallthrough
	case "backpressure":
		fallthrough
	case "always":
		*e = OutputMskMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputMskMode: %v", v)
	}
}

type OutputMskPqControls struct {
}

type OutputMsk struct {
	// Unique ID for this output
	ID   *string        `json:"id,omitempty"`
	Type *OutputMskType `json:"type,omitempty"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Enter each Kafka bootstrap server you want to use. Specify hostname and port, e.g., mykafkabroker:9092, or just hostname, in which case @{product} will assign port 9092.
	Brokers []string `json:"brokers"`
	// The topic to publish events to. Can be overridden using the __topicOut field.
	Topic string `json:"topic"`
	// Control the number of required acknowledgments.
	Ack *OutputMskAcknowledgments `default:"1" json:"ack"`
	// Format to use to serialize events before writing to Kafka.
	Format *OutputMskRecordDataFormat `default:"json" json:"format"`
	// Codec to use to compress the data before sending to Kafka
	Compression *OutputMskCompression `default:"gzip" json:"compression"`
	// Maximum size of each record batch before compression. The value must not exceed the Kafka brokers' message.max.bytes setting.
	MaxRecordSizeKB *float64 `default:"768" json:"maxRecordSizeKB"`
	// The maximum number of events you want the Destination to allow in a batch before forcing a flush
	FlushEventCount *float64 `default:"1000" json:"flushEventCount"`
	// The maximum amount of time you want the Destination to wait before forcing a flush. Shorter intervals tend to result in smaller batches being sent.
	FlushPeriodSec      *float64                                    `default:"1" json:"flushPeriodSec"`
	KafkaSchemaRegistry *OutputMskKafkaSchemaRegistryAuthentication `json:"kafkaSchemaRegistry,omitempty"`
	// Maximum time to wait for a connection to complete successfully
	ConnectionTimeout *float64 `default:"10000" json:"connectionTimeout"`
	// Maximum time to wait for Kafka to respond to a request
	RequestTimeout *float64 `default:"60000" json:"requestTimeout"`
	// If messages are failing, you can set the maximum number of retries as high as 100 to prevent loss of data
	MaxRetries *float64 `default:"5" json:"maxRetries"`
	// The maximum wait time for a retry, in milliseconds. Default (and minimum) is 30,000 ms (30 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackOff *float64 `default:"30000" json:"maxBackOff"`
	// Initial value used to calculate the retry, in milliseconds. Maximum is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"300" json:"initialBackoff"`
	// Set the backoff multiplier (2-20) to control the retry frequency for failed messages. For faster retries, use a lower multiplier. For slower retries with more delay between attempts, use a higher multiplier. The multiplier is used in an exponential backoff formula; see the Kafka [documentation](https://kafka.js.org/docs/retry-detailed) for details.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// Maximum time to wait for Kafka to respond to an authentication request
	AuthenticationTimeout *float64 `default:"10000" json:"authenticationTimeout"`
	// Specifies a time window during which @{product} can reauthenticate if needed. Creates the window measuring backwards from the moment when credentials are set to expire.
	ReauthenticationThreshold *float64 `default:"10000" json:"reauthenticationThreshold"`
	// AWS authentication method. Choose Auto to use IAM roles.
	AwsAuthenticationMethod *OutputMskAuthenticationMethod `default:"auto" json:"awsAuthenticationMethod"`
	AwsSecretKey            *string                        `json:"awsSecretKey,omitempty"`
	// Region where the MSK cluster is located
	Region string `json:"region"`
	// MSK cluster service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to MSK cluster-compatible endpoint.
	Endpoint *string `json:"endpoint,omitempty"`
	// Signature version to use for signing MSK cluster requests
	SignatureVersion *OutputMskSignatureVersion `default:"v4" json:"signatureVersion"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `default:"true" json:"reuseConnections"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Use Assume Role credentials to access MSK
	EnableAssumeRole *bool `default:"false" json:"enableAssumeRole"`
	// Amazon Resource Name (ARN) of the role to assume
	AssumeRoleArn *string `json:"assumeRoleArn,omitempty"`
	// External ID to use when assuming role
	AssumeRoleExternalID *string `json:"assumeRoleExternalId,omitempty"`
	// Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
	DurationSeconds *float64                        `default:"3600" json:"durationSeconds"`
	TLS             *OutputMskTLSSettingsClientSide `json:"tls,omitempty"`
	// Whether to block, drop, or queue events when all receivers are exerting backpressure.
	OnBackpressure *OutputMskBackpressureBehavior `default:"block" json:"onBackpressure"`
	Description    *string                        `json:"description,omitempty"`
	AwsAPIKey      *string                        `json:"awsApiKey,omitempty"`
	// Select or create a stored secret that references your access key and secret key
	AwsSecret *string `json:"awsSecret,omitempty"`
	// Select a set of Protobuf definitions for the events you want to send
	ProtobufLibraryID *string `json:"protobufLibraryId,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.).
	PqMaxFileSize *string `default:"1 MB" json:"pqMaxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `default:"5GB" json:"pqMaxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `default:"\\$CRIBL_HOME/state/queues" json:"pqPath"`
	// Codec to use to compress the persisted data.
	PqCompress *OutputMskOutputCompression `default:"none" json:"pqCompress"`
	// Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *OutputMskQueueFullBehavior `default:"block" json:"pqOnBackpressure"`
	// In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
	PqMode     *OutputMskMode       `default:"error" json:"pqMode"`
	PqControls *OutputMskPqControls `json:"pqControls,omitempty"`
	Status     *TFStatus            `json:"status,omitempty"`
}

func (o OutputMsk) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputMsk) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *OutputMsk) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *OutputMsk) GetType() *OutputMskType {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *OutputMsk) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputMsk) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputMsk) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputMsk) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputMsk) GetBrokers() []string {
	if o == nil {
		return []string{}
	}
	return o.Brokers
}

func (o *OutputMsk) GetTopic() string {
	if o == nil {
		return ""
	}
	return o.Topic
}

func (o *OutputMsk) GetAck() *OutputMskAcknowledgments {
	if o == nil {
		return nil
	}
	return o.Ack
}

func (o *OutputMsk) GetFormat() *OutputMskRecordDataFormat {
	if o == nil {
		return nil
	}
	return o.Format
}

func (o *OutputMsk) GetCompression() *OutputMskCompression {
	if o == nil {
		return nil
	}
	return o.Compression
}

func (o *OutputMsk) GetMaxRecordSizeKB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxRecordSizeKB
}

func (o *OutputMsk) GetFlushEventCount() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushEventCount
}

func (o *OutputMsk) GetFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushPeriodSec
}

func (o *OutputMsk) GetKafkaSchemaRegistry() *OutputMskKafkaSchemaRegistryAuthentication {
	if o == nil {
		return nil
	}
	return o.KafkaSchemaRegistry
}

func (o *OutputMsk) GetConnectionTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.ConnectionTimeout
}

func (o *OutputMsk) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *OutputMsk) GetMaxRetries() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxRetries
}

func (o *OutputMsk) GetMaxBackOff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackOff
}

func (o *OutputMsk) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *OutputMsk) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *OutputMsk) GetAuthenticationTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.AuthenticationTimeout
}

func (o *OutputMsk) GetReauthenticationThreshold() *float64 {
	if o == nil {
		return nil
	}
	return o.ReauthenticationThreshold
}

func (o *OutputMsk) GetAwsAuthenticationMethod() *OutputMskAuthenticationMethod {
	if o == nil {
		return nil
	}
	return o.AwsAuthenticationMethod
}

func (o *OutputMsk) GetAwsSecretKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecretKey
}

func (o *OutputMsk) GetRegion() string {
	if o == nil {
		return ""
	}
	return o.Region
}

func (o *OutputMsk) GetEndpoint() *string {
	if o == nil {
		return nil
	}
	return o.Endpoint
}

func (o *OutputMsk) GetSignatureVersion() *OutputMskSignatureVersion {
	if o == nil {
		return nil
	}
	return o.SignatureVersion
}

func (o *OutputMsk) GetReuseConnections() *bool {
	if o == nil {
		return nil
	}
	return o.ReuseConnections
}

func (o *OutputMsk) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputMsk) GetEnableAssumeRole() *bool {
	if o == nil {
		return nil
	}
	return o.EnableAssumeRole
}

func (o *OutputMsk) GetAssumeRoleArn() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleArn
}

func (o *OutputMsk) GetAssumeRoleExternalID() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleExternalID
}

func (o *OutputMsk) GetDurationSeconds() *float64 {
	if o == nil {
		return nil
	}
	return o.DurationSeconds
}

func (o *OutputMsk) GetTLS() *OutputMskTLSSettingsClientSide {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *OutputMsk) GetOnBackpressure() *OutputMskBackpressureBehavior {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputMsk) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputMsk) GetAwsAPIKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsAPIKey
}

func (o *OutputMsk) GetAwsSecret() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecret
}

func (o *OutputMsk) GetProtobufLibraryID() *string {
	if o == nil {
		return nil
	}
	return o.ProtobufLibraryID
}

func (o *OutputMsk) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputMsk) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputMsk) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputMsk) GetPqCompress() *OutputMskOutputCompression {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputMsk) GetPqOnBackpressure() *OutputMskQueueFullBehavior {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputMsk) GetPqMode() *OutputMskMode {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputMsk) GetPqControls() *OutputMskPqControls {
	if o == nil {
		return nil
	}
	return o.PqControls
}

func (o *OutputMsk) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type OutputConfluentCloudType string

const (
	OutputConfluentCloudTypeConfluentCloud OutputConfluentCloudType = "confluent_cloud"
)

func (e OutputConfluentCloudType) ToPointer() *OutputConfluentCloudType {
	return &e
}
func (e *OutputConfluentCloudType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "confluent_cloud":
		*e = OutputConfluentCloudType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputConfluentCloudType: %v", v)
	}
}

// OutputConfluentCloudMinimumTLSVersion - Minimum TLS version to use when connecting
type OutputConfluentCloudMinimumTLSVersion string

const (
	OutputConfluentCloudMinimumTLSVersionTlSv1  OutputConfluentCloudMinimumTLSVersion = "TLSv1"
	OutputConfluentCloudMinimumTLSVersionTlSv11 OutputConfluentCloudMinimumTLSVersion = "TLSv1.1"
	OutputConfluentCloudMinimumTLSVersionTlSv12 OutputConfluentCloudMinimumTLSVersion = "TLSv1.2"
	OutputConfluentCloudMinimumTLSVersionTlSv13 OutputConfluentCloudMinimumTLSVersion = "TLSv1.3"
)

func (e OutputConfluentCloudMinimumTLSVersion) ToPointer() *OutputConfluentCloudMinimumTLSVersion {
	return &e
}
func (e *OutputConfluentCloudMinimumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = OutputConfluentCloudMinimumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputConfluentCloudMinimumTLSVersion: %v", v)
	}
}

// OutputConfluentCloudMaximumTLSVersion - Maximum TLS version to use when connecting
type OutputConfluentCloudMaximumTLSVersion string

const (
	OutputConfluentCloudMaximumTLSVersionTlSv1  OutputConfluentCloudMaximumTLSVersion = "TLSv1"
	OutputConfluentCloudMaximumTLSVersionTlSv11 OutputConfluentCloudMaximumTLSVersion = "TLSv1.1"
	OutputConfluentCloudMaximumTLSVersionTlSv12 OutputConfluentCloudMaximumTLSVersion = "TLSv1.2"
	OutputConfluentCloudMaximumTLSVersionTlSv13 OutputConfluentCloudMaximumTLSVersion = "TLSv1.3"
)

func (e OutputConfluentCloudMaximumTLSVersion) ToPointer() *OutputConfluentCloudMaximumTLSVersion {
	return &e
}
func (e *OutputConfluentCloudMaximumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = OutputConfluentCloudMaximumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputConfluentCloudMaximumTLSVersion: %v", v)
	}
}

type OutputConfluentCloudTLSSettingsClientSide struct {
	Disabled *bool `default:"false" json:"disabled"`
	// Reject certs that are not authorized by a CA in the CA certificate path, or by another
	//                     trusted CA (e.g., the system's CA). Defaults to Yes. Overrides the toggle from Advanced Settings, when also present.
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.
	Servername *string `json:"servername,omitempty"`
	// The name of the predefined certificate.
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Passphrase to use to decrypt private key.
	Passphrase *string `json:"passphrase,omitempty"`
	// Minimum TLS version to use when connecting
	MinVersion *OutputConfluentCloudMinimumTLSVersion `json:"minVersion,omitempty"`
	// Maximum TLS version to use when connecting
	MaxVersion *OutputConfluentCloudMaximumTLSVersion `json:"maxVersion,omitempty"`
}

func (o OutputConfluentCloudTLSSettingsClientSide) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputConfluentCloudTLSSettingsClientSide) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputConfluentCloudTLSSettingsClientSide) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *OutputConfluentCloudTLSSettingsClientSide) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputConfluentCloudTLSSettingsClientSide) GetServername() *string {
	if o == nil {
		return nil
	}
	return o.Servername
}

func (o *OutputConfluentCloudTLSSettingsClientSide) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *OutputConfluentCloudTLSSettingsClientSide) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *OutputConfluentCloudTLSSettingsClientSide) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *OutputConfluentCloudTLSSettingsClientSide) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *OutputConfluentCloudTLSSettingsClientSide) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *OutputConfluentCloudTLSSettingsClientSide) GetMinVersion() *OutputConfluentCloudMinimumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *OutputConfluentCloudTLSSettingsClientSide) GetMaxVersion() *OutputConfluentCloudMaximumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

// OutputConfluentCloudAcknowledgments - Control the number of required acknowledgments.
type OutputConfluentCloudAcknowledgments int64

const (
	OutputConfluentCloudAcknowledgmentsOne    OutputConfluentCloudAcknowledgments = 1
	OutputConfluentCloudAcknowledgmentsZero   OutputConfluentCloudAcknowledgments = 0
	OutputConfluentCloudAcknowledgmentsMinus1 OutputConfluentCloudAcknowledgments = -1
)

func (e OutputConfluentCloudAcknowledgments) ToPointer() *OutputConfluentCloudAcknowledgments {
	return &e
}
func (e *OutputConfluentCloudAcknowledgments) UnmarshalJSON(data []byte) error {
	var v int64
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case 1:
		fallthrough
	case 0:
		fallthrough
	case -1:
		*e = OutputConfluentCloudAcknowledgments(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputConfluentCloudAcknowledgments: %v", v)
	}
}

// OutputConfluentCloudRecordDataFormat - Format to use to serialize events before writing to Kafka.
type OutputConfluentCloudRecordDataFormat string

const (
	OutputConfluentCloudRecordDataFormatJSON     OutputConfluentCloudRecordDataFormat = "json"
	OutputConfluentCloudRecordDataFormatRaw      OutputConfluentCloudRecordDataFormat = "raw"
	OutputConfluentCloudRecordDataFormatProtobuf OutputConfluentCloudRecordDataFormat = "protobuf"
)

func (e OutputConfluentCloudRecordDataFormat) ToPointer() *OutputConfluentCloudRecordDataFormat {
	return &e
}
func (e *OutputConfluentCloudRecordDataFormat) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "json":
		fallthrough
	case "raw":
		fallthrough
	case "protobuf":
		*e = OutputConfluentCloudRecordDataFormat(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputConfluentCloudRecordDataFormat: %v", v)
	}
}

// OutputConfluentCloudCompression - Codec to use to compress the data before sending to Kafka
type OutputConfluentCloudCompression string

const (
	OutputConfluentCloudCompressionNone   OutputConfluentCloudCompression = "none"
	OutputConfluentCloudCompressionGzip   OutputConfluentCloudCompression = "gzip"
	OutputConfluentCloudCompressionSnappy OutputConfluentCloudCompression = "snappy"
	OutputConfluentCloudCompressionLz4    OutputConfluentCloudCompression = "lz4"
)

func (e OutputConfluentCloudCompression) ToPointer() *OutputConfluentCloudCompression {
	return &e
}
func (e *OutputConfluentCloudCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		fallthrough
	case "snappy":
		fallthrough
	case "lz4":
		*e = OutputConfluentCloudCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputConfluentCloudCompression: %v", v)
	}
}

// OutputConfluentCloudAuth - Credentials to use when authenticating with the schema registry using basic HTTP authentication
type OutputConfluentCloudAuth struct {
	// Enable authentication
	Disabled *bool `default:"true" json:"disabled"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
}

func (o OutputConfluentCloudAuth) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputConfluentCloudAuth) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputConfluentCloudAuth) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *OutputConfluentCloudAuth) GetCredentialsSecret() *string {
	if o == nil {
		return nil
	}
	return o.CredentialsSecret
}

// OutputConfluentCloudOutputMinimumTLSVersion - Minimum TLS version to use when connecting
type OutputConfluentCloudOutputMinimumTLSVersion string

const (
	OutputConfluentCloudOutputMinimumTLSVersionTlSv1  OutputConfluentCloudOutputMinimumTLSVersion = "TLSv1"
	OutputConfluentCloudOutputMinimumTLSVersionTlSv11 OutputConfluentCloudOutputMinimumTLSVersion = "TLSv1.1"
	OutputConfluentCloudOutputMinimumTLSVersionTlSv12 OutputConfluentCloudOutputMinimumTLSVersion = "TLSv1.2"
	OutputConfluentCloudOutputMinimumTLSVersionTlSv13 OutputConfluentCloudOutputMinimumTLSVersion = "TLSv1.3"
)

func (e OutputConfluentCloudOutputMinimumTLSVersion) ToPointer() *OutputConfluentCloudOutputMinimumTLSVersion {
	return &e
}
func (e *OutputConfluentCloudOutputMinimumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = OutputConfluentCloudOutputMinimumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputConfluentCloudOutputMinimumTLSVersion: %v", v)
	}
}

// OutputConfluentCloudOutputMaximumTLSVersion - Maximum TLS version to use when connecting
type OutputConfluentCloudOutputMaximumTLSVersion string

const (
	OutputConfluentCloudOutputMaximumTLSVersionTlSv1  OutputConfluentCloudOutputMaximumTLSVersion = "TLSv1"
	OutputConfluentCloudOutputMaximumTLSVersionTlSv11 OutputConfluentCloudOutputMaximumTLSVersion = "TLSv1.1"
	OutputConfluentCloudOutputMaximumTLSVersionTlSv12 OutputConfluentCloudOutputMaximumTLSVersion = "TLSv1.2"
	OutputConfluentCloudOutputMaximumTLSVersionTlSv13 OutputConfluentCloudOutputMaximumTLSVersion = "TLSv1.3"
)

func (e OutputConfluentCloudOutputMaximumTLSVersion) ToPointer() *OutputConfluentCloudOutputMaximumTLSVersion {
	return &e
}
func (e *OutputConfluentCloudOutputMaximumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = OutputConfluentCloudOutputMaximumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputConfluentCloudOutputMaximumTLSVersion: %v", v)
	}
}

type OutputConfluentCloudOutputTLSSettingsClientSide struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Reject certs that are not authorized by a CA in the CA certificate path, or by another
	//                     trusted CA (e.g., the system's CA). Defaults to Yes. Overrides the toggle from Advanced Settings, when also present.
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.
	Servername *string `json:"servername,omitempty"`
	// The name of the predefined certificate.
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Passphrase to use to decrypt private key.
	Passphrase *string `json:"passphrase,omitempty"`
	// Minimum TLS version to use when connecting
	MinVersion *OutputConfluentCloudOutputMinimumTLSVersion `json:"minVersion,omitempty"`
	// Maximum TLS version to use when connecting
	MaxVersion *OutputConfluentCloudOutputMaximumTLSVersion `json:"maxVersion,omitempty"`
}

func (o OutputConfluentCloudOutputTLSSettingsClientSide) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputConfluentCloudOutputTLSSettingsClientSide) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputConfluentCloudOutputTLSSettingsClientSide) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *OutputConfluentCloudOutputTLSSettingsClientSide) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputConfluentCloudOutputTLSSettingsClientSide) GetServername() *string {
	if o == nil {
		return nil
	}
	return o.Servername
}

func (o *OutputConfluentCloudOutputTLSSettingsClientSide) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *OutputConfluentCloudOutputTLSSettingsClientSide) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *OutputConfluentCloudOutputTLSSettingsClientSide) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *OutputConfluentCloudOutputTLSSettingsClientSide) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *OutputConfluentCloudOutputTLSSettingsClientSide) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *OutputConfluentCloudOutputTLSSettingsClientSide) GetMinVersion() *OutputConfluentCloudOutputMinimumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *OutputConfluentCloudOutputTLSSettingsClientSide) GetMaxVersion() *OutputConfluentCloudOutputMaximumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

type OutputConfluentCloudKafkaSchemaRegistryAuthentication struct {
	// Enable Schema Registry
	Disabled *bool `default:"true" json:"disabled"`
	// URL for accessing the Confluent Schema Registry. Example: http://localhost:8081. To connect over TLS, use https instead of http.
	SchemaRegistryURL *string `default:"http://localhost:8081" json:"schemaRegistryURL"`
	// Maximum time to wait for a Schema Registry connection to complete successfully
	ConnectionTimeout *float64 `default:"30000" json:"connectionTimeout"`
	// Maximum time to wait for the Schema Registry to respond to a request
	RequestTimeout *float64 `default:"30000" json:"requestTimeout"`
	// Maximum number of times to try fetching schemas from the Schema Registry
	MaxRetries *float64 `default:"1" json:"maxRetries"`
	// Credentials to use when authenticating with the schema registry using basic HTTP authentication
	Auth *OutputConfluentCloudAuth                        `json:"auth,omitempty"`
	TLS  *OutputConfluentCloudOutputTLSSettingsClientSide `json:"tls,omitempty"`
	// Used when __keySchemaIdOut is not present, to transform key values, leave blank if key transformation is not required by default.
	DefaultKeySchemaID *float64 `json:"defaultKeySchemaId,omitempty"`
	// Used when __valueSchemaIdOut is not present, to transform _raw, leave blank if value transformation is not required by default.
	DefaultValueSchemaID *float64 `json:"defaultValueSchemaId,omitempty"`
}

func (o OutputConfluentCloudKafkaSchemaRegistryAuthentication) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputConfluentCloudKafkaSchemaRegistryAuthentication) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputConfluentCloudKafkaSchemaRegistryAuthentication) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *OutputConfluentCloudKafkaSchemaRegistryAuthentication) GetSchemaRegistryURL() *string {
	if o == nil {
		return nil
	}
	return o.SchemaRegistryURL
}

func (o *OutputConfluentCloudKafkaSchemaRegistryAuthentication) GetConnectionTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.ConnectionTimeout
}

func (o *OutputConfluentCloudKafkaSchemaRegistryAuthentication) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *OutputConfluentCloudKafkaSchemaRegistryAuthentication) GetMaxRetries() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxRetries
}

func (o *OutputConfluentCloudKafkaSchemaRegistryAuthentication) GetAuth() *OutputConfluentCloudAuth {
	if o == nil {
		return nil
	}
	return o.Auth
}

func (o *OutputConfluentCloudKafkaSchemaRegistryAuthentication) GetTLS() *OutputConfluentCloudOutputTLSSettingsClientSide {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *OutputConfluentCloudKafkaSchemaRegistryAuthentication) GetDefaultKeySchemaID() *float64 {
	if o == nil {
		return nil
	}
	return o.DefaultKeySchemaID
}

func (o *OutputConfluentCloudKafkaSchemaRegistryAuthentication) GetDefaultValueSchemaID() *float64 {
	if o == nil {
		return nil
	}
	return o.DefaultValueSchemaID
}

// OutputConfluentCloudSASLMechanism - SASL authentication mechanism to use.
type OutputConfluentCloudSASLMechanism string

const (
	OutputConfluentCloudSASLMechanismPlain       OutputConfluentCloudSASLMechanism = "plain"
	OutputConfluentCloudSASLMechanismScramSha256 OutputConfluentCloudSASLMechanism = "scram-sha-256"
	OutputConfluentCloudSASLMechanismScramSha512 OutputConfluentCloudSASLMechanism = "scram-sha-512"
	OutputConfluentCloudSASLMechanismKerberos    OutputConfluentCloudSASLMechanism = "kerberos"
)

func (e OutputConfluentCloudSASLMechanism) ToPointer() *OutputConfluentCloudSASLMechanism {
	return &e
}
func (e *OutputConfluentCloudSASLMechanism) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "plain":
		fallthrough
	case "scram-sha-256":
		fallthrough
	case "scram-sha-512":
		fallthrough
	case "kerberos":
		*e = OutputConfluentCloudSASLMechanism(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputConfluentCloudSASLMechanism: %v", v)
	}
}

// OutputConfluentCloudAuthentication - Authentication parameters to use when connecting to brokers. Using TLS is highly recommended.
type OutputConfluentCloudAuthentication struct {
	// Enable Authentication
	Disabled *bool `default:"true" json:"disabled"`
	// SASL authentication mechanism to use.
	Mechanism *OutputConfluentCloudSASLMechanism `default:"plain" json:"mechanism"`
}

func (o OutputConfluentCloudAuthentication) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputConfluentCloudAuthentication) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputConfluentCloudAuthentication) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *OutputConfluentCloudAuthentication) GetMechanism() *OutputConfluentCloudSASLMechanism {
	if o == nil {
		return nil
	}
	return o.Mechanism
}

// OutputConfluentCloudBackpressureBehavior - Whether to block, drop, or queue events when all receivers are exerting backpressure.
type OutputConfluentCloudBackpressureBehavior string

const (
	OutputConfluentCloudBackpressureBehaviorBlock OutputConfluentCloudBackpressureBehavior = "block"
	OutputConfluentCloudBackpressureBehaviorDrop  OutputConfluentCloudBackpressureBehavior = "drop"
	OutputConfluentCloudBackpressureBehaviorQueue OutputConfluentCloudBackpressureBehavior = "queue"
)

func (e OutputConfluentCloudBackpressureBehavior) ToPointer() *OutputConfluentCloudBackpressureBehavior {
	return &e
}
func (e *OutputConfluentCloudBackpressureBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		fallthrough
	case "queue":
		*e = OutputConfluentCloudBackpressureBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputConfluentCloudBackpressureBehavior: %v", v)
	}
}

// OutputConfluentCloudOutputCompression - Codec to use to compress the persisted data.
type OutputConfluentCloudOutputCompression string

const (
	OutputConfluentCloudOutputCompressionNone OutputConfluentCloudOutputCompression = "none"
	OutputConfluentCloudOutputCompressionGzip OutputConfluentCloudOutputCompression = "gzip"
)

func (e OutputConfluentCloudOutputCompression) ToPointer() *OutputConfluentCloudOutputCompression {
	return &e
}
func (e *OutputConfluentCloudOutputCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = OutputConfluentCloudOutputCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputConfluentCloudOutputCompression: %v", v)
	}
}

// OutputConfluentCloudQueueFullBehavior - Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
type OutputConfluentCloudQueueFullBehavior string

const (
	OutputConfluentCloudQueueFullBehaviorBlock OutputConfluentCloudQueueFullBehavior = "block"
	OutputConfluentCloudQueueFullBehaviorDrop  OutputConfluentCloudQueueFullBehavior = "drop"
)

func (e OutputConfluentCloudQueueFullBehavior) ToPointer() *OutputConfluentCloudQueueFullBehavior {
	return &e
}
func (e *OutputConfluentCloudQueueFullBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputConfluentCloudQueueFullBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputConfluentCloudQueueFullBehavior: %v", v)
	}
}

// OutputConfluentCloudMode - In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
type OutputConfluentCloudMode string

const (
	OutputConfluentCloudModeError        OutputConfluentCloudMode = "error"
	OutputConfluentCloudModeBackpressure OutputConfluentCloudMode = "backpressure"
	OutputConfluentCloudModeAlways       OutputConfluentCloudMode = "always"
)

func (e OutputConfluentCloudMode) ToPointer() *OutputConfluentCloudMode {
	return &e
}
func (e *OutputConfluentCloudMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "error":
		fallthrough
	case "backpressure":
		fallthrough
	case "always":
		*e = OutputConfluentCloudMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputConfluentCloudMode: %v", v)
	}
}

type OutputConfluentCloudPqControls struct {
}

type OutputConfluentCloud struct {
	// Unique ID for this output
	ID   *string                   `json:"id,omitempty"`
	Type *OutputConfluentCloudType `json:"type,omitempty"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// List of Confluent Cloud bootstrap servers to use, such as yourAccount.confluent.cloud:9092.
	Brokers []string                                   `json:"brokers"`
	TLS     *OutputConfluentCloudTLSSettingsClientSide `json:"tls,omitempty"`
	// The topic to publish events to. Can be overridden using the __topicOut field.
	Topic string `json:"topic"`
	// Control the number of required acknowledgments.
	Ack *OutputConfluentCloudAcknowledgments `default:"1" json:"ack"`
	// Format to use to serialize events before writing to Kafka.
	Format *OutputConfluentCloudRecordDataFormat `default:"json" json:"format"`
	// Codec to use to compress the data before sending to Kafka
	Compression *OutputConfluentCloudCompression `default:"gzip" json:"compression"`
	// Maximum size of each record batch before compression. The value must not exceed the Kafka brokers' message.max.bytes setting.
	MaxRecordSizeKB *float64 `default:"768" json:"maxRecordSizeKB"`
	// The maximum number of events you want the Destination to allow in a batch before forcing a flush
	FlushEventCount *float64 `default:"1000" json:"flushEventCount"`
	// The maximum amount of time you want the Destination to wait before forcing a flush. Shorter intervals tend to result in smaller batches being sent.
	FlushPeriodSec      *float64                                               `default:"1" json:"flushPeriodSec"`
	KafkaSchemaRegistry *OutputConfluentCloudKafkaSchemaRegistryAuthentication `json:"kafkaSchemaRegistry,omitempty"`
	// Maximum time to wait for a connection to complete successfully
	ConnectionTimeout *float64 `default:"10000" json:"connectionTimeout"`
	// Maximum time to wait for Kafka to respond to a request
	RequestTimeout *float64 `default:"60000" json:"requestTimeout"`
	// If messages are failing, you can set the maximum number of retries as high as 100 to prevent loss of data
	MaxRetries *float64 `default:"5" json:"maxRetries"`
	// The maximum wait time for a retry, in milliseconds. Default (and minimum) is 30,000 ms (30 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackOff *float64 `default:"30000" json:"maxBackOff"`
	// Initial value used to calculate the retry, in milliseconds. Maximum is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"300" json:"initialBackoff"`
	// Set the backoff multiplier (2-20) to control the retry frequency for failed messages. For faster retries, use a lower multiplier. For slower retries with more delay between attempts, use a higher multiplier. The multiplier is used in an exponential backoff formula; see the Kafka [documentation](https://kafka.js.org/docs/retry-detailed) for details.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// Maximum time to wait for Kafka to respond to an authentication request
	AuthenticationTimeout *float64 `default:"10000" json:"authenticationTimeout"`
	// Specifies a time window during which @{product} can reauthenticate if needed. Creates the window measuring backwards from the moment when credentials are set to expire.
	ReauthenticationThreshold *float64 `default:"10000" json:"reauthenticationThreshold"`
	// Authentication parameters to use when connecting to brokers. Using TLS is highly recommended.
	Sasl *OutputConfluentCloudAuthentication `json:"sasl,omitempty"`
	// Whether to block, drop, or queue events when all receivers are exerting backpressure.
	OnBackpressure *OutputConfluentCloudBackpressureBehavior `default:"block" json:"onBackpressure"`
	Description    *string                                   `json:"description,omitempty"`
	// Select a set of Protobuf definitions for the events you want to send
	ProtobufLibraryID *string `json:"protobufLibraryId,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.).
	PqMaxFileSize *string `default:"1 MB" json:"pqMaxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `default:"5GB" json:"pqMaxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `default:"\\$CRIBL_HOME/state/queues" json:"pqPath"`
	// Codec to use to compress the persisted data.
	PqCompress *OutputConfluentCloudOutputCompression `default:"none" json:"pqCompress"`
	// Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *OutputConfluentCloudQueueFullBehavior `default:"block" json:"pqOnBackpressure"`
	// In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
	PqMode     *OutputConfluentCloudMode       `default:"error" json:"pqMode"`
	PqControls *OutputConfluentCloudPqControls `json:"pqControls,omitempty"`
	Status     *TFStatus                       `json:"status,omitempty"`
}

func (o OutputConfluentCloud) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputConfluentCloud) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *OutputConfluentCloud) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *OutputConfluentCloud) GetType() *OutputConfluentCloudType {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *OutputConfluentCloud) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputConfluentCloud) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputConfluentCloud) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputConfluentCloud) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputConfluentCloud) GetBrokers() []string {
	if o == nil {
		return []string{}
	}
	return o.Brokers
}

func (o *OutputConfluentCloud) GetTLS() *OutputConfluentCloudTLSSettingsClientSide {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *OutputConfluentCloud) GetTopic() string {
	if o == nil {
		return ""
	}
	return o.Topic
}

func (o *OutputConfluentCloud) GetAck() *OutputConfluentCloudAcknowledgments {
	if o == nil {
		return nil
	}
	return o.Ack
}

func (o *OutputConfluentCloud) GetFormat() *OutputConfluentCloudRecordDataFormat {
	if o == nil {
		return nil
	}
	return o.Format
}

func (o *OutputConfluentCloud) GetCompression() *OutputConfluentCloudCompression {
	if o == nil {
		return nil
	}
	return o.Compression
}

func (o *OutputConfluentCloud) GetMaxRecordSizeKB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxRecordSizeKB
}

func (o *OutputConfluentCloud) GetFlushEventCount() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushEventCount
}

func (o *OutputConfluentCloud) GetFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushPeriodSec
}

func (o *OutputConfluentCloud) GetKafkaSchemaRegistry() *OutputConfluentCloudKafkaSchemaRegistryAuthentication {
	if o == nil {
		return nil
	}
	return o.KafkaSchemaRegistry
}

func (o *OutputConfluentCloud) GetConnectionTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.ConnectionTimeout
}

func (o *OutputConfluentCloud) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *OutputConfluentCloud) GetMaxRetries() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxRetries
}

func (o *OutputConfluentCloud) GetMaxBackOff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackOff
}

func (o *OutputConfluentCloud) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *OutputConfluentCloud) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *OutputConfluentCloud) GetAuthenticationTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.AuthenticationTimeout
}

func (o *OutputConfluentCloud) GetReauthenticationThreshold() *float64 {
	if o == nil {
		return nil
	}
	return o.ReauthenticationThreshold
}

func (o *OutputConfluentCloud) GetSasl() *OutputConfluentCloudAuthentication {
	if o == nil {
		return nil
	}
	return o.Sasl
}

func (o *OutputConfluentCloud) GetOnBackpressure() *OutputConfluentCloudBackpressureBehavior {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputConfluentCloud) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputConfluentCloud) GetProtobufLibraryID() *string {
	if o == nil {
		return nil
	}
	return o.ProtobufLibraryID
}

func (o *OutputConfluentCloud) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputConfluentCloud) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputConfluentCloud) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputConfluentCloud) GetPqCompress() *OutputConfluentCloudOutputCompression {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputConfluentCloud) GetPqOnBackpressure() *OutputConfluentCloudQueueFullBehavior {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputConfluentCloud) GetPqMode() *OutputConfluentCloudMode {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputConfluentCloud) GetPqControls() *OutputConfluentCloudPqControls {
	if o == nil {
		return nil
	}
	return o.PqControls
}

func (o *OutputConfluentCloud) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type OutputKafkaType string

const (
	OutputKafkaTypeKafka OutputKafkaType = "kafka"
)

func (e OutputKafkaType) ToPointer() *OutputKafkaType {
	return &e
}
func (e *OutputKafkaType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "kafka":
		*e = OutputKafkaType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputKafkaType: %v", v)
	}
}

// OutputKafkaAcknowledgments - Control the number of required acknowledgments.
type OutputKafkaAcknowledgments int64

const (
	OutputKafkaAcknowledgmentsOne    OutputKafkaAcknowledgments = 1
	OutputKafkaAcknowledgmentsZero   OutputKafkaAcknowledgments = 0
	OutputKafkaAcknowledgmentsMinus1 OutputKafkaAcknowledgments = -1
)

func (e OutputKafkaAcknowledgments) ToPointer() *OutputKafkaAcknowledgments {
	return &e
}
func (e *OutputKafkaAcknowledgments) UnmarshalJSON(data []byte) error {
	var v int64
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case 1:
		fallthrough
	case 0:
		fallthrough
	case -1:
		*e = OutputKafkaAcknowledgments(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputKafkaAcknowledgments: %v", v)
	}
}

// OutputKafkaRecordDataFormat - Format to use to serialize events before writing to Kafka.
type OutputKafkaRecordDataFormat string

const (
	OutputKafkaRecordDataFormatJSON     OutputKafkaRecordDataFormat = "json"
	OutputKafkaRecordDataFormatRaw      OutputKafkaRecordDataFormat = "raw"
	OutputKafkaRecordDataFormatProtobuf OutputKafkaRecordDataFormat = "protobuf"
)

func (e OutputKafkaRecordDataFormat) ToPointer() *OutputKafkaRecordDataFormat {
	return &e
}
func (e *OutputKafkaRecordDataFormat) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "json":
		fallthrough
	case "raw":
		fallthrough
	case "protobuf":
		*e = OutputKafkaRecordDataFormat(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputKafkaRecordDataFormat: %v", v)
	}
}

// OutputKafkaCompression - Codec to use to compress the data before sending to Kafka
type OutputKafkaCompression string

const (
	OutputKafkaCompressionNone   OutputKafkaCompression = "none"
	OutputKafkaCompressionGzip   OutputKafkaCompression = "gzip"
	OutputKafkaCompressionSnappy OutputKafkaCompression = "snappy"
	OutputKafkaCompressionLz4    OutputKafkaCompression = "lz4"
)

func (e OutputKafkaCompression) ToPointer() *OutputKafkaCompression {
	return &e
}
func (e *OutputKafkaCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		fallthrough
	case "snappy":
		fallthrough
	case "lz4":
		*e = OutputKafkaCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputKafkaCompression: %v", v)
	}
}

// OutputKafkaAuth - Credentials to use when authenticating with the schema registry using basic HTTP authentication
type OutputKafkaAuth struct {
	// Enable authentication
	Disabled *bool `default:"true" json:"disabled"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
}

func (o OutputKafkaAuth) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputKafkaAuth) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputKafkaAuth) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *OutputKafkaAuth) GetCredentialsSecret() *string {
	if o == nil {
		return nil
	}
	return o.CredentialsSecret
}

// OutputKafkaOutputMinimumTLSVersion - Minimum TLS version to use when connecting
type OutputKafkaOutputMinimumTLSVersion string

const (
	OutputKafkaOutputMinimumTLSVersionTlSv1  OutputKafkaOutputMinimumTLSVersion = "TLSv1"
	OutputKafkaOutputMinimumTLSVersionTlSv11 OutputKafkaOutputMinimumTLSVersion = "TLSv1.1"
	OutputKafkaOutputMinimumTLSVersionTlSv12 OutputKafkaOutputMinimumTLSVersion = "TLSv1.2"
	OutputKafkaOutputMinimumTLSVersionTlSv13 OutputKafkaOutputMinimumTLSVersion = "TLSv1.3"
)

func (e OutputKafkaOutputMinimumTLSVersion) ToPointer() *OutputKafkaOutputMinimumTLSVersion {
	return &e
}
func (e *OutputKafkaOutputMinimumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = OutputKafkaOutputMinimumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputKafkaOutputMinimumTLSVersion: %v", v)
	}
}

// OutputKafkaOutputMaximumTLSVersion - Maximum TLS version to use when connecting
type OutputKafkaOutputMaximumTLSVersion string

const (
	OutputKafkaOutputMaximumTLSVersionTlSv1  OutputKafkaOutputMaximumTLSVersion = "TLSv1"
	OutputKafkaOutputMaximumTLSVersionTlSv11 OutputKafkaOutputMaximumTLSVersion = "TLSv1.1"
	OutputKafkaOutputMaximumTLSVersionTlSv12 OutputKafkaOutputMaximumTLSVersion = "TLSv1.2"
	OutputKafkaOutputMaximumTLSVersionTlSv13 OutputKafkaOutputMaximumTLSVersion = "TLSv1.3"
)

func (e OutputKafkaOutputMaximumTLSVersion) ToPointer() *OutputKafkaOutputMaximumTLSVersion {
	return &e
}
func (e *OutputKafkaOutputMaximumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = OutputKafkaOutputMaximumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputKafkaOutputMaximumTLSVersion: %v", v)
	}
}

type OutputKafkaOutputTLSSettingsClientSide struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Reject certs that are not authorized by a CA in the CA certificate path, or by another
	//                     trusted CA (e.g., the system's CA). Defaults to Yes. Overrides the toggle from Advanced Settings, when also present.
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.
	Servername *string `json:"servername,omitempty"`
	// The name of the predefined certificate.
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Passphrase to use to decrypt private key.
	Passphrase *string `json:"passphrase,omitempty"`
	// Minimum TLS version to use when connecting
	MinVersion *OutputKafkaOutputMinimumTLSVersion `json:"minVersion,omitempty"`
	// Maximum TLS version to use when connecting
	MaxVersion *OutputKafkaOutputMaximumTLSVersion `json:"maxVersion,omitempty"`
}

func (o OutputKafkaOutputTLSSettingsClientSide) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputKafkaOutputTLSSettingsClientSide) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputKafkaOutputTLSSettingsClientSide) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *OutputKafkaOutputTLSSettingsClientSide) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputKafkaOutputTLSSettingsClientSide) GetServername() *string {
	if o == nil {
		return nil
	}
	return o.Servername
}

func (o *OutputKafkaOutputTLSSettingsClientSide) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *OutputKafkaOutputTLSSettingsClientSide) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *OutputKafkaOutputTLSSettingsClientSide) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *OutputKafkaOutputTLSSettingsClientSide) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *OutputKafkaOutputTLSSettingsClientSide) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *OutputKafkaOutputTLSSettingsClientSide) GetMinVersion() *OutputKafkaOutputMinimumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *OutputKafkaOutputTLSSettingsClientSide) GetMaxVersion() *OutputKafkaOutputMaximumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

type OutputKafkaKafkaSchemaRegistryAuthentication struct {
	// Enable Schema Registry
	Disabled *bool `default:"true" json:"disabled"`
	// URL for accessing the Confluent Schema Registry. Example: http://localhost:8081. To connect over TLS, use https instead of http.
	SchemaRegistryURL *string `default:"http://localhost:8081" json:"schemaRegistryURL"`
	// Maximum time to wait for a Schema Registry connection to complete successfully
	ConnectionTimeout *float64 `default:"30000" json:"connectionTimeout"`
	// Maximum time to wait for the Schema Registry to respond to a request
	RequestTimeout *float64 `default:"30000" json:"requestTimeout"`
	// Maximum number of times to try fetching schemas from the Schema Registry
	MaxRetries *float64 `default:"1" json:"maxRetries"`
	// Credentials to use when authenticating with the schema registry using basic HTTP authentication
	Auth *OutputKafkaAuth                        `json:"auth,omitempty"`
	TLS  *OutputKafkaOutputTLSSettingsClientSide `json:"tls,omitempty"`
	// Used when __keySchemaIdOut is not present, to transform key values, leave blank if key transformation is not required by default.
	DefaultKeySchemaID *float64 `json:"defaultKeySchemaId,omitempty"`
	// Used when __valueSchemaIdOut is not present, to transform _raw, leave blank if value transformation is not required by default.
	DefaultValueSchemaID *float64 `json:"defaultValueSchemaId,omitempty"`
}

func (o OutputKafkaKafkaSchemaRegistryAuthentication) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputKafkaKafkaSchemaRegistryAuthentication) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputKafkaKafkaSchemaRegistryAuthentication) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *OutputKafkaKafkaSchemaRegistryAuthentication) GetSchemaRegistryURL() *string {
	if o == nil {
		return nil
	}
	return o.SchemaRegistryURL
}

func (o *OutputKafkaKafkaSchemaRegistryAuthentication) GetConnectionTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.ConnectionTimeout
}

func (o *OutputKafkaKafkaSchemaRegistryAuthentication) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *OutputKafkaKafkaSchemaRegistryAuthentication) GetMaxRetries() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxRetries
}

func (o *OutputKafkaKafkaSchemaRegistryAuthentication) GetAuth() *OutputKafkaAuth {
	if o == nil {
		return nil
	}
	return o.Auth
}

func (o *OutputKafkaKafkaSchemaRegistryAuthentication) GetTLS() *OutputKafkaOutputTLSSettingsClientSide {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *OutputKafkaKafkaSchemaRegistryAuthentication) GetDefaultKeySchemaID() *float64 {
	if o == nil {
		return nil
	}
	return o.DefaultKeySchemaID
}

func (o *OutputKafkaKafkaSchemaRegistryAuthentication) GetDefaultValueSchemaID() *float64 {
	if o == nil {
		return nil
	}
	return o.DefaultValueSchemaID
}

// OutputKafkaSASLMechanism - SASL authentication mechanism to use.
type OutputKafkaSASLMechanism string

const (
	OutputKafkaSASLMechanismPlain       OutputKafkaSASLMechanism = "plain"
	OutputKafkaSASLMechanismScramSha256 OutputKafkaSASLMechanism = "scram-sha-256"
	OutputKafkaSASLMechanismScramSha512 OutputKafkaSASLMechanism = "scram-sha-512"
	OutputKafkaSASLMechanismKerberos    OutputKafkaSASLMechanism = "kerberos"
)

func (e OutputKafkaSASLMechanism) ToPointer() *OutputKafkaSASLMechanism {
	return &e
}
func (e *OutputKafkaSASLMechanism) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "plain":
		fallthrough
	case "scram-sha-256":
		fallthrough
	case "scram-sha-512":
		fallthrough
	case "kerberos":
		*e = OutputKafkaSASLMechanism(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputKafkaSASLMechanism: %v", v)
	}
}

// OutputKafkaAuthentication - Authentication parameters to use when connecting to brokers. Using TLS is highly recommended.
type OutputKafkaAuthentication struct {
	// Enable Authentication
	Disabled *bool `default:"true" json:"disabled"`
	// SASL authentication mechanism to use.
	Mechanism *OutputKafkaSASLMechanism `default:"plain" json:"mechanism"`
}

func (o OutputKafkaAuthentication) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputKafkaAuthentication) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputKafkaAuthentication) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *OutputKafkaAuthentication) GetMechanism() *OutputKafkaSASLMechanism {
	if o == nil {
		return nil
	}
	return o.Mechanism
}

// OutputKafkaMinimumTLSVersion - Minimum TLS version to use when connecting
type OutputKafkaMinimumTLSVersion string

const (
	OutputKafkaMinimumTLSVersionTlSv1  OutputKafkaMinimumTLSVersion = "TLSv1"
	OutputKafkaMinimumTLSVersionTlSv11 OutputKafkaMinimumTLSVersion = "TLSv1.1"
	OutputKafkaMinimumTLSVersionTlSv12 OutputKafkaMinimumTLSVersion = "TLSv1.2"
	OutputKafkaMinimumTLSVersionTlSv13 OutputKafkaMinimumTLSVersion = "TLSv1.3"
)

func (e OutputKafkaMinimumTLSVersion) ToPointer() *OutputKafkaMinimumTLSVersion {
	return &e
}
func (e *OutputKafkaMinimumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = OutputKafkaMinimumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputKafkaMinimumTLSVersion: %v", v)
	}
}

// OutputKafkaMaximumTLSVersion - Maximum TLS version to use when connecting
type OutputKafkaMaximumTLSVersion string

const (
	OutputKafkaMaximumTLSVersionTlSv1  OutputKafkaMaximumTLSVersion = "TLSv1"
	OutputKafkaMaximumTLSVersionTlSv11 OutputKafkaMaximumTLSVersion = "TLSv1.1"
	OutputKafkaMaximumTLSVersionTlSv12 OutputKafkaMaximumTLSVersion = "TLSv1.2"
	OutputKafkaMaximumTLSVersionTlSv13 OutputKafkaMaximumTLSVersion = "TLSv1.3"
)

func (e OutputKafkaMaximumTLSVersion) ToPointer() *OutputKafkaMaximumTLSVersion {
	return &e
}
func (e *OutputKafkaMaximumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = OutputKafkaMaximumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputKafkaMaximumTLSVersion: %v", v)
	}
}

type OutputKafkaTLSSettingsClientSide struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Reject certs that are not authorized by a CA in the CA certificate path, or by another
	//                     trusted CA (e.g., the system's CA). Defaults to Yes. Overrides the toggle from Advanced Settings, when also present.
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.
	Servername *string `json:"servername,omitempty"`
	// The name of the predefined certificate.
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Passphrase to use to decrypt private key.
	Passphrase *string `json:"passphrase,omitempty"`
	// Minimum TLS version to use when connecting
	MinVersion *OutputKafkaMinimumTLSVersion `json:"minVersion,omitempty"`
	// Maximum TLS version to use when connecting
	MaxVersion *OutputKafkaMaximumTLSVersion `json:"maxVersion,omitempty"`
}

func (o OutputKafkaTLSSettingsClientSide) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputKafkaTLSSettingsClientSide) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputKafkaTLSSettingsClientSide) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *OutputKafkaTLSSettingsClientSide) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputKafkaTLSSettingsClientSide) GetServername() *string {
	if o == nil {
		return nil
	}
	return o.Servername
}

func (o *OutputKafkaTLSSettingsClientSide) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *OutputKafkaTLSSettingsClientSide) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *OutputKafkaTLSSettingsClientSide) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *OutputKafkaTLSSettingsClientSide) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *OutputKafkaTLSSettingsClientSide) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *OutputKafkaTLSSettingsClientSide) GetMinVersion() *OutputKafkaMinimumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *OutputKafkaTLSSettingsClientSide) GetMaxVersion() *OutputKafkaMaximumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

// OutputKafkaBackpressureBehavior - Whether to block, drop, or queue events when all receivers are exerting backpressure.
type OutputKafkaBackpressureBehavior string

const (
	OutputKafkaBackpressureBehaviorBlock OutputKafkaBackpressureBehavior = "block"
	OutputKafkaBackpressureBehaviorDrop  OutputKafkaBackpressureBehavior = "drop"
	OutputKafkaBackpressureBehaviorQueue OutputKafkaBackpressureBehavior = "queue"
)

func (e OutputKafkaBackpressureBehavior) ToPointer() *OutputKafkaBackpressureBehavior {
	return &e
}
func (e *OutputKafkaBackpressureBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		fallthrough
	case "queue":
		*e = OutputKafkaBackpressureBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputKafkaBackpressureBehavior: %v", v)
	}
}

// OutputKafkaOutputCompression - Codec to use to compress the persisted data.
type OutputKafkaOutputCompression string

const (
	OutputKafkaOutputCompressionNone OutputKafkaOutputCompression = "none"
	OutputKafkaOutputCompressionGzip OutputKafkaOutputCompression = "gzip"
)

func (e OutputKafkaOutputCompression) ToPointer() *OutputKafkaOutputCompression {
	return &e
}
func (e *OutputKafkaOutputCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = OutputKafkaOutputCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputKafkaOutputCompression: %v", v)
	}
}

// OutputKafkaQueueFullBehavior - Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
type OutputKafkaQueueFullBehavior string

const (
	OutputKafkaQueueFullBehaviorBlock OutputKafkaQueueFullBehavior = "block"
	OutputKafkaQueueFullBehaviorDrop  OutputKafkaQueueFullBehavior = "drop"
)

func (e OutputKafkaQueueFullBehavior) ToPointer() *OutputKafkaQueueFullBehavior {
	return &e
}
func (e *OutputKafkaQueueFullBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputKafkaQueueFullBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputKafkaQueueFullBehavior: %v", v)
	}
}

// OutputKafkaMode - In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
type OutputKafkaMode string

const (
	OutputKafkaModeError        OutputKafkaMode = "error"
	OutputKafkaModeBackpressure OutputKafkaMode = "backpressure"
	OutputKafkaModeAlways       OutputKafkaMode = "always"
)

func (e OutputKafkaMode) ToPointer() *OutputKafkaMode {
	return &e
}
func (e *OutputKafkaMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "error":
		fallthrough
	case "backpressure":
		fallthrough
	case "always":
		*e = OutputKafkaMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputKafkaMode: %v", v)
	}
}

type OutputKafkaPqControls struct {
}

type OutputKafka struct {
	// Unique ID for this output
	ID   *string          `json:"id,omitempty"`
	Type *OutputKafkaType `json:"type,omitempty"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Enter each Kafka bootstrap server you want to use. Specify hostname and port, e.g., mykafkabroker:9092, or just hostname, in which case @{product} will assign port 9092.
	Brokers []string `json:"brokers"`
	// The topic to publish events to. Can be overridden using the __topicOut field.
	Topic string `json:"topic"`
	// Control the number of required acknowledgments.
	Ack *OutputKafkaAcknowledgments `default:"1" json:"ack"`
	// Format to use to serialize events before writing to Kafka.
	Format *OutputKafkaRecordDataFormat `default:"json" json:"format"`
	// Codec to use to compress the data before sending to Kafka
	Compression *OutputKafkaCompression `default:"gzip" json:"compression"`
	// Maximum size of each record batch before compression. The value must not exceed the Kafka brokers' message.max.bytes setting.
	MaxRecordSizeKB *float64 `default:"768" json:"maxRecordSizeKB"`
	// The maximum number of events you want the Destination to allow in a batch before forcing a flush
	FlushEventCount *float64 `default:"1000" json:"flushEventCount"`
	// The maximum amount of time you want the Destination to wait before forcing a flush. Shorter intervals tend to result in smaller batches being sent.
	FlushPeriodSec      *float64                                      `default:"1" json:"flushPeriodSec"`
	KafkaSchemaRegistry *OutputKafkaKafkaSchemaRegistryAuthentication `json:"kafkaSchemaRegistry,omitempty"`
	// Maximum time to wait for a connection to complete successfully
	ConnectionTimeout *float64 `default:"10000" json:"connectionTimeout"`
	// Maximum time to wait for Kafka to respond to a request
	RequestTimeout *float64 `default:"60000" json:"requestTimeout"`
	// If messages are failing, you can set the maximum number of retries as high as 100 to prevent loss of data
	MaxRetries *float64 `default:"5" json:"maxRetries"`
	// The maximum wait time for a retry, in milliseconds. Default (and minimum) is 30,000 ms (30 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackOff *float64 `default:"30000" json:"maxBackOff"`
	// Initial value used to calculate the retry, in milliseconds. Maximum is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"300" json:"initialBackoff"`
	// Set the backoff multiplier (2-20) to control the retry frequency for failed messages. For faster retries, use a lower multiplier. For slower retries with more delay between attempts, use a higher multiplier. The multiplier is used in an exponential backoff formula; see the Kafka [documentation](https://kafka.js.org/docs/retry-detailed) for details.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// Maximum time to wait for Kafka to respond to an authentication request
	AuthenticationTimeout *float64 `default:"10000" json:"authenticationTimeout"`
	// Specifies a time window during which @{product} can reauthenticate if needed. Creates the window measuring backwards from the moment when credentials are set to expire.
	ReauthenticationThreshold *float64 `default:"10000" json:"reauthenticationThreshold"`
	// Authentication parameters to use when connecting to brokers. Using TLS is highly recommended.
	Sasl *OutputKafkaAuthentication        `json:"sasl,omitempty"`
	TLS  *OutputKafkaTLSSettingsClientSide `json:"tls,omitempty"`
	// Whether to block, drop, or queue events when all receivers are exerting backpressure.
	OnBackpressure *OutputKafkaBackpressureBehavior `default:"block" json:"onBackpressure"`
	Description    *string                          `json:"description,omitempty"`
	// Select a set of Protobuf definitions for the events you want to send
	ProtobufLibraryID *string `json:"protobufLibraryId,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.).
	PqMaxFileSize *string `default:"1 MB" json:"pqMaxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `default:"5GB" json:"pqMaxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `default:"\\$CRIBL_HOME/state/queues" json:"pqPath"`
	// Codec to use to compress the persisted data.
	PqCompress *OutputKafkaOutputCompression `default:"none" json:"pqCompress"`
	// Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *OutputKafkaQueueFullBehavior `default:"block" json:"pqOnBackpressure"`
	// In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
	PqMode     *OutputKafkaMode       `default:"error" json:"pqMode"`
	PqControls *OutputKafkaPqControls `json:"pqControls,omitempty"`
	Status     *TFStatus              `json:"status,omitempty"`
}

func (o OutputKafka) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputKafka) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *OutputKafka) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *OutputKafka) GetType() *OutputKafkaType {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *OutputKafka) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputKafka) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputKafka) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputKafka) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputKafka) GetBrokers() []string {
	if o == nil {
		return []string{}
	}
	return o.Brokers
}

func (o *OutputKafka) GetTopic() string {
	if o == nil {
		return ""
	}
	return o.Topic
}

func (o *OutputKafka) GetAck() *OutputKafkaAcknowledgments {
	if o == nil {
		return nil
	}
	return o.Ack
}

func (o *OutputKafka) GetFormat() *OutputKafkaRecordDataFormat {
	if o == nil {
		return nil
	}
	return o.Format
}

func (o *OutputKafka) GetCompression() *OutputKafkaCompression {
	if o == nil {
		return nil
	}
	return o.Compression
}

func (o *OutputKafka) GetMaxRecordSizeKB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxRecordSizeKB
}

func (o *OutputKafka) GetFlushEventCount() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushEventCount
}

func (o *OutputKafka) GetFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushPeriodSec
}

func (o *OutputKafka) GetKafkaSchemaRegistry() *OutputKafkaKafkaSchemaRegistryAuthentication {
	if o == nil {
		return nil
	}
	return o.KafkaSchemaRegistry
}

func (o *OutputKafka) GetConnectionTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.ConnectionTimeout
}

func (o *OutputKafka) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *OutputKafka) GetMaxRetries() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxRetries
}

func (o *OutputKafka) GetMaxBackOff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackOff
}

func (o *OutputKafka) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *OutputKafka) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *OutputKafka) GetAuthenticationTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.AuthenticationTimeout
}

func (o *OutputKafka) GetReauthenticationThreshold() *float64 {
	if o == nil {
		return nil
	}
	return o.ReauthenticationThreshold
}

func (o *OutputKafka) GetSasl() *OutputKafkaAuthentication {
	if o == nil {
		return nil
	}
	return o.Sasl
}

func (o *OutputKafka) GetTLS() *OutputKafkaTLSSettingsClientSide {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *OutputKafka) GetOnBackpressure() *OutputKafkaBackpressureBehavior {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputKafka) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputKafka) GetProtobufLibraryID() *string {
	if o == nil {
		return nil
	}
	return o.ProtobufLibraryID
}

func (o *OutputKafka) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputKafka) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputKafka) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputKafka) GetPqCompress() *OutputKafkaOutputCompression {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputKafka) GetPqOnBackpressure() *OutputKafkaQueueFullBehavior {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputKafka) GetPqMode() *OutputKafkaMode {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputKafka) GetPqControls() *OutputKafkaPqControls {
	if o == nil {
		return nil
	}
	return o.PqControls
}

func (o *OutputKafka) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type OutputExabeamType string

const (
	OutputExabeamTypeExabeam OutputExabeamType = "exabeam"
)

func (e OutputExabeamType) ToPointer() *OutputExabeamType {
	return &e
}
func (e *OutputExabeamType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "exabeam":
		*e = OutputExabeamType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputExabeamType: %v", v)
	}
}

// OutputExabeamSignatureVersion - Signature version to use for signing Google Cloud Storage requests.
type OutputExabeamSignatureVersion string

const (
	OutputExabeamSignatureVersionV2 OutputExabeamSignatureVersion = "v2"
	OutputExabeamSignatureVersionV4 OutputExabeamSignatureVersion = "v4"
)

func (e OutputExabeamSignatureVersion) ToPointer() *OutputExabeamSignatureVersion {
	return &e
}
func (e *OutputExabeamSignatureVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "v2":
		fallthrough
	case "v4":
		*e = OutputExabeamSignatureVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputExabeamSignatureVersion: %v", v)
	}
}

// OutputExabeamObjectACL - Object ACL to assign to uploaded objects.
type OutputExabeamObjectACL string

const (
	OutputExabeamObjectACLPrivate                OutputExabeamObjectACL = "private"
	OutputExabeamObjectACLBucketOwnerRead        OutputExabeamObjectACL = "bucket-owner-read"
	OutputExabeamObjectACLBucketOwnerFullControl OutputExabeamObjectACL = "bucket-owner-full-control"
	OutputExabeamObjectACLProjectPrivate         OutputExabeamObjectACL = "project-private"
	OutputExabeamObjectACLAuthenticatedRead      OutputExabeamObjectACL = "authenticated-read"
	OutputExabeamObjectACLPublicRead             OutputExabeamObjectACL = "public-read"
)

func (e OutputExabeamObjectACL) ToPointer() *OutputExabeamObjectACL {
	return &e
}
func (e *OutputExabeamObjectACL) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "private":
		fallthrough
	case "bucket-owner-read":
		fallthrough
	case "bucket-owner-full-control":
		fallthrough
	case "project-private":
		fallthrough
	case "authenticated-read":
		fallthrough
	case "public-read":
		*e = OutputExabeamObjectACL(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputExabeamObjectACL: %v", v)
	}
}

// OutputExabeamStorageClass - Storage class to select for uploaded objects.
type OutputExabeamStorageClass string

const (
	OutputExabeamStorageClassStandard OutputExabeamStorageClass = "STANDARD"
	OutputExabeamStorageClassNearline OutputExabeamStorageClass = "NEARLINE"
	OutputExabeamStorageClassColdline OutputExabeamStorageClass = "COLDLINE"
	OutputExabeamStorageClassArchive  OutputExabeamStorageClass = "ARCHIVE"
)

func (e OutputExabeamStorageClass) ToPointer() *OutputExabeamStorageClass {
	return &e
}
func (e *OutputExabeamStorageClass) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "STANDARD":
		fallthrough
	case "NEARLINE":
		fallthrough
	case "COLDLINE":
		fallthrough
	case "ARCHIVE":
		*e = OutputExabeamStorageClass(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputExabeamStorageClass: %v", v)
	}
}

// OutputExabeamBackpressureBehavior - Whether to block or drop events when all receivers are exerting backpressure
type OutputExabeamBackpressureBehavior string

const (
	OutputExabeamBackpressureBehaviorBlock OutputExabeamBackpressureBehavior = "block"
	OutputExabeamBackpressureBehaviorDrop  OutputExabeamBackpressureBehavior = "drop"
)

func (e OutputExabeamBackpressureBehavior) ToPointer() *OutputExabeamBackpressureBehavior {
	return &e
}
func (e *OutputExabeamBackpressureBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputExabeamBackpressureBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputExabeamBackpressureBehavior: %v", v)
	}
}

// OutputExabeamDiskSpaceProtection - Whether to block or drop events when disk space is below the global 'Min free disk space' limit
type OutputExabeamDiskSpaceProtection string

const (
	OutputExabeamDiskSpaceProtectionBlock OutputExabeamDiskSpaceProtection = "block"
	OutputExabeamDiskSpaceProtectionDrop  OutputExabeamDiskSpaceProtection = "drop"
)

func (e OutputExabeamDiskSpaceProtection) ToPointer() *OutputExabeamDiskSpaceProtection {
	return &e
}
func (e *OutputExabeamDiskSpaceProtection) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputExabeamDiskSpaceProtection(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputExabeamDiskSpaceProtection: %v", v)
	}
}

type OutputExabeam struct {
	// Unique ID for this output
	ID   *string            `json:"id,omitempty"`
	Type *OutputExabeamType `json:"type,omitempty"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Name of the destination bucket. A constant or a JavaScript expression that can only be evaluated at init time. Example of referencing a JavaScript Global Variable: `myBucket-${C.vars.myVar}`.
	Bucket string `json:"bucket"`
	// Region where the bucket is located
	Region string `json:"region"`
	// Filesystem location in which to buffer files, before compressing and moving to final destination. Use performant stable storage.
	StagePath *string `default:"\\$CRIBL_HOME/state/outputs/staging" json:"stagePath"`
	// Google Cloud Storage service endpoint.
	Endpoint *string `default:"https://storage.googleapis.com" json:"endpoint"`
	// Signature version to use for signing Google Cloud Storage requests.
	SignatureVersion *OutputExabeamSignatureVersion `default:"v4" json:"signatureVersion"`
	// Object ACL to assign to uploaded objects.
	ObjectACL *OutputExabeamObjectACL `default:"private" json:"objectACL"`
	// Storage class to select for uploaded objects.
	StorageClass *OutputExabeamStorageClass `json:"storageClass,omitempty"`
	// Whether to reuse connections between requests, which can improve performance.
	ReuseConnections *bool `default:"true" json:"reuseConnections"`
	// Whether to reject certificates that cannot be verified against a valid CA (e.g., self-signed certificates).
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Append output's ID to staging location
	AddIDToStagePath *bool `default:"true" json:"addIdToStagePath"`
	// Remove empty staging directories after moving files
	RemoveEmptyDirs *bool `default:"true" json:"removeEmptyDirs"`
	// Maximum amount of time to write to a file. Files open for longer than this will be closed and moved to final output location.
	MaxFileOpenTimeSec *float64 `default:"300" json:"maxFileOpenTimeSec"`
	// Maximum amount of time to keep inactive files open. Files open for longer than this will be closed and moved to final output location.
	MaxFileIdleTimeSec *float64 `default:"30" json:"maxFileIdleTimeSec"`
	// Maximum number of files to keep open concurrently. When exceeded, @{product} will close the oldest open files and move them to the final output location.
	MaxOpenFiles *float64 `default:"100" json:"maxOpenFiles"`
	// Whether to block or drop events when all receivers are exerting backpressure
	OnBackpressure *OutputExabeamBackpressureBehavior `default:"block" json:"onBackpressure"`
	// If a file fails to move to its final destination after the maximum number of retries, dead-letter it to prevent further errors.
	DeadletterEnabled *bool `default:"false" json:"deadletterEnabled"`
	// Whether to block or drop events when disk space is below the global 'Min free disk space' limit
	OnDiskFullBackpressure *OutputExabeamDiskSpaceProtection `default:"block" json:"onDiskFullBackpressure"`
	// Maximum uncompressed output file size. Files of this size will be closed and moved to final output location.
	MaxFileSizeMB *float64 `default:"10" json:"maxFileSizeMB"`
	// Enter an encoded string containing Exabeam configurations.
	EncodedConfiguration *string `json:"encodedConfiguration,omitempty"`
	// ID of the Exabeam Collector where data should be sent. Example: 11112222-3333-4444-5555-666677778888
	//
	CollectorInstanceID string `json:"collectorInstanceId"`
	// Constant or JavaScript expression to create an Exabeam site name. Values that aren't successfully evaluated will be treated as string constants.
	SiteName *string `json:"siteName,omitempty"`
	// Exabeam site ID. If left blank, @{product} will use the value of the Exabeam site name.
	SiteID *string `json:"siteId,omitempty"`
	// Exabeam timezone offset.
	TimezoneOffset *string `json:"timezoneOffset,omitempty"`
	// HMAC access key. Can be a constant or a JavaScript expression, such as `${C.env.GCS_ACCESS_KEY}`.
	AwsAPIKey *string `json:"awsApiKey,omitempty"`
	// HMAC secret. Can be a constant or a JavaScript expression, such as `${C.env.GCS_SECRET}`.
	AwsSecretKey *string `json:"awsSecretKey,omitempty"`
	Description  *string `json:"description,omitempty"`
	// How frequently, in seconds, to clean up empty directories when 'Remove empty staging dirs' is enabled
	EmptyDirCleanupSec *float64 `default:"300" json:"emptyDirCleanupSec"`
	// Storage location for files that fail to reach their final destination after maximum retries are exceeded
	DeadletterPath *string `default:"\\$CRIBL_HOME/state/outputs/dead-letter" json:"deadletterPath"`
	// The maximum number of times a file will attempt to move to its final destination before being dead-lettered
	MaxRetryNum *float64  `default:"20" json:"maxRetryNum"`
	Status      *TFStatus `json:"status,omitempty"`
}

func (o OutputExabeam) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputExabeam) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *OutputExabeam) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *OutputExabeam) GetType() *OutputExabeamType {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *OutputExabeam) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputExabeam) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputExabeam) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputExabeam) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputExabeam) GetBucket() string {
	if o == nil {
		return ""
	}
	return o.Bucket
}

func (o *OutputExabeam) GetRegion() string {
	if o == nil {
		return ""
	}
	return o.Region
}

func (o *OutputExabeam) GetStagePath() *string {
	if o == nil {
		return nil
	}
	return o.StagePath
}

func (o *OutputExabeam) GetEndpoint() *string {
	if o == nil {
		return nil
	}
	return o.Endpoint
}

func (o *OutputExabeam) GetSignatureVersion() *OutputExabeamSignatureVersion {
	if o == nil {
		return nil
	}
	return o.SignatureVersion
}

func (o *OutputExabeam) GetObjectACL() *OutputExabeamObjectACL {
	if o == nil {
		return nil
	}
	return o.ObjectACL
}

func (o *OutputExabeam) GetStorageClass() *OutputExabeamStorageClass {
	if o == nil {
		return nil
	}
	return o.StorageClass
}

func (o *OutputExabeam) GetReuseConnections() *bool {
	if o == nil {
		return nil
	}
	return o.ReuseConnections
}

func (o *OutputExabeam) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputExabeam) GetAddIDToStagePath() *bool {
	if o == nil {
		return nil
	}
	return o.AddIDToStagePath
}

func (o *OutputExabeam) GetRemoveEmptyDirs() *bool {
	if o == nil {
		return nil
	}
	return o.RemoveEmptyDirs
}

func (o *OutputExabeam) GetMaxFileOpenTimeSec() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxFileOpenTimeSec
}

func (o *OutputExabeam) GetMaxFileIdleTimeSec() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxFileIdleTimeSec
}

func (o *OutputExabeam) GetMaxOpenFiles() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxOpenFiles
}

func (o *OutputExabeam) GetOnBackpressure() *OutputExabeamBackpressureBehavior {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputExabeam) GetDeadletterEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.DeadletterEnabled
}

func (o *OutputExabeam) GetOnDiskFullBackpressure() *OutputExabeamDiskSpaceProtection {
	if o == nil {
		return nil
	}
	return o.OnDiskFullBackpressure
}

func (o *OutputExabeam) GetMaxFileSizeMB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxFileSizeMB
}

func (o *OutputExabeam) GetEncodedConfiguration() *string {
	if o == nil {
		return nil
	}
	return o.EncodedConfiguration
}

func (o *OutputExabeam) GetCollectorInstanceID() string {
	if o == nil {
		return ""
	}
	return o.CollectorInstanceID
}

func (o *OutputExabeam) GetSiteName() *string {
	if o == nil {
		return nil
	}
	return o.SiteName
}

func (o *OutputExabeam) GetSiteID() *string {
	if o == nil {
		return nil
	}
	return o.SiteID
}

func (o *OutputExabeam) GetTimezoneOffset() *string {
	if o == nil {
		return nil
	}
	return o.TimezoneOffset
}

func (o *OutputExabeam) GetAwsAPIKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsAPIKey
}

func (o *OutputExabeam) GetAwsSecretKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecretKey
}

func (o *OutputExabeam) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputExabeam) GetEmptyDirCleanupSec() *float64 {
	if o == nil {
		return nil
	}
	return o.EmptyDirCleanupSec
}

func (o *OutputExabeam) GetDeadletterPath() *string {
	if o == nil {
		return nil
	}
	return o.DeadletterPath
}

func (o *OutputExabeam) GetMaxRetryNum() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxRetryNum
}

func (o *OutputExabeam) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type OutputGooglePubsubType string

const (
	OutputGooglePubsubTypeGooglePubsub OutputGooglePubsubType = "google_pubsub"
)

func (e OutputGooglePubsubType) ToPointer() *OutputGooglePubsubType {
	return &e
}
func (e *OutputGooglePubsubType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "google_pubsub":
		*e = OutputGooglePubsubType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputGooglePubsubType: %v", v)
	}
}

// OutputGooglePubsubAuthenticationMethod - Google authentication method. Choose Auto to use Google Application Default Credentials.
type OutputGooglePubsubAuthenticationMethod string

const (
	OutputGooglePubsubAuthenticationMethodAuto   OutputGooglePubsubAuthenticationMethod = "auto"
	OutputGooglePubsubAuthenticationMethodManual OutputGooglePubsubAuthenticationMethod = "manual"
	OutputGooglePubsubAuthenticationMethodSecret OutputGooglePubsubAuthenticationMethod = "secret"
)

func (e OutputGooglePubsubAuthenticationMethod) ToPointer() *OutputGooglePubsubAuthenticationMethod {
	return &e
}
func (e *OutputGooglePubsubAuthenticationMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "auto":
		fallthrough
	case "manual":
		fallthrough
	case "secret":
		*e = OutputGooglePubsubAuthenticationMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputGooglePubsubAuthenticationMethod: %v", v)
	}
}

// OutputGooglePubsubBackpressureBehavior - Whether to block, drop, or queue events when all receivers are exerting backpressure.
type OutputGooglePubsubBackpressureBehavior string

const (
	OutputGooglePubsubBackpressureBehaviorBlock OutputGooglePubsubBackpressureBehavior = "block"
	OutputGooglePubsubBackpressureBehaviorDrop  OutputGooglePubsubBackpressureBehavior = "drop"
	OutputGooglePubsubBackpressureBehaviorQueue OutputGooglePubsubBackpressureBehavior = "queue"
)

func (e OutputGooglePubsubBackpressureBehavior) ToPointer() *OutputGooglePubsubBackpressureBehavior {
	return &e
}
func (e *OutputGooglePubsubBackpressureBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		fallthrough
	case "queue":
		*e = OutputGooglePubsubBackpressureBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputGooglePubsubBackpressureBehavior: %v", v)
	}
}

// OutputGooglePubsubCompression - Codec to use to compress the persisted data.
type OutputGooglePubsubCompression string

const (
	OutputGooglePubsubCompressionNone OutputGooglePubsubCompression = "none"
	OutputGooglePubsubCompressionGzip OutputGooglePubsubCompression = "gzip"
)

func (e OutputGooglePubsubCompression) ToPointer() *OutputGooglePubsubCompression {
	return &e
}
func (e *OutputGooglePubsubCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = OutputGooglePubsubCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputGooglePubsubCompression: %v", v)
	}
}

// OutputGooglePubsubQueueFullBehavior - Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
type OutputGooglePubsubQueueFullBehavior string

const (
	OutputGooglePubsubQueueFullBehaviorBlock OutputGooglePubsubQueueFullBehavior = "block"
	OutputGooglePubsubQueueFullBehaviorDrop  OutputGooglePubsubQueueFullBehavior = "drop"
)

func (e OutputGooglePubsubQueueFullBehavior) ToPointer() *OutputGooglePubsubQueueFullBehavior {
	return &e
}
func (e *OutputGooglePubsubQueueFullBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputGooglePubsubQueueFullBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputGooglePubsubQueueFullBehavior: %v", v)
	}
}

// OutputGooglePubsubMode - In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
type OutputGooglePubsubMode string

const (
	OutputGooglePubsubModeError        OutputGooglePubsubMode = "error"
	OutputGooglePubsubModeBackpressure OutputGooglePubsubMode = "backpressure"
	OutputGooglePubsubModeAlways       OutputGooglePubsubMode = "always"
)

func (e OutputGooglePubsubMode) ToPointer() *OutputGooglePubsubMode {
	return &e
}
func (e *OutputGooglePubsubMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "error":
		fallthrough
	case "backpressure":
		fallthrough
	case "always":
		*e = OutputGooglePubsubMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputGooglePubsubMode: %v", v)
	}
}

type OutputGooglePubsubPqControls struct {
}

type OutputGooglePubsub struct {
	// Unique ID for this output
	ID   *string                `json:"id,omitempty"`
	Type OutputGooglePubsubType `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// ID of the topic to send events to.
	TopicName string `json:"topicName"`
	// If enabled, create topic if it does not exist.
	CreateTopic *bool `default:"false" json:"createTopic"`
	// If enabled, send events in the order they were added to the queue. For this to work correctly, the process receiving events must have ordering enabled.
	OrderedDelivery *bool `default:"false" json:"orderedDelivery"`
	// Region to publish messages to. Select 'default' to allow Google to auto-select the nearest region. When using ordered delivery, the selected region must be allowed by message storage policy.
	Region *string `json:"region,omitempty"`
	// Google authentication method. Choose Auto to use Google Application Default Credentials.
	GoogleAuthMethod *OutputGooglePubsubAuthenticationMethod `default:"manual" json:"googleAuthMethod"`
	// Contents of service account credentials (JSON keys) file downloaded from Google Cloud. To upload a file, click the upload button at this field's upper right.
	ServiceAccountCredentials *string `json:"serviceAccountCredentials,omitempty"`
	// Select or create a stored text secret
	Secret *string `json:"secret,omitempty"`
	// The maximum number of items the Google API should batch before it sends them to the topic.
	BatchSize *float64 `default:"1000" json:"batchSize"`
	// The maximum amount of time, in milliseconds, that the Google API should wait to send a batch (if the Batch size is not reached).
	BatchTimeout *float64 `default:"100" json:"batchTimeout"`
	// Maximum number of queued batches before blocking.
	MaxQueueSize *float64 `default:"100" json:"maxQueueSize"`
	// Maximum size (KB) of batches to send.
	MaxRecordSizeKB *float64 `default:"256" json:"maxRecordSizeKB"`
	// Maximum time to wait before sending a batch (when batch size limit is not reached).
	FlushPeriodSec *float64 `default:"1" json:"flushPeriodSec"`
	// The maximum number of in-progress API requests before backpressure is applied.
	MaxInProgress *float64 `default:"10" json:"maxInProgress"`
	// Whether to block, drop, or queue events when all receivers are exerting backpressure.
	OnBackpressure *OutputGooglePubsubBackpressureBehavior `default:"block" json:"onBackpressure"`
	Description    *string                                 `json:"description,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.).
	PqMaxFileSize *string `default:"1 MB" json:"pqMaxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `default:"5GB" json:"pqMaxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `default:"\\$CRIBL_HOME/state/queues" json:"pqPath"`
	// Codec to use to compress the persisted data.
	PqCompress *OutputGooglePubsubCompression `default:"none" json:"pqCompress"`
	// Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *OutputGooglePubsubQueueFullBehavior `default:"block" json:"pqOnBackpressure"`
	// In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
	PqMode     *OutputGooglePubsubMode       `default:"error" json:"pqMode"`
	PqControls *OutputGooglePubsubPqControls `json:"pqControls,omitempty"`
	Status     *TFStatus                     `json:"status,omitempty"`
}

func (o OutputGooglePubsub) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputGooglePubsub) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *OutputGooglePubsub) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *OutputGooglePubsub) GetType() OutputGooglePubsubType {
	if o == nil {
		return OutputGooglePubsubType("")
	}
	return o.Type
}

func (o *OutputGooglePubsub) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputGooglePubsub) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputGooglePubsub) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputGooglePubsub) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputGooglePubsub) GetTopicName() string {
	if o == nil {
		return ""
	}
	return o.TopicName
}

func (o *OutputGooglePubsub) GetCreateTopic() *bool {
	if o == nil {
		return nil
	}
	return o.CreateTopic
}

func (o *OutputGooglePubsub) GetOrderedDelivery() *bool {
	if o == nil {
		return nil
	}
	return o.OrderedDelivery
}

func (o *OutputGooglePubsub) GetRegion() *string {
	if o == nil {
		return nil
	}
	return o.Region
}

func (o *OutputGooglePubsub) GetGoogleAuthMethod() *OutputGooglePubsubAuthenticationMethod {
	if o == nil {
		return nil
	}
	return o.GoogleAuthMethod
}

func (o *OutputGooglePubsub) GetServiceAccountCredentials() *string {
	if o == nil {
		return nil
	}
	return o.ServiceAccountCredentials
}

func (o *OutputGooglePubsub) GetSecret() *string {
	if o == nil {
		return nil
	}
	return o.Secret
}

func (o *OutputGooglePubsub) GetBatchSize() *float64 {
	if o == nil {
		return nil
	}
	return o.BatchSize
}

func (o *OutputGooglePubsub) GetBatchTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.BatchTimeout
}

func (o *OutputGooglePubsub) GetMaxQueueSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxQueueSize
}

func (o *OutputGooglePubsub) GetMaxRecordSizeKB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxRecordSizeKB
}

func (o *OutputGooglePubsub) GetFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushPeriodSec
}

func (o *OutputGooglePubsub) GetMaxInProgress() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxInProgress
}

func (o *OutputGooglePubsub) GetOnBackpressure() *OutputGooglePubsubBackpressureBehavior {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputGooglePubsub) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputGooglePubsub) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputGooglePubsub) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputGooglePubsub) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputGooglePubsub) GetPqCompress() *OutputGooglePubsubCompression {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputGooglePubsub) GetPqOnBackpressure() *OutputGooglePubsubQueueFullBehavior {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputGooglePubsub) GetPqMode() *OutputGooglePubsubMode {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputGooglePubsub) GetPqControls() *OutputGooglePubsubPqControls {
	if o == nil {
		return nil
	}
	return o.PqControls
}

func (o *OutputGooglePubsub) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type OutputGoogleCloudLoggingType string

const (
	OutputGoogleCloudLoggingTypeGoogleCloudLogging OutputGoogleCloudLoggingType = "google_cloud_logging"
)

func (e OutputGoogleCloudLoggingType) ToPointer() *OutputGoogleCloudLoggingType {
	return &e
}
func (e *OutputGoogleCloudLoggingType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "google_cloud_logging":
		*e = OutputGoogleCloudLoggingType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputGoogleCloudLoggingType: %v", v)
	}
}

type LogLocationType string

const (
	LogLocationTypeProject        LogLocationType = "project"
	LogLocationTypeOrganization   LogLocationType = "organization"
	LogLocationTypeBillingAccount LogLocationType = "billingAccount"
	LogLocationTypeFolder         LogLocationType = "folder"
)

func (e LogLocationType) ToPointer() *LogLocationType {
	return &e
}
func (e *LogLocationType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "project":
		fallthrough
	case "organization":
		fallthrough
	case "billingAccount":
		fallthrough
	case "folder":
		*e = LogLocationType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for LogLocationType: %v", v)
	}
}

// PayloadFormat - Format to use when sending payload. Defaults to Text.
type PayloadFormat string

const (
	PayloadFormatText PayloadFormat = "text"
	PayloadFormatJSON PayloadFormat = "json"
)

func (e PayloadFormat) ToPointer() *PayloadFormat {
	return &e
}
func (e *PayloadFormat) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "text":
		fallthrough
	case "json":
		*e = PayloadFormat(v)
		return nil
	default:
		return fmt.Errorf("invalid value for PayloadFormat: %v", v)
	}
}

type LogLabels struct {
	// Label name
	Label string `json:"label"`
	// JavaScript expression to compute the label's value.
	ValueExpression string `json:"valueExpression"`
}

func (o *LogLabels) GetLabel() string {
	if o == nil {
		return ""
	}
	return o.Label
}

func (o *LogLabels) GetValueExpression() string {
	if o == nil {
		return ""
	}
	return o.ValueExpression
}

type ResourceTypeLabels struct {
	// Label name
	Label string `json:"label"`
	// JavaScript expression to compute the label's value.
	ValueExpression string `json:"valueExpression"`
}

func (o *ResourceTypeLabels) GetLabel() string {
	if o == nil {
		return ""
	}
	return o.Label
}

func (o *ResourceTypeLabels) GetValueExpression() string {
	if o == nil {
		return ""
	}
	return o.ValueExpression
}

// OutputGoogleCloudLoggingAuthenticationMethod - Google authentication method. Choose Auto to use Google Application Default Credentials.
type OutputGoogleCloudLoggingAuthenticationMethod string

const (
	OutputGoogleCloudLoggingAuthenticationMethodAuto   OutputGoogleCloudLoggingAuthenticationMethod = "auto"
	OutputGoogleCloudLoggingAuthenticationMethodManual OutputGoogleCloudLoggingAuthenticationMethod = "manual"
	OutputGoogleCloudLoggingAuthenticationMethodSecret OutputGoogleCloudLoggingAuthenticationMethod = "secret"
)

func (e OutputGoogleCloudLoggingAuthenticationMethod) ToPointer() *OutputGoogleCloudLoggingAuthenticationMethod {
	return &e
}
func (e *OutputGoogleCloudLoggingAuthenticationMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "auto":
		fallthrough
	case "manual":
		fallthrough
	case "secret":
		*e = OutputGoogleCloudLoggingAuthenticationMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputGoogleCloudLoggingAuthenticationMethod: %v", v)
	}
}

// OutputGoogleCloudLoggingBackpressureBehavior - Whether to block, drop, or queue events when all receivers are exerting backpressure.
type OutputGoogleCloudLoggingBackpressureBehavior string

const (
	OutputGoogleCloudLoggingBackpressureBehaviorBlock OutputGoogleCloudLoggingBackpressureBehavior = "block"
	OutputGoogleCloudLoggingBackpressureBehaviorDrop  OutputGoogleCloudLoggingBackpressureBehavior = "drop"
	OutputGoogleCloudLoggingBackpressureBehaviorQueue OutputGoogleCloudLoggingBackpressureBehavior = "queue"
)

func (e OutputGoogleCloudLoggingBackpressureBehavior) ToPointer() *OutputGoogleCloudLoggingBackpressureBehavior {
	return &e
}
func (e *OutputGoogleCloudLoggingBackpressureBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		fallthrough
	case "queue":
		*e = OutputGoogleCloudLoggingBackpressureBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputGoogleCloudLoggingBackpressureBehavior: %v", v)
	}
}

// OutputGoogleCloudLoggingCompression - Codec to use to compress the persisted data.
type OutputGoogleCloudLoggingCompression string

const (
	OutputGoogleCloudLoggingCompressionNone OutputGoogleCloudLoggingCompression = "none"
	OutputGoogleCloudLoggingCompressionGzip OutputGoogleCloudLoggingCompression = "gzip"
)

func (e OutputGoogleCloudLoggingCompression) ToPointer() *OutputGoogleCloudLoggingCompression {
	return &e
}
func (e *OutputGoogleCloudLoggingCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = OutputGoogleCloudLoggingCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputGoogleCloudLoggingCompression: %v", v)
	}
}

// OutputGoogleCloudLoggingQueueFullBehavior - Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
type OutputGoogleCloudLoggingQueueFullBehavior string

const (
	OutputGoogleCloudLoggingQueueFullBehaviorBlock OutputGoogleCloudLoggingQueueFullBehavior = "block"
	OutputGoogleCloudLoggingQueueFullBehaviorDrop  OutputGoogleCloudLoggingQueueFullBehavior = "drop"
)

func (e OutputGoogleCloudLoggingQueueFullBehavior) ToPointer() *OutputGoogleCloudLoggingQueueFullBehavior {
	return &e
}
func (e *OutputGoogleCloudLoggingQueueFullBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputGoogleCloudLoggingQueueFullBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputGoogleCloudLoggingQueueFullBehavior: %v", v)
	}
}

// OutputGoogleCloudLoggingMode - In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
type OutputGoogleCloudLoggingMode string

const (
	OutputGoogleCloudLoggingModeError        OutputGoogleCloudLoggingMode = "error"
	OutputGoogleCloudLoggingModeBackpressure OutputGoogleCloudLoggingMode = "backpressure"
	OutputGoogleCloudLoggingModeAlways       OutputGoogleCloudLoggingMode = "always"
)

func (e OutputGoogleCloudLoggingMode) ToPointer() *OutputGoogleCloudLoggingMode {
	return &e
}
func (e *OutputGoogleCloudLoggingMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "error":
		fallthrough
	case "backpressure":
		fallthrough
	case "always":
		*e = OutputGoogleCloudLoggingMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputGoogleCloudLoggingMode: %v", v)
	}
}

type OutputGoogleCloudLoggingPqControls struct {
}

type OutputGoogleCloudLogging struct {
	// Unique ID for this output
	ID   *string                       `json:"id,omitempty"`
	Type *OutputGoogleCloudLoggingType `json:"type,omitempty"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags      []string        `json:"streamtags,omitempty"`
	LogLocationType LogLocationType `json:"logLocationType"`
	// JavaScript expression to compute the value of the log name.
	LogNameExpression string `json:"logNameExpression"`
	// Format to use when sending payload. Defaults to Text.
	PayloadFormat *PayloadFormat `default:"text" json:"payloadFormat"`
	// Labels to apply to the log entry
	LogLabels []LogLabels `json:"logLabels,omitempty"`
	// JavaScript expression to compute the value of the managed resource type field. Must evaluate to one of the valid values [here](https://cloud.google.com/logging/docs/api/v2/resource-list#resource-types). Defaults to "global".
	ResourceTypeExpression *string `json:"resourceTypeExpression,omitempty"`
	// Labels to apply to the managed resource. These must correspond to the valid labels for the specified resource type (see [here](https://cloud.google.com/logging/docs/api/v2/resource-list#resource-types)). Otherwise, they will be dropped by Google Cloud Logging.
	ResourceTypeLabels []ResourceTypeLabels `json:"resourceTypeLabels,omitempty"`
	// JavaScript expression to compute the value of the severity field. Must evaluate to one of the severity values supported by Google Cloud Logging [here](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#logseverity) (case insensitive). Defaults to "DEFAULT".
	SeverityExpression *string `json:"severityExpression,omitempty"`
	// JavaScript expression to compute the value of the insert ID field.
	InsertIDExpression *string `json:"insertIdExpression,omitempty"`
	// Google authentication method. Choose Auto to use Google Application Default Credentials.
	GoogleAuthMethod *OutputGoogleCloudLoggingAuthenticationMethod `default:"manual" json:"googleAuthMethod"`
	// Contents of service account credentials (JSON keys) file downloaded from Google Cloud. To upload a file, click the upload button at this field's upper right.
	ServiceAccountCredentials *string `json:"serviceAccountCredentials,omitempty"`
	// Select or create a stored text secret
	Secret *string `json:"secret,omitempty"`
	// Maximum size, in KB, of the request body.
	MaxPayloadSizeKB *float64 `default:"4096" json:"maxPayloadSizeKB"`
	// Max number of events to include in the request body. Default is 0 (unlimited).
	MaxPayloadEvents *float64 `default:"0" json:"maxPayloadEvents"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Max record size.
	FlushPeriodSec *float64 `default:"1" json:"flushPeriodSec"`
	// Maximum number of ongoing requests before blocking.
	Concurrency *float64 `default:"5" json:"concurrency"`
	// Amount of time (milliseconds) to wait for the connection to establish before retrying
	ConnectionTimeout *float64 `default:"10000" json:"connectionTimeout"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it.
	TimeoutSec *float64 `default:"30" json:"timeoutSec"`
	// Maximum number of requests to limit to per second.
	ThrottleRateReqPerSec *int64 `json:"throttleRateReqPerSec,omitempty"`
	// A JavaScript expression that evaluates to the HTTP request method as a string. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#httprequest) for details.
	RequestMethodExpression *string `json:"requestMethodExpression,omitempty"`
	// A JavaScript expression that evaluates to the HTTP request URL as a string. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#httprequest) for details.
	RequestURLExpression *string `json:"requestUrlExpression,omitempty"`
	// A JavaScript expression that evaluates to the HTTP request size as a string, in int64 format. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#httprequest) for details.
	RequestSizeExpression *string `json:"requestSizeExpression,omitempty"`
	// A JavaScript expression that evaluates to the HTTP request method as a number. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#httprequest) for details.
	StatusExpression *string `json:"statusExpression,omitempty"`
	// A JavaScript expression that evaluates to the HTTP response size as a string, in int64 format. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#httprequest) for details.
	ResponseSizeExpression *string `json:"responseSizeExpression,omitempty"`
	// A JavaScript expression that evaluates to the HTTP request user agent as a string. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#httprequest) for details.
	UserAgentExpression *string `json:"userAgentExpression,omitempty"`
	// A JavaScript expression that evaluates to the HTTP request remote IP as a string. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#httprequest) for details.
	RemoteIPExpression *string `json:"remoteIpExpression,omitempty"`
	// A JavaScript expression that evaluates to the HTTP request server IP as a string. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#httprequest) for details.
	ServerIPExpression *string `json:"serverIpExpression,omitempty"`
	// A JavaScript expression that evaluates to the HTTP request referer as a string. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#httprequest) for details.
	RefererExpression *string `json:"refererExpression,omitempty"`
	// A JavaScript expression that evaluates to the HTTP request latency, formatted as <seconds>.<nanoseconds>s (for example, 1.23s). See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#httprequest) for details.
	LatencyExpression *string `json:"latencyExpression,omitempty"`
	// A JavaScript expression that evaluates to the HTTP request cache lookup as a boolean. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#httprequest) for details.
	CacheLookupExpression *string `json:"cacheLookupExpression,omitempty"`
	// A JavaScript expression that evaluates to the HTTP request cache hit as a boolean. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#httprequest) for details.
	CacheHitExpression *string `json:"cacheHitExpression,omitempty"`
	// A JavaScript expression that evaluates to the HTTP request cache validated with origin server as a boolean. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#httprequest) for details.
	CacheValidatedExpression *string `json:"cacheValidatedExpression,omitempty"`
	// A JavaScript expression that evaluates to the HTTP request cache fill bytes as a string, in int64 format. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#httprequest) for details.
	CacheFillBytesExpression *string `json:"cacheFillBytesExpression,omitempty"`
	// A JavaScript expression that evaluates to the HTTP request protocol as a string. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#httprequest) for details.
	ProtocolExpression *string `json:"protocolExpression,omitempty"`
	// A JavaScript expression that evaluates to the log entry operation ID as a string. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#logentryoperation) for details.
	IDExpression *string `json:"idExpression,omitempty"`
	// A JavaScript expression that evaluates to the log entry operation producer as a string. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#logentryoperation) for details.
	ProducerExpression *string `json:"producerExpression,omitempty"`
	// A JavaScript expression that evaluates to the log entry operation first flag as a boolean. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#logentryoperation) for details.
	FirstExpression *string `json:"firstExpression,omitempty"`
	// A JavaScript expression that evaluates to the log entry operation last flag as a boolean. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#logentryoperation) for details.
	LastExpression *string `json:"lastExpression,omitempty"`
	// A JavaScript expression that evaluates to the log entry source location file as a string. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#logentrysourcelocation) for details.
	FileExpression *string `json:"fileExpression,omitempty"`
	// A JavaScript expression that evaluates to the log entry source location line as a string, in int64 format. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#logentrysourcelocation) for details.
	LineExpression *string `json:"lineExpression,omitempty"`
	// A JavaScript expression that evaluates to the log entry source location function as a string. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#logentrysourcelocation) for details.
	FunctionExpression *string `json:"functionExpression,omitempty"`
	// A JavaScript expression that evaluates to the log entry log split UID as a string. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#logsplit) for details.
	UIDExpression *string `json:"uidExpression,omitempty"`
	// A JavaScript expression that evaluates to the log entry log split index as a number. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#logsplit) for details.
	IndexExpression *string `json:"indexExpression,omitempty"`
	// A JavaScript expression that evaluates to the log entry log split total splits as a number. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#logsplit) for details.
	TotalSplitsExpression *string `json:"totalSplitsExpression,omitempty"`
	// A JavaScript expression that evaluates to the REST resource name of the trace being written as a string. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry) for details.
	TraceExpression *string `json:"traceExpression,omitempty"`
	// A JavaScript expression that evaluates to the ID of the cloud trace span associated with the current operation in which the log is being written as a string. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry) for details.
	SpanIDExpression *string `json:"spanIdExpression,omitempty"`
	// A JavaScript expression that evaluates to the the sampling decision of the span associated with the log entry. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry) for details.
	TraceSampledExpression *string `json:"traceSampledExpression,omitempty"`
	// Whether to block, drop, or queue events when all receivers are exerting backpressure.
	OnBackpressure *OutputGoogleCloudLoggingBackpressureBehavior `default:"block" json:"onBackpressure"`
	// Maximum total size of the batches waiting to be sent. If left blank, defaults to 5 times the max body size (if set). If 0, no limit is enforced.
	TotalMemoryLimitKB *float64 `json:"totalMemoryLimitKB,omitempty"`
	Description        *string  `json:"description,omitempty"`
	// JavaScript expression to compute the value of the folder ID with which log entries should be associated.
	LogLocationExpression string `json:"logLocationExpression"`
	// JavaScript expression to compute the value of the payload. Must evaluate to a JavaScript object value. If an invalid value is encountered it will result in the default value instead. Defaults to the entire event.
	PayloadExpression *string `json:"payloadExpression,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.).
	PqMaxFileSize *string `default:"1 MB" json:"pqMaxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `default:"5GB" json:"pqMaxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `default:"\\$CRIBL_HOME/state/queues" json:"pqPath"`
	// Codec to use to compress the persisted data.
	PqCompress *OutputGoogleCloudLoggingCompression `default:"none" json:"pqCompress"`
	// Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *OutputGoogleCloudLoggingQueueFullBehavior `default:"block" json:"pqOnBackpressure"`
	// In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
	PqMode     *OutputGoogleCloudLoggingMode       `default:"error" json:"pqMode"`
	PqControls *OutputGoogleCloudLoggingPqControls `json:"pqControls,omitempty"`
	Status     *TFStatus                           `json:"status,omitempty"`
}

func (o OutputGoogleCloudLogging) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputGoogleCloudLogging) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *OutputGoogleCloudLogging) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *OutputGoogleCloudLogging) GetType() *OutputGoogleCloudLoggingType {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *OutputGoogleCloudLogging) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputGoogleCloudLogging) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputGoogleCloudLogging) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputGoogleCloudLogging) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputGoogleCloudLogging) GetLogLocationType() LogLocationType {
	if o == nil {
		return LogLocationType("")
	}
	return o.LogLocationType
}

func (o *OutputGoogleCloudLogging) GetLogNameExpression() string {
	if o == nil {
		return ""
	}
	return o.LogNameExpression
}

func (o *OutputGoogleCloudLogging) GetPayloadFormat() *PayloadFormat {
	if o == nil {
		return nil
	}
	return o.PayloadFormat
}

func (o *OutputGoogleCloudLogging) GetLogLabels() []LogLabels {
	if o == nil {
		return nil
	}
	return o.LogLabels
}

func (o *OutputGoogleCloudLogging) GetResourceTypeExpression() *string {
	if o == nil {
		return nil
	}
	return o.ResourceTypeExpression
}

func (o *OutputGoogleCloudLogging) GetResourceTypeLabels() []ResourceTypeLabels {
	if o == nil {
		return nil
	}
	return o.ResourceTypeLabels
}

func (o *OutputGoogleCloudLogging) GetSeverityExpression() *string {
	if o == nil {
		return nil
	}
	return o.SeverityExpression
}

func (o *OutputGoogleCloudLogging) GetInsertIDExpression() *string {
	if o == nil {
		return nil
	}
	return o.InsertIDExpression
}

func (o *OutputGoogleCloudLogging) GetGoogleAuthMethod() *OutputGoogleCloudLoggingAuthenticationMethod {
	if o == nil {
		return nil
	}
	return o.GoogleAuthMethod
}

func (o *OutputGoogleCloudLogging) GetServiceAccountCredentials() *string {
	if o == nil {
		return nil
	}
	return o.ServiceAccountCredentials
}

func (o *OutputGoogleCloudLogging) GetSecret() *string {
	if o == nil {
		return nil
	}
	return o.Secret
}

func (o *OutputGoogleCloudLogging) GetMaxPayloadSizeKB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadSizeKB
}

func (o *OutputGoogleCloudLogging) GetMaxPayloadEvents() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadEvents
}

func (o *OutputGoogleCloudLogging) GetFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushPeriodSec
}

func (o *OutputGoogleCloudLogging) GetConcurrency() *float64 {
	if o == nil {
		return nil
	}
	return o.Concurrency
}

func (o *OutputGoogleCloudLogging) GetConnectionTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.ConnectionTimeout
}

func (o *OutputGoogleCloudLogging) GetTimeoutSec() *float64 {
	if o == nil {
		return nil
	}
	return o.TimeoutSec
}

func (o *OutputGoogleCloudLogging) GetThrottleRateReqPerSec() *int64 {
	if o == nil {
		return nil
	}
	return o.ThrottleRateReqPerSec
}

func (o *OutputGoogleCloudLogging) GetRequestMethodExpression() *string {
	if o == nil {
		return nil
	}
	return o.RequestMethodExpression
}

func (o *OutputGoogleCloudLogging) GetRequestURLExpression() *string {
	if o == nil {
		return nil
	}
	return o.RequestURLExpression
}

func (o *OutputGoogleCloudLogging) GetRequestSizeExpression() *string {
	if o == nil {
		return nil
	}
	return o.RequestSizeExpression
}

func (o *OutputGoogleCloudLogging) GetStatusExpression() *string {
	if o == nil {
		return nil
	}
	return o.StatusExpression
}

func (o *OutputGoogleCloudLogging) GetResponseSizeExpression() *string {
	if o == nil {
		return nil
	}
	return o.ResponseSizeExpression
}

func (o *OutputGoogleCloudLogging) GetUserAgentExpression() *string {
	if o == nil {
		return nil
	}
	return o.UserAgentExpression
}

func (o *OutputGoogleCloudLogging) GetRemoteIPExpression() *string {
	if o == nil {
		return nil
	}
	return o.RemoteIPExpression
}

func (o *OutputGoogleCloudLogging) GetServerIPExpression() *string {
	if o == nil {
		return nil
	}
	return o.ServerIPExpression
}

func (o *OutputGoogleCloudLogging) GetRefererExpression() *string {
	if o == nil {
		return nil
	}
	return o.RefererExpression
}

func (o *OutputGoogleCloudLogging) GetLatencyExpression() *string {
	if o == nil {
		return nil
	}
	return o.LatencyExpression
}

func (o *OutputGoogleCloudLogging) GetCacheLookupExpression() *string {
	if o == nil {
		return nil
	}
	return o.CacheLookupExpression
}

func (o *OutputGoogleCloudLogging) GetCacheHitExpression() *string {
	if o == nil {
		return nil
	}
	return o.CacheHitExpression
}

func (o *OutputGoogleCloudLogging) GetCacheValidatedExpression() *string {
	if o == nil {
		return nil
	}
	return o.CacheValidatedExpression
}

func (o *OutputGoogleCloudLogging) GetCacheFillBytesExpression() *string {
	if o == nil {
		return nil
	}
	return o.CacheFillBytesExpression
}

func (o *OutputGoogleCloudLogging) GetProtocolExpression() *string {
	if o == nil {
		return nil
	}
	return o.ProtocolExpression
}

func (o *OutputGoogleCloudLogging) GetIDExpression() *string {
	if o == nil {
		return nil
	}
	return o.IDExpression
}

func (o *OutputGoogleCloudLogging) GetProducerExpression() *string {
	if o == nil {
		return nil
	}
	return o.ProducerExpression
}

func (o *OutputGoogleCloudLogging) GetFirstExpression() *string {
	if o == nil {
		return nil
	}
	return o.FirstExpression
}

func (o *OutputGoogleCloudLogging) GetLastExpression() *string {
	if o == nil {
		return nil
	}
	return o.LastExpression
}

func (o *OutputGoogleCloudLogging) GetFileExpression() *string {
	if o == nil {
		return nil
	}
	return o.FileExpression
}

func (o *OutputGoogleCloudLogging) GetLineExpression() *string {
	if o == nil {
		return nil
	}
	return o.LineExpression
}

func (o *OutputGoogleCloudLogging) GetFunctionExpression() *string {
	if o == nil {
		return nil
	}
	return o.FunctionExpression
}

func (o *OutputGoogleCloudLogging) GetUIDExpression() *string {
	if o == nil {
		return nil
	}
	return o.UIDExpression
}

func (o *OutputGoogleCloudLogging) GetIndexExpression() *string {
	if o == nil {
		return nil
	}
	return o.IndexExpression
}

func (o *OutputGoogleCloudLogging) GetTotalSplitsExpression() *string {
	if o == nil {
		return nil
	}
	return o.TotalSplitsExpression
}

func (o *OutputGoogleCloudLogging) GetTraceExpression() *string {
	if o == nil {
		return nil
	}
	return o.TraceExpression
}

func (o *OutputGoogleCloudLogging) GetSpanIDExpression() *string {
	if o == nil {
		return nil
	}
	return o.SpanIDExpression
}

func (o *OutputGoogleCloudLogging) GetTraceSampledExpression() *string {
	if o == nil {
		return nil
	}
	return o.TraceSampledExpression
}

func (o *OutputGoogleCloudLogging) GetOnBackpressure() *OutputGoogleCloudLoggingBackpressureBehavior {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputGoogleCloudLogging) GetTotalMemoryLimitKB() *float64 {
	if o == nil {
		return nil
	}
	return o.TotalMemoryLimitKB
}

func (o *OutputGoogleCloudLogging) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputGoogleCloudLogging) GetLogLocationExpression() string {
	if o == nil {
		return ""
	}
	return o.LogLocationExpression
}

func (o *OutputGoogleCloudLogging) GetPayloadExpression() *string {
	if o == nil {
		return nil
	}
	return o.PayloadExpression
}

func (o *OutputGoogleCloudLogging) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputGoogleCloudLogging) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputGoogleCloudLogging) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputGoogleCloudLogging) GetPqCompress() *OutputGoogleCloudLoggingCompression {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputGoogleCloudLogging) GetPqOnBackpressure() *OutputGoogleCloudLoggingQueueFullBehavior {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputGoogleCloudLogging) GetPqMode() *OutputGoogleCloudLoggingMode {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputGoogleCloudLogging) GetPqControls() *OutputGoogleCloudLoggingPqControls {
	if o == nil {
		return nil
	}
	return o.PqControls
}

func (o *OutputGoogleCloudLogging) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type OutputGoogleCloudStorageType string

const (
	OutputGoogleCloudStorageTypeGoogleCloudStorage OutputGoogleCloudStorageType = "google_cloud_storage"
)

func (e OutputGoogleCloudStorageType) ToPointer() *OutputGoogleCloudStorageType {
	return &e
}
func (e *OutputGoogleCloudStorageType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "google_cloud_storage":
		*e = OutputGoogleCloudStorageType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputGoogleCloudStorageType: %v", v)
	}
}

// OutputGoogleCloudStorageSignatureVersion - Signature version to use for signing Google Cloud Storage requests.
type OutputGoogleCloudStorageSignatureVersion string

const (
	OutputGoogleCloudStorageSignatureVersionV2 OutputGoogleCloudStorageSignatureVersion = "v2"
	OutputGoogleCloudStorageSignatureVersionV4 OutputGoogleCloudStorageSignatureVersion = "v4"
)

func (e OutputGoogleCloudStorageSignatureVersion) ToPointer() *OutputGoogleCloudStorageSignatureVersion {
	return &e
}
func (e *OutputGoogleCloudStorageSignatureVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "v2":
		fallthrough
	case "v4":
		*e = OutputGoogleCloudStorageSignatureVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputGoogleCloudStorageSignatureVersion: %v", v)
	}
}

type OutputGoogleCloudStorageAuthenticationMethod string

const (
	OutputGoogleCloudStorageAuthenticationMethodAuto   OutputGoogleCloudStorageAuthenticationMethod = "auto"
	OutputGoogleCloudStorageAuthenticationMethodManual OutputGoogleCloudStorageAuthenticationMethod = "manual"
	OutputGoogleCloudStorageAuthenticationMethodSecret OutputGoogleCloudStorageAuthenticationMethod = "secret"
)

func (e OutputGoogleCloudStorageAuthenticationMethod) ToPointer() *OutputGoogleCloudStorageAuthenticationMethod {
	return &e
}
func (e *OutputGoogleCloudStorageAuthenticationMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "auto":
		fallthrough
	case "manual":
		fallthrough
	case "secret":
		*e = OutputGoogleCloudStorageAuthenticationMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputGoogleCloudStorageAuthenticationMethod: %v", v)
	}
}

// OutputGoogleCloudStorageObjectACL - Object ACL to assign to uploaded objects.
type OutputGoogleCloudStorageObjectACL string

const (
	OutputGoogleCloudStorageObjectACLPrivate                OutputGoogleCloudStorageObjectACL = "private"
	OutputGoogleCloudStorageObjectACLBucketOwnerRead        OutputGoogleCloudStorageObjectACL = "bucket-owner-read"
	OutputGoogleCloudStorageObjectACLBucketOwnerFullControl OutputGoogleCloudStorageObjectACL = "bucket-owner-full-control"
	OutputGoogleCloudStorageObjectACLProjectPrivate         OutputGoogleCloudStorageObjectACL = "project-private"
	OutputGoogleCloudStorageObjectACLAuthenticatedRead      OutputGoogleCloudStorageObjectACL = "authenticated-read"
	OutputGoogleCloudStorageObjectACLPublicRead             OutputGoogleCloudStorageObjectACL = "public-read"
)

func (e OutputGoogleCloudStorageObjectACL) ToPointer() *OutputGoogleCloudStorageObjectACL {
	return &e
}
func (e *OutputGoogleCloudStorageObjectACL) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "private":
		fallthrough
	case "bucket-owner-read":
		fallthrough
	case "bucket-owner-full-control":
		fallthrough
	case "project-private":
		fallthrough
	case "authenticated-read":
		fallthrough
	case "public-read":
		*e = OutputGoogleCloudStorageObjectACL(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputGoogleCloudStorageObjectACL: %v", v)
	}
}

// OutputGoogleCloudStorageStorageClass - Storage class to select for uploaded objects.
type OutputGoogleCloudStorageStorageClass string

const (
	OutputGoogleCloudStorageStorageClassStandard OutputGoogleCloudStorageStorageClass = "STANDARD"
	OutputGoogleCloudStorageStorageClassNearline OutputGoogleCloudStorageStorageClass = "NEARLINE"
	OutputGoogleCloudStorageStorageClassColdline OutputGoogleCloudStorageStorageClass = "COLDLINE"
	OutputGoogleCloudStorageStorageClassArchive  OutputGoogleCloudStorageStorageClass = "ARCHIVE"
)

func (e OutputGoogleCloudStorageStorageClass) ToPointer() *OutputGoogleCloudStorageStorageClass {
	return &e
}
func (e *OutputGoogleCloudStorageStorageClass) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "STANDARD":
		fallthrough
	case "NEARLINE":
		fallthrough
	case "COLDLINE":
		fallthrough
	case "ARCHIVE":
		*e = OutputGoogleCloudStorageStorageClass(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputGoogleCloudStorageStorageClass: %v", v)
	}
}

// OutputGoogleCloudStorageDataFormat - Format of the output data
type OutputGoogleCloudStorageDataFormat string

const (
	OutputGoogleCloudStorageDataFormatJSON    OutputGoogleCloudStorageDataFormat = "json"
	OutputGoogleCloudStorageDataFormatRaw     OutputGoogleCloudStorageDataFormat = "raw"
	OutputGoogleCloudStorageDataFormatParquet OutputGoogleCloudStorageDataFormat = "parquet"
)

func (e OutputGoogleCloudStorageDataFormat) ToPointer() *OutputGoogleCloudStorageDataFormat {
	return &e
}
func (e *OutputGoogleCloudStorageDataFormat) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "json":
		fallthrough
	case "raw":
		fallthrough
	case "parquet":
		*e = OutputGoogleCloudStorageDataFormat(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputGoogleCloudStorageDataFormat: %v", v)
	}
}

// OutputGoogleCloudStorageBackpressureBehavior - Whether to block or drop events when all receivers are exerting backpressure
type OutputGoogleCloudStorageBackpressureBehavior string

const (
	OutputGoogleCloudStorageBackpressureBehaviorBlock OutputGoogleCloudStorageBackpressureBehavior = "block"
	OutputGoogleCloudStorageBackpressureBehaviorDrop  OutputGoogleCloudStorageBackpressureBehavior = "drop"
)

func (e OutputGoogleCloudStorageBackpressureBehavior) ToPointer() *OutputGoogleCloudStorageBackpressureBehavior {
	return &e
}
func (e *OutputGoogleCloudStorageBackpressureBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputGoogleCloudStorageBackpressureBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputGoogleCloudStorageBackpressureBehavior: %v", v)
	}
}

// OutputGoogleCloudStorageDiskSpaceProtection - Whether to block or drop events when disk space is below the global 'Min free disk space' limit
type OutputGoogleCloudStorageDiskSpaceProtection string

const (
	OutputGoogleCloudStorageDiskSpaceProtectionBlock OutputGoogleCloudStorageDiskSpaceProtection = "block"
	OutputGoogleCloudStorageDiskSpaceProtectionDrop  OutputGoogleCloudStorageDiskSpaceProtection = "drop"
)

func (e OutputGoogleCloudStorageDiskSpaceProtection) ToPointer() *OutputGoogleCloudStorageDiskSpaceProtection {
	return &e
}
func (e *OutputGoogleCloudStorageDiskSpaceProtection) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputGoogleCloudStorageDiskSpaceProtection(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputGoogleCloudStorageDiskSpaceProtection: %v", v)
	}
}

// OutputGoogleCloudStorageCompress - Choose data compression format to apply before moving files to final destination
type OutputGoogleCloudStorageCompress string

const (
	OutputGoogleCloudStorageCompressNone OutputGoogleCloudStorageCompress = "none"
	OutputGoogleCloudStorageCompressGzip OutputGoogleCloudStorageCompress = "gzip"
)

func (e OutputGoogleCloudStorageCompress) ToPointer() *OutputGoogleCloudStorageCompress {
	return &e
}
func (e *OutputGoogleCloudStorageCompress) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = OutputGoogleCloudStorageCompress(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputGoogleCloudStorageCompress: %v", v)
	}
}

// OutputGoogleCloudStorageCompressionLevel - Compression level to apply before moving files to final destination
type OutputGoogleCloudStorageCompressionLevel string

const (
	OutputGoogleCloudStorageCompressionLevelBestSpeed       OutputGoogleCloudStorageCompressionLevel = "best_speed"
	OutputGoogleCloudStorageCompressionLevelNormal          OutputGoogleCloudStorageCompressionLevel = "normal"
	OutputGoogleCloudStorageCompressionLevelBestCompression OutputGoogleCloudStorageCompressionLevel = "best_compression"
)

func (e OutputGoogleCloudStorageCompressionLevel) ToPointer() *OutputGoogleCloudStorageCompressionLevel {
	return &e
}
func (e *OutputGoogleCloudStorageCompressionLevel) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "best_speed":
		fallthrough
	case "normal":
		fallthrough
	case "best_compression":
		*e = OutputGoogleCloudStorageCompressionLevel(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputGoogleCloudStorageCompressionLevel: %v", v)
	}
}

// OutputGoogleCloudStorageParquetVersion - Determines which data types are supported and how they are represented
type OutputGoogleCloudStorageParquetVersion string

const (
	OutputGoogleCloudStorageParquetVersionParquet10 OutputGoogleCloudStorageParquetVersion = "PARQUET_1_0"
	OutputGoogleCloudStorageParquetVersionParquet24 OutputGoogleCloudStorageParquetVersion = "PARQUET_2_4"
	OutputGoogleCloudStorageParquetVersionParquet26 OutputGoogleCloudStorageParquetVersion = "PARQUET_2_6"
)

func (e OutputGoogleCloudStorageParquetVersion) ToPointer() *OutputGoogleCloudStorageParquetVersion {
	return &e
}
func (e *OutputGoogleCloudStorageParquetVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "PARQUET_1_0":
		fallthrough
	case "PARQUET_2_4":
		fallthrough
	case "PARQUET_2_6":
		*e = OutputGoogleCloudStorageParquetVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputGoogleCloudStorageParquetVersion: %v", v)
	}
}

// OutputGoogleCloudStorageDataPageVersion - Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
type OutputGoogleCloudStorageDataPageVersion string

const (
	OutputGoogleCloudStorageDataPageVersionDataPageV1 OutputGoogleCloudStorageDataPageVersion = "DATA_PAGE_V1"
	OutputGoogleCloudStorageDataPageVersionDataPageV2 OutputGoogleCloudStorageDataPageVersion = "DATA_PAGE_V2"
)

func (e OutputGoogleCloudStorageDataPageVersion) ToPointer() *OutputGoogleCloudStorageDataPageVersion {
	return &e
}
func (e *OutputGoogleCloudStorageDataPageVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "DATA_PAGE_V1":
		fallthrough
	case "DATA_PAGE_V2":
		*e = OutputGoogleCloudStorageDataPageVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputGoogleCloudStorageDataPageVersion: %v", v)
	}
}

type OutputGoogleCloudStorageKeyValueMetadata struct {
	Key   *string `default:"" json:"key"`
	Value string  `json:"value"`
}

func (o OutputGoogleCloudStorageKeyValueMetadata) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputGoogleCloudStorageKeyValueMetadata) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputGoogleCloudStorageKeyValueMetadata) GetKey() *string {
	if o == nil {
		return nil
	}
	return o.Key
}

func (o *OutputGoogleCloudStorageKeyValueMetadata) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type OutputGoogleCloudStorage struct {
	// Unique ID for this output
	ID   *string                       `json:"id,omitempty"`
	Type *OutputGoogleCloudStorageType `json:"type,omitempty"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Name of the destination bucket. This value can be a constant or a JavaScript expression that can only be evaluated at init time. Example of referencing a Global Variable: `myBucket-${C.vars.myVar}`.
	Bucket string `json:"bucket"`
	// Region where the bucket is located
	Region string `json:"region"`
	// Google Cloud Storage service endpoint.
	Endpoint *string `default:"https://storage.googleapis.com" json:"endpoint"`
	// Signature version to use for signing Google Cloud Storage requests.
	SignatureVersion        *OutputGoogleCloudStorageSignatureVersion     `default:"v4" json:"signatureVersion"`
	AwsAuthenticationMethod *OutputGoogleCloudStorageAuthenticationMethod `default:"manual" json:"awsAuthenticationMethod"`
	// Filesystem location in which to buffer files, before compressing and moving to final destination. Use performant stable storage.
	StagePath *string `default:"\\$CRIBL_HOME/state/outputs/staging" json:"stagePath"`
	// Prefix to append to files before uploading. Must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at init time. E.g., referencing a Global Variable: `myKeyPrefix-${C.vars.myVar}`.
	DestPath *string `default:"" json:"destPath"`
	// Disable if you can access files within the bucket but not the bucket itself.
	VerifyPermissions *bool `default:"true" json:"verifyPermissions"`
	// Object ACL to assign to uploaded objects.
	ObjectACL *OutputGoogleCloudStorageObjectACL `default:"private" json:"objectACL"`
	// Storage class to select for uploaded objects.
	StorageClass *OutputGoogleCloudStorageStorageClass `json:"storageClass,omitempty"`
	// Whether to reuse connections between requests, which can improve performance.
	ReuseConnections *bool `default:"true" json:"reuseConnections"`
	// Whether to reject certificates that cannot be verified against a valid CA (e.g., self-signed certificates).
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Append output's ID to staging location
	AddIDToStagePath *bool `default:"true" json:"addIdToStagePath"`
	// Remove empty staging directories after moving files
	RemoveEmptyDirs *bool `default:"true" json:"removeEmptyDirs"`
	// JavaScript expression defining how files are partitioned and organized. Default is date-based. If blank, Stream will fall back to the event's __partition field value  if present  otherwise to each location's root directory.
	PartitionExpr *string `default:"C.Time.strftime(_time ? _time : Date.now()/1000, '%Y/%m/%d')" json:"partitionExpr"`
	// Format of the output data
	Format *OutputGoogleCloudStorageDataFormat `default:"json" json:"format"`
	// JavaScript expression to define the output filename prefix (can be constant)
	BaseFileName *string `default:"CriblOut" json:"baseFileName"`
	// JavaScript expression to define the output filename suffix (can be constant).  The `__format` variable refers to the value of the `Data format` field (`json` or `raw`).  The `__compression` field refers to the kind of compression being used (`none` or `gzip`).
	FileNameSuffix *string `default:".\\${C.env[\"CRIBL_WORKER_ID\"]}.\\${__format}\\${__compression === \"gzip\" ? \".gz\" : \"\"}" json:"fileNameSuffix"`
	// Maximum uncompressed output file size. Files of this size will be closed and moved to final output location.
	MaxFileSizeMB *float64 `default:"32" json:"maxFileSizeMB"`
	// Maximum amount of time to write to a file. Files open for longer than this will be closed and moved to final output location.
	MaxFileOpenTimeSec *float64 `default:"300" json:"maxFileOpenTimeSec"`
	// Maximum amount of time to keep inactive files open. Files open for longer than this will be closed and moved to final output location.
	MaxFileIdleTimeSec *float64 `default:"30" json:"maxFileIdleTimeSec"`
	// Maximum number of files to keep open concurrently. When exceeded, @{product} will close the oldest open files and move them to the final output location.
	MaxOpenFiles *float64 `default:"100" json:"maxOpenFiles"`
	// If set, this line will be written to the beginning of each output file
	HeaderLine *string `default:"" json:"headerLine"`
	// Buffer size used to write to a file
	WriteHighWaterMark *float64 `default:"64" json:"writeHighWaterMark"`
	// Whether to block or drop events when all receivers are exerting backpressure
	OnBackpressure *OutputGoogleCloudStorageBackpressureBehavior `default:"block" json:"onBackpressure"`
	// If a file fails to move to its final destination after the maximum number of retries, dead-letter it to prevent further errors.
	DeadletterEnabled *bool `default:"false" json:"deadletterEnabled"`
	// Whether to block or drop events when disk space is below the global 'Min free disk space' limit
	OnDiskFullBackpressure *OutputGoogleCloudStorageDiskSpaceProtection `default:"block" json:"onDiskFullBackpressure"`
	Description            *string                                      `json:"description,omitempty"`
	// Choose data compression format to apply before moving files to final destination
	Compress *OutputGoogleCloudStorageCompress `default:"gzip" json:"compress"`
	// Compression level to apply before moving files to final destination
	CompressionLevel *OutputGoogleCloudStorageCompressionLevel `default:"best_speed" json:"compressionLevel"`
	// Automatically calculate the schema based on the events of each Parquet file generated
	AutomaticSchema *bool `default:"false" json:"automaticSchema"`
	// Determines which data types are supported and how they are represented
	ParquetVersion *OutputGoogleCloudStorageParquetVersion `default:"PARQUET_2_6" json:"parquetVersion"`
	// Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
	ParquetDataPageVersion *OutputGoogleCloudStorageDataPageVersion `default:"DATA_PAGE_V2" json:"parquetDataPageVersion"`
	// The number of rows that every group will contain. The final group can contain a smaller number of rows.
	ParquetRowGroupLength *float64 `default:"10000" json:"parquetRowGroupLength"`
	// Target memory size for page segments, such as 1MB or 128MB. Generally, lower values improve reading speed, while higher values improve compression.
	ParquetPageSize *string `default:"1MB" json:"parquetPageSize"`
	// Log up to 3 rows that @{product} skips due to data mismatch
	ShouldLogInvalidRows *bool `json:"shouldLogInvalidRows,omitempty"`
	// The metadata of files the Destination writes will include the properties you add here as key-value pairs. Useful for tagging, e.g., "key":"OCSF Event Class", "value":"9001".
	KeyValueMetadata []OutputGoogleCloudStorageKeyValueMetadata `json:"keyValueMetadata,omitempty"`
	// Statistics profile an entire file in terms of minimum/maximum values within data, numbers of nulls, etc. You can use Parquet tools to view statistics.
	EnableStatistics *bool `default:"true" json:"enableStatistics"`
	// One page index contains statistics for one data page. Parquet readers use statistics to enable page skipping.
	EnableWritePageIndex *bool `default:"true" json:"enableWritePageIndex"`
	// Parquet tools can use the checksum of a Parquet page to verify data integrity
	EnablePageChecksum *bool `default:"false" json:"enablePageChecksum"`
	// How frequently, in seconds, to clean up empty directories when 'Remove empty staging dirs' is enabled
	EmptyDirCleanupSec *float64 `default:"300" json:"emptyDirCleanupSec"`
	// Storage location for files that fail to reach their final destination after maximum retries are exceeded
	DeadletterPath *string `default:"\\$CRIBL_HOME/state/outputs/dead-letter" json:"deadletterPath"`
	// The maximum number of times a file will attempt to move to its final destination before being dead-lettered
	MaxRetryNum *float64 `default:"20" json:"maxRetryNum"`
	// HMAC access key. This value can be a constant or a JavaScript expression (e.g., `${C.env.GCS_ACCESS_KEY}`).
	AwsAPIKey *string `json:"awsApiKey,omitempty"`
	// HMAC secret. This value can be a constant or a JavaScript expression (e.g., `${C.env.GCS_SECRET}`).
	AwsSecretKey *string `json:"awsSecretKey,omitempty"`
	// Select or create a stored secret that references your access key and secret key
	AwsSecret *string   `json:"awsSecret,omitempty"`
	Status    *TFStatus `json:"status,omitempty"`
}

func (o OutputGoogleCloudStorage) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputGoogleCloudStorage) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *OutputGoogleCloudStorage) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *OutputGoogleCloudStorage) GetType() *OutputGoogleCloudStorageType {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *OutputGoogleCloudStorage) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputGoogleCloudStorage) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputGoogleCloudStorage) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputGoogleCloudStorage) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputGoogleCloudStorage) GetBucket() string {
	if o == nil {
		return ""
	}
	return o.Bucket
}

func (o *OutputGoogleCloudStorage) GetRegion() string {
	if o == nil {
		return ""
	}
	return o.Region
}

func (o *OutputGoogleCloudStorage) GetEndpoint() *string {
	if o == nil {
		return nil
	}
	return o.Endpoint
}

func (o *OutputGoogleCloudStorage) GetSignatureVersion() *OutputGoogleCloudStorageSignatureVersion {
	if o == nil {
		return nil
	}
	return o.SignatureVersion
}

func (o *OutputGoogleCloudStorage) GetAwsAuthenticationMethod() *OutputGoogleCloudStorageAuthenticationMethod {
	if o == nil {
		return nil
	}
	return o.AwsAuthenticationMethod
}

func (o *OutputGoogleCloudStorage) GetStagePath() *string {
	if o == nil {
		return nil
	}
	return o.StagePath
}

func (o *OutputGoogleCloudStorage) GetDestPath() *string {
	if o == nil {
		return nil
	}
	return o.DestPath
}

func (o *OutputGoogleCloudStorage) GetVerifyPermissions() *bool {
	if o == nil {
		return nil
	}
	return o.VerifyPermissions
}

func (o *OutputGoogleCloudStorage) GetObjectACL() *OutputGoogleCloudStorageObjectACL {
	if o == nil {
		return nil
	}
	return o.ObjectACL
}

func (o *OutputGoogleCloudStorage) GetStorageClass() *OutputGoogleCloudStorageStorageClass {
	if o == nil {
		return nil
	}
	return o.StorageClass
}

func (o *OutputGoogleCloudStorage) GetReuseConnections() *bool {
	if o == nil {
		return nil
	}
	return o.ReuseConnections
}

func (o *OutputGoogleCloudStorage) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputGoogleCloudStorage) GetAddIDToStagePath() *bool {
	if o == nil {
		return nil
	}
	return o.AddIDToStagePath
}

func (o *OutputGoogleCloudStorage) GetRemoveEmptyDirs() *bool {
	if o == nil {
		return nil
	}
	return o.RemoveEmptyDirs
}

func (o *OutputGoogleCloudStorage) GetPartitionExpr() *string {
	if o == nil {
		return nil
	}
	return o.PartitionExpr
}

func (o *OutputGoogleCloudStorage) GetFormat() *OutputGoogleCloudStorageDataFormat {
	if o == nil {
		return nil
	}
	return o.Format
}

func (o *OutputGoogleCloudStorage) GetBaseFileName() *string {
	if o == nil {
		return nil
	}
	return o.BaseFileName
}

func (o *OutputGoogleCloudStorage) GetFileNameSuffix() *string {
	if o == nil {
		return nil
	}
	return o.FileNameSuffix
}

func (o *OutputGoogleCloudStorage) GetMaxFileSizeMB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxFileSizeMB
}

func (o *OutputGoogleCloudStorage) GetMaxFileOpenTimeSec() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxFileOpenTimeSec
}

func (o *OutputGoogleCloudStorage) GetMaxFileIdleTimeSec() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxFileIdleTimeSec
}

func (o *OutputGoogleCloudStorage) GetMaxOpenFiles() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxOpenFiles
}

func (o *OutputGoogleCloudStorage) GetHeaderLine() *string {
	if o == nil {
		return nil
	}
	return o.HeaderLine
}

func (o *OutputGoogleCloudStorage) GetWriteHighWaterMark() *float64 {
	if o == nil {
		return nil
	}
	return o.WriteHighWaterMark
}

func (o *OutputGoogleCloudStorage) GetOnBackpressure() *OutputGoogleCloudStorageBackpressureBehavior {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputGoogleCloudStorage) GetDeadletterEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.DeadletterEnabled
}

func (o *OutputGoogleCloudStorage) GetOnDiskFullBackpressure() *OutputGoogleCloudStorageDiskSpaceProtection {
	if o == nil {
		return nil
	}
	return o.OnDiskFullBackpressure
}

func (o *OutputGoogleCloudStorage) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputGoogleCloudStorage) GetCompress() *OutputGoogleCloudStorageCompress {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *OutputGoogleCloudStorage) GetCompressionLevel() *OutputGoogleCloudStorageCompressionLevel {
	if o == nil {
		return nil
	}
	return o.CompressionLevel
}

func (o *OutputGoogleCloudStorage) GetAutomaticSchema() *bool {
	if o == nil {
		return nil
	}
	return o.AutomaticSchema
}

func (o *OutputGoogleCloudStorage) GetParquetVersion() *OutputGoogleCloudStorageParquetVersion {
	if o == nil {
		return nil
	}
	return o.ParquetVersion
}

func (o *OutputGoogleCloudStorage) GetParquetDataPageVersion() *OutputGoogleCloudStorageDataPageVersion {
	if o == nil {
		return nil
	}
	return o.ParquetDataPageVersion
}

func (o *OutputGoogleCloudStorage) GetParquetRowGroupLength() *float64 {
	if o == nil {
		return nil
	}
	return o.ParquetRowGroupLength
}

func (o *OutputGoogleCloudStorage) GetParquetPageSize() *string {
	if o == nil {
		return nil
	}
	return o.ParquetPageSize
}

func (o *OutputGoogleCloudStorage) GetShouldLogInvalidRows() *bool {
	if o == nil {
		return nil
	}
	return o.ShouldLogInvalidRows
}

func (o *OutputGoogleCloudStorage) GetKeyValueMetadata() []OutputGoogleCloudStorageKeyValueMetadata {
	if o == nil {
		return nil
	}
	return o.KeyValueMetadata
}

func (o *OutputGoogleCloudStorage) GetEnableStatistics() *bool {
	if o == nil {
		return nil
	}
	return o.EnableStatistics
}

func (o *OutputGoogleCloudStorage) GetEnableWritePageIndex() *bool {
	if o == nil {
		return nil
	}
	return o.EnableWritePageIndex
}

func (o *OutputGoogleCloudStorage) GetEnablePageChecksum() *bool {
	if o == nil {
		return nil
	}
	return o.EnablePageChecksum
}

func (o *OutputGoogleCloudStorage) GetEmptyDirCleanupSec() *float64 {
	if o == nil {
		return nil
	}
	return o.EmptyDirCleanupSec
}

func (o *OutputGoogleCloudStorage) GetDeadletterPath() *string {
	if o == nil {
		return nil
	}
	return o.DeadletterPath
}

func (o *OutputGoogleCloudStorage) GetMaxRetryNum() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxRetryNum
}

func (o *OutputGoogleCloudStorage) GetAwsAPIKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsAPIKey
}

func (o *OutputGoogleCloudStorage) GetAwsSecretKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecretKey
}

func (o *OutputGoogleCloudStorage) GetAwsSecret() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecret
}

func (o *OutputGoogleCloudStorage) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type OutputGoogleChronicleType string

const (
	OutputGoogleChronicleTypeGoogleChronicle OutputGoogleChronicleType = "google_chronicle"
)

func (e OutputGoogleChronicleType) ToPointer() *OutputGoogleChronicleType {
	return &e
}
func (e *OutputGoogleChronicleType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "google_chronicle":
		*e = OutputGoogleChronicleType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputGoogleChronicleType: %v", v)
	}
}

type OutputGoogleChronicleAPIVersion string

const (
	OutputGoogleChronicleAPIVersionV1 OutputGoogleChronicleAPIVersion = "v1"
	OutputGoogleChronicleAPIVersionV2 OutputGoogleChronicleAPIVersion = "v2"
)

func (e OutputGoogleChronicleAPIVersion) ToPointer() *OutputGoogleChronicleAPIVersion {
	return &e
}
func (e *OutputGoogleChronicleAPIVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "v1":
		fallthrough
	case "v2":
		*e = OutputGoogleChronicleAPIVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputGoogleChronicleAPIVersion: %v", v)
	}
}

type OutputGoogleChronicleAuthenticationMethod string

const (
	OutputGoogleChronicleAuthenticationMethodManual               OutputGoogleChronicleAuthenticationMethod = "manual"
	OutputGoogleChronicleAuthenticationMethodSecret               OutputGoogleChronicleAuthenticationMethod = "secret"
	OutputGoogleChronicleAuthenticationMethodServiceAccount       OutputGoogleChronicleAuthenticationMethod = "serviceAccount"
	OutputGoogleChronicleAuthenticationMethodServiceAccountSecret OutputGoogleChronicleAuthenticationMethod = "serviceAccountSecret"
)

func (e OutputGoogleChronicleAuthenticationMethod) ToPointer() *OutputGoogleChronicleAuthenticationMethod {
	return &e
}
func (e *OutputGoogleChronicleAuthenticationMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "manual":
		fallthrough
	case "secret":
		fallthrough
	case "serviceAccount":
		fallthrough
	case "serviceAccountSecret":
		*e = OutputGoogleChronicleAuthenticationMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputGoogleChronicleAuthenticationMethod: %v", v)
	}
}

type OutputGoogleChronicleResponseRetrySettings struct {
	// The HTTP response status code that will trigger retries
	HTTPStatus float64 `json:"httpStatus"`
	// How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"1000" json:"initialBackoff"`
	// Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackoff *float64 `default:"10000" json:"maxBackoff"`
}

func (o OutputGoogleChronicleResponseRetrySettings) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputGoogleChronicleResponseRetrySettings) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputGoogleChronicleResponseRetrySettings) GetHTTPStatus() float64 {
	if o == nil {
		return 0.0
	}
	return o.HTTPStatus
}

func (o *OutputGoogleChronicleResponseRetrySettings) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *OutputGoogleChronicleResponseRetrySettings) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *OutputGoogleChronicleResponseRetrySettings) GetMaxBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackoff
}

type OutputGoogleChronicleTimeoutRetrySettings struct {
	// Enable to retry on request timeout
	TimeoutRetry *bool `default:"false" json:"timeoutRetry"`
	// How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"1000" json:"initialBackoff"`
	// Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackoff *float64 `default:"10000" json:"maxBackoff"`
}

func (o OutputGoogleChronicleTimeoutRetrySettings) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputGoogleChronicleTimeoutRetrySettings) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputGoogleChronicleTimeoutRetrySettings) GetTimeoutRetry() *bool {
	if o == nil {
		return nil
	}
	return o.TimeoutRetry
}

func (o *OutputGoogleChronicleTimeoutRetrySettings) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *OutputGoogleChronicleTimeoutRetrySettings) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *OutputGoogleChronicleTimeoutRetrySettings) GetMaxBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackoff
}

type SendEventsAs string

const (
	SendEventsAsUnstructured SendEventsAs = "unstructured"
	SendEventsAsUdm          SendEventsAs = "udm"
)

func (e SendEventsAs) ToPointer() *SendEventsAs {
	return &e
}
func (e *SendEventsAs) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "unstructured":
		fallthrough
	case "udm":
		*e = SendEventsAs(v)
		return nil
	default:
		return fmt.Errorf("invalid value for SendEventsAs: %v", v)
	}
}

type OutputGoogleChronicleExtraHTTPHeaders struct {
	// Field name
	Name *string `json:"name,omitempty"`
	// Field value
	Value string `json:"value"`
}

func (o *OutputGoogleChronicleExtraHTTPHeaders) GetName() *string {
	if o == nil {
		return nil
	}
	return o.Name
}

func (o *OutputGoogleChronicleExtraHTTPHeaders) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// OutputGoogleChronicleFailedRequestLoggingMode - Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
type OutputGoogleChronicleFailedRequestLoggingMode string

const (
	OutputGoogleChronicleFailedRequestLoggingModePayload           OutputGoogleChronicleFailedRequestLoggingMode = "payload"
	OutputGoogleChronicleFailedRequestLoggingModePayloadAndHeaders OutputGoogleChronicleFailedRequestLoggingMode = "payloadAndHeaders"
	OutputGoogleChronicleFailedRequestLoggingModeNone              OutputGoogleChronicleFailedRequestLoggingMode = "none"
)

func (e OutputGoogleChronicleFailedRequestLoggingMode) ToPointer() *OutputGoogleChronicleFailedRequestLoggingMode {
	return &e
}
func (e *OutputGoogleChronicleFailedRequestLoggingMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "payload":
		fallthrough
	case "payloadAndHeaders":
		fallthrough
	case "none":
		*e = OutputGoogleChronicleFailedRequestLoggingMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputGoogleChronicleFailedRequestLoggingMode: %v", v)
	}
}

// OutputGoogleChronicleBackpressureBehavior - Whether to block, drop, or queue events when all receivers are exerting backpressure.
type OutputGoogleChronicleBackpressureBehavior string

const (
	OutputGoogleChronicleBackpressureBehaviorBlock OutputGoogleChronicleBackpressureBehavior = "block"
	OutputGoogleChronicleBackpressureBehaviorDrop  OutputGoogleChronicleBackpressureBehavior = "drop"
	OutputGoogleChronicleBackpressureBehaviorQueue OutputGoogleChronicleBackpressureBehavior = "queue"
)

func (e OutputGoogleChronicleBackpressureBehavior) ToPointer() *OutputGoogleChronicleBackpressureBehavior {
	return &e
}
func (e *OutputGoogleChronicleBackpressureBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		fallthrough
	case "queue":
		*e = OutputGoogleChronicleBackpressureBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputGoogleChronicleBackpressureBehavior: %v", v)
	}
}

type ExtraLogTypes struct {
	// Log type
	LogType string `json:"logType"`
	// Log type description
	Description *string `json:"description,omitempty"`
}

func (o *ExtraLogTypes) GetLogType() string {
	if o == nil {
		return ""
	}
	return o.LogType
}

func (o *ExtraLogTypes) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

type CustomLabels struct {
	// Label key
	Key string `json:"key"`
	// Label value
	Value string `json:"value"`
}

func (o *CustomLabels) GetKey() string {
	if o == nil {
		return ""
	}
	return o.Key
}

func (o *CustomLabels) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// OutputGoogleChronicleCompression - Codec to use to compress the persisted data.
type OutputGoogleChronicleCompression string

const (
	OutputGoogleChronicleCompressionNone OutputGoogleChronicleCompression = "none"
	OutputGoogleChronicleCompressionGzip OutputGoogleChronicleCompression = "gzip"
)

func (e OutputGoogleChronicleCompression) ToPointer() *OutputGoogleChronicleCompression {
	return &e
}
func (e *OutputGoogleChronicleCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = OutputGoogleChronicleCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputGoogleChronicleCompression: %v", v)
	}
}

// OutputGoogleChronicleQueueFullBehavior - Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
type OutputGoogleChronicleQueueFullBehavior string

const (
	OutputGoogleChronicleQueueFullBehaviorBlock OutputGoogleChronicleQueueFullBehavior = "block"
	OutputGoogleChronicleQueueFullBehaviorDrop  OutputGoogleChronicleQueueFullBehavior = "drop"
)

func (e OutputGoogleChronicleQueueFullBehavior) ToPointer() *OutputGoogleChronicleQueueFullBehavior {
	return &e
}
func (e *OutputGoogleChronicleQueueFullBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputGoogleChronicleQueueFullBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputGoogleChronicleQueueFullBehavior: %v", v)
	}
}

// OutputGoogleChronicleMode - In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
type OutputGoogleChronicleMode string

const (
	OutputGoogleChronicleModeError        OutputGoogleChronicleMode = "error"
	OutputGoogleChronicleModeBackpressure OutputGoogleChronicleMode = "backpressure"
	OutputGoogleChronicleModeAlways       OutputGoogleChronicleMode = "always"
)

func (e OutputGoogleChronicleMode) ToPointer() *OutputGoogleChronicleMode {
	return &e
}
func (e *OutputGoogleChronicleMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "error":
		fallthrough
	case "backpressure":
		fallthrough
	case "always":
		*e = OutputGoogleChronicleMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputGoogleChronicleMode: %v", v)
	}
}

type OutputGoogleChroniclePqControls struct {
}

type OutputGoogleChronicle struct {
	// Unique ID for this output
	ID   *string                   `json:"id,omitempty"`
	Type OutputGoogleChronicleType `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags           []string                                   `json:"streamtags,omitempty"`
	APIVersion           *OutputGoogleChronicleAPIVersion           `default:"v1" json:"apiVersion"`
	AuthenticationMethod *OutputGoogleChronicleAuthenticationMethod `default:"serviceAccount" json:"authenticationMethod"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable).
	ResponseRetrySettings []OutputGoogleChronicleResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *OutputGoogleChronicleTimeoutRetrySettings   `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool         `default:"false" json:"responseHonorRetryAfterHeader"`
	LogFormatType                 *SendEventsAs `default:"unstructured" json:"logFormatType"`
	// Regional endpoint to send events to
	Region *string `json:"region,omitempty"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `default:"5" json:"concurrency"`
	// Maximum size, in KB, of the request body
	MaxPayloadSizeKB *float64 `default:"1024" json:"maxPayloadSizeKB"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited).
	MaxPayloadEvents *float64 `default:"0" json:"maxPayloadEvents"`
	// Compress the payload body before sending
	Compress *bool `default:"true" json:"compress"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Defaults to Yes. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `default:"90" json:"timeoutSec"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Max body size.
	FlushPeriodSec *float64 `default:"1" json:"flushPeriodSec"`
	// Headers to add to all events.
	ExtraHTTPHeaders []OutputGoogleChronicleExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *OutputGoogleChronicleFailedRequestLoggingMode `default:"none" json:"failedRequestLoggingMode"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// Enables round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned.
	UseRoundRobinDNS *bool `default:"false" json:"useRoundRobinDns"`
	// Whether to block, drop, or queue events when all receivers are exerting backpressure.
	OnBackpressure *OutputGoogleChronicleBackpressureBehavior `default:"block" json:"onBackpressure"`
	// Maximum total size of the batches waiting to be sent. If left blank, defaults to 5 times the max body size (if set). If 0, no limit is enforced.
	TotalMemoryLimitKB *float64 `json:"totalMemoryLimitKB,omitempty"`
	Description        *string  `json:"description,omitempty"`
	// Custom log types. If the value "Custom" is selected in the setting "Default log type" above, the first custom log type in this table will be automatically selected as default log type.
	ExtraLogTypes []ExtraLogTypes `json:"extraLogTypes,omitempty"`
	// Default log type value to send to SecOps. Can be overwritten by event field __logType.
	LogType *string `json:"logType,omitempty"`
	// Name of the event field that contains the log text to send. If not specified, Stream sends a JSON representation of the whole event.
	LogTextField *string `json:"logTextField,omitempty"`
	// Unique identifier (UUID) corresponding to a particular SecOps instance. Provided by your SecOps representative.
	CustomerID *string `json:"customerId,omitempty"`
	// User-configured environment namespace to identify the data domain the logs originated from. Use namespace as a tag to identify the appropriate data domain for indexing and enrichment functionality. Can be overwritten by event field __namespace.
	Namespace *string `json:"namespace,omitempty"`
	// Custom labels to be added to every batch.
	CustomLabels []CustomLabels `json:"customLabels,omitempty"`
	// Organization's API key in Google SecOps
	APIKey *string `json:"apiKey,omitempty"`
	// Select or create a stored text secret
	APIKeySecret *string `json:"apiKeySecret,omitempty"`
	// Contents of service account credentials (JSON keys) file downloaded from Google Cloud. To upload a file, click the upload button at this field's upper right.
	ServiceAccountCredentials *string `json:"serviceAccountCredentials,omitempty"`
	// Select or create a stored text secret
	ServiceAccountCredentialsSecret *string `json:"serviceAccountCredentialsSecret,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.).
	PqMaxFileSize *string `default:"1 MB" json:"pqMaxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `default:"5GB" json:"pqMaxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `default:"\\$CRIBL_HOME/state/queues" json:"pqPath"`
	// Codec to use to compress the persisted data.
	PqCompress *OutputGoogleChronicleCompression `default:"none" json:"pqCompress"`
	// Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *OutputGoogleChronicleQueueFullBehavior `default:"block" json:"pqOnBackpressure"`
	// In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
	PqMode     *OutputGoogleChronicleMode       `default:"error" json:"pqMode"`
	PqControls *OutputGoogleChroniclePqControls `json:"pqControls,omitempty"`
	Status     *TFStatus                        `json:"status,omitempty"`
}

func (o OutputGoogleChronicle) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputGoogleChronicle) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *OutputGoogleChronicle) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *OutputGoogleChronicle) GetType() OutputGoogleChronicleType {
	if o == nil {
		return OutputGoogleChronicleType("")
	}
	return o.Type
}

func (o *OutputGoogleChronicle) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputGoogleChronicle) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputGoogleChronicle) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputGoogleChronicle) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputGoogleChronicle) GetAPIVersion() *OutputGoogleChronicleAPIVersion {
	if o == nil {
		return nil
	}
	return o.APIVersion
}

func (o *OutputGoogleChronicle) GetAuthenticationMethod() *OutputGoogleChronicleAuthenticationMethod {
	if o == nil {
		return nil
	}
	return o.AuthenticationMethod
}

func (o *OutputGoogleChronicle) GetResponseRetrySettings() []OutputGoogleChronicleResponseRetrySettings {
	if o == nil {
		return nil
	}
	return o.ResponseRetrySettings
}

func (o *OutputGoogleChronicle) GetTimeoutRetrySettings() *OutputGoogleChronicleTimeoutRetrySettings {
	if o == nil {
		return nil
	}
	return o.TimeoutRetrySettings
}

func (o *OutputGoogleChronicle) GetResponseHonorRetryAfterHeader() *bool {
	if o == nil {
		return nil
	}
	return o.ResponseHonorRetryAfterHeader
}

func (o *OutputGoogleChronicle) GetLogFormatType() *SendEventsAs {
	if o == nil {
		return nil
	}
	return o.LogFormatType
}

func (o *OutputGoogleChronicle) GetRegion() *string {
	if o == nil {
		return nil
	}
	return o.Region
}

func (o *OutputGoogleChronicle) GetConcurrency() *float64 {
	if o == nil {
		return nil
	}
	return o.Concurrency
}

func (o *OutputGoogleChronicle) GetMaxPayloadSizeKB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadSizeKB
}

func (o *OutputGoogleChronicle) GetMaxPayloadEvents() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadEvents
}

func (o *OutputGoogleChronicle) GetCompress() *bool {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *OutputGoogleChronicle) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputGoogleChronicle) GetTimeoutSec() *float64 {
	if o == nil {
		return nil
	}
	return o.TimeoutSec
}

func (o *OutputGoogleChronicle) GetFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushPeriodSec
}

func (o *OutputGoogleChronicle) GetExtraHTTPHeaders() []OutputGoogleChronicleExtraHTTPHeaders {
	if o == nil {
		return nil
	}
	return o.ExtraHTTPHeaders
}

func (o *OutputGoogleChronicle) GetFailedRequestLoggingMode() *OutputGoogleChronicleFailedRequestLoggingMode {
	if o == nil {
		return nil
	}
	return o.FailedRequestLoggingMode
}

func (o *OutputGoogleChronicle) GetSafeHeaders() []string {
	if o == nil {
		return nil
	}
	return o.SafeHeaders
}

func (o *OutputGoogleChronicle) GetUseRoundRobinDNS() *bool {
	if o == nil {
		return nil
	}
	return o.UseRoundRobinDNS
}

func (o *OutputGoogleChronicle) GetOnBackpressure() *OutputGoogleChronicleBackpressureBehavior {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputGoogleChronicle) GetTotalMemoryLimitKB() *float64 {
	if o == nil {
		return nil
	}
	return o.TotalMemoryLimitKB
}

func (o *OutputGoogleChronicle) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputGoogleChronicle) GetExtraLogTypes() []ExtraLogTypes {
	if o == nil {
		return nil
	}
	return o.ExtraLogTypes
}

func (o *OutputGoogleChronicle) GetLogType() *string {
	if o == nil {
		return nil
	}
	return o.LogType
}

func (o *OutputGoogleChronicle) GetLogTextField() *string {
	if o == nil {
		return nil
	}
	return o.LogTextField
}

func (o *OutputGoogleChronicle) GetCustomerID() *string {
	if o == nil {
		return nil
	}
	return o.CustomerID
}

func (o *OutputGoogleChronicle) GetNamespace() *string {
	if o == nil {
		return nil
	}
	return o.Namespace
}

func (o *OutputGoogleChronicle) GetCustomLabels() []CustomLabels {
	if o == nil {
		return nil
	}
	return o.CustomLabels
}

func (o *OutputGoogleChronicle) GetAPIKey() *string {
	if o == nil {
		return nil
	}
	return o.APIKey
}

func (o *OutputGoogleChronicle) GetAPIKeySecret() *string {
	if o == nil {
		return nil
	}
	return o.APIKeySecret
}

func (o *OutputGoogleChronicle) GetServiceAccountCredentials() *string {
	if o == nil {
		return nil
	}
	return o.ServiceAccountCredentials
}

func (o *OutputGoogleChronicle) GetServiceAccountCredentialsSecret() *string {
	if o == nil {
		return nil
	}
	return o.ServiceAccountCredentialsSecret
}

func (o *OutputGoogleChronicle) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputGoogleChronicle) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputGoogleChronicle) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputGoogleChronicle) GetPqCompress() *OutputGoogleChronicleCompression {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputGoogleChronicle) GetPqOnBackpressure() *OutputGoogleChronicleQueueFullBehavior {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputGoogleChronicle) GetPqMode() *OutputGoogleChronicleMode {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputGoogleChronicle) GetPqControls() *OutputGoogleChroniclePqControls {
	if o == nil {
		return nil
	}
	return o.PqControls
}

func (o *OutputGoogleChronicle) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type OutputAzureEventhubType string

const (
	OutputAzureEventhubTypeAzureEventhub OutputAzureEventhubType = "azure_eventhub"
)

func (e OutputAzureEventhubType) ToPointer() *OutputAzureEventhubType {
	return &e
}
func (e *OutputAzureEventhubType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "azure_eventhub":
		*e = OutputAzureEventhubType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputAzureEventhubType: %v", v)
	}
}

// Acknowledgments - Control the number of required acknowledgments
type Acknowledgments int64

const (
	AcknowledgmentsOne    Acknowledgments = 1
	AcknowledgmentsZero   Acknowledgments = 0
	AcknowledgmentsMinus1 Acknowledgments = -1
)

func (e Acknowledgments) ToPointer() *Acknowledgments {
	return &e
}
func (e *Acknowledgments) UnmarshalJSON(data []byte) error {
	var v int64
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case 1:
		fallthrough
	case 0:
		fallthrough
	case -1:
		*e = Acknowledgments(v)
		return nil
	default:
		return fmt.Errorf("invalid value for Acknowledgments: %v", v)
	}
}

// OutputAzureEventhubRecordDataFormat - Format to use to serialize events before writing to the Event Hubs Kafka brokers.
type OutputAzureEventhubRecordDataFormat string

const (
	OutputAzureEventhubRecordDataFormatJSON OutputAzureEventhubRecordDataFormat = "json"
	OutputAzureEventhubRecordDataFormatRaw  OutputAzureEventhubRecordDataFormat = "raw"
)

func (e OutputAzureEventhubRecordDataFormat) ToPointer() *OutputAzureEventhubRecordDataFormat {
	return &e
}
func (e *OutputAzureEventhubRecordDataFormat) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "json":
		fallthrough
	case "raw":
		*e = OutputAzureEventhubRecordDataFormat(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputAzureEventhubRecordDataFormat: %v", v)
	}
}

// OutputAzureEventhubSASLMechanism - SASL authentication mechanism to use
type OutputAzureEventhubSASLMechanism string

const (
	OutputAzureEventhubSASLMechanismPlain       OutputAzureEventhubSASLMechanism = "plain"
	OutputAzureEventhubSASLMechanismOauthbearer OutputAzureEventhubSASLMechanism = "oauthbearer"
)

func (e OutputAzureEventhubSASLMechanism) ToPointer() *OutputAzureEventhubSASLMechanism {
	return &e
}
func (e *OutputAzureEventhubSASLMechanism) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "plain":
		fallthrough
	case "oauthbearer":
		*e = OutputAzureEventhubSASLMechanism(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputAzureEventhubSASLMechanism: %v", v)
	}
}

// OutputAzureEventhubAuthentication - Authentication parameters to use when connecting to brokers. Using TLS is highly recommended.
type OutputAzureEventhubAuthentication struct {
	// Enable authentication.
	Disabled *bool `default:"false" json:"disabled"`
	// SASL authentication mechanism to use
	Mechanism *OutputAzureEventhubSASLMechanism `default:"plain" json:"mechanism"`
}

func (o OutputAzureEventhubAuthentication) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputAzureEventhubAuthentication) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputAzureEventhubAuthentication) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *OutputAzureEventhubAuthentication) GetMechanism() *OutputAzureEventhubSASLMechanism {
	if o == nil {
		return nil
	}
	return o.Mechanism
}

type OutputAzureEventhubTLSSettingsClientSide struct {
	Disabled *bool `default:"false" json:"disabled"`
	// Reject certs that are not authorized by a CA in the CA certificate path, or by another trusted CA (e.g., the system's CA).
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
}

func (o OutputAzureEventhubTLSSettingsClientSide) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputAzureEventhubTLSSettingsClientSide) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputAzureEventhubTLSSettingsClientSide) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *OutputAzureEventhubTLSSettingsClientSide) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

// OutputAzureEventhubBackpressureBehavior - Whether to block, drop, or queue events when all receivers are exerting backpressure.
type OutputAzureEventhubBackpressureBehavior string

const (
	OutputAzureEventhubBackpressureBehaviorBlock OutputAzureEventhubBackpressureBehavior = "block"
	OutputAzureEventhubBackpressureBehaviorDrop  OutputAzureEventhubBackpressureBehavior = "drop"
	OutputAzureEventhubBackpressureBehaviorQueue OutputAzureEventhubBackpressureBehavior = "queue"
)

func (e OutputAzureEventhubBackpressureBehavior) ToPointer() *OutputAzureEventhubBackpressureBehavior {
	return &e
}
func (e *OutputAzureEventhubBackpressureBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		fallthrough
	case "queue":
		*e = OutputAzureEventhubBackpressureBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputAzureEventhubBackpressureBehavior: %v", v)
	}
}

// OutputAzureEventhubCompression - Codec to use to compress the persisted data.
type OutputAzureEventhubCompression string

const (
	OutputAzureEventhubCompressionNone OutputAzureEventhubCompression = "none"
	OutputAzureEventhubCompressionGzip OutputAzureEventhubCompression = "gzip"
)

func (e OutputAzureEventhubCompression) ToPointer() *OutputAzureEventhubCompression {
	return &e
}
func (e *OutputAzureEventhubCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = OutputAzureEventhubCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputAzureEventhubCompression: %v", v)
	}
}

// OutputAzureEventhubQueueFullBehavior - Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
type OutputAzureEventhubQueueFullBehavior string

const (
	OutputAzureEventhubQueueFullBehaviorBlock OutputAzureEventhubQueueFullBehavior = "block"
	OutputAzureEventhubQueueFullBehaviorDrop  OutputAzureEventhubQueueFullBehavior = "drop"
)

func (e OutputAzureEventhubQueueFullBehavior) ToPointer() *OutputAzureEventhubQueueFullBehavior {
	return &e
}
func (e *OutputAzureEventhubQueueFullBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputAzureEventhubQueueFullBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputAzureEventhubQueueFullBehavior: %v", v)
	}
}

// OutputAzureEventhubMode - In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
type OutputAzureEventhubMode string

const (
	OutputAzureEventhubModeError        OutputAzureEventhubMode = "error"
	OutputAzureEventhubModeBackpressure OutputAzureEventhubMode = "backpressure"
	OutputAzureEventhubModeAlways       OutputAzureEventhubMode = "always"
)

func (e OutputAzureEventhubMode) ToPointer() *OutputAzureEventhubMode {
	return &e
}
func (e *OutputAzureEventhubMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "error":
		fallthrough
	case "backpressure":
		fallthrough
	case "always":
		*e = OutputAzureEventhubMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputAzureEventhubMode: %v", v)
	}
}

type OutputAzureEventhubPqControls struct {
}

type OutputAzureEventhub struct {
	// Unique ID for this output
	ID   *string                  `json:"id,omitempty"`
	Type *OutputAzureEventhubType `json:"type,omitempty"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// List of Event Hubs Kafka brokers to connect to, eg. yourdomain.servicebus.windows.net:9093. The hostname can be found in the host portion of the primary or secondary connection string in Shared Access Policies.
	Brokers []string `json:"brokers"`
	// The name of the Event Hub (a.k.a. Kafka Topic) to publish events. Can be overwritten using field __topicOut.
	Topic string `json:"topic"`
	// Control the number of required acknowledgments
	Ack *Acknowledgments `default:"1" json:"ack"`
	// Format to use to serialize events before writing to the Event Hubs Kafka brokers.
	Format *OutputAzureEventhubRecordDataFormat `default:"json" json:"format"`
	// Maximum size (KB) of each record batch before compression. Setting should be < message.max.bytes settings in Event Hubs brokers.
	MaxRecordSizeKB *float64 `default:"768" json:"maxRecordSizeKB"`
	// Maximum number of events in a batch before forcing a flush.
	FlushEventCount *float64 `default:"1000" json:"flushEventCount"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Max record size.
	FlushPeriodSec *float64 `default:"1" json:"flushPeriodSec"`
	// Maximum time to wait for a connection to complete successfully
	ConnectionTimeout *float64 `default:"10000" json:"connectionTimeout"`
	// Maximum time to wait for Kafka to respond to a request
	RequestTimeout *float64 `default:"60000" json:"requestTimeout"`
	// If messages are failing, you can set the maximum number of retries as high as 100 to prevent loss of data
	MaxRetries *float64 `default:"5" json:"maxRetries"`
	// The maximum wait time for a retry, in milliseconds. Default (and minimum) is 30,000 ms (30 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackOff *float64 `default:"30000" json:"maxBackOff"`
	// Initial value used to calculate the retry, in milliseconds. Maximum is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"300" json:"initialBackoff"`
	// Set the backoff multiplier (2-20) to control the retry frequency for failed messages. For faster retries, use a lower multiplier. For slower retries with more delay between attempts, use a higher multiplier. The multiplier is used in an exponential backoff formula; see the Kafka [documentation](https://kafka.js.org/docs/retry-detailed) for details.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// Maximum time to wait for Kafka to respond to an authentication request
	AuthenticationTimeout *float64 `default:"10000" json:"authenticationTimeout"`
	// Specifies a time window during which @{product} can reauthenticate if needed. Creates the window measuring backwards from the moment when credentials are set to expire.
	ReauthenticationThreshold *float64 `default:"10000" json:"reauthenticationThreshold"`
	// Authentication parameters to use when connecting to brokers. Using TLS is highly recommended.
	Sasl *OutputAzureEventhubAuthentication        `json:"sasl,omitempty"`
	TLS  *OutputAzureEventhubTLSSettingsClientSide `json:"tls,omitempty"`
	// Whether to block, drop, or queue events when all receivers are exerting backpressure.
	OnBackpressure *OutputAzureEventhubBackpressureBehavior `default:"block" json:"onBackpressure"`
	Description    *string                                  `json:"description,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.).
	PqMaxFileSize *string `default:"1 MB" json:"pqMaxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `default:"5GB" json:"pqMaxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `default:"\\$CRIBL_HOME/state/queues" json:"pqPath"`
	// Codec to use to compress the persisted data.
	PqCompress *OutputAzureEventhubCompression `default:"none" json:"pqCompress"`
	// Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *OutputAzureEventhubQueueFullBehavior `default:"block" json:"pqOnBackpressure"`
	// In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
	PqMode     *OutputAzureEventhubMode       `default:"error" json:"pqMode"`
	PqControls *OutputAzureEventhubPqControls `json:"pqControls,omitempty"`
	Status     *TFStatus                      `json:"status,omitempty"`
}

func (o OutputAzureEventhub) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputAzureEventhub) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *OutputAzureEventhub) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *OutputAzureEventhub) GetType() *OutputAzureEventhubType {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *OutputAzureEventhub) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputAzureEventhub) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputAzureEventhub) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputAzureEventhub) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputAzureEventhub) GetBrokers() []string {
	if o == nil {
		return []string{}
	}
	return o.Brokers
}

func (o *OutputAzureEventhub) GetTopic() string {
	if o == nil {
		return ""
	}
	return o.Topic
}

func (o *OutputAzureEventhub) GetAck() *Acknowledgments {
	if o == nil {
		return nil
	}
	return o.Ack
}

func (o *OutputAzureEventhub) GetFormat() *OutputAzureEventhubRecordDataFormat {
	if o == nil {
		return nil
	}
	return o.Format
}

func (o *OutputAzureEventhub) GetMaxRecordSizeKB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxRecordSizeKB
}

func (o *OutputAzureEventhub) GetFlushEventCount() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushEventCount
}

func (o *OutputAzureEventhub) GetFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushPeriodSec
}

func (o *OutputAzureEventhub) GetConnectionTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.ConnectionTimeout
}

func (o *OutputAzureEventhub) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *OutputAzureEventhub) GetMaxRetries() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxRetries
}

func (o *OutputAzureEventhub) GetMaxBackOff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackOff
}

func (o *OutputAzureEventhub) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *OutputAzureEventhub) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *OutputAzureEventhub) GetAuthenticationTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.AuthenticationTimeout
}

func (o *OutputAzureEventhub) GetReauthenticationThreshold() *float64 {
	if o == nil {
		return nil
	}
	return o.ReauthenticationThreshold
}

func (o *OutputAzureEventhub) GetSasl() *OutputAzureEventhubAuthentication {
	if o == nil {
		return nil
	}
	return o.Sasl
}

func (o *OutputAzureEventhub) GetTLS() *OutputAzureEventhubTLSSettingsClientSide {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *OutputAzureEventhub) GetOnBackpressure() *OutputAzureEventhubBackpressureBehavior {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputAzureEventhub) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputAzureEventhub) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputAzureEventhub) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputAzureEventhub) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputAzureEventhub) GetPqCompress() *OutputAzureEventhubCompression {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputAzureEventhub) GetPqOnBackpressure() *OutputAzureEventhubQueueFullBehavior {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputAzureEventhub) GetPqMode() *OutputAzureEventhubMode {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputAzureEventhub) GetPqControls() *OutputAzureEventhubPqControls {
	if o == nil {
		return nil
	}
	return o.PqControls
}

func (o *OutputAzureEventhub) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type OutputHoneycombType string

const (
	OutputHoneycombTypeHoneycomb OutputHoneycombType = "honeycomb"
)

func (e OutputHoneycombType) ToPointer() *OutputHoneycombType {
	return &e
}
func (e *OutputHoneycombType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "honeycomb":
		*e = OutputHoneycombType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputHoneycombType: %v", v)
	}
}

type OutputHoneycombExtraHTTPHeaders struct {
	// Field name
	Name *string `json:"name,omitempty"`
	// Field value
	Value string `json:"value"`
}

func (o *OutputHoneycombExtraHTTPHeaders) GetName() *string {
	if o == nil {
		return nil
	}
	return o.Name
}

func (o *OutputHoneycombExtraHTTPHeaders) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// OutputHoneycombFailedRequestLoggingMode - Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
type OutputHoneycombFailedRequestLoggingMode string

const (
	OutputHoneycombFailedRequestLoggingModePayload           OutputHoneycombFailedRequestLoggingMode = "payload"
	OutputHoneycombFailedRequestLoggingModePayloadAndHeaders OutputHoneycombFailedRequestLoggingMode = "payloadAndHeaders"
	OutputHoneycombFailedRequestLoggingModeNone              OutputHoneycombFailedRequestLoggingMode = "none"
)

func (e OutputHoneycombFailedRequestLoggingMode) ToPointer() *OutputHoneycombFailedRequestLoggingMode {
	return &e
}
func (e *OutputHoneycombFailedRequestLoggingMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "payload":
		fallthrough
	case "payloadAndHeaders":
		fallthrough
	case "none":
		*e = OutputHoneycombFailedRequestLoggingMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputHoneycombFailedRequestLoggingMode: %v", v)
	}
}

type OutputHoneycombResponseRetrySettings struct {
	// The HTTP response status code that will trigger retries
	HTTPStatus float64 `json:"httpStatus"`
	// How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"1000" json:"initialBackoff"`
	// Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackoff *float64 `default:"10000" json:"maxBackoff"`
}

func (o OutputHoneycombResponseRetrySettings) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputHoneycombResponseRetrySettings) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputHoneycombResponseRetrySettings) GetHTTPStatus() float64 {
	if o == nil {
		return 0.0
	}
	return o.HTTPStatus
}

func (o *OutputHoneycombResponseRetrySettings) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *OutputHoneycombResponseRetrySettings) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *OutputHoneycombResponseRetrySettings) GetMaxBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackoff
}

type OutputHoneycombTimeoutRetrySettings struct {
	// Enable to retry on request timeout
	TimeoutRetry *bool `default:"false" json:"timeoutRetry"`
	// How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"1000" json:"initialBackoff"`
	// Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackoff *float64 `default:"10000" json:"maxBackoff"`
}

func (o OutputHoneycombTimeoutRetrySettings) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputHoneycombTimeoutRetrySettings) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputHoneycombTimeoutRetrySettings) GetTimeoutRetry() *bool {
	if o == nil {
		return nil
	}
	return o.TimeoutRetry
}

func (o *OutputHoneycombTimeoutRetrySettings) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *OutputHoneycombTimeoutRetrySettings) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *OutputHoneycombTimeoutRetrySettings) GetMaxBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackoff
}

// OutputHoneycombBackpressureBehavior - Whether to block, drop, or queue events when all receivers are exerting backpressure.
type OutputHoneycombBackpressureBehavior string

const (
	OutputHoneycombBackpressureBehaviorBlock OutputHoneycombBackpressureBehavior = "block"
	OutputHoneycombBackpressureBehaviorDrop  OutputHoneycombBackpressureBehavior = "drop"
	OutputHoneycombBackpressureBehaviorQueue OutputHoneycombBackpressureBehavior = "queue"
)

func (e OutputHoneycombBackpressureBehavior) ToPointer() *OutputHoneycombBackpressureBehavior {
	return &e
}
func (e *OutputHoneycombBackpressureBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		fallthrough
	case "queue":
		*e = OutputHoneycombBackpressureBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputHoneycombBackpressureBehavior: %v", v)
	}
}

// OutputHoneycombAuthenticationMethod - Enter API key directly, or select a stored secret
type OutputHoneycombAuthenticationMethod string

const (
	OutputHoneycombAuthenticationMethodManual OutputHoneycombAuthenticationMethod = "manual"
	OutputHoneycombAuthenticationMethodSecret OutputHoneycombAuthenticationMethod = "secret"
)

func (e OutputHoneycombAuthenticationMethod) ToPointer() *OutputHoneycombAuthenticationMethod {
	return &e
}
func (e *OutputHoneycombAuthenticationMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "manual":
		fallthrough
	case "secret":
		*e = OutputHoneycombAuthenticationMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputHoneycombAuthenticationMethod: %v", v)
	}
}

// OutputHoneycombCompression - Codec to use to compress the persisted data.
type OutputHoneycombCompression string

const (
	OutputHoneycombCompressionNone OutputHoneycombCompression = "none"
	OutputHoneycombCompressionGzip OutputHoneycombCompression = "gzip"
)

func (e OutputHoneycombCompression) ToPointer() *OutputHoneycombCompression {
	return &e
}
func (e *OutputHoneycombCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = OutputHoneycombCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputHoneycombCompression: %v", v)
	}
}

// OutputHoneycombQueueFullBehavior - Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
type OutputHoneycombQueueFullBehavior string

const (
	OutputHoneycombQueueFullBehaviorBlock OutputHoneycombQueueFullBehavior = "block"
	OutputHoneycombQueueFullBehaviorDrop  OutputHoneycombQueueFullBehavior = "drop"
)

func (e OutputHoneycombQueueFullBehavior) ToPointer() *OutputHoneycombQueueFullBehavior {
	return &e
}
func (e *OutputHoneycombQueueFullBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputHoneycombQueueFullBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputHoneycombQueueFullBehavior: %v", v)
	}
}

// OutputHoneycombMode - In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
type OutputHoneycombMode string

const (
	OutputHoneycombModeError        OutputHoneycombMode = "error"
	OutputHoneycombModeBackpressure OutputHoneycombMode = "backpressure"
	OutputHoneycombModeAlways       OutputHoneycombMode = "always"
)

func (e OutputHoneycombMode) ToPointer() *OutputHoneycombMode {
	return &e
}
func (e *OutputHoneycombMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "error":
		fallthrough
	case "backpressure":
		fallthrough
	case "always":
		*e = OutputHoneycombMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputHoneycombMode: %v", v)
	}
}

type OutputHoneycombPqControls struct {
}

type OutputHoneycomb struct {
	// Unique ID for this output
	ID   *string             `json:"id,omitempty"`
	Type OutputHoneycombType `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Name of the dataset to send events to  e.g., observability
	Dataset string `json:"dataset"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `default:"5" json:"concurrency"`
	// Maximum size, in KB, of the request body
	MaxPayloadSizeKB *float64 `default:"4096" json:"maxPayloadSizeKB"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited).
	MaxPayloadEvents *float64 `default:"0" json:"maxPayloadEvents"`
	// Compress the payload body before sending
	Compress *bool `default:"true" json:"compress"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Defaults to Yes. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `default:"30" json:"timeoutSec"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Max body size.
	FlushPeriodSec *float64 `default:"1" json:"flushPeriodSec"`
	// Headers to add to all events.
	ExtraHTTPHeaders []OutputHoneycombExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// Enables round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `default:"false" json:"useRoundRobinDns"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *OutputHoneycombFailedRequestLoggingMode `default:"none" json:"failedRequestLoggingMode"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable).
	ResponseRetrySettings []OutputHoneycombResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *OutputHoneycombTimeoutRetrySettings   `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `default:"false" json:"responseHonorRetryAfterHeader"`
	// Whether to block, drop, or queue events when all receivers are exerting backpressure.
	OnBackpressure *OutputHoneycombBackpressureBehavior `default:"block" json:"onBackpressure"`
	// Enter API key directly, or select a stored secret
	AuthType    *OutputHoneycombAuthenticationMethod `default:"manual" json:"authType"`
	Description *string                              `json:"description,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.).
	PqMaxFileSize *string `default:"1 MB" json:"pqMaxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `default:"5GB" json:"pqMaxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `default:"\\$CRIBL_HOME/state/queues" json:"pqPath"`
	// Codec to use to compress the persisted data.
	PqCompress *OutputHoneycombCompression `default:"none" json:"pqCompress"`
	// Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *OutputHoneycombQueueFullBehavior `default:"block" json:"pqOnBackpressure"`
	// In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
	PqMode     *OutputHoneycombMode       `default:"error" json:"pqMode"`
	PqControls *OutputHoneycombPqControls `json:"pqControls,omitempty"`
	// Team API key where the dataset belongs
	Team *string `json:"team,omitempty"`
	// Select or create a stored text secret
	TextSecret *string   `json:"textSecret,omitempty"`
	Status     *TFStatus `json:"status,omitempty"`
}

func (o OutputHoneycomb) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputHoneycomb) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *OutputHoneycomb) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *OutputHoneycomb) GetType() OutputHoneycombType {
	if o == nil {
		return OutputHoneycombType("")
	}
	return o.Type
}

func (o *OutputHoneycomb) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputHoneycomb) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputHoneycomb) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputHoneycomb) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputHoneycomb) GetDataset() string {
	if o == nil {
		return ""
	}
	return o.Dataset
}

func (o *OutputHoneycomb) GetConcurrency() *float64 {
	if o == nil {
		return nil
	}
	return o.Concurrency
}

func (o *OutputHoneycomb) GetMaxPayloadSizeKB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadSizeKB
}

func (o *OutputHoneycomb) GetMaxPayloadEvents() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadEvents
}

func (o *OutputHoneycomb) GetCompress() *bool {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *OutputHoneycomb) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputHoneycomb) GetTimeoutSec() *float64 {
	if o == nil {
		return nil
	}
	return o.TimeoutSec
}

func (o *OutputHoneycomb) GetFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushPeriodSec
}

func (o *OutputHoneycomb) GetExtraHTTPHeaders() []OutputHoneycombExtraHTTPHeaders {
	if o == nil {
		return nil
	}
	return o.ExtraHTTPHeaders
}

func (o *OutputHoneycomb) GetUseRoundRobinDNS() *bool {
	if o == nil {
		return nil
	}
	return o.UseRoundRobinDNS
}

func (o *OutputHoneycomb) GetFailedRequestLoggingMode() *OutputHoneycombFailedRequestLoggingMode {
	if o == nil {
		return nil
	}
	return o.FailedRequestLoggingMode
}

func (o *OutputHoneycomb) GetSafeHeaders() []string {
	if o == nil {
		return nil
	}
	return o.SafeHeaders
}

func (o *OutputHoneycomb) GetResponseRetrySettings() []OutputHoneycombResponseRetrySettings {
	if o == nil {
		return nil
	}
	return o.ResponseRetrySettings
}

func (o *OutputHoneycomb) GetTimeoutRetrySettings() *OutputHoneycombTimeoutRetrySettings {
	if o == nil {
		return nil
	}
	return o.TimeoutRetrySettings
}

func (o *OutputHoneycomb) GetResponseHonorRetryAfterHeader() *bool {
	if o == nil {
		return nil
	}
	return o.ResponseHonorRetryAfterHeader
}

func (o *OutputHoneycomb) GetOnBackpressure() *OutputHoneycombBackpressureBehavior {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputHoneycomb) GetAuthType() *OutputHoneycombAuthenticationMethod {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *OutputHoneycomb) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputHoneycomb) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputHoneycomb) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputHoneycomb) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputHoneycomb) GetPqCompress() *OutputHoneycombCompression {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputHoneycomb) GetPqOnBackpressure() *OutputHoneycombQueueFullBehavior {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputHoneycomb) GetPqMode() *OutputHoneycombMode {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputHoneycomb) GetPqControls() *OutputHoneycombPqControls {
	if o == nil {
		return nil
	}
	return o.PqControls
}

func (o *OutputHoneycomb) GetTeam() *string {
	if o == nil {
		return nil
	}
	return o.Team
}

func (o *OutputHoneycomb) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *OutputHoneycomb) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type OutputKinesisType string

const (
	OutputKinesisTypeKinesis OutputKinesisType = "kinesis"
)

func (e OutputKinesisType) ToPointer() *OutputKinesisType {
	return &e
}
func (e *OutputKinesisType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "kinesis":
		*e = OutputKinesisType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputKinesisType: %v", v)
	}
}

// OutputKinesisAuthenticationMethod - AWS authentication method. Choose Auto to use IAM roles.
type OutputKinesisAuthenticationMethod string

const (
	OutputKinesisAuthenticationMethodAuto   OutputKinesisAuthenticationMethod = "auto"
	OutputKinesisAuthenticationMethodManual OutputKinesisAuthenticationMethod = "manual"
	OutputKinesisAuthenticationMethodSecret OutputKinesisAuthenticationMethod = "secret"
)

func (e OutputKinesisAuthenticationMethod) ToPointer() *OutputKinesisAuthenticationMethod {
	return &e
}
func (e *OutputKinesisAuthenticationMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "auto":
		fallthrough
	case "manual":
		fallthrough
	case "secret":
		*e = OutputKinesisAuthenticationMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputKinesisAuthenticationMethod: %v", v)
	}
}

// OutputKinesisSignatureVersion - Signature version to use for signing Kinesis stream requests
type OutputKinesisSignatureVersion string

const (
	OutputKinesisSignatureVersionV2 OutputKinesisSignatureVersion = "v2"
	OutputKinesisSignatureVersionV4 OutputKinesisSignatureVersion = "v4"
)

func (e OutputKinesisSignatureVersion) ToPointer() *OutputKinesisSignatureVersion {
	return &e
}
func (e *OutputKinesisSignatureVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "v2":
		fallthrough
	case "v4":
		*e = OutputKinesisSignatureVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputKinesisSignatureVersion: %v", v)
	}
}

// OutputKinesisCompression - Compression type to use for records
type OutputKinesisCompression string

const (
	OutputKinesisCompressionNone OutputKinesisCompression = "none"
	OutputKinesisCompressionGzip OutputKinesisCompression = "gzip"
)

func (e OutputKinesisCompression) ToPointer() *OutputKinesisCompression {
	return &e
}
func (e *OutputKinesisCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = OutputKinesisCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputKinesisCompression: %v", v)
	}
}

// OutputKinesisBackpressureBehavior - Whether to block, drop, or queue events when all receivers are exerting backpressure.
type OutputKinesisBackpressureBehavior string

const (
	OutputKinesisBackpressureBehaviorBlock OutputKinesisBackpressureBehavior = "block"
	OutputKinesisBackpressureBehaviorDrop  OutputKinesisBackpressureBehavior = "drop"
	OutputKinesisBackpressureBehaviorQueue OutputKinesisBackpressureBehavior = "queue"
)

func (e OutputKinesisBackpressureBehavior) ToPointer() *OutputKinesisBackpressureBehavior {
	return &e
}
func (e *OutputKinesisBackpressureBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		fallthrough
	case "queue":
		*e = OutputKinesisBackpressureBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputKinesisBackpressureBehavior: %v", v)
	}
}

// OutputKinesisOutputCompression - Codec to use to compress the persisted data.
type OutputKinesisOutputCompression string

const (
	OutputKinesisOutputCompressionNone OutputKinesisOutputCompression = "none"
	OutputKinesisOutputCompressionGzip OutputKinesisOutputCompression = "gzip"
)

func (e OutputKinesisOutputCompression) ToPointer() *OutputKinesisOutputCompression {
	return &e
}
func (e *OutputKinesisOutputCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = OutputKinesisOutputCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputKinesisOutputCompression: %v", v)
	}
}

// OutputKinesisQueueFullBehavior - Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
type OutputKinesisQueueFullBehavior string

const (
	OutputKinesisQueueFullBehaviorBlock OutputKinesisQueueFullBehavior = "block"
	OutputKinesisQueueFullBehaviorDrop  OutputKinesisQueueFullBehavior = "drop"
)

func (e OutputKinesisQueueFullBehavior) ToPointer() *OutputKinesisQueueFullBehavior {
	return &e
}
func (e *OutputKinesisQueueFullBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputKinesisQueueFullBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputKinesisQueueFullBehavior: %v", v)
	}
}

// OutputKinesisMode - In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
type OutputKinesisMode string

const (
	OutputKinesisModeError        OutputKinesisMode = "error"
	OutputKinesisModeBackpressure OutputKinesisMode = "backpressure"
	OutputKinesisModeAlways       OutputKinesisMode = "always"
)

func (e OutputKinesisMode) ToPointer() *OutputKinesisMode {
	return &e
}
func (e *OutputKinesisMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "error":
		fallthrough
	case "backpressure":
		fallthrough
	case "always":
		*e = OutputKinesisMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputKinesisMode: %v", v)
	}
}

type OutputKinesisPqControls struct {
}

type OutputKinesis struct {
	// Unique ID for this output
	ID   *string            `json:"id,omitempty"`
	Type *OutputKinesisType `json:"type,omitempty"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Kinesis stream name to send events to.
	StreamName string `json:"streamName"`
	// AWS authentication method. Choose Auto to use IAM roles.
	AwsAuthenticationMethod *OutputKinesisAuthenticationMethod `default:"auto" json:"awsAuthenticationMethod"`
	AwsSecretKey            *string                            `json:"awsSecretKey,omitempty"`
	// Region where the Kinesis stream is located
	Region string `json:"region"`
	// Kinesis stream service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to Kinesis stream-compatible endpoint.
	Endpoint *string `json:"endpoint,omitempty"`
	// Signature version to use for signing Kinesis stream requests
	SignatureVersion *OutputKinesisSignatureVersion `default:"v4" json:"signatureVersion"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `default:"true" json:"reuseConnections"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Use Assume Role credentials to access Kinesis stream
	EnableAssumeRole *bool `default:"false" json:"enableAssumeRole"`
	// Amazon Resource Name (ARN) of the role to assume
	AssumeRoleArn *string `json:"assumeRoleArn,omitempty"`
	// External ID to use when assuming role
	AssumeRoleExternalID *string `json:"assumeRoleExternalId,omitempty"`
	// Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
	DurationSeconds *float64 `default:"3600" json:"durationSeconds"`
	// Maximum number of ongoing put requests before blocking.
	Concurrency *float64 `default:"5" json:"concurrency"`
	// Maximum size (KB) of each individual record before compression. For uncompressed or non-compressible data 1MB is the max recommended size
	MaxRecordSizeKB *float64 `default:"1024" json:"maxRecordSizeKB"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Max record size.
	FlushPeriodSec *float64 `default:"1" json:"flushPeriodSec"`
	// Compression type to use for records
	Compression *OutputKinesisCompression `default:"gzip" json:"compression"`
	// Provides higher stream rate limits, improving delivery speed and reliability by minimizing throttling. See the [ListShards API](https://docs.aws.amazon.com/kinesis/latest/APIReference/API_ListShards.html) documentation for details.
	UseListShards *bool `default:"false" json:"useListShards"`
	// Batch events into a single record as NDJSON
	AsNdjson *bool `default:"true" json:"asNdjson"`
	// Whether to block, drop, or queue events when all receivers are exerting backpressure.
	OnBackpressure *OutputKinesisBackpressureBehavior `default:"block" json:"onBackpressure"`
	Description    *string                            `json:"description,omitempty"`
	AwsAPIKey      *string                            `json:"awsApiKey,omitempty"`
	// Select or create a stored secret that references your access key and secret key
	AwsSecret *string `json:"awsSecret,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.).
	PqMaxFileSize *string `default:"1 MB" json:"pqMaxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `default:"5GB" json:"pqMaxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `default:"\\$CRIBL_HOME/state/queues" json:"pqPath"`
	// Codec to use to compress the persisted data.
	PqCompress *OutputKinesisOutputCompression `default:"none" json:"pqCompress"`
	// Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *OutputKinesisQueueFullBehavior `default:"block" json:"pqOnBackpressure"`
	// In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
	PqMode     *OutputKinesisMode       `default:"error" json:"pqMode"`
	PqControls *OutputKinesisPqControls `json:"pqControls,omitempty"`
	Status     *TFStatus                `json:"status,omitempty"`
}

func (o OutputKinesis) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputKinesis) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *OutputKinesis) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *OutputKinesis) GetType() *OutputKinesisType {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *OutputKinesis) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputKinesis) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputKinesis) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputKinesis) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputKinesis) GetStreamName() string {
	if o == nil {
		return ""
	}
	return o.StreamName
}

func (o *OutputKinesis) GetAwsAuthenticationMethod() *OutputKinesisAuthenticationMethod {
	if o == nil {
		return nil
	}
	return o.AwsAuthenticationMethod
}

func (o *OutputKinesis) GetAwsSecretKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecretKey
}

func (o *OutputKinesis) GetRegion() string {
	if o == nil {
		return ""
	}
	return o.Region
}

func (o *OutputKinesis) GetEndpoint() *string {
	if o == nil {
		return nil
	}
	return o.Endpoint
}

func (o *OutputKinesis) GetSignatureVersion() *OutputKinesisSignatureVersion {
	if o == nil {
		return nil
	}
	return o.SignatureVersion
}

func (o *OutputKinesis) GetReuseConnections() *bool {
	if o == nil {
		return nil
	}
	return o.ReuseConnections
}

func (o *OutputKinesis) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputKinesis) GetEnableAssumeRole() *bool {
	if o == nil {
		return nil
	}
	return o.EnableAssumeRole
}

func (o *OutputKinesis) GetAssumeRoleArn() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleArn
}

func (o *OutputKinesis) GetAssumeRoleExternalID() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleExternalID
}

func (o *OutputKinesis) GetDurationSeconds() *float64 {
	if o == nil {
		return nil
	}
	return o.DurationSeconds
}

func (o *OutputKinesis) GetConcurrency() *float64 {
	if o == nil {
		return nil
	}
	return o.Concurrency
}

func (o *OutputKinesis) GetMaxRecordSizeKB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxRecordSizeKB
}

func (o *OutputKinesis) GetFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushPeriodSec
}

func (o *OutputKinesis) GetCompression() *OutputKinesisCompression {
	if o == nil {
		return nil
	}
	return o.Compression
}

func (o *OutputKinesis) GetUseListShards() *bool {
	if o == nil {
		return nil
	}
	return o.UseListShards
}

func (o *OutputKinesis) GetAsNdjson() *bool {
	if o == nil {
		return nil
	}
	return o.AsNdjson
}

func (o *OutputKinesis) GetOnBackpressure() *OutputKinesisBackpressureBehavior {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputKinesis) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputKinesis) GetAwsAPIKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsAPIKey
}

func (o *OutputKinesis) GetAwsSecret() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecret
}

func (o *OutputKinesis) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputKinesis) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputKinesis) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputKinesis) GetPqCompress() *OutputKinesisOutputCompression {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputKinesis) GetPqOnBackpressure() *OutputKinesisQueueFullBehavior {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputKinesis) GetPqMode() *OutputKinesisMode {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputKinesis) GetPqControls() *OutputKinesisPqControls {
	if o == nil {
		return nil
	}
	return o.PqControls
}

func (o *OutputKinesis) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type OutputAzureLogsType string

const (
	OutputAzureLogsTypeAzureLogs OutputAzureLogsType = "azure_logs"
)

func (e OutputAzureLogsType) ToPointer() *OutputAzureLogsType {
	return &e
}
func (e *OutputAzureLogsType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "azure_logs":
		*e = OutputAzureLogsType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputAzureLogsType: %v", v)
	}
}

type OutputAzureLogsExtraHTTPHeaders struct {
	// Field name
	Name *string `json:"name,omitempty"`
	// Field value
	Value string `json:"value"`
}

func (o *OutputAzureLogsExtraHTTPHeaders) GetName() *string {
	if o == nil {
		return nil
	}
	return o.Name
}

func (o *OutputAzureLogsExtraHTTPHeaders) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// OutputAzureLogsFailedRequestLoggingMode - Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
type OutputAzureLogsFailedRequestLoggingMode string

const (
	OutputAzureLogsFailedRequestLoggingModePayload           OutputAzureLogsFailedRequestLoggingMode = "payload"
	OutputAzureLogsFailedRequestLoggingModePayloadAndHeaders OutputAzureLogsFailedRequestLoggingMode = "payloadAndHeaders"
	OutputAzureLogsFailedRequestLoggingModeNone              OutputAzureLogsFailedRequestLoggingMode = "none"
)

func (e OutputAzureLogsFailedRequestLoggingMode) ToPointer() *OutputAzureLogsFailedRequestLoggingMode {
	return &e
}
func (e *OutputAzureLogsFailedRequestLoggingMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "payload":
		fallthrough
	case "payloadAndHeaders":
		fallthrough
	case "none":
		*e = OutputAzureLogsFailedRequestLoggingMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputAzureLogsFailedRequestLoggingMode: %v", v)
	}
}

type OutputAzureLogsResponseRetrySettings struct {
	// The HTTP response status code that will trigger retries
	HTTPStatus float64 `json:"httpStatus"`
	// How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"1000" json:"initialBackoff"`
	// Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackoff *float64 `default:"10000" json:"maxBackoff"`
}

func (o OutputAzureLogsResponseRetrySettings) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputAzureLogsResponseRetrySettings) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputAzureLogsResponseRetrySettings) GetHTTPStatus() float64 {
	if o == nil {
		return 0.0
	}
	return o.HTTPStatus
}

func (o *OutputAzureLogsResponseRetrySettings) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *OutputAzureLogsResponseRetrySettings) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *OutputAzureLogsResponseRetrySettings) GetMaxBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackoff
}

type OutputAzureLogsTimeoutRetrySettings struct {
	// Enable to retry on request timeout
	TimeoutRetry *bool `default:"false" json:"timeoutRetry"`
	// How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"1000" json:"initialBackoff"`
	// Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackoff *float64 `default:"10000" json:"maxBackoff"`
}

func (o OutputAzureLogsTimeoutRetrySettings) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputAzureLogsTimeoutRetrySettings) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputAzureLogsTimeoutRetrySettings) GetTimeoutRetry() *bool {
	if o == nil {
		return nil
	}
	return o.TimeoutRetry
}

func (o *OutputAzureLogsTimeoutRetrySettings) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *OutputAzureLogsTimeoutRetrySettings) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *OutputAzureLogsTimeoutRetrySettings) GetMaxBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackoff
}

// OutputAzureLogsBackpressureBehavior - Whether to block, drop, or queue events when all receivers are exerting backpressure.
type OutputAzureLogsBackpressureBehavior string

const (
	OutputAzureLogsBackpressureBehaviorBlock OutputAzureLogsBackpressureBehavior = "block"
	OutputAzureLogsBackpressureBehaviorDrop  OutputAzureLogsBackpressureBehavior = "drop"
	OutputAzureLogsBackpressureBehaviorQueue OutputAzureLogsBackpressureBehavior = "queue"
)

func (e OutputAzureLogsBackpressureBehavior) ToPointer() *OutputAzureLogsBackpressureBehavior {
	return &e
}
func (e *OutputAzureLogsBackpressureBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		fallthrough
	case "queue":
		*e = OutputAzureLogsBackpressureBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputAzureLogsBackpressureBehavior: %v", v)
	}
}

// OutputAzureLogsAuthenticationMethod - Enter workspace ID and workspace key directly, or select a stored secret
type OutputAzureLogsAuthenticationMethod string

const (
	OutputAzureLogsAuthenticationMethodManual OutputAzureLogsAuthenticationMethod = "manual"
	OutputAzureLogsAuthenticationMethodSecret OutputAzureLogsAuthenticationMethod = "secret"
)

func (e OutputAzureLogsAuthenticationMethod) ToPointer() *OutputAzureLogsAuthenticationMethod {
	return &e
}
func (e *OutputAzureLogsAuthenticationMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "manual":
		fallthrough
	case "secret":
		*e = OutputAzureLogsAuthenticationMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputAzureLogsAuthenticationMethod: %v", v)
	}
}

// OutputAzureLogsCompression - Codec to use to compress the persisted data.
type OutputAzureLogsCompression string

const (
	OutputAzureLogsCompressionNone OutputAzureLogsCompression = "none"
	OutputAzureLogsCompressionGzip OutputAzureLogsCompression = "gzip"
)

func (e OutputAzureLogsCompression) ToPointer() *OutputAzureLogsCompression {
	return &e
}
func (e *OutputAzureLogsCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = OutputAzureLogsCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputAzureLogsCompression: %v", v)
	}
}

// OutputAzureLogsQueueFullBehavior - Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
type OutputAzureLogsQueueFullBehavior string

const (
	OutputAzureLogsQueueFullBehaviorBlock OutputAzureLogsQueueFullBehavior = "block"
	OutputAzureLogsQueueFullBehaviorDrop  OutputAzureLogsQueueFullBehavior = "drop"
)

func (e OutputAzureLogsQueueFullBehavior) ToPointer() *OutputAzureLogsQueueFullBehavior {
	return &e
}
func (e *OutputAzureLogsQueueFullBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputAzureLogsQueueFullBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputAzureLogsQueueFullBehavior: %v", v)
	}
}

// OutputAzureLogsMode - In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
type OutputAzureLogsMode string

const (
	OutputAzureLogsModeError        OutputAzureLogsMode = "error"
	OutputAzureLogsModeBackpressure OutputAzureLogsMode = "backpressure"
	OutputAzureLogsModeAlways       OutputAzureLogsMode = "always"
)

func (e OutputAzureLogsMode) ToPointer() *OutputAzureLogsMode {
	return &e
}
func (e *OutputAzureLogsMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "error":
		fallthrough
	case "backpressure":
		fallthrough
	case "always":
		*e = OutputAzureLogsMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputAzureLogsMode: %v", v)
	}
}

type OutputAzureLogsPqControls struct {
}

type OutputAzureLogs struct {
	// Unique ID for this output
	ID   *string             `json:"id,omitempty"`
	Type OutputAzureLogsType `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// The Log Type of events sent to this LogAnalytics workspace. Defaults to `Cribl`. Use only letters, numbers, and `_` characters, and can't exceed 100 characters. Can be overwritten by event field __logType.
	LogType *string `default:"Cribl" json:"logType"`
	// Optional Resource ID of the Azure resource to associate the data with. Can be overridden by the __resourceId event field. This ID populates the _ResourceId property, allowing the data to be included in resource-centric queries. If the ID is neither specified nor overridden, resource-centric queries will omit the data.
	ResourceID *string `json:"resourceId,omitempty"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `default:"5" json:"concurrency"`
	// Maximum size, in KB, of the request body
	MaxPayloadSizeKB *float64 `default:"1024" json:"maxPayloadSizeKB"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited).
	MaxPayloadEvents *float64 `default:"0" json:"maxPayloadEvents"`
	Compress         *bool    `json:"compress,omitempty"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Defaults to Yes. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `default:"30" json:"timeoutSec"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Max body size.
	FlushPeriodSec *float64 `default:"1" json:"flushPeriodSec"`
	// Headers to add to all events.
	ExtraHTTPHeaders []OutputAzureLogsExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// Enables round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `default:"false" json:"useRoundRobinDns"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *OutputAzureLogsFailedRequestLoggingMode `default:"none" json:"failedRequestLoggingMode"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// Enter the DNS name of the Log API endpoint that sends log data to a Log Analytics workspace in Azure Monitor. Defaults to .ods.opinsights.azure.com. @{product} will add a prefix and suffix around this DNS name to construct a URI in this format: <https://<Workspace_ID><your_DNS_name>/api/logs?api-version=<API version>.
	APIURL *string `default:".ods.opinsights.azure.com" json:"apiUrl"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable).
	ResponseRetrySettings []OutputAzureLogsResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *OutputAzureLogsTimeoutRetrySettings   `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `default:"false" json:"responseHonorRetryAfterHeader"`
	// Whether to block, drop, or queue events when all receivers are exerting backpressure.
	OnBackpressure *OutputAzureLogsBackpressureBehavior `default:"block" json:"onBackpressure"`
	// Enter workspace ID and workspace key directly, or select a stored secret
	AuthType    *OutputAzureLogsAuthenticationMethod `default:"manual" json:"authType"`
	Description *string                              `json:"description,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.).
	PqMaxFileSize *string `default:"1 MB" json:"pqMaxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `default:"5GB" json:"pqMaxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `default:"\\$CRIBL_HOME/state/queues" json:"pqPath"`
	// Codec to use to compress the persisted data.
	PqCompress *OutputAzureLogsCompression `default:"none" json:"pqCompress"`
	// Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *OutputAzureLogsQueueFullBehavior `default:"block" json:"pqOnBackpressure"`
	// In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
	PqMode     *OutputAzureLogsMode       `default:"error" json:"pqMode"`
	PqControls *OutputAzureLogsPqControls `json:"pqControls,omitempty"`
	// Azure Log Analytics Workspace ID. See Azure Dashboard Workspace > Advanced settings.
	WorkspaceID *string `json:"workspaceId,omitempty"`
	// Azure Log Analytics Workspace Primary or Secondary Shared Key. See Azure Dashboard Workspace > Advanced settings.
	WorkspaceKey *string `json:"workspaceKey,omitempty"`
	// Select or create a stored secret that references your access key and secret key
	KeypairSecret *string   `json:"keypairSecret,omitempty"`
	Status        *TFStatus `json:"status,omitempty"`
}

func (o OutputAzureLogs) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputAzureLogs) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *OutputAzureLogs) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *OutputAzureLogs) GetType() OutputAzureLogsType {
	if o == nil {
		return OutputAzureLogsType("")
	}
	return o.Type
}

func (o *OutputAzureLogs) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputAzureLogs) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputAzureLogs) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputAzureLogs) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputAzureLogs) GetLogType() *string {
	if o == nil {
		return nil
	}
	return o.LogType
}

func (o *OutputAzureLogs) GetResourceID() *string {
	if o == nil {
		return nil
	}
	return o.ResourceID
}

func (o *OutputAzureLogs) GetConcurrency() *float64 {
	if o == nil {
		return nil
	}
	return o.Concurrency
}

func (o *OutputAzureLogs) GetMaxPayloadSizeKB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadSizeKB
}

func (o *OutputAzureLogs) GetMaxPayloadEvents() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadEvents
}

func (o *OutputAzureLogs) GetCompress() *bool {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *OutputAzureLogs) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputAzureLogs) GetTimeoutSec() *float64 {
	if o == nil {
		return nil
	}
	return o.TimeoutSec
}

func (o *OutputAzureLogs) GetFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushPeriodSec
}

func (o *OutputAzureLogs) GetExtraHTTPHeaders() []OutputAzureLogsExtraHTTPHeaders {
	if o == nil {
		return nil
	}
	return o.ExtraHTTPHeaders
}

func (o *OutputAzureLogs) GetUseRoundRobinDNS() *bool {
	if o == nil {
		return nil
	}
	return o.UseRoundRobinDNS
}

func (o *OutputAzureLogs) GetFailedRequestLoggingMode() *OutputAzureLogsFailedRequestLoggingMode {
	if o == nil {
		return nil
	}
	return o.FailedRequestLoggingMode
}

func (o *OutputAzureLogs) GetSafeHeaders() []string {
	if o == nil {
		return nil
	}
	return o.SafeHeaders
}

func (o *OutputAzureLogs) GetAPIURL() *string {
	if o == nil {
		return nil
	}
	return o.APIURL
}

func (o *OutputAzureLogs) GetResponseRetrySettings() []OutputAzureLogsResponseRetrySettings {
	if o == nil {
		return nil
	}
	return o.ResponseRetrySettings
}

func (o *OutputAzureLogs) GetTimeoutRetrySettings() *OutputAzureLogsTimeoutRetrySettings {
	if o == nil {
		return nil
	}
	return o.TimeoutRetrySettings
}

func (o *OutputAzureLogs) GetResponseHonorRetryAfterHeader() *bool {
	if o == nil {
		return nil
	}
	return o.ResponseHonorRetryAfterHeader
}

func (o *OutputAzureLogs) GetOnBackpressure() *OutputAzureLogsBackpressureBehavior {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputAzureLogs) GetAuthType() *OutputAzureLogsAuthenticationMethod {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *OutputAzureLogs) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputAzureLogs) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputAzureLogs) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputAzureLogs) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputAzureLogs) GetPqCompress() *OutputAzureLogsCompression {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputAzureLogs) GetPqOnBackpressure() *OutputAzureLogsQueueFullBehavior {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputAzureLogs) GetPqMode() *OutputAzureLogsMode {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputAzureLogs) GetPqControls() *OutputAzureLogsPqControls {
	if o == nil {
		return nil
	}
	return o.PqControls
}

func (o *OutputAzureLogs) GetWorkspaceID() *string {
	if o == nil {
		return nil
	}
	return o.WorkspaceID
}

func (o *OutputAzureLogs) GetWorkspaceKey() *string {
	if o == nil {
		return nil
	}
	return o.WorkspaceKey
}

func (o *OutputAzureLogs) GetKeypairSecret() *string {
	if o == nil {
		return nil
	}
	return o.KeypairSecret
}

func (o *OutputAzureLogs) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type OutputAzureDataExplorerType string

const (
	OutputAzureDataExplorerTypeAzureDataExplorer OutputAzureDataExplorerType = "azure_data_explorer"
)

func (e OutputAzureDataExplorerType) ToPointer() *OutputAzureDataExplorerType {
	return &e
}
func (e *OutputAzureDataExplorerType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "azure_data_explorer":
		*e = OutputAzureDataExplorerType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputAzureDataExplorerType: %v", v)
	}
}

// IngestionMode - Method to use for ingesting data.
type IngestionMode string

const (
	IngestionModeBatching  IngestionMode = "batching"
	IngestionModeStreaming IngestionMode = "streaming"
)

func (e IngestionMode) ToPointer() *IngestionMode {
	return &e
}
func (e *IngestionMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "batching":
		fallthrough
	case "streaming":
		*e = IngestionMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for IngestionMode: %v", v)
	}
}

// AzureADAuthenticationEndpoint - Endpoint used to acquire authentication tokens from Azure.
type AzureADAuthenticationEndpoint string

const (
	AzureADAuthenticationEndpointHTTPSLoginMicrosoftonlineCom       AzureADAuthenticationEndpoint = "https://login.microsoftonline.com"
	AzureADAuthenticationEndpointHTTPSLoginMicrosoftonlineUs        AzureADAuthenticationEndpoint = "https://login.microsoftonline.us"
	AzureADAuthenticationEndpointHTTPSLoginPartnerMicrosoftonlineCn AzureADAuthenticationEndpoint = "https://login.partner.microsoftonline.cn"
)

func (e AzureADAuthenticationEndpoint) ToPointer() *AzureADAuthenticationEndpoint {
	return &e
}
func (e *AzureADAuthenticationEndpoint) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "https://login.microsoftonline.com":
		fallthrough
	case "https://login.microsoftonline.us":
		fallthrough
	case "https://login.partner.microsoftonline.cn":
		*e = AzureADAuthenticationEndpoint(v)
		return nil
	default:
		return fmt.Errorf("invalid value for AzureADAuthenticationEndpoint: %v", v)
	}
}

// OutputAzureDataExplorerAuthenticationMethod - The type of OAuth 2.0 client credentials grant flow to use.
type OutputAzureDataExplorerAuthenticationMethod string

const (
	OutputAzureDataExplorerAuthenticationMethodClientSecret     OutputAzureDataExplorerAuthenticationMethod = "clientSecret"
	OutputAzureDataExplorerAuthenticationMethodClientTextSecret OutputAzureDataExplorerAuthenticationMethod = "clientTextSecret"
	OutputAzureDataExplorerAuthenticationMethodCertificate      OutputAzureDataExplorerAuthenticationMethod = "certificate"
)

func (e OutputAzureDataExplorerAuthenticationMethod) ToPointer() *OutputAzureDataExplorerAuthenticationMethod {
	return &e
}
func (e *OutputAzureDataExplorerAuthenticationMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "clientSecret":
		fallthrough
	case "clientTextSecret":
		fallthrough
	case "certificate":
		*e = OutputAzureDataExplorerAuthenticationMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputAzureDataExplorerAuthenticationMethod: %v", v)
	}
}

type OutputAzureDataExplorerCertificate struct {
	// The certificate you registered as credentials for your app in the Azure portal.
	CertificateName *string `json:"certificateName,omitempty"`
}

func (o *OutputAzureDataExplorerCertificate) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

// OutputAzureDataExplorerBackpressureBehavior - Whether to block, drop, or queue events when all receivers are exerting backpressure.
type OutputAzureDataExplorerBackpressureBehavior string

const (
	OutputAzureDataExplorerBackpressureBehaviorBlock OutputAzureDataExplorerBackpressureBehavior = "block"
	OutputAzureDataExplorerBackpressureBehaviorDrop  OutputAzureDataExplorerBackpressureBehavior = "drop"
	OutputAzureDataExplorerBackpressureBehaviorQueue OutputAzureDataExplorerBackpressureBehavior = "queue"
)

func (e OutputAzureDataExplorerBackpressureBehavior) ToPointer() *OutputAzureDataExplorerBackpressureBehavior {
	return &e
}
func (e *OutputAzureDataExplorerBackpressureBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		fallthrough
	case "queue":
		*e = OutputAzureDataExplorerBackpressureBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputAzureDataExplorerBackpressureBehavior: %v", v)
	}
}

// OutputAzureDataExplorerDataFormat - Format of the output data
type OutputAzureDataExplorerDataFormat string

const (
	OutputAzureDataExplorerDataFormatJSON    OutputAzureDataExplorerDataFormat = "json"
	OutputAzureDataExplorerDataFormatRaw     OutputAzureDataExplorerDataFormat = "raw"
	OutputAzureDataExplorerDataFormatParquet OutputAzureDataExplorerDataFormat = "parquet"
)

func (e OutputAzureDataExplorerDataFormat) ToPointer() *OutputAzureDataExplorerDataFormat {
	return &e
}
func (e *OutputAzureDataExplorerDataFormat) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "json":
		fallthrough
	case "raw":
		fallthrough
	case "parquet":
		*e = OutputAzureDataExplorerDataFormat(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputAzureDataExplorerDataFormat: %v", v)
	}
}

// OutputAzureDataExplorerDiskSpaceProtection - Whether to block or drop events when disk space is below the global 'Min free disk space' limit
type OutputAzureDataExplorerDiskSpaceProtection string

const (
	OutputAzureDataExplorerDiskSpaceProtectionBlock OutputAzureDataExplorerDiskSpaceProtection = "block"
	OutputAzureDataExplorerDiskSpaceProtectionDrop  OutputAzureDataExplorerDiskSpaceProtection = "drop"
)

func (e OutputAzureDataExplorerDiskSpaceProtection) ToPointer() *OutputAzureDataExplorerDiskSpaceProtection {
	return &e
}
func (e *OutputAzureDataExplorerDiskSpaceProtection) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputAzureDataExplorerDiskSpaceProtection(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputAzureDataExplorerDiskSpaceProtection: %v", v)
	}
}

type PrefixOptional string

const (
	PrefixOptionalDropBy   PrefixOptional = "dropBy"
	PrefixOptionalIngestBy PrefixOptional = "ingestBy"
)

func (e PrefixOptional) ToPointer() *PrefixOptional {
	return &e
}
func (e *PrefixOptional) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "dropBy":
		fallthrough
	case "ingestBy":
		*e = PrefixOptional(v)
		return nil
	default:
		return fmt.Errorf("invalid value for PrefixOptional: %v", v)
	}
}

type ExtentTags struct {
	Prefix *PrefixOptional `json:"prefix,omitempty"`
	Value  string          `json:"value"`
}

func (o *ExtentTags) GetPrefix() *PrefixOptional {
	if o == nil {
		return nil
	}
	return o.Prefix
}

func (o *ExtentTags) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type IngestIfNotExists struct {
	Value string `json:"value"`
}

func (o *IngestIfNotExists) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// ReportLevel - Level of ingestion status reporting. Defaults to FailuresOnly.
type ReportLevel string

const (
	ReportLevelFailuresOnly         ReportLevel = "failuresOnly"
	ReportLevelDoNotReport          ReportLevel = "doNotReport"
	ReportLevelFailuresAndSuccesses ReportLevel = "failuresAndSuccesses"
)

func (e ReportLevel) ToPointer() *ReportLevel {
	return &e
}
func (e *ReportLevel) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "failuresOnly":
		fallthrough
	case "doNotReport":
		fallthrough
	case "failuresAndSuccesses":
		*e = ReportLevel(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ReportLevel: %v", v)
	}
}

// ReportMethod - Target of the ingestion status reporting. Defaults to Queue.
type ReportMethod string

const (
	ReportMethodQueue         ReportMethod = "queue"
	ReportMethodTable         ReportMethod = "table"
	ReportMethodQueueAndTable ReportMethod = "queueAndTable"
)

func (e ReportMethod) ToPointer() *ReportMethod {
	return &e
}
func (e *ReportMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "queue":
		fallthrough
	case "table":
		fallthrough
	case "queueAndTable":
		*e = ReportMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ReportMethod: %v", v)
	}
}

type AdditionalProperties struct {
	Key   string `json:"key"`
	Value string `json:"value"`
}

func (o *AdditionalProperties) GetKey() string {
	if o == nil {
		return ""
	}
	return o.Key
}

func (o *AdditionalProperties) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type OutputAzureDataExplorerResponseRetrySettings struct {
	// The HTTP response status code that will trigger retries
	HTTPStatus float64 `json:"httpStatus"`
	// How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"1000" json:"initialBackoff"`
	// Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackoff *float64 `default:"10000" json:"maxBackoff"`
}

func (o OutputAzureDataExplorerResponseRetrySettings) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputAzureDataExplorerResponseRetrySettings) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputAzureDataExplorerResponseRetrySettings) GetHTTPStatus() float64 {
	if o == nil {
		return 0.0
	}
	return o.HTTPStatus
}

func (o *OutputAzureDataExplorerResponseRetrySettings) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *OutputAzureDataExplorerResponseRetrySettings) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *OutputAzureDataExplorerResponseRetrySettings) GetMaxBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackoff
}

type OutputAzureDataExplorerTimeoutRetrySettings struct {
	// Enable to retry on request timeout
	TimeoutRetry *bool `default:"false" json:"timeoutRetry"`
	// How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"1000" json:"initialBackoff"`
	// Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackoff *float64 `default:"10000" json:"maxBackoff"`
}

func (o OutputAzureDataExplorerTimeoutRetrySettings) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputAzureDataExplorerTimeoutRetrySettings) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputAzureDataExplorerTimeoutRetrySettings) GetTimeoutRetry() *bool {
	if o == nil {
		return nil
	}
	return o.TimeoutRetry
}

func (o *OutputAzureDataExplorerTimeoutRetrySettings) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *OutputAzureDataExplorerTimeoutRetrySettings) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *OutputAzureDataExplorerTimeoutRetrySettings) GetMaxBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackoff
}

// OutputAzureDataExplorerCompress - Choose data compression format to apply to HTTP content before it is delivered.
type OutputAzureDataExplorerCompress string

const (
	OutputAzureDataExplorerCompressNone OutputAzureDataExplorerCompress = "none"
	OutputAzureDataExplorerCompressGzip OutputAzureDataExplorerCompress = "gzip"
)

func (e OutputAzureDataExplorerCompress) ToPointer() *OutputAzureDataExplorerCompress {
	return &e
}
func (e *OutputAzureDataExplorerCompress) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = OutputAzureDataExplorerCompress(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputAzureDataExplorerCompress: %v", v)
	}
}

// OutputAzureDataExplorerCompression - Codec to use to compress the persisted data.
type OutputAzureDataExplorerCompression string

const (
	OutputAzureDataExplorerCompressionNone OutputAzureDataExplorerCompression = "none"
	OutputAzureDataExplorerCompressionGzip OutputAzureDataExplorerCompression = "gzip"
)

func (e OutputAzureDataExplorerCompression) ToPointer() *OutputAzureDataExplorerCompression {
	return &e
}
func (e *OutputAzureDataExplorerCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = OutputAzureDataExplorerCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputAzureDataExplorerCompression: %v", v)
	}
}

// OutputAzureDataExplorerQueueFullBehavior - Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
type OutputAzureDataExplorerQueueFullBehavior string

const (
	OutputAzureDataExplorerQueueFullBehaviorBlock OutputAzureDataExplorerQueueFullBehavior = "block"
	OutputAzureDataExplorerQueueFullBehaviorDrop  OutputAzureDataExplorerQueueFullBehavior = "drop"
)

func (e OutputAzureDataExplorerQueueFullBehavior) ToPointer() *OutputAzureDataExplorerQueueFullBehavior {
	return &e
}
func (e *OutputAzureDataExplorerQueueFullBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputAzureDataExplorerQueueFullBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputAzureDataExplorerQueueFullBehavior: %v", v)
	}
}

// OutputAzureDataExplorerMode - In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
type OutputAzureDataExplorerMode string

const (
	OutputAzureDataExplorerModeError        OutputAzureDataExplorerMode = "error"
	OutputAzureDataExplorerModeBackpressure OutputAzureDataExplorerMode = "backpressure"
	OutputAzureDataExplorerModeAlways       OutputAzureDataExplorerMode = "always"
)

func (e OutputAzureDataExplorerMode) ToPointer() *OutputAzureDataExplorerMode {
	return &e
}
func (e *OutputAzureDataExplorerMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "error":
		fallthrough
	case "backpressure":
		fallthrough
	case "always":
		*e = OutputAzureDataExplorerMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputAzureDataExplorerMode: %v", v)
	}
}

type OutputAzureDataExplorerPqControls struct {
}

type OutputAzureDataExplorer struct {
	// Unique ID for this output
	ID   *string                      `json:"id,omitempty"`
	Type *OutputAzureDataExplorerType `json:"type,omitempty"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// The base URI for your cluster. Typically, `https://<cluster>.<region>.kusto.windows.net`.
	ClusterURL string `json:"clusterUrl"`
	// Name of the database containing the table where data will be ingested.
	Database string `json:"database"`
	// Name of the table to ingest data into.
	Table string `json:"table"`
	// When you save or start the Destination, validates database name and credentials; also validates table name except when creating a new table. Disable if your Azure app does not have both the Database Viewer and the Table Viewer role.
	ValidateDatabaseSettings *bool `default:"true" json:"validateDatabaseSettings"`
	// Method to use for ingesting data.
	IngestMode *IngestionMode `default:"batching" json:"ingestMode"`
	// Endpoint used to acquire authentication tokens from Azure.
	OauthEndpoint *AzureADAuthenticationEndpoint `default:"https://login.microsoftonline.com" json:"oauthEndpoint"`
	// Directory ID (tenant identifier) in Azure Active Directory.
	TenantID string `json:"tenantId"`
	// client_id to pass in the OAuth request parameter.
	ClientID string `json:"clientId"`
	// Scope to pass in the OAuth request parameter.
	Scope string `json:"scope"`
	// The type of OAuth 2.0 client credentials grant flow to use.
	OauthType   *OutputAzureDataExplorerAuthenticationMethod `default:"clientSecret" json:"oauthType"`
	Description *string                                      `json:"description,omitempty"`
	// The client secret that you generated for your app in the Azure portal.
	ClientSecret *string `json:"clientSecret,omitempty"`
	// Select or create a stored text secret
	TextSecret  *string                             `json:"textSecret,omitempty"`
	Certificate *OutputAzureDataExplorerCertificate `json:"certificate,omitempty"`
	// The ingestion service URI for your cluster. Typically, `https://ingest-<cluster>.<region>.kusto.windows.net`.
	IngestURL *string `json:"ingestUrl,omitempty"`
	// Whether to block, drop, or queue events when all receivers are exerting backpressure.
	OnBackpressure *OutputAzureDataExplorerBackpressureBehavior `default:"block" json:"onBackpressure"`
	// Enable if you want to send a (JSON) mapping object instead of specifying an existing named data mapping.
	IsMappingObj *bool `default:"false" json:"isMappingObj"`
	// Format of the output data
	Format *OutputAzureDataExplorerDataFormat `default:"json" json:"format"`
	// Filesystem location in which to buffer files, before compressing and moving to final destination. Use performant stable storage.
	StagePath *string `default:"\\$CRIBL_HOME/state/outputs/staging" json:"stagePath"`
	// JavaScript expression to define the output filename suffix (can be constant).  The `__format` variable refers to the value of the `Data format` field (`json` or `raw`).  The `__compression` field refers to the kind of compression being used (`none` or `gzip`).
	FileNameSuffix *string `default:".\\${C.env[\"CRIBL_WORKER_ID\"]}.\\${__format}\\${__compression === \"gzip\" ? \".gz\" : \"\"}" json:"fileNameSuffix"`
	// Maximum uncompressed output file size. Files of this size will be closed and moved to final output location.
	MaxFileSizeMB *float64 `default:"32" json:"maxFileSizeMB"`
	// Maximum amount of time to write to a file. Files open for longer than this will be closed and moved to final output location.
	MaxFileOpenTimeSec *float64 `default:"300" json:"maxFileOpenTimeSec"`
	// Maximum amount of time to keep inactive files open. Files open for longer than this will be closed and moved to final output location.
	MaxFileIdleTimeSec *float64 `default:"30" json:"maxFileIdleTimeSec"`
	// Maximum number of files to keep open concurrently. When exceeded, @{product} will close the oldest open files and move them to the final output location.
	MaxOpenFiles *float64 `default:"100" json:"maxOpenFiles"`
	// Maximum number of parts to upload in parallel per file.
	MaxConcurrentFileParts *float64 `default:"1" json:"maxConcurrentFileParts"`
	// Whether to block or drop events when disk space is below the global 'Min free disk space' limit
	OnDiskFullBackpressure *OutputAzureDataExplorerDiskSpaceProtection `default:"block" json:"onDiskFullBackpressure"`
	// Append output's ID to staging location
	AddIDToStagePath *bool `default:"true" json:"addIdToStagePath"`
	// Remove empty staging directories after moving files
	RemoveEmptyDirs *bool `default:"true" json:"removeEmptyDirs"`
	// If a file fails to move to its final destination after the maximum number of retries, dead-letter it to prevent further errors.
	DeadletterEnabled *bool `default:"false" json:"deadletterEnabled"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `default:"30" json:"timeoutSec"`
	// Enable to bypass the data management service's aggregation mechanism.
	FlushImmediately *bool `default:"false" json:"flushImmediately"`
	// Enable to prevent blob deletion after ingestion is complete.
	RetainBlobOnSuccess *bool `default:"false" json:"retainBlobOnSuccess"`
	// Strings or tags associated with the extent (ingested data shard).
	ExtentTags []ExtentTags `json:"extentTags,omitempty"`
	// Prevents duplicate ingestion by checking if an extent with the specified ingest-by tag already exists.
	IngestIfNotExists []IngestIfNotExists `json:"ingestIfNotExists,omitempty"`
	// Level of ingestion status reporting. Defaults to FailuresOnly.
	ReportLevel *ReportLevel `default:"failuresOnly" json:"reportLevel"`
	// Target of the ingestion status reporting. Defaults to Queue.
	ReportMethod *ReportMethod `default:"queue" json:"reportMethod"`
	// Optionally, enter additional configuration properties to send to the ingestion service.
	AdditionalProperties []AdditionalProperties `json:"additionalProperties,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable).
	ResponseRetrySettings []OutputAzureDataExplorerResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *OutputAzureDataExplorerTimeoutRetrySettings   `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `default:"false" json:"responseHonorRetryAfterHeader"`
	// Choose data compression format to apply to HTTP content before it is delivered.
	Compress *OutputAzureDataExplorerCompress `default:"gzip" json:"compress"`
	// Enter the name of a data mapping associated with your target table. Or, if incoming event and target table fields match exactly, you can leave the field empty.
	MappingRef *string `json:"mappingRef,omitempty"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `default:"5" json:"concurrency"`
	// Maximum size, in KB, of the request body
	MaxPayloadSizeKB *float64 `default:"4096" json:"maxPayloadSizeKB"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited).
	MaxPayloadEvents *float64 `default:"0" json:"maxPayloadEvents"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Max body size.
	FlushPeriodSec *float64 `default:"1" json:"flushPeriodSec"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Defaults to Yes. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Enables round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `default:"false" json:"useRoundRobinDns"`
	// Disable to close the connection immediately after sending the outgoing request.
	KeepAlive *bool `default:"true" json:"keepAlive"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.).
	PqMaxFileSize *string `default:"1 MB" json:"pqMaxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `default:"5GB" json:"pqMaxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `default:"\\$CRIBL_HOME/state/queues" json:"pqPath"`
	// Codec to use to compress the persisted data.
	PqCompress *OutputAzureDataExplorerCompression `default:"none" json:"pqCompress"`
	// Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *OutputAzureDataExplorerQueueFullBehavior `default:"block" json:"pqOnBackpressure"`
	// In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
	PqMode     *OutputAzureDataExplorerMode       `default:"error" json:"pqMode"`
	PqControls *OutputAzureDataExplorerPqControls `json:"pqControls,omitempty"`
	Status     *TFStatus                          `json:"status,omitempty"`
}

func (o OutputAzureDataExplorer) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputAzureDataExplorer) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *OutputAzureDataExplorer) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *OutputAzureDataExplorer) GetType() *OutputAzureDataExplorerType {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *OutputAzureDataExplorer) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputAzureDataExplorer) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputAzureDataExplorer) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputAzureDataExplorer) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputAzureDataExplorer) GetClusterURL() string {
	if o == nil {
		return ""
	}
	return o.ClusterURL
}

func (o *OutputAzureDataExplorer) GetDatabase() string {
	if o == nil {
		return ""
	}
	return o.Database
}

func (o *OutputAzureDataExplorer) GetTable() string {
	if o == nil {
		return ""
	}
	return o.Table
}

func (o *OutputAzureDataExplorer) GetValidateDatabaseSettings() *bool {
	if o == nil {
		return nil
	}
	return o.ValidateDatabaseSettings
}

func (o *OutputAzureDataExplorer) GetIngestMode() *IngestionMode {
	if o == nil {
		return nil
	}
	return o.IngestMode
}

func (o *OutputAzureDataExplorer) GetOauthEndpoint() *AzureADAuthenticationEndpoint {
	if o == nil {
		return nil
	}
	return o.OauthEndpoint
}

func (o *OutputAzureDataExplorer) GetTenantID() string {
	if o == nil {
		return ""
	}
	return o.TenantID
}

func (o *OutputAzureDataExplorer) GetClientID() string {
	if o == nil {
		return ""
	}
	return o.ClientID
}

func (o *OutputAzureDataExplorer) GetScope() string {
	if o == nil {
		return ""
	}
	return o.Scope
}

func (o *OutputAzureDataExplorer) GetOauthType() *OutputAzureDataExplorerAuthenticationMethod {
	if o == nil {
		return nil
	}
	return o.OauthType
}

func (o *OutputAzureDataExplorer) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputAzureDataExplorer) GetClientSecret() *string {
	if o == nil {
		return nil
	}
	return o.ClientSecret
}

func (o *OutputAzureDataExplorer) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *OutputAzureDataExplorer) GetCertificate() *OutputAzureDataExplorerCertificate {
	if o == nil {
		return nil
	}
	return o.Certificate
}

func (o *OutputAzureDataExplorer) GetIngestURL() *string {
	if o == nil {
		return nil
	}
	return o.IngestURL
}

func (o *OutputAzureDataExplorer) GetOnBackpressure() *OutputAzureDataExplorerBackpressureBehavior {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputAzureDataExplorer) GetIsMappingObj() *bool {
	if o == nil {
		return nil
	}
	return o.IsMappingObj
}

func (o *OutputAzureDataExplorer) GetFormat() *OutputAzureDataExplorerDataFormat {
	if o == nil {
		return nil
	}
	return o.Format
}

func (o *OutputAzureDataExplorer) GetStagePath() *string {
	if o == nil {
		return nil
	}
	return o.StagePath
}

func (o *OutputAzureDataExplorer) GetFileNameSuffix() *string {
	if o == nil {
		return nil
	}
	return o.FileNameSuffix
}

func (o *OutputAzureDataExplorer) GetMaxFileSizeMB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxFileSizeMB
}

func (o *OutputAzureDataExplorer) GetMaxFileOpenTimeSec() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxFileOpenTimeSec
}

func (o *OutputAzureDataExplorer) GetMaxFileIdleTimeSec() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxFileIdleTimeSec
}

func (o *OutputAzureDataExplorer) GetMaxOpenFiles() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxOpenFiles
}

func (o *OutputAzureDataExplorer) GetMaxConcurrentFileParts() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxConcurrentFileParts
}

func (o *OutputAzureDataExplorer) GetOnDiskFullBackpressure() *OutputAzureDataExplorerDiskSpaceProtection {
	if o == nil {
		return nil
	}
	return o.OnDiskFullBackpressure
}

func (o *OutputAzureDataExplorer) GetAddIDToStagePath() *bool {
	if o == nil {
		return nil
	}
	return o.AddIDToStagePath
}

func (o *OutputAzureDataExplorer) GetRemoveEmptyDirs() *bool {
	if o == nil {
		return nil
	}
	return o.RemoveEmptyDirs
}

func (o *OutputAzureDataExplorer) GetDeadletterEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.DeadletterEnabled
}

func (o *OutputAzureDataExplorer) GetTimeoutSec() *float64 {
	if o == nil {
		return nil
	}
	return o.TimeoutSec
}

func (o *OutputAzureDataExplorer) GetFlushImmediately() *bool {
	if o == nil {
		return nil
	}
	return o.FlushImmediately
}

func (o *OutputAzureDataExplorer) GetRetainBlobOnSuccess() *bool {
	if o == nil {
		return nil
	}
	return o.RetainBlobOnSuccess
}

func (o *OutputAzureDataExplorer) GetExtentTags() []ExtentTags {
	if o == nil {
		return nil
	}
	return o.ExtentTags
}

func (o *OutputAzureDataExplorer) GetIngestIfNotExists() []IngestIfNotExists {
	if o == nil {
		return nil
	}
	return o.IngestIfNotExists
}

func (o *OutputAzureDataExplorer) GetReportLevel() *ReportLevel {
	if o == nil {
		return nil
	}
	return o.ReportLevel
}

func (o *OutputAzureDataExplorer) GetReportMethod() *ReportMethod {
	if o == nil {
		return nil
	}
	return o.ReportMethod
}

func (o *OutputAzureDataExplorer) GetAdditionalProperties() []AdditionalProperties {
	if o == nil {
		return nil
	}
	return o.AdditionalProperties
}

func (o *OutputAzureDataExplorer) GetResponseRetrySettings() []OutputAzureDataExplorerResponseRetrySettings {
	if o == nil {
		return nil
	}
	return o.ResponseRetrySettings
}

func (o *OutputAzureDataExplorer) GetTimeoutRetrySettings() *OutputAzureDataExplorerTimeoutRetrySettings {
	if o == nil {
		return nil
	}
	return o.TimeoutRetrySettings
}

func (o *OutputAzureDataExplorer) GetResponseHonorRetryAfterHeader() *bool {
	if o == nil {
		return nil
	}
	return o.ResponseHonorRetryAfterHeader
}

func (o *OutputAzureDataExplorer) GetCompress() *OutputAzureDataExplorerCompress {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *OutputAzureDataExplorer) GetMappingRef() *string {
	if o == nil {
		return nil
	}
	return o.MappingRef
}

func (o *OutputAzureDataExplorer) GetConcurrency() *float64 {
	if o == nil {
		return nil
	}
	return o.Concurrency
}

func (o *OutputAzureDataExplorer) GetMaxPayloadSizeKB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadSizeKB
}

func (o *OutputAzureDataExplorer) GetMaxPayloadEvents() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadEvents
}

func (o *OutputAzureDataExplorer) GetFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushPeriodSec
}

func (o *OutputAzureDataExplorer) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputAzureDataExplorer) GetUseRoundRobinDNS() *bool {
	if o == nil {
		return nil
	}
	return o.UseRoundRobinDNS
}

func (o *OutputAzureDataExplorer) GetKeepAlive() *bool {
	if o == nil {
		return nil
	}
	return o.KeepAlive
}

func (o *OutputAzureDataExplorer) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputAzureDataExplorer) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputAzureDataExplorer) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputAzureDataExplorer) GetPqCompress() *OutputAzureDataExplorerCompression {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputAzureDataExplorer) GetPqOnBackpressure() *OutputAzureDataExplorerQueueFullBehavior {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputAzureDataExplorer) GetPqMode() *OutputAzureDataExplorerMode {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputAzureDataExplorer) GetPqControls() *OutputAzureDataExplorerPqControls {
	if o == nil {
		return nil
	}
	return o.PqControls
}

func (o *OutputAzureDataExplorer) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type OutputAzureBlobType string

const (
	OutputAzureBlobTypeAzureBlob OutputAzureBlobType = "azure_blob"
)

func (e OutputAzureBlobType) ToPointer() *OutputAzureBlobType {
	return &e
}
func (e *OutputAzureBlobType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "azure_blob":
		*e = OutputAzureBlobType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputAzureBlobType: %v", v)
	}
}

// OutputAzureBlobDataFormat - Format of the output data
type OutputAzureBlobDataFormat string

const (
	OutputAzureBlobDataFormatJSON    OutputAzureBlobDataFormat = "json"
	OutputAzureBlobDataFormatRaw     OutputAzureBlobDataFormat = "raw"
	OutputAzureBlobDataFormatParquet OutputAzureBlobDataFormat = "parquet"
)

func (e OutputAzureBlobDataFormat) ToPointer() *OutputAzureBlobDataFormat {
	return &e
}
func (e *OutputAzureBlobDataFormat) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "json":
		fallthrough
	case "raw":
		fallthrough
	case "parquet":
		*e = OutputAzureBlobDataFormat(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputAzureBlobDataFormat: %v", v)
	}
}

// OutputAzureBlobBackpressureBehavior - Whether to block or drop events when all receivers are exerting backpressure
type OutputAzureBlobBackpressureBehavior string

const (
	OutputAzureBlobBackpressureBehaviorBlock OutputAzureBlobBackpressureBehavior = "block"
	OutputAzureBlobBackpressureBehaviorDrop  OutputAzureBlobBackpressureBehavior = "drop"
)

func (e OutputAzureBlobBackpressureBehavior) ToPointer() *OutputAzureBlobBackpressureBehavior {
	return &e
}
func (e *OutputAzureBlobBackpressureBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputAzureBlobBackpressureBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputAzureBlobBackpressureBehavior: %v", v)
	}
}

// OutputAzureBlobDiskSpaceProtection - Whether to block or drop events when disk space is below the global 'Min free disk space' limit
type OutputAzureBlobDiskSpaceProtection string

const (
	OutputAzureBlobDiskSpaceProtectionBlock OutputAzureBlobDiskSpaceProtection = "block"
	OutputAzureBlobDiskSpaceProtectionDrop  OutputAzureBlobDiskSpaceProtection = "drop"
)

func (e OutputAzureBlobDiskSpaceProtection) ToPointer() *OutputAzureBlobDiskSpaceProtection {
	return &e
}
func (e *OutputAzureBlobDiskSpaceProtection) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputAzureBlobDiskSpaceProtection(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputAzureBlobDiskSpaceProtection: %v", v)
	}
}

// OutputAzureBlobAuthenticationMethod - Enter connection string directly, or select a stored secret
type OutputAzureBlobAuthenticationMethod string

const (
	OutputAzureBlobAuthenticationMethodManual       OutputAzureBlobAuthenticationMethod = "manual"
	OutputAzureBlobAuthenticationMethodSecret       OutputAzureBlobAuthenticationMethod = "secret"
	OutputAzureBlobAuthenticationMethodClientSecret OutputAzureBlobAuthenticationMethod = "clientSecret"
	OutputAzureBlobAuthenticationMethodClientCert   OutputAzureBlobAuthenticationMethod = "clientCert"
)

func (e OutputAzureBlobAuthenticationMethod) ToPointer() *OutputAzureBlobAuthenticationMethod {
	return &e
}
func (e *OutputAzureBlobAuthenticationMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "manual":
		fallthrough
	case "secret":
		fallthrough
	case "clientSecret":
		fallthrough
	case "clientCert":
		*e = OutputAzureBlobAuthenticationMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputAzureBlobAuthenticationMethod: %v", v)
	}
}

type BlobAccessTier string

const (
	BlobAccessTierInferred BlobAccessTier = "Inferred"
	BlobAccessTierHot      BlobAccessTier = "Hot"
	BlobAccessTierCool     BlobAccessTier = "Cool"
	BlobAccessTierCold     BlobAccessTier = "Cold"
	BlobAccessTierArchive  BlobAccessTier = "Archive"
)

func (e BlobAccessTier) ToPointer() *BlobAccessTier {
	return &e
}
func (e *BlobAccessTier) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "Inferred":
		fallthrough
	case "Hot":
		fallthrough
	case "Cool":
		fallthrough
	case "Cold":
		fallthrough
	case "Archive":
		*e = BlobAccessTier(v)
		return nil
	default:
		return fmt.Errorf("invalid value for BlobAccessTier: %v", v)
	}
}

// OutputAzureBlobCompress - Choose data compression format to apply before moving files to final destination
type OutputAzureBlobCompress string

const (
	OutputAzureBlobCompressNone OutputAzureBlobCompress = "none"
	OutputAzureBlobCompressGzip OutputAzureBlobCompress = "gzip"
)

func (e OutputAzureBlobCompress) ToPointer() *OutputAzureBlobCompress {
	return &e
}
func (e *OutputAzureBlobCompress) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = OutputAzureBlobCompress(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputAzureBlobCompress: %v", v)
	}
}

// OutputAzureBlobCompressionLevel - Compression level to apply before moving files to final destination
type OutputAzureBlobCompressionLevel string

const (
	OutputAzureBlobCompressionLevelBestSpeed       OutputAzureBlobCompressionLevel = "best_speed"
	OutputAzureBlobCompressionLevelNormal          OutputAzureBlobCompressionLevel = "normal"
	OutputAzureBlobCompressionLevelBestCompression OutputAzureBlobCompressionLevel = "best_compression"
)

func (e OutputAzureBlobCompressionLevel) ToPointer() *OutputAzureBlobCompressionLevel {
	return &e
}
func (e *OutputAzureBlobCompressionLevel) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "best_speed":
		fallthrough
	case "normal":
		fallthrough
	case "best_compression":
		*e = OutputAzureBlobCompressionLevel(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputAzureBlobCompressionLevel: %v", v)
	}
}

// OutputAzureBlobParquetVersion - Determines which data types are supported and how they are represented
type OutputAzureBlobParquetVersion string

const (
	OutputAzureBlobParquetVersionParquet10 OutputAzureBlobParquetVersion = "PARQUET_1_0"
	OutputAzureBlobParquetVersionParquet24 OutputAzureBlobParquetVersion = "PARQUET_2_4"
	OutputAzureBlobParquetVersionParquet26 OutputAzureBlobParquetVersion = "PARQUET_2_6"
)

func (e OutputAzureBlobParquetVersion) ToPointer() *OutputAzureBlobParquetVersion {
	return &e
}
func (e *OutputAzureBlobParquetVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "PARQUET_1_0":
		fallthrough
	case "PARQUET_2_4":
		fallthrough
	case "PARQUET_2_6":
		*e = OutputAzureBlobParquetVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputAzureBlobParquetVersion: %v", v)
	}
}

// OutputAzureBlobDataPageVersion - Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
type OutputAzureBlobDataPageVersion string

const (
	OutputAzureBlobDataPageVersionDataPageV1 OutputAzureBlobDataPageVersion = "DATA_PAGE_V1"
	OutputAzureBlobDataPageVersionDataPageV2 OutputAzureBlobDataPageVersion = "DATA_PAGE_V2"
)

func (e OutputAzureBlobDataPageVersion) ToPointer() *OutputAzureBlobDataPageVersion {
	return &e
}
func (e *OutputAzureBlobDataPageVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "DATA_PAGE_V1":
		fallthrough
	case "DATA_PAGE_V2":
		*e = OutputAzureBlobDataPageVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputAzureBlobDataPageVersion: %v", v)
	}
}

type OutputAzureBlobKeyValueMetadata struct {
	Key   *string `default:"" json:"key"`
	Value string  `json:"value"`
}

func (o OutputAzureBlobKeyValueMetadata) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputAzureBlobKeyValueMetadata) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputAzureBlobKeyValueMetadata) GetKey() *string {
	if o == nil {
		return nil
	}
	return o.Key
}

func (o *OutputAzureBlobKeyValueMetadata) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type OutputAzureBlobCertificate struct {
	// The certificate you registered as credentials for your app in the Azure portal
	CertificateName string `json:"certificateName"`
}

func (o *OutputAzureBlobCertificate) GetCertificateName() string {
	if o == nil {
		return ""
	}
	return o.CertificateName
}

type OutputAzureBlob struct {
	// Unique ID for this output
	ID   *string              `json:"id,omitempty"`
	Type *OutputAzureBlobType `json:"type,omitempty"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// A container organizes a set of blobs, similar to a directory in a file system. Value can be a JavaScript expression enclosed in quotes or backticks. @{product} evaluates the expression at init time. The expression can evaluate to a constant value, and can reference Global Variables, e.g., `myContainer-${C.env["CRIBL_WORKER_ID"]}`
	ContainerName string `json:"containerName"`
	// Creates the configured container in Azure Blob Storage if it does not already exist.
	CreateContainer *bool `default:"false" json:"createContainer"`
	// Root directory prepended to path before uploading. Value can be a JavaScript expression enclosed in quotes or backticks. @{product} evaluates the expression at init time. The expression can evaluate to a constant value, and can reference Global Variables, e.g., `myBlobPrefix-${C.env["CRIBL_WORKER_ID"]}`
	DestPath *string `json:"destPath,omitempty"`
	// Filesystem location in which to buffer files, before compressing and moving to final destination. Use performant stable storage.
	StagePath *string `default:"\\$CRIBL_HOME/state/outputs/staging" json:"stagePath"`
	// Append output's ID to staging location
	AddIDToStagePath *bool `default:"true" json:"addIdToStagePath"`
	// Maximum number of parts to upload in parallel per file.
	MaxConcurrentFileParts *float64 `default:"1" json:"maxConcurrentFileParts"`
	// Remove empty staging directories after moving files
	RemoveEmptyDirs *bool `default:"true" json:"removeEmptyDirs"`
	// JavaScript expression defining how files are partitioned and organized. Default is date-based. If blank, Stream will fall back to the event's __partition field value  if present  otherwise to each location's root directory.
	PartitionExpr *string `default:"C.Time.strftime(_time ? _time : Date.now()/1000, '%Y/%m/%d')" json:"partitionExpr"`
	// Format of the output data
	Format *OutputAzureBlobDataFormat `default:"json" json:"format"`
	// JavaScript expression to define the output filename prefix (can be constant)
	BaseFileName *string `default:"CriblOut" json:"baseFileName"`
	// JavaScript expression to define the output filename suffix (can be constant).  The `__format` variable refers to the value of the `Data format` field (`json` or `raw`).  The `__compression` field refers to the kind of compression being used (`none` or `gzip`).
	FileNameSuffix *string `default:".\\${C.env[\"CRIBL_WORKER_ID\"]}.\\${__format}\\${__compression === \"gzip\" ? \".gz\" : \"\"}" json:"fileNameSuffix"`
	// Maximum uncompressed output file size. Files of this size will be closed and moved to final output location.
	MaxFileSizeMB *float64 `default:"32" json:"maxFileSizeMB"`
	// Maximum amount of time to write to a file. Files open for longer than this will be closed and moved to final output location.
	MaxFileOpenTimeSec *float64 `default:"300" json:"maxFileOpenTimeSec"`
	// Maximum amount of time to keep inactive files open. Files open for longer than this will be closed and moved to final output location.
	MaxFileIdleTimeSec *float64 `default:"30" json:"maxFileIdleTimeSec"`
	// Maximum number of files to keep open concurrently. When exceeded, @{product} will close the oldest open files and move them to the final output location.
	MaxOpenFiles *float64 `default:"100" json:"maxOpenFiles"`
	// If set, this line will be written to the beginning of each output file
	HeaderLine *string `default:"" json:"headerLine"`
	// Buffer size used to write to a file
	WriteHighWaterMark *float64 `default:"64" json:"writeHighWaterMark"`
	// Whether to block or drop events when all receivers are exerting backpressure
	OnBackpressure *OutputAzureBlobBackpressureBehavior `default:"block" json:"onBackpressure"`
	// If a file fails to move to its final destination after the maximum number of retries, dead-letter it to prevent further errors.
	DeadletterEnabled *bool `default:"false" json:"deadletterEnabled"`
	// Whether to block or drop events when disk space is below the global 'Min free disk space' limit
	OnDiskFullBackpressure *OutputAzureBlobDiskSpaceProtection `default:"block" json:"onDiskFullBackpressure"`
	// Enter connection string directly, or select a stored secret
	AuthType     *OutputAzureBlobAuthenticationMethod `default:"manual" json:"authType"`
	StorageClass *BlobAccessTier                      `default:"Inferred" json:"storageClass"`
	Description  *string                              `json:"description,omitempty"`
	// Choose data compression format to apply before moving files to final destination
	Compress *OutputAzureBlobCompress `default:"gzip" json:"compress"`
	// Compression level to apply before moving files to final destination
	CompressionLevel *OutputAzureBlobCompressionLevel `default:"best_speed" json:"compressionLevel"`
	// Automatically calculate the schema based on the events of each Parquet file generated
	AutomaticSchema *bool `default:"false" json:"automaticSchema"`
	// Determines which data types are supported and how they are represented
	ParquetVersion *OutputAzureBlobParquetVersion `default:"PARQUET_2_6" json:"parquetVersion"`
	// Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
	ParquetDataPageVersion *OutputAzureBlobDataPageVersion `default:"DATA_PAGE_V2" json:"parquetDataPageVersion"`
	// The number of rows that every group will contain. The final group can contain a smaller number of rows.
	ParquetRowGroupLength *float64 `default:"10000" json:"parquetRowGroupLength"`
	// Target memory size for page segments, such as 1MB or 128MB. Generally, lower values improve reading speed, while higher values improve compression.
	ParquetPageSize *string `default:"1MB" json:"parquetPageSize"`
	// Log up to 3 rows that @{product} skips due to data mismatch
	ShouldLogInvalidRows *bool `json:"shouldLogInvalidRows,omitempty"`
	// The metadata of files the Destination writes will include the properties you add here as key-value pairs. Useful for tagging, e.g., "key":"OCSF Event Class", "value":"9001".
	KeyValueMetadata []OutputAzureBlobKeyValueMetadata `json:"keyValueMetadata,omitempty"`
	// Statistics profile an entire file in terms of minimum/maximum values within data, numbers of nulls, etc. You can use Parquet tools to view statistics.
	EnableStatistics *bool `default:"true" json:"enableStatistics"`
	// One page index contains statistics for one data page. Parquet readers use statistics to enable page skipping.
	EnableWritePageIndex *bool `default:"true" json:"enableWritePageIndex"`
	// Parquet tools can use the checksum of a Parquet page to verify data integrity
	EnablePageChecksum *bool `default:"false" json:"enablePageChecksum"`
	// How frequently, in seconds, to clean up empty directories when 'Remove empty staging dirs' is enabled
	EmptyDirCleanupSec *float64 `default:"300" json:"emptyDirCleanupSec"`
	// Storage location for files that fail to reach their final destination after maximum retries are exceeded
	DeadletterPath *string `default:"\\$CRIBL_HOME/state/outputs/dead-letter" json:"deadletterPath"`
	// The maximum number of times a file will attempt to move to its final destination before being dead-lettered
	MaxRetryNum *float64 `default:"20" json:"maxRetryNum"`
	// Enter your Azure Storage account connection string. If left blank, Stream will fall back to env.AZURE_STORAGE_CONNECTION_STRING.
	ConnectionString *string `json:"connectionString,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// The name of your Azure storage account
	StorageAccountName *string `json:"storageAccountName,omitempty"`
	// The service principal's tenant ID
	TenantID *string `json:"tenantId,omitempty"`
	// The service principal's client ID
	ClientID *string `json:"clientId,omitempty"`
	// Endpoint suffix for the service URL. Defaults to core.windows.net.
	EndpointSuffix *string `json:"endpointSuffix,omitempty"`
	// Select or create a stored text secret
	ClientTextSecret *string                     `json:"clientTextSecret,omitempty"`
	Certificate      *OutputAzureBlobCertificate `json:"certificate,omitempty"`
	Status           *TFStatus                   `json:"status,omitempty"`
}

func (o OutputAzureBlob) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputAzureBlob) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *OutputAzureBlob) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *OutputAzureBlob) GetType() *OutputAzureBlobType {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *OutputAzureBlob) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputAzureBlob) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputAzureBlob) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputAzureBlob) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputAzureBlob) GetContainerName() string {
	if o == nil {
		return ""
	}
	return o.ContainerName
}

func (o *OutputAzureBlob) GetCreateContainer() *bool {
	if o == nil {
		return nil
	}
	return o.CreateContainer
}

func (o *OutputAzureBlob) GetDestPath() *string {
	if o == nil {
		return nil
	}
	return o.DestPath
}

func (o *OutputAzureBlob) GetStagePath() *string {
	if o == nil {
		return nil
	}
	return o.StagePath
}

func (o *OutputAzureBlob) GetAddIDToStagePath() *bool {
	if o == nil {
		return nil
	}
	return o.AddIDToStagePath
}

func (o *OutputAzureBlob) GetMaxConcurrentFileParts() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxConcurrentFileParts
}

func (o *OutputAzureBlob) GetRemoveEmptyDirs() *bool {
	if o == nil {
		return nil
	}
	return o.RemoveEmptyDirs
}

func (o *OutputAzureBlob) GetPartitionExpr() *string {
	if o == nil {
		return nil
	}
	return o.PartitionExpr
}

func (o *OutputAzureBlob) GetFormat() *OutputAzureBlobDataFormat {
	if o == nil {
		return nil
	}
	return o.Format
}

func (o *OutputAzureBlob) GetBaseFileName() *string {
	if o == nil {
		return nil
	}
	return o.BaseFileName
}

func (o *OutputAzureBlob) GetFileNameSuffix() *string {
	if o == nil {
		return nil
	}
	return o.FileNameSuffix
}

func (o *OutputAzureBlob) GetMaxFileSizeMB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxFileSizeMB
}

func (o *OutputAzureBlob) GetMaxFileOpenTimeSec() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxFileOpenTimeSec
}

func (o *OutputAzureBlob) GetMaxFileIdleTimeSec() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxFileIdleTimeSec
}

func (o *OutputAzureBlob) GetMaxOpenFiles() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxOpenFiles
}

func (o *OutputAzureBlob) GetHeaderLine() *string {
	if o == nil {
		return nil
	}
	return o.HeaderLine
}

func (o *OutputAzureBlob) GetWriteHighWaterMark() *float64 {
	if o == nil {
		return nil
	}
	return o.WriteHighWaterMark
}

func (o *OutputAzureBlob) GetOnBackpressure() *OutputAzureBlobBackpressureBehavior {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputAzureBlob) GetDeadletterEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.DeadletterEnabled
}

func (o *OutputAzureBlob) GetOnDiskFullBackpressure() *OutputAzureBlobDiskSpaceProtection {
	if o == nil {
		return nil
	}
	return o.OnDiskFullBackpressure
}

func (o *OutputAzureBlob) GetAuthType() *OutputAzureBlobAuthenticationMethod {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *OutputAzureBlob) GetStorageClass() *BlobAccessTier {
	if o == nil {
		return nil
	}
	return o.StorageClass
}

func (o *OutputAzureBlob) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputAzureBlob) GetCompress() *OutputAzureBlobCompress {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *OutputAzureBlob) GetCompressionLevel() *OutputAzureBlobCompressionLevel {
	if o == nil {
		return nil
	}
	return o.CompressionLevel
}

func (o *OutputAzureBlob) GetAutomaticSchema() *bool {
	if o == nil {
		return nil
	}
	return o.AutomaticSchema
}

func (o *OutputAzureBlob) GetParquetVersion() *OutputAzureBlobParquetVersion {
	if o == nil {
		return nil
	}
	return o.ParquetVersion
}

func (o *OutputAzureBlob) GetParquetDataPageVersion() *OutputAzureBlobDataPageVersion {
	if o == nil {
		return nil
	}
	return o.ParquetDataPageVersion
}

func (o *OutputAzureBlob) GetParquetRowGroupLength() *float64 {
	if o == nil {
		return nil
	}
	return o.ParquetRowGroupLength
}

func (o *OutputAzureBlob) GetParquetPageSize() *string {
	if o == nil {
		return nil
	}
	return o.ParquetPageSize
}

func (o *OutputAzureBlob) GetShouldLogInvalidRows() *bool {
	if o == nil {
		return nil
	}
	return o.ShouldLogInvalidRows
}

func (o *OutputAzureBlob) GetKeyValueMetadata() []OutputAzureBlobKeyValueMetadata {
	if o == nil {
		return nil
	}
	return o.KeyValueMetadata
}

func (o *OutputAzureBlob) GetEnableStatistics() *bool {
	if o == nil {
		return nil
	}
	return o.EnableStatistics
}

func (o *OutputAzureBlob) GetEnableWritePageIndex() *bool {
	if o == nil {
		return nil
	}
	return o.EnableWritePageIndex
}

func (o *OutputAzureBlob) GetEnablePageChecksum() *bool {
	if o == nil {
		return nil
	}
	return o.EnablePageChecksum
}

func (o *OutputAzureBlob) GetEmptyDirCleanupSec() *float64 {
	if o == nil {
		return nil
	}
	return o.EmptyDirCleanupSec
}

func (o *OutputAzureBlob) GetDeadletterPath() *string {
	if o == nil {
		return nil
	}
	return o.DeadletterPath
}

func (o *OutputAzureBlob) GetMaxRetryNum() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxRetryNum
}

func (o *OutputAzureBlob) GetConnectionString() *string {
	if o == nil {
		return nil
	}
	return o.ConnectionString
}

func (o *OutputAzureBlob) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *OutputAzureBlob) GetStorageAccountName() *string {
	if o == nil {
		return nil
	}
	return o.StorageAccountName
}

func (o *OutputAzureBlob) GetTenantID() *string {
	if o == nil {
		return nil
	}
	return o.TenantID
}

func (o *OutputAzureBlob) GetClientID() *string {
	if o == nil {
		return nil
	}
	return o.ClientID
}

func (o *OutputAzureBlob) GetEndpointSuffix() *string {
	if o == nil {
		return nil
	}
	return o.EndpointSuffix
}

func (o *OutputAzureBlob) GetClientTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.ClientTextSecret
}

func (o *OutputAzureBlob) GetCertificate() *OutputAzureBlobCertificate {
	if o == nil {
		return nil
	}
	return o.Certificate
}

func (o *OutputAzureBlob) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type OutputS3Type string

const (
	OutputS3TypeS3 OutputS3Type = "s3"
)

func (e OutputS3Type) ToPointer() *OutputS3Type {
	return &e
}
func (e *OutputS3Type) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "s3":
		*e = OutputS3Type(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputS3Type: %v", v)
	}
}

// OutputS3AuthenticationMethod - AWS authentication method. Choose Auto to use IAM roles.
type OutputS3AuthenticationMethod string

const (
	OutputS3AuthenticationMethodAuto   OutputS3AuthenticationMethod = "auto"
	OutputS3AuthenticationMethodManual OutputS3AuthenticationMethod = "manual"
	OutputS3AuthenticationMethodSecret OutputS3AuthenticationMethod = "secret"
)

func (e OutputS3AuthenticationMethod) ToPointer() *OutputS3AuthenticationMethod {
	return &e
}
func (e *OutputS3AuthenticationMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "auto":
		fallthrough
	case "manual":
		fallthrough
	case "secret":
		*e = OutputS3AuthenticationMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputS3AuthenticationMethod: %v", v)
	}
}

// OutputS3SignatureVersion - Signature version to use for signing S3 requests
type OutputS3SignatureVersion string

const (
	OutputS3SignatureVersionV2 OutputS3SignatureVersion = "v2"
	OutputS3SignatureVersionV4 OutputS3SignatureVersion = "v4"
)

func (e OutputS3SignatureVersion) ToPointer() *OutputS3SignatureVersion {
	return &e
}
func (e *OutputS3SignatureVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "v2":
		fallthrough
	case "v4":
		*e = OutputS3SignatureVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputS3SignatureVersion: %v", v)
	}
}

// ObjectACL - Object ACL to assign to uploaded objects.
type ObjectACL string

const (
	ObjectACLPrivate                ObjectACL = "private"
	ObjectACLPublicRead             ObjectACL = "public-read"
	ObjectACLPublicReadWrite        ObjectACL = "public-read-write"
	ObjectACLAuthenticatedRead      ObjectACL = "authenticated-read"
	ObjectACLAwsExecRead            ObjectACL = "aws-exec-read"
	ObjectACLBucketOwnerRead        ObjectACL = "bucket-owner-read"
	ObjectACLBucketOwnerFullControl ObjectACL = "bucket-owner-full-control"
)

func (e ObjectACL) ToPointer() *ObjectACL {
	return &e
}
func (e *ObjectACL) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "private":
		fallthrough
	case "public-read":
		fallthrough
	case "public-read-write":
		fallthrough
	case "authenticated-read":
		fallthrough
	case "aws-exec-read":
		fallthrough
	case "bucket-owner-read":
		fallthrough
	case "bucket-owner-full-control":
		*e = ObjectACL(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ObjectACL: %v", v)
	}
}

// StorageClass - Storage class to select for uploaded objects.
type StorageClass string

const (
	StorageClassStandard           StorageClass = "STANDARD"
	StorageClassReducedRedundancy  StorageClass = "REDUCED_REDUNDANCY"
	StorageClassStandardIa         StorageClass = "STANDARD_IA"
	StorageClassOnezoneIa          StorageClass = "ONEZONE_IA"
	StorageClassIntelligentTiering StorageClass = "INTELLIGENT_TIERING"
	StorageClassGlacier            StorageClass = "GLACIER"
	StorageClassGlacierIr          StorageClass = "GLACIER_IR"
	StorageClassDeepArchive        StorageClass = "DEEP_ARCHIVE"
)

func (e StorageClass) ToPointer() *StorageClass {
	return &e
}
func (e *StorageClass) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "STANDARD":
		fallthrough
	case "REDUCED_REDUNDANCY":
		fallthrough
	case "STANDARD_IA":
		fallthrough
	case "ONEZONE_IA":
		fallthrough
	case "INTELLIGENT_TIERING":
		fallthrough
	case "GLACIER":
		fallthrough
	case "GLACIER_IR":
		fallthrough
	case "DEEP_ARCHIVE":
		*e = StorageClass(v)
		return nil
	default:
		return fmt.Errorf("invalid value for StorageClass: %v", v)
	}
}

// ServerSideEncryption - Server-side encryption for uploaded objects.
type ServerSideEncryption string

const (
	ServerSideEncryptionAes256 ServerSideEncryption = "AES256"
	ServerSideEncryptionAwsKms ServerSideEncryption = "aws:kms"
)

func (e ServerSideEncryption) ToPointer() *ServerSideEncryption {
	return &e
}
func (e *ServerSideEncryption) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "AES256":
		fallthrough
	case "aws:kms":
		*e = ServerSideEncryption(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ServerSideEncryption: %v", v)
	}
}

// OutputS3DataFormat - Format of the output data
type OutputS3DataFormat string

const (
	OutputS3DataFormatJSON    OutputS3DataFormat = "json"
	OutputS3DataFormatRaw     OutputS3DataFormat = "raw"
	OutputS3DataFormatParquet OutputS3DataFormat = "parquet"
)

func (e OutputS3DataFormat) ToPointer() *OutputS3DataFormat {
	return &e
}
func (e *OutputS3DataFormat) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "json":
		fallthrough
	case "raw":
		fallthrough
	case "parquet":
		*e = OutputS3DataFormat(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputS3DataFormat: %v", v)
	}
}

// OutputS3BackpressureBehavior - Whether to block or drop events when all receivers are exerting backpressure
type OutputS3BackpressureBehavior string

const (
	OutputS3BackpressureBehaviorBlock OutputS3BackpressureBehavior = "block"
	OutputS3BackpressureBehaviorDrop  OutputS3BackpressureBehavior = "drop"
)

func (e OutputS3BackpressureBehavior) ToPointer() *OutputS3BackpressureBehavior {
	return &e
}
func (e *OutputS3BackpressureBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputS3BackpressureBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputS3BackpressureBehavior: %v", v)
	}
}

// OutputS3DiskSpaceProtection - Whether to block or drop events when disk space is below the global 'Min free disk space' limit
type OutputS3DiskSpaceProtection string

const (
	OutputS3DiskSpaceProtectionBlock OutputS3DiskSpaceProtection = "block"
	OutputS3DiskSpaceProtectionDrop  OutputS3DiskSpaceProtection = "drop"
)

func (e OutputS3DiskSpaceProtection) ToPointer() *OutputS3DiskSpaceProtection {
	return &e
}
func (e *OutputS3DiskSpaceProtection) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputS3DiskSpaceProtection(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputS3DiskSpaceProtection: %v", v)
	}
}

// OutputS3Compress - Choose data compression format to apply before moving files to final destination
type OutputS3Compress string

const (
	OutputS3CompressNone OutputS3Compress = "none"
	OutputS3CompressGzip OutputS3Compress = "gzip"
)

func (e OutputS3Compress) ToPointer() *OutputS3Compress {
	return &e
}
func (e *OutputS3Compress) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = OutputS3Compress(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputS3Compress: %v", v)
	}
}

// OutputS3CompressionLevel - Compression level to apply before moving files to final destination
type OutputS3CompressionLevel string

const (
	OutputS3CompressionLevelBestSpeed       OutputS3CompressionLevel = "best_speed"
	OutputS3CompressionLevelNormal          OutputS3CompressionLevel = "normal"
	OutputS3CompressionLevelBestCompression OutputS3CompressionLevel = "best_compression"
)

func (e OutputS3CompressionLevel) ToPointer() *OutputS3CompressionLevel {
	return &e
}
func (e *OutputS3CompressionLevel) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "best_speed":
		fallthrough
	case "normal":
		fallthrough
	case "best_compression":
		*e = OutputS3CompressionLevel(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputS3CompressionLevel: %v", v)
	}
}

// OutputS3ParquetVersion - Determines which data types are supported and how they are represented
type OutputS3ParquetVersion string

const (
	OutputS3ParquetVersionParquet10 OutputS3ParquetVersion = "PARQUET_1_0"
	OutputS3ParquetVersionParquet24 OutputS3ParquetVersion = "PARQUET_2_4"
	OutputS3ParquetVersionParquet26 OutputS3ParquetVersion = "PARQUET_2_6"
)

func (e OutputS3ParquetVersion) ToPointer() *OutputS3ParquetVersion {
	return &e
}
func (e *OutputS3ParquetVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "PARQUET_1_0":
		fallthrough
	case "PARQUET_2_4":
		fallthrough
	case "PARQUET_2_6":
		*e = OutputS3ParquetVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputS3ParquetVersion: %v", v)
	}
}

// OutputS3DataPageVersion - Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
type OutputS3DataPageVersion string

const (
	OutputS3DataPageVersionDataPageV1 OutputS3DataPageVersion = "DATA_PAGE_V1"
	OutputS3DataPageVersionDataPageV2 OutputS3DataPageVersion = "DATA_PAGE_V2"
)

func (e OutputS3DataPageVersion) ToPointer() *OutputS3DataPageVersion {
	return &e
}
func (e *OutputS3DataPageVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "DATA_PAGE_V1":
		fallthrough
	case "DATA_PAGE_V2":
		*e = OutputS3DataPageVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputS3DataPageVersion: %v", v)
	}
}

type OutputS3KeyValueMetadata struct {
	Key   *string `default:"" json:"key"`
	Value string  `json:"value"`
}

func (o OutputS3KeyValueMetadata) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputS3KeyValueMetadata) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputS3KeyValueMetadata) GetKey() *string {
	if o == nil {
		return nil
	}
	return o.Key
}

func (o *OutputS3KeyValueMetadata) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type OutputS3 struct {
	// Unique ID for this output
	ID   *string       `json:"id,omitempty"`
	Type *OutputS3Type `json:"type,omitempty"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Name of the destination S3 bucket. Must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at init time. E.g., referencing a Global Variable: `myBucket-${C.vars.myVar}`.
	Bucket string `json:"bucket"`
	// Region where the S3 bucket is located.
	Region *string `json:"region,omitempty"`
	// Secret key. This value can be a constant or a JavaScript expression(e.g., `${C.env.SOME_SECRET}`).
	AwsSecretKey *string `json:"awsSecretKey,omitempty"`
	// AWS authentication method. Choose Auto to use IAM roles.
	AwsAuthenticationMethod *OutputS3AuthenticationMethod `default:"auto" json:"awsAuthenticationMethod"`
	// S3 service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to S3-compatible endpoint.
	Endpoint *string `json:"endpoint,omitempty"`
	// Signature version to use for signing S3 requests
	SignatureVersion *OutputS3SignatureVersion `default:"v4" json:"signatureVersion"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `default:"true" json:"reuseConnections"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Use Assume Role credentials to access S3
	EnableAssumeRole *bool `default:"false" json:"enableAssumeRole"`
	// Amazon Resource Name (ARN) of the role to assume
	AssumeRoleArn *string `json:"assumeRoleArn,omitempty"`
	// External ID to use when assuming role
	AssumeRoleExternalID *string `json:"assumeRoleExternalId,omitempty"`
	// Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
	DurationSeconds *float64 `default:"3600" json:"durationSeconds"`
	// Filesystem location in which to buffer files, before compressing and moving to final destination. Use performant stable storage.
	StagePath *string `default:"\\$CRIBL_HOME/state/outputs/staging" json:"stagePath"`
	// Append output's ID to staging location
	AddIDToStagePath *bool `default:"true" json:"addIdToStagePath"`
	// Prefix to append to files before uploading. Must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at init time. E.g., referencing a Global Variable: `myKeyPrefix-${C.vars.myVar}`.
	DestPath *string `default:"" json:"destPath"`
	// Object ACL to assign to uploaded objects.
	ObjectACL *ObjectACL `default:"private" json:"objectACL"`
	// Storage class to select for uploaded objects.
	StorageClass *StorageClass `json:"storageClass,omitempty"`
	// Server-side encryption for uploaded objects.
	ServerSideEncryption *ServerSideEncryption `json:"serverSideEncryption,omitempty"`
	// ID or ARN of the KMS customer-managed key to use for encryption
	KmsKeyID *string `json:"kmsKeyId,omitempty"`
	// Remove empty staging directories after moving files
	RemoveEmptyDirs *bool `default:"true" json:"removeEmptyDirs"`
	// JavaScript expression defining how files are partitioned and organized. Default is date-based. If blank, Stream will fall back to the event's __partition field value  if present  otherwise to each location's root directory.
	PartitionExpr *string `default:"C.Time.strftime(_time ? _time : Date.now()/1000, '%Y/%m/%d')" json:"partitionExpr"`
	// Format of the output data
	Format *OutputS3DataFormat `default:"json" json:"format"`
	// JavaScript expression to define the output filename prefix (can be constant)
	BaseFileName *string `default:"CriblOut" json:"baseFileName"`
	// JavaScript expression to define the output filename suffix (can be constant).  The `__format` variable refers to the value of the `Data format` field (`json` or `raw`).  The `__compression` field refers to the kind of compression being used (`none` or `gzip`).
	FileNameSuffix *string `default:".\\${C.env[\"CRIBL_WORKER_ID\"]}.\\${__format}\\${__compression === \"gzip\" ? \".gz\" : \"\"}" json:"fileNameSuffix"`
	// Maximum uncompressed output file size. Files of this size will be closed and moved to final output location.
	MaxFileSizeMB *float64 `default:"32" json:"maxFileSizeMB"`
	// Maximum number of files to keep open concurrently. When exceeded, @{product} will close the oldest open files and move them to the final output location.
	MaxOpenFiles *float64 `default:"100" json:"maxOpenFiles"`
	// If set, this line will be written to the beginning of each output file
	HeaderLine *string `default:"" json:"headerLine"`
	// Buffer size used to write to a file
	WriteHighWaterMark *float64 `default:"64" json:"writeHighWaterMark"`
	// Whether to block or drop events when all receivers are exerting backpressure
	OnBackpressure *OutputS3BackpressureBehavior `default:"block" json:"onBackpressure"`
	// If a file fails to move to its final destination after the maximum number of retries, dead-letter it to prevent further errors.
	DeadletterEnabled *bool `default:"false" json:"deadletterEnabled"`
	// Whether to block or drop events when disk space is below the global 'Min free disk space' limit
	OnDiskFullBackpressure *OutputS3DiskSpaceProtection `default:"block" json:"onDiskFullBackpressure"`
	// Maximum amount of time to write to a file. Files open for longer than this will be closed and moved to final output location.
	MaxFileOpenTimeSec *float64 `default:"300" json:"maxFileOpenTimeSec"`
	// Maximum amount of time to keep inactive files open. Files open for longer than this will be closed and moved to final output location.
	MaxFileIdleTimeSec *float64 `default:"30" json:"maxFileIdleTimeSec"`
	// Maximum number of parts to upload in parallel per file. Minimum part size is 5MB.
	MaxConcurrentFileParts *float64 `default:"4" json:"maxConcurrentFileParts"`
	// Disable if you can access files within the bucket but not the bucket itself.
	VerifyPermissions *bool `default:"true" json:"verifyPermissions"`
	// Maximum number of files that can be waiting for upload before backpressure is applied
	MaxClosingFilesToBackpressure *float64 `default:"100" json:"maxClosingFilesToBackpressure"`
	Description                   *string  `json:"description,omitempty"`
	// This value can be a constant or a JavaScript expression (`${C.env.SOME_ACCESS_KEY}`)
	AwsAPIKey *string `json:"awsApiKey,omitempty"`
	// Select or create a stored secret that references your access key and secret key
	AwsSecret *string `json:"awsSecret,omitempty"`
	// Choose data compression format to apply before moving files to final destination
	Compress *OutputS3Compress `default:"gzip" json:"compress"`
	// Compression level to apply before moving files to final destination
	CompressionLevel *OutputS3CompressionLevel `default:"best_speed" json:"compressionLevel"`
	// Automatically calculate the schema based on the events of each Parquet file generated
	AutomaticSchema *bool `default:"false" json:"automaticSchema"`
	// Determines which data types are supported and how they are represented
	ParquetVersion *OutputS3ParquetVersion `default:"PARQUET_2_6" json:"parquetVersion"`
	// Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
	ParquetDataPageVersion *OutputS3DataPageVersion `default:"DATA_PAGE_V2" json:"parquetDataPageVersion"`
	// The number of rows that every group will contain. The final group can contain a smaller number of rows.
	ParquetRowGroupLength *float64 `default:"10000" json:"parquetRowGroupLength"`
	// Target memory size for page segments, such as 1MB or 128MB. Generally, lower values improve reading speed, while higher values improve compression.
	ParquetPageSize *string `default:"1MB" json:"parquetPageSize"`
	// Log up to 3 rows that @{product} skips due to data mismatch
	ShouldLogInvalidRows *bool `json:"shouldLogInvalidRows,omitempty"`
	// The metadata of files the Destination writes will include the properties you add here as key-value pairs. Useful for tagging, e.g., "key":"OCSF Event Class", "value":"9001".
	KeyValueMetadata []OutputS3KeyValueMetadata `json:"keyValueMetadata,omitempty"`
	// Statistics profile an entire file in terms of minimum/maximum values within data, numbers of nulls, etc. You can use Parquet tools to view statistics.
	EnableStatistics *bool `default:"true" json:"enableStatistics"`
	// One page index contains statistics for one data page. Parquet readers use statistics to enable page skipping.
	EnableWritePageIndex *bool `default:"true" json:"enableWritePageIndex"`
	// Parquet tools can use the checksum of a Parquet page to verify data integrity
	EnablePageChecksum *bool `default:"false" json:"enablePageChecksum"`
	// How frequently, in seconds, to clean up empty directories when 'Remove empty staging dirs' is enabled
	EmptyDirCleanupSec *float64 `default:"300" json:"emptyDirCleanupSec"`
	// Storage location for files that fail to reach their final destination after maximum retries are exceeded
	DeadletterPath *string `default:"\\$CRIBL_HOME/state/outputs/dead-letter" json:"deadletterPath"`
	// The maximum number of times a file will attempt to move to its final destination before being dead-lettered
	MaxRetryNum *float64  `default:"20" json:"maxRetryNum"`
	Status      *TFStatus `json:"status,omitempty"`
}

func (o OutputS3) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputS3) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *OutputS3) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *OutputS3) GetType() *OutputS3Type {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *OutputS3) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputS3) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputS3) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputS3) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputS3) GetBucket() string {
	if o == nil {
		return ""
	}
	return o.Bucket
}

func (o *OutputS3) GetRegion() *string {
	if o == nil {
		return nil
	}
	return o.Region
}

func (o *OutputS3) GetAwsSecretKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecretKey
}

func (o *OutputS3) GetAwsAuthenticationMethod() *OutputS3AuthenticationMethod {
	if o == nil {
		return nil
	}
	return o.AwsAuthenticationMethod
}

func (o *OutputS3) GetEndpoint() *string {
	if o == nil {
		return nil
	}
	return o.Endpoint
}

func (o *OutputS3) GetSignatureVersion() *OutputS3SignatureVersion {
	if o == nil {
		return nil
	}
	return o.SignatureVersion
}

func (o *OutputS3) GetReuseConnections() *bool {
	if o == nil {
		return nil
	}
	return o.ReuseConnections
}

func (o *OutputS3) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputS3) GetEnableAssumeRole() *bool {
	if o == nil {
		return nil
	}
	return o.EnableAssumeRole
}

func (o *OutputS3) GetAssumeRoleArn() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleArn
}

func (o *OutputS3) GetAssumeRoleExternalID() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleExternalID
}

func (o *OutputS3) GetDurationSeconds() *float64 {
	if o == nil {
		return nil
	}
	return o.DurationSeconds
}

func (o *OutputS3) GetStagePath() *string {
	if o == nil {
		return nil
	}
	return o.StagePath
}

func (o *OutputS3) GetAddIDToStagePath() *bool {
	if o == nil {
		return nil
	}
	return o.AddIDToStagePath
}

func (o *OutputS3) GetDestPath() *string {
	if o == nil {
		return nil
	}
	return o.DestPath
}

func (o *OutputS3) GetObjectACL() *ObjectACL {
	if o == nil {
		return nil
	}
	return o.ObjectACL
}

func (o *OutputS3) GetStorageClass() *StorageClass {
	if o == nil {
		return nil
	}
	return o.StorageClass
}

func (o *OutputS3) GetServerSideEncryption() *ServerSideEncryption {
	if o == nil {
		return nil
	}
	return o.ServerSideEncryption
}

func (o *OutputS3) GetKmsKeyID() *string {
	if o == nil {
		return nil
	}
	return o.KmsKeyID
}

func (o *OutputS3) GetRemoveEmptyDirs() *bool {
	if o == nil {
		return nil
	}
	return o.RemoveEmptyDirs
}

func (o *OutputS3) GetPartitionExpr() *string {
	if o == nil {
		return nil
	}
	return o.PartitionExpr
}

func (o *OutputS3) GetFormat() *OutputS3DataFormat {
	if o == nil {
		return nil
	}
	return o.Format
}

func (o *OutputS3) GetBaseFileName() *string {
	if o == nil {
		return nil
	}
	return o.BaseFileName
}

func (o *OutputS3) GetFileNameSuffix() *string {
	if o == nil {
		return nil
	}
	return o.FileNameSuffix
}

func (o *OutputS3) GetMaxFileSizeMB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxFileSizeMB
}

func (o *OutputS3) GetMaxOpenFiles() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxOpenFiles
}

func (o *OutputS3) GetHeaderLine() *string {
	if o == nil {
		return nil
	}
	return o.HeaderLine
}

func (o *OutputS3) GetWriteHighWaterMark() *float64 {
	if o == nil {
		return nil
	}
	return o.WriteHighWaterMark
}

func (o *OutputS3) GetOnBackpressure() *OutputS3BackpressureBehavior {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputS3) GetDeadletterEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.DeadletterEnabled
}

func (o *OutputS3) GetOnDiskFullBackpressure() *OutputS3DiskSpaceProtection {
	if o == nil {
		return nil
	}
	return o.OnDiskFullBackpressure
}

func (o *OutputS3) GetMaxFileOpenTimeSec() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxFileOpenTimeSec
}

func (o *OutputS3) GetMaxFileIdleTimeSec() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxFileIdleTimeSec
}

func (o *OutputS3) GetMaxConcurrentFileParts() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxConcurrentFileParts
}

func (o *OutputS3) GetVerifyPermissions() *bool {
	if o == nil {
		return nil
	}
	return o.VerifyPermissions
}

func (o *OutputS3) GetMaxClosingFilesToBackpressure() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxClosingFilesToBackpressure
}

func (o *OutputS3) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputS3) GetAwsAPIKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsAPIKey
}

func (o *OutputS3) GetAwsSecret() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecret
}

func (o *OutputS3) GetCompress() *OutputS3Compress {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *OutputS3) GetCompressionLevel() *OutputS3CompressionLevel {
	if o == nil {
		return nil
	}
	return o.CompressionLevel
}

func (o *OutputS3) GetAutomaticSchema() *bool {
	if o == nil {
		return nil
	}
	return o.AutomaticSchema
}

func (o *OutputS3) GetParquetVersion() *OutputS3ParquetVersion {
	if o == nil {
		return nil
	}
	return o.ParquetVersion
}

func (o *OutputS3) GetParquetDataPageVersion() *OutputS3DataPageVersion {
	if o == nil {
		return nil
	}
	return o.ParquetDataPageVersion
}

func (o *OutputS3) GetParquetRowGroupLength() *float64 {
	if o == nil {
		return nil
	}
	return o.ParquetRowGroupLength
}

func (o *OutputS3) GetParquetPageSize() *string {
	if o == nil {
		return nil
	}
	return o.ParquetPageSize
}

func (o *OutputS3) GetShouldLogInvalidRows() *bool {
	if o == nil {
		return nil
	}
	return o.ShouldLogInvalidRows
}

func (o *OutputS3) GetKeyValueMetadata() []OutputS3KeyValueMetadata {
	if o == nil {
		return nil
	}
	return o.KeyValueMetadata
}

func (o *OutputS3) GetEnableStatistics() *bool {
	if o == nil {
		return nil
	}
	return o.EnableStatistics
}

func (o *OutputS3) GetEnableWritePageIndex() *bool {
	if o == nil {
		return nil
	}
	return o.EnableWritePageIndex
}

func (o *OutputS3) GetEnablePageChecksum() *bool {
	if o == nil {
		return nil
	}
	return o.EnablePageChecksum
}

func (o *OutputS3) GetEmptyDirCleanupSec() *float64 {
	if o == nil {
		return nil
	}
	return o.EmptyDirCleanupSec
}

func (o *OutputS3) GetDeadletterPath() *string {
	if o == nil {
		return nil
	}
	return o.DeadletterPath
}

func (o *OutputS3) GetMaxRetryNum() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxRetryNum
}

func (o *OutputS3) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type OutputFilesystemType string

const (
	OutputFilesystemTypeFilesystem OutputFilesystemType = "filesystem"
)

func (e OutputFilesystemType) ToPointer() *OutputFilesystemType {
	return &e
}
func (e *OutputFilesystemType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "filesystem":
		*e = OutputFilesystemType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputFilesystemType: %v", v)
	}
}

// DataFormat - Format of the output data
type DataFormat string

const (
	DataFormatJSON    DataFormat = "json"
	DataFormatRaw     DataFormat = "raw"
	DataFormatParquet DataFormat = "parquet"
)

func (e DataFormat) ToPointer() *DataFormat {
	return &e
}
func (e *DataFormat) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "json":
		fallthrough
	case "raw":
		fallthrough
	case "parquet":
		*e = DataFormat(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DataFormat: %v", v)
	}
}

// OutputFilesystemBackpressureBehavior - Whether to block or drop events when all receivers are exerting backpressure
type OutputFilesystemBackpressureBehavior string

const (
	OutputFilesystemBackpressureBehaviorBlock OutputFilesystemBackpressureBehavior = "block"
	OutputFilesystemBackpressureBehaviorDrop  OutputFilesystemBackpressureBehavior = "drop"
)

func (e OutputFilesystemBackpressureBehavior) ToPointer() *OutputFilesystemBackpressureBehavior {
	return &e
}
func (e *OutputFilesystemBackpressureBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputFilesystemBackpressureBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputFilesystemBackpressureBehavior: %v", v)
	}
}

// DiskSpaceProtection - Whether to block or drop events when disk space is below the global 'Min free disk space' limit
type DiskSpaceProtection string

const (
	DiskSpaceProtectionBlock DiskSpaceProtection = "block"
	DiskSpaceProtectionDrop  DiskSpaceProtection = "drop"
)

func (e DiskSpaceProtection) ToPointer() *DiskSpaceProtection {
	return &e
}
func (e *DiskSpaceProtection) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = DiskSpaceProtection(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DiskSpaceProtection: %v", v)
	}
}

// Compress - Choose data compression format to apply before moving files to final destination
type Compress string

const (
	CompressNone Compress = "none"
	CompressGzip Compress = "gzip"
)

func (e Compress) ToPointer() *Compress {
	return &e
}
func (e *Compress) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = Compress(v)
		return nil
	default:
		return fmt.Errorf("invalid value for Compress: %v", v)
	}
}

// CompressionLevel - Compression level to apply before moving files to final destination
type CompressionLevel string

const (
	CompressionLevelBestSpeed       CompressionLevel = "best_speed"
	CompressionLevelNormal          CompressionLevel = "normal"
	CompressionLevelBestCompression CompressionLevel = "best_compression"
)

func (e CompressionLevel) ToPointer() *CompressionLevel {
	return &e
}
func (e *CompressionLevel) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "best_speed":
		fallthrough
	case "normal":
		fallthrough
	case "best_compression":
		*e = CompressionLevel(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CompressionLevel: %v", v)
	}
}

// ParquetVersion - Determines which data types are supported and how they are represented
type ParquetVersion string

const (
	ParquetVersionParquet10 ParquetVersion = "PARQUET_1_0"
	ParquetVersionParquet24 ParquetVersion = "PARQUET_2_4"
	ParquetVersionParquet26 ParquetVersion = "PARQUET_2_6"
)

func (e ParquetVersion) ToPointer() *ParquetVersion {
	return &e
}
func (e *ParquetVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "PARQUET_1_0":
		fallthrough
	case "PARQUET_2_4":
		fallthrough
	case "PARQUET_2_6":
		*e = ParquetVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ParquetVersion: %v", v)
	}
}

// DataPageVersion - Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
type DataPageVersion string

const (
	DataPageVersionDataPageV1 DataPageVersion = "DATA_PAGE_V1"
	DataPageVersionDataPageV2 DataPageVersion = "DATA_PAGE_V2"
)

func (e DataPageVersion) ToPointer() *DataPageVersion {
	return &e
}
func (e *DataPageVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "DATA_PAGE_V1":
		fallthrough
	case "DATA_PAGE_V2":
		*e = DataPageVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DataPageVersion: %v", v)
	}
}

type KeyValueMetadata struct {
	Key   *string `default:"" json:"key"`
	Value string  `json:"value"`
}

func (k KeyValueMetadata) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(k, "", false)
}

func (k *KeyValueMetadata) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &k, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *KeyValueMetadata) GetKey() *string {
	if o == nil {
		return nil
	}
	return o.Key
}

func (o *KeyValueMetadata) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type OutputFilesystem struct {
	// Unique ID for this output
	ID   *string              `json:"id,omitempty"`
	Type OutputFilesystemType `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Final destination for the output files
	DestPath string `json:"destPath"`
	// Filesystem location in which to buffer files before compressing and moving to final destination. Use performant, stable storage.
	StagePath *string `json:"stagePath,omitempty"`
	// Append output's ID to staging location
	AddIDToStagePath *bool `default:"true" json:"addIdToStagePath"`
	// Remove empty staging directories after moving files
	RemoveEmptyDirs *bool `default:"true" json:"removeEmptyDirs"`
	// JavaScript expression defining how files are partitioned and organized. Default is date-based. If blank, Stream will fall back to the event's __partition field value  if present  otherwise to each location's root directory.
	PartitionExpr *string `default:"C.Time.strftime(_time ? _time : Date.now()/1000, '%Y/%m/%d')" json:"partitionExpr"`
	// Format of the output data
	Format *DataFormat `default:"json" json:"format"`
	// JavaScript expression to define the output filename prefix (can be constant)
	BaseFileName *string `default:"CriblOut" json:"baseFileName"`
	// JavaScript expression to define the output filename suffix (can be constant).  The `__format` variable refers to the value of the `Data format` field (`json` or `raw`).  The `__compression` field refers to the kind of compression being used (`none` or `gzip`).
	FileNameSuffix *string `default:".\\${C.env[\"CRIBL_WORKER_ID\"]}.\\${__format}\\${__compression === \"gzip\" ? \".gz\" : \"\"}" json:"fileNameSuffix"`
	// Maximum uncompressed output file size. Files of this size will be closed and moved to final output location.
	MaxFileSizeMB *float64 `default:"32" json:"maxFileSizeMB"`
	// Maximum amount of time to write to a file. Files open for longer than this will be closed and moved to final output location.
	MaxFileOpenTimeSec *float64 `default:"300" json:"maxFileOpenTimeSec"`
	// Maximum amount of time to keep inactive files open. Files open for longer than this will be closed and moved to final output location.
	MaxFileIdleTimeSec *float64 `default:"30" json:"maxFileIdleTimeSec"`
	// Maximum number of files to keep open concurrently. When exceeded, @{product} will close the oldest open files and move them to the final output location.
	MaxOpenFiles *float64 `default:"100" json:"maxOpenFiles"`
	// If set, this line will be written to the beginning of each output file
	HeaderLine *string `default:"" json:"headerLine"`
	// Buffer size used to write to a file
	WriteHighWaterMark *float64 `default:"64" json:"writeHighWaterMark"`
	// Whether to block or drop events when all receivers are exerting backpressure
	OnBackpressure *OutputFilesystemBackpressureBehavior `default:"block" json:"onBackpressure"`
	// If a file fails to move to its final destination after the maximum number of retries, dead-letter it to prevent further errors.
	DeadletterEnabled *bool `default:"false" json:"deadletterEnabled"`
	// Whether to block or drop events when disk space is below the global 'Min free disk space' limit
	OnDiskFullBackpressure *DiskSpaceProtection `default:"block" json:"onDiskFullBackpressure"`
	Description            *string              `json:"description,omitempty"`
	// Choose data compression format to apply before moving files to final destination
	Compress *Compress `default:"gzip" json:"compress"`
	// Compression level to apply before moving files to final destination
	CompressionLevel *CompressionLevel `default:"best_speed" json:"compressionLevel"`
	// Automatically calculate the schema based on the events of each Parquet file generated
	AutomaticSchema *bool `default:"false" json:"automaticSchema"`
	// Determines which data types are supported and how they are represented
	ParquetVersion *ParquetVersion `default:"PARQUET_2_6" json:"parquetVersion"`
	// Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
	ParquetDataPageVersion *DataPageVersion `default:"DATA_PAGE_V2" json:"parquetDataPageVersion"`
	// The number of rows that every group will contain. The final group can contain a smaller number of rows.
	ParquetRowGroupLength *float64 `default:"10000" json:"parquetRowGroupLength"`
	// Target memory size for page segments, such as 1MB or 128MB. Generally, lower values improve reading speed, while higher values improve compression.
	ParquetPageSize *string `default:"1MB" json:"parquetPageSize"`
	// Log up to 3 rows that @{product} skips due to data mismatch
	ShouldLogInvalidRows *bool `json:"shouldLogInvalidRows,omitempty"`
	// The metadata of files the Destination writes will include the properties you add here as key-value pairs. Useful for tagging, e.g., "key":"OCSF Event Class", "value":"9001".
	KeyValueMetadata []KeyValueMetadata `json:"keyValueMetadata,omitempty"`
	// Statistics profile an entire file in terms of minimum/maximum values within data, numbers of nulls, etc. You can use Parquet tools to view statistics.
	EnableStatistics *bool `default:"true" json:"enableStatistics"`
	// One page index contains statistics for one data page. Parquet readers use statistics to enable page skipping.
	EnableWritePageIndex *bool `default:"true" json:"enableWritePageIndex"`
	// Parquet tools can use the checksum of a Parquet page to verify data integrity
	EnablePageChecksum *bool `default:"false" json:"enablePageChecksum"`
	// How frequently, in seconds, to clean up empty directories when 'Remove empty staging dirs' is enabled
	EmptyDirCleanupSec *float64 `default:"300" json:"emptyDirCleanupSec"`
	// Storage location for files that fail to reach their final destination after maximum retries are exceeded
	DeadletterPath *string `default:"\\$CRIBL_HOME/state/outputs/dead-letter" json:"deadletterPath"`
	// The maximum number of times a file will attempt to move to its final destination before being dead-lettered
	MaxRetryNum *float64  `default:"20" json:"maxRetryNum"`
	Status      *TFStatus `json:"status,omitempty"`
}

func (o OutputFilesystem) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputFilesystem) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *OutputFilesystem) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *OutputFilesystem) GetType() OutputFilesystemType {
	if o == nil {
		return OutputFilesystemType("")
	}
	return o.Type
}

func (o *OutputFilesystem) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputFilesystem) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputFilesystem) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputFilesystem) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputFilesystem) GetDestPath() string {
	if o == nil {
		return ""
	}
	return o.DestPath
}

func (o *OutputFilesystem) GetStagePath() *string {
	if o == nil {
		return nil
	}
	return o.StagePath
}

func (o *OutputFilesystem) GetAddIDToStagePath() *bool {
	if o == nil {
		return nil
	}
	return o.AddIDToStagePath
}

func (o *OutputFilesystem) GetRemoveEmptyDirs() *bool {
	if o == nil {
		return nil
	}
	return o.RemoveEmptyDirs
}

func (o *OutputFilesystem) GetPartitionExpr() *string {
	if o == nil {
		return nil
	}
	return o.PartitionExpr
}

func (o *OutputFilesystem) GetFormat() *DataFormat {
	if o == nil {
		return nil
	}
	return o.Format
}

func (o *OutputFilesystem) GetBaseFileName() *string {
	if o == nil {
		return nil
	}
	return o.BaseFileName
}

func (o *OutputFilesystem) GetFileNameSuffix() *string {
	if o == nil {
		return nil
	}
	return o.FileNameSuffix
}

func (o *OutputFilesystem) GetMaxFileSizeMB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxFileSizeMB
}

func (o *OutputFilesystem) GetMaxFileOpenTimeSec() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxFileOpenTimeSec
}

func (o *OutputFilesystem) GetMaxFileIdleTimeSec() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxFileIdleTimeSec
}

func (o *OutputFilesystem) GetMaxOpenFiles() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxOpenFiles
}

func (o *OutputFilesystem) GetHeaderLine() *string {
	if o == nil {
		return nil
	}
	return o.HeaderLine
}

func (o *OutputFilesystem) GetWriteHighWaterMark() *float64 {
	if o == nil {
		return nil
	}
	return o.WriteHighWaterMark
}

func (o *OutputFilesystem) GetOnBackpressure() *OutputFilesystemBackpressureBehavior {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputFilesystem) GetDeadletterEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.DeadletterEnabled
}

func (o *OutputFilesystem) GetOnDiskFullBackpressure() *DiskSpaceProtection {
	if o == nil {
		return nil
	}
	return o.OnDiskFullBackpressure
}

func (o *OutputFilesystem) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputFilesystem) GetCompress() *Compress {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *OutputFilesystem) GetCompressionLevel() *CompressionLevel {
	if o == nil {
		return nil
	}
	return o.CompressionLevel
}

func (o *OutputFilesystem) GetAutomaticSchema() *bool {
	if o == nil {
		return nil
	}
	return o.AutomaticSchema
}

func (o *OutputFilesystem) GetParquetVersion() *ParquetVersion {
	if o == nil {
		return nil
	}
	return o.ParquetVersion
}

func (o *OutputFilesystem) GetParquetDataPageVersion() *DataPageVersion {
	if o == nil {
		return nil
	}
	return o.ParquetDataPageVersion
}

func (o *OutputFilesystem) GetParquetRowGroupLength() *float64 {
	if o == nil {
		return nil
	}
	return o.ParquetRowGroupLength
}

func (o *OutputFilesystem) GetParquetPageSize() *string {
	if o == nil {
		return nil
	}
	return o.ParquetPageSize
}

func (o *OutputFilesystem) GetShouldLogInvalidRows() *bool {
	if o == nil {
		return nil
	}
	return o.ShouldLogInvalidRows
}

func (o *OutputFilesystem) GetKeyValueMetadata() []KeyValueMetadata {
	if o == nil {
		return nil
	}
	return o.KeyValueMetadata
}

func (o *OutputFilesystem) GetEnableStatistics() *bool {
	if o == nil {
		return nil
	}
	return o.EnableStatistics
}

func (o *OutputFilesystem) GetEnableWritePageIndex() *bool {
	if o == nil {
		return nil
	}
	return o.EnableWritePageIndex
}

func (o *OutputFilesystem) GetEnablePageChecksum() *bool {
	if o == nil {
		return nil
	}
	return o.EnablePageChecksum
}

func (o *OutputFilesystem) GetEmptyDirCleanupSec() *float64 {
	if o == nil {
		return nil
	}
	return o.EmptyDirCleanupSec
}

func (o *OutputFilesystem) GetDeadletterPath() *string {
	if o == nil {
		return nil
	}
	return o.DeadletterPath
}

func (o *OutputFilesystem) GetMaxRetryNum() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxRetryNum
}

func (o *OutputFilesystem) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type OutputSignalfxType string

const (
	OutputSignalfxTypeSignalfx OutputSignalfxType = "signalfx"
)

func (e OutputSignalfxType) ToPointer() *OutputSignalfxType {
	return &e
}
func (e *OutputSignalfxType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "signalfx":
		*e = OutputSignalfxType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSignalfxType: %v", v)
	}
}

// OutputSignalfxAuthenticationMethod - Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
type OutputSignalfxAuthenticationMethod string

const (
	OutputSignalfxAuthenticationMethodManual OutputSignalfxAuthenticationMethod = "manual"
	OutputSignalfxAuthenticationMethodSecret OutputSignalfxAuthenticationMethod = "secret"
)

func (e OutputSignalfxAuthenticationMethod) ToPointer() *OutputSignalfxAuthenticationMethod {
	return &e
}
func (e *OutputSignalfxAuthenticationMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "manual":
		fallthrough
	case "secret":
		*e = OutputSignalfxAuthenticationMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSignalfxAuthenticationMethod: %v", v)
	}
}

type OutputSignalfxExtraHTTPHeaders struct {
	// Field name
	Name *string `json:"name,omitempty"`
	// Field value
	Value string `json:"value"`
}

func (o *OutputSignalfxExtraHTTPHeaders) GetName() *string {
	if o == nil {
		return nil
	}
	return o.Name
}

func (o *OutputSignalfxExtraHTTPHeaders) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// OutputSignalfxFailedRequestLoggingMode - Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
type OutputSignalfxFailedRequestLoggingMode string

const (
	OutputSignalfxFailedRequestLoggingModePayload           OutputSignalfxFailedRequestLoggingMode = "payload"
	OutputSignalfxFailedRequestLoggingModePayloadAndHeaders OutputSignalfxFailedRequestLoggingMode = "payloadAndHeaders"
	OutputSignalfxFailedRequestLoggingModeNone              OutputSignalfxFailedRequestLoggingMode = "none"
)

func (e OutputSignalfxFailedRequestLoggingMode) ToPointer() *OutputSignalfxFailedRequestLoggingMode {
	return &e
}
func (e *OutputSignalfxFailedRequestLoggingMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "payload":
		fallthrough
	case "payloadAndHeaders":
		fallthrough
	case "none":
		*e = OutputSignalfxFailedRequestLoggingMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSignalfxFailedRequestLoggingMode: %v", v)
	}
}

type OutputSignalfxResponseRetrySettings struct {
	// The HTTP response status code that will trigger retries
	HTTPStatus float64 `json:"httpStatus"`
	// How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"1000" json:"initialBackoff"`
	// Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackoff *float64 `default:"10000" json:"maxBackoff"`
}

func (o OutputSignalfxResponseRetrySettings) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputSignalfxResponseRetrySettings) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputSignalfxResponseRetrySettings) GetHTTPStatus() float64 {
	if o == nil {
		return 0.0
	}
	return o.HTTPStatus
}

func (o *OutputSignalfxResponseRetrySettings) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *OutputSignalfxResponseRetrySettings) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *OutputSignalfxResponseRetrySettings) GetMaxBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackoff
}

type OutputSignalfxTimeoutRetrySettings struct {
	// Enable to retry on request timeout
	TimeoutRetry *bool `default:"false" json:"timeoutRetry"`
	// How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"1000" json:"initialBackoff"`
	// Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackoff *float64 `default:"10000" json:"maxBackoff"`
}

func (o OutputSignalfxTimeoutRetrySettings) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputSignalfxTimeoutRetrySettings) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputSignalfxTimeoutRetrySettings) GetTimeoutRetry() *bool {
	if o == nil {
		return nil
	}
	return o.TimeoutRetry
}

func (o *OutputSignalfxTimeoutRetrySettings) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *OutputSignalfxTimeoutRetrySettings) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *OutputSignalfxTimeoutRetrySettings) GetMaxBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackoff
}

// OutputSignalfxBackpressureBehavior - Whether to block, drop, or queue events when all receivers are exerting backpressure.
type OutputSignalfxBackpressureBehavior string

const (
	OutputSignalfxBackpressureBehaviorBlock OutputSignalfxBackpressureBehavior = "block"
	OutputSignalfxBackpressureBehaviorDrop  OutputSignalfxBackpressureBehavior = "drop"
	OutputSignalfxBackpressureBehaviorQueue OutputSignalfxBackpressureBehavior = "queue"
)

func (e OutputSignalfxBackpressureBehavior) ToPointer() *OutputSignalfxBackpressureBehavior {
	return &e
}
func (e *OutputSignalfxBackpressureBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		fallthrough
	case "queue":
		*e = OutputSignalfxBackpressureBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSignalfxBackpressureBehavior: %v", v)
	}
}

// OutputSignalfxCompression - Codec to use to compress the persisted data.
type OutputSignalfxCompression string

const (
	OutputSignalfxCompressionNone OutputSignalfxCompression = "none"
	OutputSignalfxCompressionGzip OutputSignalfxCompression = "gzip"
)

func (e OutputSignalfxCompression) ToPointer() *OutputSignalfxCompression {
	return &e
}
func (e *OutputSignalfxCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = OutputSignalfxCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSignalfxCompression: %v", v)
	}
}

// OutputSignalfxQueueFullBehavior - Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
type OutputSignalfxQueueFullBehavior string

const (
	OutputSignalfxQueueFullBehaviorBlock OutputSignalfxQueueFullBehavior = "block"
	OutputSignalfxQueueFullBehaviorDrop  OutputSignalfxQueueFullBehavior = "drop"
)

func (e OutputSignalfxQueueFullBehavior) ToPointer() *OutputSignalfxQueueFullBehavior {
	return &e
}
func (e *OutputSignalfxQueueFullBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputSignalfxQueueFullBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSignalfxQueueFullBehavior: %v", v)
	}
}

// OutputSignalfxMode - In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
type OutputSignalfxMode string

const (
	OutputSignalfxModeError        OutputSignalfxMode = "error"
	OutputSignalfxModeBackpressure OutputSignalfxMode = "backpressure"
	OutputSignalfxModeAlways       OutputSignalfxMode = "always"
)

func (e OutputSignalfxMode) ToPointer() *OutputSignalfxMode {
	return &e
}
func (e *OutputSignalfxMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "error":
		fallthrough
	case "backpressure":
		fallthrough
	case "always":
		*e = OutputSignalfxMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSignalfxMode: %v", v)
	}
}

type OutputSignalfxPqControls struct {
}

type OutputSignalfx struct {
	// Unique ID for this output
	ID   *string            `json:"id,omitempty"`
	Type OutputSignalfxType `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
	AuthType *OutputSignalfxAuthenticationMethod `default:"manual" json:"authType"`
	// SignalFx realm name, e.g. "us0". For a complete list of available SignalFx realm names, please check [here](https://docs.splunk.com/observability/en/get-started/service-description.html#sd-regions).
	Realm *string `default:"us0" json:"realm"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `default:"5" json:"concurrency"`
	// Maximum size, in KB, of the request body
	MaxPayloadSizeKB *float64 `default:"4096" json:"maxPayloadSizeKB"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited).
	MaxPayloadEvents *float64 `default:"0" json:"maxPayloadEvents"`
	// Compress the payload body before sending
	Compress *bool `default:"true" json:"compress"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Defaults to Yes. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `default:"30" json:"timeoutSec"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Max body size.
	FlushPeriodSec *float64 `default:"1" json:"flushPeriodSec"`
	// Headers to add to all events.
	ExtraHTTPHeaders []OutputSignalfxExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// Enables round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `default:"false" json:"useRoundRobinDns"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *OutputSignalfxFailedRequestLoggingMode `default:"none" json:"failedRequestLoggingMode"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable).
	ResponseRetrySettings []OutputSignalfxResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *OutputSignalfxTimeoutRetrySettings   `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `default:"false" json:"responseHonorRetryAfterHeader"`
	// Whether to block, drop, or queue events when all receivers are exerting backpressure.
	OnBackpressure *OutputSignalfxBackpressureBehavior `default:"block" json:"onBackpressure"`
	Description    *string                             `json:"description,omitempty"`
	// SignalFx API access token (see [here](https://docs.signalfx.com/en/latest/admin-guide/tokens.html#working-with-access-tokens))
	Token *string `json:"token,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.).
	PqMaxFileSize *string `default:"1 MB" json:"pqMaxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `default:"5GB" json:"pqMaxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `default:"\\$CRIBL_HOME/state/queues" json:"pqPath"`
	// Codec to use to compress the persisted data.
	PqCompress *OutputSignalfxCompression `default:"none" json:"pqCompress"`
	// Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *OutputSignalfxQueueFullBehavior `default:"block" json:"pqOnBackpressure"`
	// In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
	PqMode     *OutputSignalfxMode       `default:"error" json:"pqMode"`
	PqControls *OutputSignalfxPqControls `json:"pqControls,omitempty"`
	Status     *TFStatus                 `json:"status,omitempty"`
}

func (o OutputSignalfx) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputSignalfx) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *OutputSignalfx) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *OutputSignalfx) GetType() OutputSignalfxType {
	if o == nil {
		return OutputSignalfxType("")
	}
	return o.Type
}

func (o *OutputSignalfx) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputSignalfx) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputSignalfx) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputSignalfx) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputSignalfx) GetAuthType() *OutputSignalfxAuthenticationMethod {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *OutputSignalfx) GetRealm() *string {
	if o == nil {
		return nil
	}
	return o.Realm
}

func (o *OutputSignalfx) GetConcurrency() *float64 {
	if o == nil {
		return nil
	}
	return o.Concurrency
}

func (o *OutputSignalfx) GetMaxPayloadSizeKB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadSizeKB
}

func (o *OutputSignalfx) GetMaxPayloadEvents() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadEvents
}

func (o *OutputSignalfx) GetCompress() *bool {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *OutputSignalfx) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputSignalfx) GetTimeoutSec() *float64 {
	if o == nil {
		return nil
	}
	return o.TimeoutSec
}

func (o *OutputSignalfx) GetFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushPeriodSec
}

func (o *OutputSignalfx) GetExtraHTTPHeaders() []OutputSignalfxExtraHTTPHeaders {
	if o == nil {
		return nil
	}
	return o.ExtraHTTPHeaders
}

func (o *OutputSignalfx) GetUseRoundRobinDNS() *bool {
	if o == nil {
		return nil
	}
	return o.UseRoundRobinDNS
}

func (o *OutputSignalfx) GetFailedRequestLoggingMode() *OutputSignalfxFailedRequestLoggingMode {
	if o == nil {
		return nil
	}
	return o.FailedRequestLoggingMode
}

func (o *OutputSignalfx) GetSafeHeaders() []string {
	if o == nil {
		return nil
	}
	return o.SafeHeaders
}

func (o *OutputSignalfx) GetResponseRetrySettings() []OutputSignalfxResponseRetrySettings {
	if o == nil {
		return nil
	}
	return o.ResponseRetrySettings
}

func (o *OutputSignalfx) GetTimeoutRetrySettings() *OutputSignalfxTimeoutRetrySettings {
	if o == nil {
		return nil
	}
	return o.TimeoutRetrySettings
}

func (o *OutputSignalfx) GetResponseHonorRetryAfterHeader() *bool {
	if o == nil {
		return nil
	}
	return o.ResponseHonorRetryAfterHeader
}

func (o *OutputSignalfx) GetOnBackpressure() *OutputSignalfxBackpressureBehavior {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputSignalfx) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputSignalfx) GetToken() *string {
	if o == nil {
		return nil
	}
	return o.Token
}

func (o *OutputSignalfx) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *OutputSignalfx) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputSignalfx) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputSignalfx) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputSignalfx) GetPqCompress() *OutputSignalfxCompression {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputSignalfx) GetPqOnBackpressure() *OutputSignalfxQueueFullBehavior {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputSignalfx) GetPqMode() *OutputSignalfxMode {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputSignalfx) GetPqControls() *OutputSignalfxPqControls {
	if o == nil {
		return nil
	}
	return o.PqControls
}

func (o *OutputSignalfx) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type OutputWavefrontType string

const (
	OutputWavefrontTypeWavefront OutputWavefrontType = "wavefront"
)

func (e OutputWavefrontType) ToPointer() *OutputWavefrontType {
	return &e
}
func (e *OutputWavefrontType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "wavefront":
		*e = OutputWavefrontType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputWavefrontType: %v", v)
	}
}

// OutputWavefrontAuthenticationMethod - Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
type OutputWavefrontAuthenticationMethod string

const (
	OutputWavefrontAuthenticationMethodManual OutputWavefrontAuthenticationMethod = "manual"
	OutputWavefrontAuthenticationMethodSecret OutputWavefrontAuthenticationMethod = "secret"
)

func (e OutputWavefrontAuthenticationMethod) ToPointer() *OutputWavefrontAuthenticationMethod {
	return &e
}
func (e *OutputWavefrontAuthenticationMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "manual":
		fallthrough
	case "secret":
		*e = OutputWavefrontAuthenticationMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputWavefrontAuthenticationMethod: %v", v)
	}
}

type OutputWavefrontExtraHTTPHeaders struct {
	// Field name
	Name *string `json:"name,omitempty"`
	// Field value
	Value string `json:"value"`
}

func (o *OutputWavefrontExtraHTTPHeaders) GetName() *string {
	if o == nil {
		return nil
	}
	return o.Name
}

func (o *OutputWavefrontExtraHTTPHeaders) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// OutputWavefrontFailedRequestLoggingMode - Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
type OutputWavefrontFailedRequestLoggingMode string

const (
	OutputWavefrontFailedRequestLoggingModePayload           OutputWavefrontFailedRequestLoggingMode = "payload"
	OutputWavefrontFailedRequestLoggingModePayloadAndHeaders OutputWavefrontFailedRequestLoggingMode = "payloadAndHeaders"
	OutputWavefrontFailedRequestLoggingModeNone              OutputWavefrontFailedRequestLoggingMode = "none"
)

func (e OutputWavefrontFailedRequestLoggingMode) ToPointer() *OutputWavefrontFailedRequestLoggingMode {
	return &e
}
func (e *OutputWavefrontFailedRequestLoggingMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "payload":
		fallthrough
	case "payloadAndHeaders":
		fallthrough
	case "none":
		*e = OutputWavefrontFailedRequestLoggingMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputWavefrontFailedRequestLoggingMode: %v", v)
	}
}

type OutputWavefrontResponseRetrySettings struct {
	// The HTTP response status code that will trigger retries
	HTTPStatus float64 `json:"httpStatus"`
	// How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"1000" json:"initialBackoff"`
	// Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackoff *float64 `default:"10000" json:"maxBackoff"`
}

func (o OutputWavefrontResponseRetrySettings) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputWavefrontResponseRetrySettings) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputWavefrontResponseRetrySettings) GetHTTPStatus() float64 {
	if o == nil {
		return 0.0
	}
	return o.HTTPStatus
}

func (o *OutputWavefrontResponseRetrySettings) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *OutputWavefrontResponseRetrySettings) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *OutputWavefrontResponseRetrySettings) GetMaxBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackoff
}

type OutputWavefrontTimeoutRetrySettings struct {
	// Enable to retry on request timeout
	TimeoutRetry *bool `default:"false" json:"timeoutRetry"`
	// How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"1000" json:"initialBackoff"`
	// Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackoff *float64 `default:"10000" json:"maxBackoff"`
}

func (o OutputWavefrontTimeoutRetrySettings) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputWavefrontTimeoutRetrySettings) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputWavefrontTimeoutRetrySettings) GetTimeoutRetry() *bool {
	if o == nil {
		return nil
	}
	return o.TimeoutRetry
}

func (o *OutputWavefrontTimeoutRetrySettings) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *OutputWavefrontTimeoutRetrySettings) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *OutputWavefrontTimeoutRetrySettings) GetMaxBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackoff
}

// OutputWavefrontBackpressureBehavior - Whether to block, drop, or queue events when all receivers are exerting backpressure.
type OutputWavefrontBackpressureBehavior string

const (
	OutputWavefrontBackpressureBehaviorBlock OutputWavefrontBackpressureBehavior = "block"
	OutputWavefrontBackpressureBehaviorDrop  OutputWavefrontBackpressureBehavior = "drop"
	OutputWavefrontBackpressureBehaviorQueue OutputWavefrontBackpressureBehavior = "queue"
)

func (e OutputWavefrontBackpressureBehavior) ToPointer() *OutputWavefrontBackpressureBehavior {
	return &e
}
func (e *OutputWavefrontBackpressureBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		fallthrough
	case "queue":
		*e = OutputWavefrontBackpressureBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputWavefrontBackpressureBehavior: %v", v)
	}
}

// OutputWavefrontCompression - Codec to use to compress the persisted data.
type OutputWavefrontCompression string

const (
	OutputWavefrontCompressionNone OutputWavefrontCompression = "none"
	OutputWavefrontCompressionGzip OutputWavefrontCompression = "gzip"
)

func (e OutputWavefrontCompression) ToPointer() *OutputWavefrontCompression {
	return &e
}
func (e *OutputWavefrontCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = OutputWavefrontCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputWavefrontCompression: %v", v)
	}
}

// OutputWavefrontQueueFullBehavior - Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
type OutputWavefrontQueueFullBehavior string

const (
	OutputWavefrontQueueFullBehaviorBlock OutputWavefrontQueueFullBehavior = "block"
	OutputWavefrontQueueFullBehaviorDrop  OutputWavefrontQueueFullBehavior = "drop"
)

func (e OutputWavefrontQueueFullBehavior) ToPointer() *OutputWavefrontQueueFullBehavior {
	return &e
}
func (e *OutputWavefrontQueueFullBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputWavefrontQueueFullBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputWavefrontQueueFullBehavior: %v", v)
	}
}

// OutputWavefrontMode - In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
type OutputWavefrontMode string

const (
	OutputWavefrontModeError        OutputWavefrontMode = "error"
	OutputWavefrontModeBackpressure OutputWavefrontMode = "backpressure"
	OutputWavefrontModeAlways       OutputWavefrontMode = "always"
)

func (e OutputWavefrontMode) ToPointer() *OutputWavefrontMode {
	return &e
}
func (e *OutputWavefrontMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "error":
		fallthrough
	case "backpressure":
		fallthrough
	case "always":
		*e = OutputWavefrontMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputWavefrontMode: %v", v)
	}
}

type OutputWavefrontPqControls struct {
}

type OutputWavefront struct {
	// Unique ID for this output
	ID   *string             `json:"id,omitempty"`
	Type OutputWavefrontType `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
	AuthType *OutputWavefrontAuthenticationMethod `default:"manual" json:"authType"`
	// WaveFront domain name, e.g. "longboard"
	Domain *string `default:"longboard" json:"domain"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `default:"5" json:"concurrency"`
	// Maximum size, in KB, of the request body
	MaxPayloadSizeKB *float64 `default:"4096" json:"maxPayloadSizeKB"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited).
	MaxPayloadEvents *float64 `default:"0" json:"maxPayloadEvents"`
	// Compress the payload body before sending
	Compress *bool `default:"true" json:"compress"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Defaults to Yes. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `default:"30" json:"timeoutSec"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Max body size.
	FlushPeriodSec *float64 `default:"1" json:"flushPeriodSec"`
	// Headers to add to all events.
	ExtraHTTPHeaders []OutputWavefrontExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// Enables round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `default:"false" json:"useRoundRobinDns"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *OutputWavefrontFailedRequestLoggingMode `default:"none" json:"failedRequestLoggingMode"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable).
	ResponseRetrySettings []OutputWavefrontResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *OutputWavefrontTimeoutRetrySettings   `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `default:"false" json:"responseHonorRetryAfterHeader"`
	// Whether to block, drop, or queue events when all receivers are exerting backpressure.
	OnBackpressure *OutputWavefrontBackpressureBehavior `default:"block" json:"onBackpressure"`
	Description    *string                              `json:"description,omitempty"`
	// WaveFront API authentication token (see [here](https://docs.wavefront.com/wavefront_api.html#generating-an-api-token))
	Token *string `json:"token,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.).
	PqMaxFileSize *string `default:"1 MB" json:"pqMaxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `default:"5GB" json:"pqMaxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `default:"\\$CRIBL_HOME/state/queues" json:"pqPath"`
	// Codec to use to compress the persisted data.
	PqCompress *OutputWavefrontCompression `default:"none" json:"pqCompress"`
	// Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *OutputWavefrontQueueFullBehavior `default:"block" json:"pqOnBackpressure"`
	// In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
	PqMode     *OutputWavefrontMode       `default:"error" json:"pqMode"`
	PqControls *OutputWavefrontPqControls `json:"pqControls,omitempty"`
	Status     *TFStatus                  `json:"status,omitempty"`
}

func (o OutputWavefront) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputWavefront) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *OutputWavefront) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *OutputWavefront) GetType() OutputWavefrontType {
	if o == nil {
		return OutputWavefrontType("")
	}
	return o.Type
}

func (o *OutputWavefront) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputWavefront) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputWavefront) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputWavefront) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputWavefront) GetAuthType() *OutputWavefrontAuthenticationMethod {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *OutputWavefront) GetDomain() *string {
	if o == nil {
		return nil
	}
	return o.Domain
}

func (o *OutputWavefront) GetConcurrency() *float64 {
	if o == nil {
		return nil
	}
	return o.Concurrency
}

func (o *OutputWavefront) GetMaxPayloadSizeKB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadSizeKB
}

func (o *OutputWavefront) GetMaxPayloadEvents() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadEvents
}

func (o *OutputWavefront) GetCompress() *bool {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *OutputWavefront) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputWavefront) GetTimeoutSec() *float64 {
	if o == nil {
		return nil
	}
	return o.TimeoutSec
}

func (o *OutputWavefront) GetFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushPeriodSec
}

func (o *OutputWavefront) GetExtraHTTPHeaders() []OutputWavefrontExtraHTTPHeaders {
	if o == nil {
		return nil
	}
	return o.ExtraHTTPHeaders
}

func (o *OutputWavefront) GetUseRoundRobinDNS() *bool {
	if o == nil {
		return nil
	}
	return o.UseRoundRobinDNS
}

func (o *OutputWavefront) GetFailedRequestLoggingMode() *OutputWavefrontFailedRequestLoggingMode {
	if o == nil {
		return nil
	}
	return o.FailedRequestLoggingMode
}

func (o *OutputWavefront) GetSafeHeaders() []string {
	if o == nil {
		return nil
	}
	return o.SafeHeaders
}

func (o *OutputWavefront) GetResponseRetrySettings() []OutputWavefrontResponseRetrySettings {
	if o == nil {
		return nil
	}
	return o.ResponseRetrySettings
}

func (o *OutputWavefront) GetTimeoutRetrySettings() *OutputWavefrontTimeoutRetrySettings {
	if o == nil {
		return nil
	}
	return o.TimeoutRetrySettings
}

func (o *OutputWavefront) GetResponseHonorRetryAfterHeader() *bool {
	if o == nil {
		return nil
	}
	return o.ResponseHonorRetryAfterHeader
}

func (o *OutputWavefront) GetOnBackpressure() *OutputWavefrontBackpressureBehavior {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputWavefront) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputWavefront) GetToken() *string {
	if o == nil {
		return nil
	}
	return o.Token
}

func (o *OutputWavefront) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *OutputWavefront) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputWavefront) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputWavefront) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputWavefront) GetPqCompress() *OutputWavefrontCompression {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputWavefront) GetPqOnBackpressure() *OutputWavefrontQueueFullBehavior {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputWavefront) GetPqMode() *OutputWavefrontMode {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputWavefront) GetPqControls() *OutputWavefrontPqControls {
	if o == nil {
		return nil
	}
	return o.PqControls
}

func (o *OutputWavefront) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type OutputTcpjsonType string

const (
	OutputTcpjsonTypeTcpjson OutputTcpjsonType = "tcpjson"
)

func (e OutputTcpjsonType) ToPointer() *OutputTcpjsonType {
	return &e
}
func (e *OutputTcpjsonType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "tcpjson":
		*e = OutputTcpjsonType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputTcpjsonType: %v", v)
	}
}

// OutputTcpjsonCompression - Codec to use to compress the data before sending
type OutputTcpjsonCompression string

const (
	OutputTcpjsonCompressionNone OutputTcpjsonCompression = "none"
	OutputTcpjsonCompressionGzip OutputTcpjsonCompression = "gzip"
)

func (e OutputTcpjsonCompression) ToPointer() *OutputTcpjsonCompression {
	return &e
}
func (e *OutputTcpjsonCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = OutputTcpjsonCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputTcpjsonCompression: %v", v)
	}
}

// OutputTcpjsonMinimumTLSVersion - Minimum TLS version to use when connecting
type OutputTcpjsonMinimumTLSVersion string

const (
	OutputTcpjsonMinimumTLSVersionTlSv1  OutputTcpjsonMinimumTLSVersion = "TLSv1"
	OutputTcpjsonMinimumTLSVersionTlSv11 OutputTcpjsonMinimumTLSVersion = "TLSv1.1"
	OutputTcpjsonMinimumTLSVersionTlSv12 OutputTcpjsonMinimumTLSVersion = "TLSv1.2"
	OutputTcpjsonMinimumTLSVersionTlSv13 OutputTcpjsonMinimumTLSVersion = "TLSv1.3"
)

func (e OutputTcpjsonMinimumTLSVersion) ToPointer() *OutputTcpjsonMinimumTLSVersion {
	return &e
}
func (e *OutputTcpjsonMinimumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = OutputTcpjsonMinimumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputTcpjsonMinimumTLSVersion: %v", v)
	}
}

// OutputTcpjsonMaximumTLSVersion - Maximum TLS version to use when connecting
type OutputTcpjsonMaximumTLSVersion string

const (
	OutputTcpjsonMaximumTLSVersionTlSv1  OutputTcpjsonMaximumTLSVersion = "TLSv1"
	OutputTcpjsonMaximumTLSVersionTlSv11 OutputTcpjsonMaximumTLSVersion = "TLSv1.1"
	OutputTcpjsonMaximumTLSVersionTlSv12 OutputTcpjsonMaximumTLSVersion = "TLSv1.2"
	OutputTcpjsonMaximumTLSVersionTlSv13 OutputTcpjsonMaximumTLSVersion = "TLSv1.3"
)

func (e OutputTcpjsonMaximumTLSVersion) ToPointer() *OutputTcpjsonMaximumTLSVersion {
	return &e
}
func (e *OutputTcpjsonMaximumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = OutputTcpjsonMaximumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputTcpjsonMaximumTLSVersion: %v", v)
	}
}

type OutputTcpjsonTLSSettingsClientSide struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Reject certs that are not authorized by a CA in the CA certificate path, or by another
	//                     trusted CA (e.g., the system's CA). Defaults to Yes. Overrides the toggle from Advanced Settings, when also present.
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.
	Servername *string `json:"servername,omitempty"`
	// The name of the predefined certificate.
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Passphrase to use to decrypt private key.
	Passphrase *string `json:"passphrase,omitempty"`
	// Minimum TLS version to use when connecting
	MinVersion *OutputTcpjsonMinimumTLSVersion `json:"minVersion,omitempty"`
	// Maximum TLS version to use when connecting
	MaxVersion *OutputTcpjsonMaximumTLSVersion `json:"maxVersion,omitempty"`
}

func (o OutputTcpjsonTLSSettingsClientSide) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputTcpjsonTLSSettingsClientSide) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputTcpjsonTLSSettingsClientSide) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *OutputTcpjsonTLSSettingsClientSide) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputTcpjsonTLSSettingsClientSide) GetServername() *string {
	if o == nil {
		return nil
	}
	return o.Servername
}

func (o *OutputTcpjsonTLSSettingsClientSide) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *OutputTcpjsonTLSSettingsClientSide) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *OutputTcpjsonTLSSettingsClientSide) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *OutputTcpjsonTLSSettingsClientSide) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *OutputTcpjsonTLSSettingsClientSide) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *OutputTcpjsonTLSSettingsClientSide) GetMinVersion() *OutputTcpjsonMinimumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *OutputTcpjsonTLSSettingsClientSide) GetMaxVersion() *OutputTcpjsonMaximumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

// OutputTcpjsonBackpressureBehavior - Whether to block, drop, or queue events when all receivers are exerting backpressure.
type OutputTcpjsonBackpressureBehavior string

const (
	OutputTcpjsonBackpressureBehaviorBlock OutputTcpjsonBackpressureBehavior = "block"
	OutputTcpjsonBackpressureBehaviorDrop  OutputTcpjsonBackpressureBehavior = "drop"
	OutputTcpjsonBackpressureBehaviorQueue OutputTcpjsonBackpressureBehavior = "queue"
)

func (e OutputTcpjsonBackpressureBehavior) ToPointer() *OutputTcpjsonBackpressureBehavior {
	return &e
}
func (e *OutputTcpjsonBackpressureBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		fallthrough
	case "queue":
		*e = OutputTcpjsonBackpressureBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputTcpjsonBackpressureBehavior: %v", v)
	}
}

// OutputTcpjsonAuthenticationMethod - Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
type OutputTcpjsonAuthenticationMethod string

const (
	OutputTcpjsonAuthenticationMethodManual OutputTcpjsonAuthenticationMethod = "manual"
	OutputTcpjsonAuthenticationMethodSecret OutputTcpjsonAuthenticationMethod = "secret"
)

func (e OutputTcpjsonAuthenticationMethod) ToPointer() *OutputTcpjsonAuthenticationMethod {
	return &e
}
func (e *OutputTcpjsonAuthenticationMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "manual":
		fallthrough
	case "secret":
		*e = OutputTcpjsonAuthenticationMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputTcpjsonAuthenticationMethod: %v", v)
	}
}

// OutputTcpjsonTLS - Whether to inherit TLS configs from group setting or disable TLS.
type OutputTcpjsonTLS string

const (
	OutputTcpjsonTLSInherit OutputTcpjsonTLS = "inherit"
	OutputTcpjsonTLSFalse   OutputTcpjsonTLS = "false"
)

func (e OutputTcpjsonTLS) ToPointer() *OutputTcpjsonTLS {
	return &e
}
func (e *OutputTcpjsonTLS) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "inherit":
		fallthrough
	case "false":
		*e = OutputTcpjsonTLS(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputTcpjsonTLS: %v", v)
	}
}

type OutputTcpjsonHosts struct {
	// The hostname of the receiver.
	Host string `json:"host"`
	// The port to connect to on the provided host.
	Port float64 `json:"port"`
	// Whether to inherit TLS configs from group setting or disable TLS.
	TLS *OutputTcpjsonTLS `default:"inherit" json:"tls"`
	// Servername to use if establishing a TLS connection. If not specified, defaults to connection host (iff not an IP); otherwise, to the global TLS settings.
	Servername *string `json:"servername,omitempty"`
	// Assign a weight (>0) to each endpoint to indicate its traffic-handling capability
	Weight *float64 `default:"1" json:"weight"`
}

func (o OutputTcpjsonHosts) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputTcpjsonHosts) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputTcpjsonHosts) GetHost() string {
	if o == nil {
		return ""
	}
	return o.Host
}

func (o *OutputTcpjsonHosts) GetPort() float64 {
	if o == nil {
		return 0.0
	}
	return o.Port
}

func (o *OutputTcpjsonHosts) GetTLS() *OutputTcpjsonTLS {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *OutputTcpjsonHosts) GetServername() *string {
	if o == nil {
		return nil
	}
	return o.Servername
}

func (o *OutputTcpjsonHosts) GetWeight() *float64 {
	if o == nil {
		return nil
	}
	return o.Weight
}

// OutputTcpjsonOutputCompression - Codec to use to compress the persisted data.
type OutputTcpjsonOutputCompression string

const (
	OutputTcpjsonOutputCompressionNone OutputTcpjsonOutputCompression = "none"
	OutputTcpjsonOutputCompressionGzip OutputTcpjsonOutputCompression = "gzip"
)

func (e OutputTcpjsonOutputCompression) ToPointer() *OutputTcpjsonOutputCompression {
	return &e
}
func (e *OutputTcpjsonOutputCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = OutputTcpjsonOutputCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputTcpjsonOutputCompression: %v", v)
	}
}

// OutputTcpjsonQueueFullBehavior - Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
type OutputTcpjsonQueueFullBehavior string

const (
	OutputTcpjsonQueueFullBehaviorBlock OutputTcpjsonQueueFullBehavior = "block"
	OutputTcpjsonQueueFullBehaviorDrop  OutputTcpjsonQueueFullBehavior = "drop"
)

func (e OutputTcpjsonQueueFullBehavior) ToPointer() *OutputTcpjsonQueueFullBehavior {
	return &e
}
func (e *OutputTcpjsonQueueFullBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputTcpjsonQueueFullBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputTcpjsonQueueFullBehavior: %v", v)
	}
}

// OutputTcpjsonMode - In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
type OutputTcpjsonMode string

const (
	OutputTcpjsonModeError        OutputTcpjsonMode = "error"
	OutputTcpjsonModeBackpressure OutputTcpjsonMode = "backpressure"
	OutputTcpjsonModeAlways       OutputTcpjsonMode = "always"
)

func (e OutputTcpjsonMode) ToPointer() *OutputTcpjsonMode {
	return &e
}
func (e *OutputTcpjsonMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "error":
		fallthrough
	case "backpressure":
		fallthrough
	case "always":
		*e = OutputTcpjsonMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputTcpjsonMode: %v", v)
	}
}

type OutputTcpjsonPqControls struct {
}

type OutputTcpjson struct {
	// Unique ID for this output
	ID   string            `json:"id"`
	Type OutputTcpjsonType `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Use load-balanced destinations
	LoadBalanced *bool `default:"true" json:"loadBalanced"`
	// Codec to use to compress the data before sending
	Compression *OutputTcpjsonCompression `default:"gzip" json:"compression"`
	// Use to troubleshoot issues with sending data
	LogFailedRequests *bool `default:"false" json:"logFailedRequests"`
	// Rate (in bytes per second) to throttle while writing to an output. Accepts values with multiple-byte units, such as KB, MB, and GB. (Example: 42 MB) Default value of 0 specifies no throttling.
	ThrottleRatePerSec *string                             `default:"0" json:"throttleRatePerSec"`
	TLS                *OutputTcpjsonTLSSettingsClientSide `json:"tls,omitempty"`
	// Amount of time (milliseconds) to wait for the connection to establish before retrying
	ConnectionTimeout *float64 `default:"10000" json:"connectionTimeout"`
	// Amount of time (milliseconds) to wait for a write to complete before assuming connection is dead
	WriteTimeout *float64 `default:"60000" json:"writeTimeout"`
	// The number of minutes before the internally generated authentication token expires, valid values between 1 and 60
	TokenTTLMinutes *float64 `default:"60" json:"tokenTTLMinutes"`
	// Upon connection, send a header-like record containing the auth token and other metadata.This record will not contain an actual event  only subsequent records will.
	SendHeader *bool `default:"true" json:"sendHeader"`
	// Whether to block, drop, or queue events when all receivers are exerting backpressure.
	OnBackpressure *OutputTcpjsonBackpressureBehavior `default:"block" json:"onBackpressure"`
	// Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
	AuthType    *OutputTcpjsonAuthenticationMethod `default:"manual" json:"authType"`
	Description *string                            `json:"description,omitempty"`
	// The hostname of the receiver
	Host *string `json:"host,omitempty"`
	// The port to connect to on the provided host
	Port *float64 `json:"port,omitempty"`
	// Exclude all IPs of the current host from the list of any resolved hostnames.
	ExcludeSelf *bool `default:"false" json:"excludeSelf"`
	// Set of hosts to load-balance data to.
	Hosts []OutputTcpjsonHosts `json:"hosts,omitempty"`
	// Re-resolve any hostnames every this many seconds and pick up destinations from A records.
	DNSResolvePeriodSec *float64 `default:"600" json:"dnsResolvePeriodSec"`
	// How far back in time to keep traffic stats for load balancing purposes.
	LoadBalanceStatsPeriodSec *float64 `default:"300" json:"loadBalanceStatsPeriodSec"`
	// Maximum number of concurrent connections (per worker process). A random set of IPs will be picked on every DNS resolution period. Use 0 for unlimited.
	MaxConcurrentSenders *float64 `default:"0" json:"maxConcurrentSenders"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.).
	PqMaxFileSize *string `default:"1 MB" json:"pqMaxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `default:"5GB" json:"pqMaxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `default:"\\$CRIBL_HOME/state/queues" json:"pqPath"`
	// Codec to use to compress the persisted data.
	PqCompress *OutputTcpjsonOutputCompression `default:"none" json:"pqCompress"`
	// Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *OutputTcpjsonQueueFullBehavior `default:"block" json:"pqOnBackpressure"`
	// In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
	PqMode     *OutputTcpjsonMode       `default:"error" json:"pqMode"`
	PqControls *OutputTcpjsonPqControls `json:"pqControls,omitempty"`
	// Optional authentication token to include as part of the connection header
	AuthToken *string `default:"" json:"authToken"`
	// Select or create a stored text secret
	TextSecret *string   `json:"textSecret,omitempty"`
	Status     *TFStatus `json:"status,omitempty"`
}

func (o OutputTcpjson) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputTcpjson) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *OutputTcpjson) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *OutputTcpjson) GetType() OutputTcpjsonType {
	if o == nil {
		return OutputTcpjsonType("")
	}
	return o.Type
}

func (o *OutputTcpjson) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputTcpjson) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputTcpjson) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputTcpjson) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputTcpjson) GetLoadBalanced() *bool {
	if o == nil {
		return nil
	}
	return o.LoadBalanced
}

func (o *OutputTcpjson) GetCompression() *OutputTcpjsonCompression {
	if o == nil {
		return nil
	}
	return o.Compression
}

func (o *OutputTcpjson) GetLogFailedRequests() *bool {
	if o == nil {
		return nil
	}
	return o.LogFailedRequests
}

func (o *OutputTcpjson) GetThrottleRatePerSec() *string {
	if o == nil {
		return nil
	}
	return o.ThrottleRatePerSec
}

func (o *OutputTcpjson) GetTLS() *OutputTcpjsonTLSSettingsClientSide {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *OutputTcpjson) GetConnectionTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.ConnectionTimeout
}

func (o *OutputTcpjson) GetWriteTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.WriteTimeout
}

func (o *OutputTcpjson) GetTokenTTLMinutes() *float64 {
	if o == nil {
		return nil
	}
	return o.TokenTTLMinutes
}

func (o *OutputTcpjson) GetSendHeader() *bool {
	if o == nil {
		return nil
	}
	return o.SendHeader
}

func (o *OutputTcpjson) GetOnBackpressure() *OutputTcpjsonBackpressureBehavior {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputTcpjson) GetAuthType() *OutputTcpjsonAuthenticationMethod {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *OutputTcpjson) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputTcpjson) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *OutputTcpjson) GetPort() *float64 {
	if o == nil {
		return nil
	}
	return o.Port
}

func (o *OutputTcpjson) GetExcludeSelf() *bool {
	if o == nil {
		return nil
	}
	return o.ExcludeSelf
}

func (o *OutputTcpjson) GetHosts() []OutputTcpjsonHosts {
	if o == nil {
		return nil
	}
	return o.Hosts
}

func (o *OutputTcpjson) GetDNSResolvePeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.DNSResolvePeriodSec
}

func (o *OutputTcpjson) GetLoadBalanceStatsPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.LoadBalanceStatsPeriodSec
}

func (o *OutputTcpjson) GetMaxConcurrentSenders() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxConcurrentSenders
}

func (o *OutputTcpjson) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputTcpjson) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputTcpjson) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputTcpjson) GetPqCompress() *OutputTcpjsonOutputCompression {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputTcpjson) GetPqOnBackpressure() *OutputTcpjsonQueueFullBehavior {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputTcpjson) GetPqMode() *OutputTcpjsonMode {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputTcpjson) GetPqControls() *OutputTcpjsonPqControls {
	if o == nil {
		return nil
	}
	return o.PqControls
}

func (o *OutputTcpjson) GetAuthToken() *string {
	if o == nil {
		return nil
	}
	return o.AuthToken
}

func (o *OutputTcpjson) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *OutputTcpjson) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type OutputSplunkHecType string

const (
	OutputSplunkHecTypeSplunkHec OutputSplunkHecType = "splunk_hec"
)

func (e OutputSplunkHecType) ToPointer() *OutputSplunkHecType {
	return &e
}
func (e *OutputSplunkHecType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "splunk_hec":
		*e = OutputSplunkHecType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSplunkHecType: %v", v)
	}
}

type OutputSplunkHecExtraHTTPHeaders struct {
	// Field name
	Name *string `json:"name,omitempty"`
	// Field value
	Value string `json:"value"`
}

func (o *OutputSplunkHecExtraHTTPHeaders) GetName() *string {
	if o == nil {
		return nil
	}
	return o.Name
}

func (o *OutputSplunkHecExtraHTTPHeaders) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// OutputSplunkHecFailedRequestLoggingMode - Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
type OutputSplunkHecFailedRequestLoggingMode string

const (
	OutputSplunkHecFailedRequestLoggingModePayload           OutputSplunkHecFailedRequestLoggingMode = "payload"
	OutputSplunkHecFailedRequestLoggingModePayloadAndHeaders OutputSplunkHecFailedRequestLoggingMode = "payloadAndHeaders"
	OutputSplunkHecFailedRequestLoggingModeNone              OutputSplunkHecFailedRequestLoggingMode = "none"
)

func (e OutputSplunkHecFailedRequestLoggingMode) ToPointer() *OutputSplunkHecFailedRequestLoggingMode {
	return &e
}
func (e *OutputSplunkHecFailedRequestLoggingMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "payload":
		fallthrough
	case "payloadAndHeaders":
		fallthrough
	case "none":
		*e = OutputSplunkHecFailedRequestLoggingMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSplunkHecFailedRequestLoggingMode: %v", v)
	}
}

// OutputSplunkHecAuthenticationMethod - Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
type OutputSplunkHecAuthenticationMethod string

const (
	OutputSplunkHecAuthenticationMethodManual OutputSplunkHecAuthenticationMethod = "manual"
	OutputSplunkHecAuthenticationMethodSecret OutputSplunkHecAuthenticationMethod = "secret"
)

func (e OutputSplunkHecAuthenticationMethod) ToPointer() *OutputSplunkHecAuthenticationMethod {
	return &e
}
func (e *OutputSplunkHecAuthenticationMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "manual":
		fallthrough
	case "secret":
		*e = OutputSplunkHecAuthenticationMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSplunkHecAuthenticationMethod: %v", v)
	}
}

type OutputSplunkHecResponseRetrySettings struct {
	// The HTTP response status code that will trigger retries
	HTTPStatus float64 `json:"httpStatus"`
	// How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"1000" json:"initialBackoff"`
	// Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackoff *float64 `default:"10000" json:"maxBackoff"`
}

func (o OutputSplunkHecResponseRetrySettings) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputSplunkHecResponseRetrySettings) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputSplunkHecResponseRetrySettings) GetHTTPStatus() float64 {
	if o == nil {
		return 0.0
	}
	return o.HTTPStatus
}

func (o *OutputSplunkHecResponseRetrySettings) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *OutputSplunkHecResponseRetrySettings) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *OutputSplunkHecResponseRetrySettings) GetMaxBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackoff
}

type OutputSplunkHecTimeoutRetrySettings struct {
	// Enable to retry on request timeout
	TimeoutRetry *bool `default:"false" json:"timeoutRetry"`
	// How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"1000" json:"initialBackoff"`
	// Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackoff *float64 `default:"10000" json:"maxBackoff"`
}

func (o OutputSplunkHecTimeoutRetrySettings) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputSplunkHecTimeoutRetrySettings) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputSplunkHecTimeoutRetrySettings) GetTimeoutRetry() *bool {
	if o == nil {
		return nil
	}
	return o.TimeoutRetry
}

func (o *OutputSplunkHecTimeoutRetrySettings) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *OutputSplunkHecTimeoutRetrySettings) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *OutputSplunkHecTimeoutRetrySettings) GetMaxBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackoff
}

// OutputSplunkHecBackpressureBehavior - Whether to block, drop, or queue events when all receivers are exerting backpressure.
type OutputSplunkHecBackpressureBehavior string

const (
	OutputSplunkHecBackpressureBehaviorBlock OutputSplunkHecBackpressureBehavior = "block"
	OutputSplunkHecBackpressureBehaviorDrop  OutputSplunkHecBackpressureBehavior = "drop"
	OutputSplunkHecBackpressureBehaviorQueue OutputSplunkHecBackpressureBehavior = "queue"
)

func (e OutputSplunkHecBackpressureBehavior) ToPointer() *OutputSplunkHecBackpressureBehavior {
	return &e
}
func (e *OutputSplunkHecBackpressureBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		fallthrough
	case "queue":
		*e = OutputSplunkHecBackpressureBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSplunkHecBackpressureBehavior: %v", v)
	}
}

type OutputSplunkHecUrls struct {
	// URL to a Splunk HEC endpoint to send events to, e.g., http://localhost:8088/services/collector/event
	URL *string `default:"http://localhost:8088/services/collector/event" json:"url"`
	// Assign a weight (>0) to each endpoint to indicate its traffic-handling capability
	Weight *float64 `default:"1" json:"weight"`
}

func (o OutputSplunkHecUrls) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputSplunkHecUrls) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputSplunkHecUrls) GetURL() *string {
	if o == nil {
		return nil
	}
	return o.URL
}

func (o *OutputSplunkHecUrls) GetWeight() *float64 {
	if o == nil {
		return nil
	}
	return o.Weight
}

// OutputSplunkHecCompression - Codec to use to compress the persisted data.
type OutputSplunkHecCompression string

const (
	OutputSplunkHecCompressionNone OutputSplunkHecCompression = "none"
	OutputSplunkHecCompressionGzip OutputSplunkHecCompression = "gzip"
)

func (e OutputSplunkHecCompression) ToPointer() *OutputSplunkHecCompression {
	return &e
}
func (e *OutputSplunkHecCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = OutputSplunkHecCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSplunkHecCompression: %v", v)
	}
}

// OutputSplunkHecQueueFullBehavior - Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
type OutputSplunkHecQueueFullBehavior string

const (
	OutputSplunkHecQueueFullBehaviorBlock OutputSplunkHecQueueFullBehavior = "block"
	OutputSplunkHecQueueFullBehaviorDrop  OutputSplunkHecQueueFullBehavior = "drop"
)

func (e OutputSplunkHecQueueFullBehavior) ToPointer() *OutputSplunkHecQueueFullBehavior {
	return &e
}
func (e *OutputSplunkHecQueueFullBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputSplunkHecQueueFullBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSplunkHecQueueFullBehavior: %v", v)
	}
}

// OutputSplunkHecMode - In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
type OutputSplunkHecMode string

const (
	OutputSplunkHecModeError        OutputSplunkHecMode = "error"
	OutputSplunkHecModeBackpressure OutputSplunkHecMode = "backpressure"
	OutputSplunkHecModeAlways       OutputSplunkHecMode = "always"
)

func (e OutputSplunkHecMode) ToPointer() *OutputSplunkHecMode {
	return &e
}
func (e *OutputSplunkHecMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "error":
		fallthrough
	case "backpressure":
		fallthrough
	case "always":
		*e = OutputSplunkHecMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSplunkHecMode: %v", v)
	}
}

type OutputSplunkHecPqControls struct {
}

type OutputSplunkHec struct {
	// Unique ID for this output
	ID   string              `json:"id"`
	Type OutputSplunkHecType `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Enable for optimal performance. Even if you have one hostname, it can expand to multiple IPs. If disabled, consider enabling round-robin DNS.
	LoadBalanced *bool `default:"true" json:"loadBalanced"`
	// In the Splunk app, define which Splunk processing queue to send the events after HEC processing.
	NextQueue *string `default:"indexQueue" json:"nextQueue"`
	// In the Splunk app, set the value of _TCP_ROUTING for events that do not have _ctrl._TCP_ROUTING set.
	TCPRouting *string `default:"nowhere" json:"tcpRouting"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `default:"5" json:"concurrency"`
	// Maximum size, in KB, of the request body
	MaxPayloadSizeKB *float64 `default:"4096" json:"maxPayloadSizeKB"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited).
	MaxPayloadEvents *float64 `default:"0" json:"maxPayloadEvents"`
	// Compress the payload body before sending
	Compress *bool `default:"true" json:"compress"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Defaults to Yes. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `default:"30" json:"timeoutSec"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Max body size.
	FlushPeriodSec *float64 `default:"1" json:"flushPeriodSec"`
	// Headers to add to all events.
	ExtraHTTPHeaders []OutputSplunkHecExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *OutputSplunkHecFailedRequestLoggingMode `default:"none" json:"failedRequestLoggingMode"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// Output metrics in multiple-metric format, supported in Splunk 8.0 and above to allow multiple metrics in a single event.
	EnableMultiMetrics *bool `default:"false" json:"enableMultiMetrics"`
	// Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
	AuthType *OutputSplunkHecAuthenticationMethod `default:"manual" json:"authType"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable).
	ResponseRetrySettings []OutputSplunkHecResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *OutputSplunkHecTimeoutRetrySettings   `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `default:"false" json:"responseHonorRetryAfterHeader"`
	// Whether to block, drop, or queue events when all receivers are exerting backpressure.
	OnBackpressure *OutputSplunkHecBackpressureBehavior `default:"block" json:"onBackpressure"`
	Description    *string                              `json:"description,omitempty"`
	// URL to a Splunk HEC endpoint to send events to, e.g., http://localhost:8088/services/collector/event
	URL *string `default:"http://localhost:8088/services/collector/event" json:"url"`
	// Enables round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `default:"false" json:"useRoundRobinDns"`
	// Exclude all IPs of the current host from the list of any resolved hostnames.
	ExcludeSelf *bool                 `default:"false" json:"excludeSelf"`
	Urls        []OutputSplunkHecUrls `json:"urls,omitempty"`
	// Re-resolve any hostnames every this many seconds and pick up destinations from A records.
	DNSResolvePeriodSec *float64 `default:"600" json:"dnsResolvePeriodSec"`
	// How far back in time to keep traffic stats for load balancing purposes.
	LoadBalanceStatsPeriodSec *float64 `default:"300" json:"loadBalanceStatsPeriodSec"`
	// Splunk HEC authentication token
	Token *string `json:"token,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.).
	PqMaxFileSize *string `default:"1 MB" json:"pqMaxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `default:"5GB" json:"pqMaxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `default:"\\$CRIBL_HOME/state/queues" json:"pqPath"`
	// Codec to use to compress the persisted data.
	PqCompress *OutputSplunkHecCompression `default:"none" json:"pqCompress"`
	// Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *OutputSplunkHecQueueFullBehavior `default:"block" json:"pqOnBackpressure"`
	// In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
	PqMode     *OutputSplunkHecMode       `default:"error" json:"pqMode"`
	PqControls *OutputSplunkHecPqControls `json:"pqControls,omitempty"`
	Status     *TFStatus                  `json:"status,omitempty"`
}

func (o OutputSplunkHec) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputSplunkHec) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *OutputSplunkHec) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *OutputSplunkHec) GetType() OutputSplunkHecType {
	if o == nil {
		return OutputSplunkHecType("")
	}
	return o.Type
}

func (o *OutputSplunkHec) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputSplunkHec) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputSplunkHec) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputSplunkHec) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputSplunkHec) GetLoadBalanced() *bool {
	if o == nil {
		return nil
	}
	return o.LoadBalanced
}

func (o *OutputSplunkHec) GetNextQueue() *string {
	if o == nil {
		return nil
	}
	return o.NextQueue
}

func (o *OutputSplunkHec) GetTCPRouting() *string {
	if o == nil {
		return nil
	}
	return o.TCPRouting
}

func (o *OutputSplunkHec) GetConcurrency() *float64 {
	if o == nil {
		return nil
	}
	return o.Concurrency
}

func (o *OutputSplunkHec) GetMaxPayloadSizeKB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadSizeKB
}

func (o *OutputSplunkHec) GetMaxPayloadEvents() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadEvents
}

func (o *OutputSplunkHec) GetCompress() *bool {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *OutputSplunkHec) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputSplunkHec) GetTimeoutSec() *float64 {
	if o == nil {
		return nil
	}
	return o.TimeoutSec
}

func (o *OutputSplunkHec) GetFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushPeriodSec
}

func (o *OutputSplunkHec) GetExtraHTTPHeaders() []OutputSplunkHecExtraHTTPHeaders {
	if o == nil {
		return nil
	}
	return o.ExtraHTTPHeaders
}

func (o *OutputSplunkHec) GetFailedRequestLoggingMode() *OutputSplunkHecFailedRequestLoggingMode {
	if o == nil {
		return nil
	}
	return o.FailedRequestLoggingMode
}

func (o *OutputSplunkHec) GetSafeHeaders() []string {
	if o == nil {
		return nil
	}
	return o.SafeHeaders
}

func (o *OutputSplunkHec) GetEnableMultiMetrics() *bool {
	if o == nil {
		return nil
	}
	return o.EnableMultiMetrics
}

func (o *OutputSplunkHec) GetAuthType() *OutputSplunkHecAuthenticationMethod {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *OutputSplunkHec) GetResponseRetrySettings() []OutputSplunkHecResponseRetrySettings {
	if o == nil {
		return nil
	}
	return o.ResponseRetrySettings
}

func (o *OutputSplunkHec) GetTimeoutRetrySettings() *OutputSplunkHecTimeoutRetrySettings {
	if o == nil {
		return nil
	}
	return o.TimeoutRetrySettings
}

func (o *OutputSplunkHec) GetResponseHonorRetryAfterHeader() *bool {
	if o == nil {
		return nil
	}
	return o.ResponseHonorRetryAfterHeader
}

func (o *OutputSplunkHec) GetOnBackpressure() *OutputSplunkHecBackpressureBehavior {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputSplunkHec) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputSplunkHec) GetURL() *string {
	if o == nil {
		return nil
	}
	return o.URL
}

func (o *OutputSplunkHec) GetUseRoundRobinDNS() *bool {
	if o == nil {
		return nil
	}
	return o.UseRoundRobinDNS
}

func (o *OutputSplunkHec) GetExcludeSelf() *bool {
	if o == nil {
		return nil
	}
	return o.ExcludeSelf
}

func (o *OutputSplunkHec) GetUrls() []OutputSplunkHecUrls {
	if o == nil {
		return nil
	}
	return o.Urls
}

func (o *OutputSplunkHec) GetDNSResolvePeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.DNSResolvePeriodSec
}

func (o *OutputSplunkHec) GetLoadBalanceStatsPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.LoadBalanceStatsPeriodSec
}

func (o *OutputSplunkHec) GetToken() *string {
	if o == nil {
		return nil
	}
	return o.Token
}

func (o *OutputSplunkHec) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *OutputSplunkHec) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputSplunkHec) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputSplunkHec) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputSplunkHec) GetPqCompress() *OutputSplunkHecCompression {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputSplunkHec) GetPqOnBackpressure() *OutputSplunkHecQueueFullBehavior {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputSplunkHec) GetPqMode() *OutputSplunkHecMode {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputSplunkHec) GetPqControls() *OutputSplunkHecPqControls {
	if o == nil {
		return nil
	}
	return o.PqControls
}

func (o *OutputSplunkHec) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type OutputSplunkLbType string

const (
	OutputSplunkLbTypeSplunkLb OutputSplunkLbType = "splunk_lb"
)

func (e OutputSplunkLbType) ToPointer() *OutputSplunkLbType {
	return &e
}
func (e *OutputSplunkLbType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "splunk_lb":
		*e = OutputSplunkLbType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSplunkLbType: %v", v)
	}
}

// OutputSplunkLbNestedFieldSerialization - How to serialize nested fields into index-time fields
type OutputSplunkLbNestedFieldSerialization string

const (
	OutputSplunkLbNestedFieldSerializationJSON OutputSplunkLbNestedFieldSerialization = "json"
	OutputSplunkLbNestedFieldSerializationNone OutputSplunkLbNestedFieldSerialization = "none"
)

func (e OutputSplunkLbNestedFieldSerialization) ToPointer() *OutputSplunkLbNestedFieldSerialization {
	return &e
}
func (e *OutputSplunkLbNestedFieldSerialization) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "json":
		fallthrough
	case "none":
		*e = OutputSplunkLbNestedFieldSerialization(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSplunkLbNestedFieldSerialization: %v", v)
	}
}

// OutputSplunkLbMinimumTLSVersion - Minimum TLS version to use when connecting
type OutputSplunkLbMinimumTLSVersion string

const (
	OutputSplunkLbMinimumTLSVersionTlSv1  OutputSplunkLbMinimumTLSVersion = "TLSv1"
	OutputSplunkLbMinimumTLSVersionTlSv11 OutputSplunkLbMinimumTLSVersion = "TLSv1.1"
	OutputSplunkLbMinimumTLSVersionTlSv12 OutputSplunkLbMinimumTLSVersion = "TLSv1.2"
	OutputSplunkLbMinimumTLSVersionTlSv13 OutputSplunkLbMinimumTLSVersion = "TLSv1.3"
)

func (e OutputSplunkLbMinimumTLSVersion) ToPointer() *OutputSplunkLbMinimumTLSVersion {
	return &e
}
func (e *OutputSplunkLbMinimumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = OutputSplunkLbMinimumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSplunkLbMinimumTLSVersion: %v", v)
	}
}

// OutputSplunkLbMaximumTLSVersion - Maximum TLS version to use when connecting
type OutputSplunkLbMaximumTLSVersion string

const (
	OutputSplunkLbMaximumTLSVersionTlSv1  OutputSplunkLbMaximumTLSVersion = "TLSv1"
	OutputSplunkLbMaximumTLSVersionTlSv11 OutputSplunkLbMaximumTLSVersion = "TLSv1.1"
	OutputSplunkLbMaximumTLSVersionTlSv12 OutputSplunkLbMaximumTLSVersion = "TLSv1.2"
	OutputSplunkLbMaximumTLSVersionTlSv13 OutputSplunkLbMaximumTLSVersion = "TLSv1.3"
)

func (e OutputSplunkLbMaximumTLSVersion) ToPointer() *OutputSplunkLbMaximumTLSVersion {
	return &e
}
func (e *OutputSplunkLbMaximumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = OutputSplunkLbMaximumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSplunkLbMaximumTLSVersion: %v", v)
	}
}

type OutputSplunkLbTLSSettingsClientSide struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Reject certs that are not authorized by a CA in the CA certificate path, or by another
	//                     trusted CA (e.g., the system's CA). Defaults to Yes. Overrides the toggle from Advanced Settings, when also present.
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.
	Servername *string `json:"servername,omitempty"`
	// The name of the predefined certificate.
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Passphrase to use to decrypt private key.
	Passphrase *string `json:"passphrase,omitempty"`
	// Minimum TLS version to use when connecting
	MinVersion *OutputSplunkLbMinimumTLSVersion `json:"minVersion,omitempty"`
	// Maximum TLS version to use when connecting
	MaxVersion *OutputSplunkLbMaximumTLSVersion `json:"maxVersion,omitempty"`
}

func (o OutputSplunkLbTLSSettingsClientSide) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputSplunkLbTLSSettingsClientSide) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputSplunkLbTLSSettingsClientSide) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *OutputSplunkLbTLSSettingsClientSide) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputSplunkLbTLSSettingsClientSide) GetServername() *string {
	if o == nil {
		return nil
	}
	return o.Servername
}

func (o *OutputSplunkLbTLSSettingsClientSide) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *OutputSplunkLbTLSSettingsClientSide) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *OutputSplunkLbTLSSettingsClientSide) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *OutputSplunkLbTLSSettingsClientSide) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *OutputSplunkLbTLSSettingsClientSide) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *OutputSplunkLbTLSSettingsClientSide) GetMinVersion() *OutputSplunkLbMinimumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *OutputSplunkLbTLSSettingsClientSide) GetMaxVersion() *OutputSplunkLbMaximumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

// OutputSplunkLbMaxS2SVersion - The highest S2S protocol version to advertise during handshake
type OutputSplunkLbMaxS2SVersion string

const (
	OutputSplunkLbMaxS2SVersionV3 OutputSplunkLbMaxS2SVersion = "v3"
	OutputSplunkLbMaxS2SVersionV4 OutputSplunkLbMaxS2SVersion = "v4"
)

func (e OutputSplunkLbMaxS2SVersion) ToPointer() *OutputSplunkLbMaxS2SVersion {
	return &e
}
func (e *OutputSplunkLbMaxS2SVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "v3":
		fallthrough
	case "v4":
		*e = OutputSplunkLbMaxS2SVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSplunkLbMaxS2SVersion: %v", v)
	}
}

// OutputSplunkLbBackpressureBehavior - Whether to block, drop, or queue events when all receivers are exerting backpressure.
type OutputSplunkLbBackpressureBehavior string

const (
	OutputSplunkLbBackpressureBehaviorBlock OutputSplunkLbBackpressureBehavior = "block"
	OutputSplunkLbBackpressureBehaviorDrop  OutputSplunkLbBackpressureBehavior = "drop"
	OutputSplunkLbBackpressureBehaviorQueue OutputSplunkLbBackpressureBehavior = "queue"
)

func (e OutputSplunkLbBackpressureBehavior) ToPointer() *OutputSplunkLbBackpressureBehavior {
	return &e
}
func (e *OutputSplunkLbBackpressureBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		fallthrough
	case "queue":
		*e = OutputSplunkLbBackpressureBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSplunkLbBackpressureBehavior: %v", v)
	}
}

// OutputSplunkLbAuthenticationMethod - Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
type OutputSplunkLbAuthenticationMethod string

const (
	OutputSplunkLbAuthenticationMethodManual OutputSplunkLbAuthenticationMethod = "manual"
	OutputSplunkLbAuthenticationMethodSecret OutputSplunkLbAuthenticationMethod = "secret"
)

func (e OutputSplunkLbAuthenticationMethod) ToPointer() *OutputSplunkLbAuthenticationMethod {
	return &e
}
func (e *OutputSplunkLbAuthenticationMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "manual":
		fallthrough
	case "secret":
		*e = OutputSplunkLbAuthenticationMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSplunkLbAuthenticationMethod: %v", v)
	}
}

// OutputSplunkLbCompression - Controls whether the sender should send compressed data to the server. Select 'Disabled' to reject compressed connections or 'Always' to ignore server's configuration and send compressed data.
type OutputSplunkLbCompression string

const (
	OutputSplunkLbCompressionDisabled OutputSplunkLbCompression = "disabled"
	OutputSplunkLbCompressionAuto     OutputSplunkLbCompression = "auto"
	OutputSplunkLbCompressionAlways   OutputSplunkLbCompression = "always"
)

func (e OutputSplunkLbCompression) ToPointer() *OutputSplunkLbCompression {
	return &e
}
func (e *OutputSplunkLbCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "disabled":
		fallthrough
	case "auto":
		fallthrough
	case "always":
		*e = OutputSplunkLbCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSplunkLbCompression: %v", v)
	}
}

// OutputSplunkLbOutputIndexerDiscoveryConfigsAuthenticationMethod - Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
type OutputSplunkLbOutputIndexerDiscoveryConfigsAuthenticationMethod string

const (
	OutputSplunkLbOutputIndexerDiscoveryConfigsAuthenticationMethodManual OutputSplunkLbOutputIndexerDiscoveryConfigsAuthenticationMethod = "manual"
	OutputSplunkLbOutputIndexerDiscoveryConfigsAuthenticationMethodSecret OutputSplunkLbOutputIndexerDiscoveryConfigsAuthenticationMethod = "secret"
)

func (e OutputSplunkLbOutputIndexerDiscoveryConfigsAuthenticationMethod) ToPointer() *OutputSplunkLbOutputIndexerDiscoveryConfigsAuthenticationMethod {
	return &e
}
func (e *OutputSplunkLbOutputIndexerDiscoveryConfigsAuthenticationMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "manual":
		fallthrough
	case "secret":
		*e = OutputSplunkLbOutputIndexerDiscoveryConfigsAuthenticationMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSplunkLbOutputIndexerDiscoveryConfigsAuthenticationMethod: %v", v)
	}
}

type OutputSplunkLbAuthTokens struct {
	// Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
	AuthType *OutputSplunkLbOutputIndexerDiscoveryConfigsAuthenticationMethod `default:"manual" json:"authType"`
}

func (o OutputSplunkLbAuthTokens) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputSplunkLbAuthTokens) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputSplunkLbAuthTokens) GetAuthType() *OutputSplunkLbOutputIndexerDiscoveryConfigsAuthenticationMethod {
	if o == nil {
		return nil
	}
	return o.AuthType
}

// OutputSplunkLbOutputAuthenticationMethod - Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
type OutputSplunkLbOutputAuthenticationMethod string

const (
	OutputSplunkLbOutputAuthenticationMethodManual OutputSplunkLbOutputAuthenticationMethod = "manual"
	OutputSplunkLbOutputAuthenticationMethodSecret OutputSplunkLbOutputAuthenticationMethod = "secret"
)

func (e OutputSplunkLbOutputAuthenticationMethod) ToPointer() *OutputSplunkLbOutputAuthenticationMethod {
	return &e
}
func (e *OutputSplunkLbOutputAuthenticationMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "manual":
		fallthrough
	case "secret":
		*e = OutputSplunkLbOutputAuthenticationMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSplunkLbOutputAuthenticationMethod: %v", v)
	}
}

// IndexerDiscoveryConfigs - List of configurations to set up indexer discovery in Splunk Indexer clustering environment.
type IndexerDiscoveryConfigs struct {
	// Clustering site of the indexers from where indexers need to be discovered. In case of single site cluster, it defaults to 'default' site.
	Site *string `default:"default" json:"site"`
	// Full URI of Splunk cluster manager (scheme://host:port). Example: https://managerAddress:8089
	MasterURI string `json:"masterUri"`
	// Time interval, in seconds, between two consecutive indexer list fetches from cluster manager
	RefreshIntervalSec *float64 `default:"300" json:"refreshIntervalSec"`
	// During indexer discovery, reject cluster manager certificates that are not authorized by the system's CA. Disable to allow untrusted (for example, self-signed) certificates.
	RejectUnauthorized *bool `default:"false" json:"rejectUnauthorized"`
	// Tokens required to authenticate to cluster manager for indexer discovery
	AuthTokens []OutputSplunkLbAuthTokens `json:"authTokens,omitempty"`
	// Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
	AuthType *OutputSplunkLbOutputAuthenticationMethod `default:"manual" json:"authType"`
	// Shared secret to be provided by any client (in authToken header field). If empty, unauthorized access is permitted.
	AuthToken *string `default:"" json:"authToken"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
}

func (i IndexerDiscoveryConfigs) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *IndexerDiscoveryConfigs) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *IndexerDiscoveryConfigs) GetSite() *string {
	if o == nil {
		return nil
	}
	return o.Site
}

func (o *IndexerDiscoveryConfigs) GetMasterURI() string {
	if o == nil {
		return ""
	}
	return o.MasterURI
}

func (o *IndexerDiscoveryConfigs) GetRefreshIntervalSec() *float64 {
	if o == nil {
		return nil
	}
	return o.RefreshIntervalSec
}

func (o *IndexerDiscoveryConfigs) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *IndexerDiscoveryConfigs) GetAuthTokens() []OutputSplunkLbAuthTokens {
	if o == nil {
		return nil
	}
	return o.AuthTokens
}

func (o *IndexerDiscoveryConfigs) GetAuthType() *OutputSplunkLbOutputAuthenticationMethod {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *IndexerDiscoveryConfigs) GetAuthToken() *string {
	if o == nil {
		return nil
	}
	return o.AuthToken
}

func (o *IndexerDiscoveryConfigs) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

// OutputSplunkLbTLS - Whether to inherit TLS configs from group setting or disable TLS.
type OutputSplunkLbTLS string

const (
	OutputSplunkLbTLSInherit OutputSplunkLbTLS = "inherit"
	OutputSplunkLbTLSFalse   OutputSplunkLbTLS = "false"
)

func (e OutputSplunkLbTLS) ToPointer() *OutputSplunkLbTLS {
	return &e
}
func (e *OutputSplunkLbTLS) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "inherit":
		fallthrough
	case "false":
		*e = OutputSplunkLbTLS(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSplunkLbTLS: %v", v)
	}
}

type Hosts struct {
	// The hostname of the receiver.
	Host string `json:"host"`
	// The port to connect to on the provided host.
	Port *float64 `default:"9997" json:"port"`
	// Whether to inherit TLS configs from group setting or disable TLS.
	TLS *OutputSplunkLbTLS `default:"inherit" json:"tls"`
	// Servername to use if establishing a TLS connection. If not specified, defaults to connection host (iff not an IP); otherwise, to the global TLS settings.
	Servername *string `json:"servername,omitempty"`
	// Assign a weight (>0) to each endpoint to indicate its traffic-handling capability
	Weight *float64 `default:"1" json:"weight"`
}

func (h Hosts) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(h, "", false)
}

func (h *Hosts) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &h, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *Hosts) GetHost() string {
	if o == nil {
		return ""
	}
	return o.Host
}

func (o *Hosts) GetPort() *float64 {
	if o == nil {
		return nil
	}
	return o.Port
}

func (o *Hosts) GetTLS() *OutputSplunkLbTLS {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *Hosts) GetServername() *string {
	if o == nil {
		return nil
	}
	return o.Servername
}

func (o *Hosts) GetWeight() *float64 {
	if o == nil {
		return nil
	}
	return o.Weight
}

// OutputSplunkLbOutputCompression - Codec to use to compress the persisted data.
type OutputSplunkLbOutputCompression string

const (
	OutputSplunkLbOutputCompressionNone OutputSplunkLbOutputCompression = "none"
	OutputSplunkLbOutputCompressionGzip OutputSplunkLbOutputCompression = "gzip"
)

func (e OutputSplunkLbOutputCompression) ToPointer() *OutputSplunkLbOutputCompression {
	return &e
}
func (e *OutputSplunkLbOutputCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = OutputSplunkLbOutputCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSplunkLbOutputCompression: %v", v)
	}
}

// OutputSplunkLbQueueFullBehavior - Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
type OutputSplunkLbQueueFullBehavior string

const (
	OutputSplunkLbQueueFullBehaviorBlock OutputSplunkLbQueueFullBehavior = "block"
	OutputSplunkLbQueueFullBehaviorDrop  OutputSplunkLbQueueFullBehavior = "drop"
)

func (e OutputSplunkLbQueueFullBehavior) ToPointer() *OutputSplunkLbQueueFullBehavior {
	return &e
}
func (e *OutputSplunkLbQueueFullBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputSplunkLbQueueFullBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSplunkLbQueueFullBehavior: %v", v)
	}
}

// OutputSplunkLbMode - In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
type OutputSplunkLbMode string

const (
	OutputSplunkLbModeError        OutputSplunkLbMode = "error"
	OutputSplunkLbModeBackpressure OutputSplunkLbMode = "backpressure"
	OutputSplunkLbModeAlways       OutputSplunkLbMode = "always"
)

func (e OutputSplunkLbMode) ToPointer() *OutputSplunkLbMode {
	return &e
}
func (e *OutputSplunkLbMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "error":
		fallthrough
	case "backpressure":
		fallthrough
	case "always":
		*e = OutputSplunkLbMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSplunkLbMode: %v", v)
	}
}

type OutputSplunkLbPqControls struct {
}

type OutputSplunkLb struct {
	// Unique ID for this output
	ID   *string            `json:"id,omitempty"`
	Type OutputSplunkLbType `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Re-resolve any hostnames every this many seconds and pick up destinations from A records.
	DNSResolvePeriodSec *float64 `default:"600" json:"dnsResolvePeriodSec"`
	// How far back in time to keep traffic stats for load balancing purposes.
	LoadBalanceStatsPeriodSec *float64 `default:"300" json:"loadBalanceStatsPeriodSec"`
	// Maximum number of concurrent connections (per worker process). A random set of IPs will be picked on every DNS resolution period. Use 0 for unlimited.
	MaxConcurrentSenders *float64 `default:"0" json:"maxConcurrentSenders"`
	// How to serialize nested fields into index-time fields
	NestedFields *OutputSplunkLbNestedFieldSerialization `default:"none" json:"nestedFields"`
	// Rate (in bytes per second) to throttle while writing to an output. Accepts values with multiple-byte units, such as KB, MB, and GB. (Example: 42 MB) Default value of 0 specifies no throttling.
	ThrottleRatePerSec *string `default:"0" json:"throttleRatePerSec"`
	// Amount of time (milliseconds) to wait for the connection to establish before retrying
	ConnectionTimeout *float64 `default:"10000" json:"connectionTimeout"`
	// Amount of time (milliseconds) to wait for a write to complete before assuming connection is dead
	WriteTimeout *float64                             `default:"60000" json:"writeTimeout"`
	TLS          *OutputSplunkLbTLSSettingsClientSide `json:"tls,omitempty"`
	// Output metrics in multiple-metric format in a single event. Supported in Splunk 8.0 and above.
	EnableMultiMetrics *bool `default:"false" json:"enableMultiMetrics"`
	// Check if indexer is shutting down and stop sending data. This helps minimize data loss during shutdown.
	EnableACK *bool `default:"true" json:"enableACK"`
	// Use to troubleshoot issues with sending data
	LogFailedRequests *bool `default:"false" json:"logFailedRequests"`
	// The highest S2S protocol version to advertise during handshake
	MaxS2Sversion *OutputSplunkLbMaxS2SVersion `default:"v3" json:"maxS2Sversion"`
	// Whether to block, drop, or queue events when all receivers are exerting backpressure.
	OnBackpressure *OutputSplunkLbBackpressureBehavior `default:"block" json:"onBackpressure"`
	// Automatically discover indexers in indexer clustering environment.
	IndexerDiscovery *bool `default:"false" json:"indexerDiscovery"`
	// How long (in milliseconds) each LB endpoint can report blocked before the Destination reports unhealthy, blocking the sender. (Grace period for fluctuations.) Use 0 to disable; max 1 minute.
	SenderUnhealthyTimeAllowance *float64 `default:"100" json:"senderUnhealthyTimeAllowance"`
	// Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
	AuthType    *OutputSplunkLbAuthenticationMethod `default:"manual" json:"authType"`
	Description *string                             `json:"description,omitempty"`
	// Maximum number of times healthcheck can fail before we close connection. If set to 0 (disabled), and the connection to Splunk is forcibly closed, some data loss might occur.
	MaxFailedHealthChecks *float64 `default:"1" json:"maxFailedHealthChecks"`
	// Controls whether the sender should send compressed data to the server. Select 'Disabled' to reject compressed connections or 'Always' to ignore server's configuration and send compressed data.
	Compress *OutputSplunkLbCompression `default:"disabled" json:"compress"`
	// List of configurations to set up indexer discovery in Splunk Indexer clustering environment.
	IndexerDiscoveryConfigs *IndexerDiscoveryConfigs `json:"indexerDiscoveryConfigs,omitempty"`
	// Exclude all IPs of the current host from the list of any resolved hostnames.
	ExcludeSelf *bool `default:"false" json:"excludeSelf"`
	// Set of Splunk indexers to load-balance data to.
	Hosts []Hosts `json:"hosts"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.).
	PqMaxFileSize *string `default:"1 MB" json:"pqMaxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `default:"5GB" json:"pqMaxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `default:"\\$CRIBL_HOME/state/queues" json:"pqPath"`
	// Codec to use to compress the persisted data.
	PqCompress *OutputSplunkLbOutputCompression `default:"none" json:"pqCompress"`
	// Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *OutputSplunkLbQueueFullBehavior `default:"block" json:"pqOnBackpressure"`
	// In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
	PqMode     *OutputSplunkLbMode       `default:"error" json:"pqMode"`
	PqControls *OutputSplunkLbPqControls `json:"pqControls,omitempty"`
	// Shared secret token to use when establishing a connection to a Splunk indexer.
	AuthToken *string `default:"" json:"authToken"`
	// Select or create a stored text secret
	TextSecret *string   `json:"textSecret,omitempty"`
	Status     *TFStatus `json:"status,omitempty"`
}

func (o OutputSplunkLb) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputSplunkLb) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *OutputSplunkLb) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *OutputSplunkLb) GetType() OutputSplunkLbType {
	if o == nil {
		return OutputSplunkLbType("")
	}
	return o.Type
}

func (o *OutputSplunkLb) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputSplunkLb) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputSplunkLb) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputSplunkLb) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputSplunkLb) GetDNSResolvePeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.DNSResolvePeriodSec
}

func (o *OutputSplunkLb) GetLoadBalanceStatsPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.LoadBalanceStatsPeriodSec
}

func (o *OutputSplunkLb) GetMaxConcurrentSenders() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxConcurrentSenders
}

func (o *OutputSplunkLb) GetNestedFields() *OutputSplunkLbNestedFieldSerialization {
	if o == nil {
		return nil
	}
	return o.NestedFields
}

func (o *OutputSplunkLb) GetThrottleRatePerSec() *string {
	if o == nil {
		return nil
	}
	return o.ThrottleRatePerSec
}

func (o *OutputSplunkLb) GetConnectionTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.ConnectionTimeout
}

func (o *OutputSplunkLb) GetWriteTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.WriteTimeout
}

func (o *OutputSplunkLb) GetTLS() *OutputSplunkLbTLSSettingsClientSide {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *OutputSplunkLb) GetEnableMultiMetrics() *bool {
	if o == nil {
		return nil
	}
	return o.EnableMultiMetrics
}

func (o *OutputSplunkLb) GetEnableACK() *bool {
	if o == nil {
		return nil
	}
	return o.EnableACK
}

func (o *OutputSplunkLb) GetLogFailedRequests() *bool {
	if o == nil {
		return nil
	}
	return o.LogFailedRequests
}

func (o *OutputSplunkLb) GetMaxS2Sversion() *OutputSplunkLbMaxS2SVersion {
	if o == nil {
		return nil
	}
	return o.MaxS2Sversion
}

func (o *OutputSplunkLb) GetOnBackpressure() *OutputSplunkLbBackpressureBehavior {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputSplunkLb) GetIndexerDiscovery() *bool {
	if o == nil {
		return nil
	}
	return o.IndexerDiscovery
}

func (o *OutputSplunkLb) GetSenderUnhealthyTimeAllowance() *float64 {
	if o == nil {
		return nil
	}
	return o.SenderUnhealthyTimeAllowance
}

func (o *OutputSplunkLb) GetAuthType() *OutputSplunkLbAuthenticationMethod {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *OutputSplunkLb) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputSplunkLb) GetMaxFailedHealthChecks() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxFailedHealthChecks
}

func (o *OutputSplunkLb) GetCompress() *OutputSplunkLbCompression {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *OutputSplunkLb) GetIndexerDiscoveryConfigs() *IndexerDiscoveryConfigs {
	if o == nil {
		return nil
	}
	return o.IndexerDiscoveryConfigs
}

func (o *OutputSplunkLb) GetExcludeSelf() *bool {
	if o == nil {
		return nil
	}
	return o.ExcludeSelf
}

func (o *OutputSplunkLb) GetHosts() []Hosts {
	if o == nil {
		return []Hosts{}
	}
	return o.Hosts
}

func (o *OutputSplunkLb) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputSplunkLb) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputSplunkLb) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputSplunkLb) GetPqCompress() *OutputSplunkLbOutputCompression {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputSplunkLb) GetPqOnBackpressure() *OutputSplunkLbQueueFullBehavior {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputSplunkLb) GetPqMode() *OutputSplunkLbMode {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputSplunkLb) GetPqControls() *OutputSplunkLbPqControls {
	if o == nil {
		return nil
	}
	return o.PqControls
}

func (o *OutputSplunkLb) GetAuthToken() *string {
	if o == nil {
		return nil
	}
	return o.AuthToken
}

func (o *OutputSplunkLb) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *OutputSplunkLb) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type OutputSplunkType string

const (
	OutputSplunkTypeSplunk OutputSplunkType = "splunk"
)

func (e OutputSplunkType) ToPointer() *OutputSplunkType {
	return &e
}
func (e *OutputSplunkType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "splunk":
		*e = OutputSplunkType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSplunkType: %v", v)
	}
}

// NestedFieldSerialization - How to serialize nested fields into index-time fields
type NestedFieldSerialization string

const (
	NestedFieldSerializationJSON NestedFieldSerialization = "json"
	NestedFieldSerializationNone NestedFieldSerialization = "none"
)

func (e NestedFieldSerialization) ToPointer() *NestedFieldSerialization {
	return &e
}
func (e *NestedFieldSerialization) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "json":
		fallthrough
	case "none":
		*e = NestedFieldSerialization(v)
		return nil
	default:
		return fmt.Errorf("invalid value for NestedFieldSerialization: %v", v)
	}
}

// OutputSplunkMinimumTLSVersion - Minimum TLS version to use when connecting
type OutputSplunkMinimumTLSVersion string

const (
	OutputSplunkMinimumTLSVersionTlSv1  OutputSplunkMinimumTLSVersion = "TLSv1"
	OutputSplunkMinimumTLSVersionTlSv11 OutputSplunkMinimumTLSVersion = "TLSv1.1"
	OutputSplunkMinimumTLSVersionTlSv12 OutputSplunkMinimumTLSVersion = "TLSv1.2"
	OutputSplunkMinimumTLSVersionTlSv13 OutputSplunkMinimumTLSVersion = "TLSv1.3"
)

func (e OutputSplunkMinimumTLSVersion) ToPointer() *OutputSplunkMinimumTLSVersion {
	return &e
}
func (e *OutputSplunkMinimumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = OutputSplunkMinimumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSplunkMinimumTLSVersion: %v", v)
	}
}

// OutputSplunkMaximumTLSVersion - Maximum TLS version to use when connecting
type OutputSplunkMaximumTLSVersion string

const (
	OutputSplunkMaximumTLSVersionTlSv1  OutputSplunkMaximumTLSVersion = "TLSv1"
	OutputSplunkMaximumTLSVersionTlSv11 OutputSplunkMaximumTLSVersion = "TLSv1.1"
	OutputSplunkMaximumTLSVersionTlSv12 OutputSplunkMaximumTLSVersion = "TLSv1.2"
	OutputSplunkMaximumTLSVersionTlSv13 OutputSplunkMaximumTLSVersion = "TLSv1.3"
)

func (e OutputSplunkMaximumTLSVersion) ToPointer() *OutputSplunkMaximumTLSVersion {
	return &e
}
func (e *OutputSplunkMaximumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = OutputSplunkMaximumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSplunkMaximumTLSVersion: %v", v)
	}
}

type OutputSplunkTLSSettingsClientSide struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Reject certs that are not authorized by a CA in the CA certificate path, or by another
	//                     trusted CA (e.g., the system's CA). Defaults to Yes. Overrides the toggle from Advanced Settings, when also present.
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.
	Servername *string `json:"servername,omitempty"`
	// The name of the predefined certificate.
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Passphrase to use to decrypt private key.
	Passphrase *string `json:"passphrase,omitempty"`
	// Minimum TLS version to use when connecting
	MinVersion *OutputSplunkMinimumTLSVersion `json:"minVersion,omitempty"`
	// Maximum TLS version to use when connecting
	MaxVersion *OutputSplunkMaximumTLSVersion `json:"maxVersion,omitempty"`
}

func (o OutputSplunkTLSSettingsClientSide) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputSplunkTLSSettingsClientSide) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputSplunkTLSSettingsClientSide) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *OutputSplunkTLSSettingsClientSide) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputSplunkTLSSettingsClientSide) GetServername() *string {
	if o == nil {
		return nil
	}
	return o.Servername
}

func (o *OutputSplunkTLSSettingsClientSide) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *OutputSplunkTLSSettingsClientSide) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *OutputSplunkTLSSettingsClientSide) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *OutputSplunkTLSSettingsClientSide) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *OutputSplunkTLSSettingsClientSide) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *OutputSplunkTLSSettingsClientSide) GetMinVersion() *OutputSplunkMinimumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *OutputSplunkTLSSettingsClientSide) GetMaxVersion() *OutputSplunkMaximumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

// OutputSplunkMaxS2SVersion - The highest S2S protocol version to advertise during handshake
type OutputSplunkMaxS2SVersion string

const (
	OutputSplunkMaxS2SVersionV3 OutputSplunkMaxS2SVersion = "v3"
	OutputSplunkMaxS2SVersionV4 OutputSplunkMaxS2SVersion = "v4"
)

func (e OutputSplunkMaxS2SVersion) ToPointer() *OutputSplunkMaxS2SVersion {
	return &e
}
func (e *OutputSplunkMaxS2SVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "v3":
		fallthrough
	case "v4":
		*e = OutputSplunkMaxS2SVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSplunkMaxS2SVersion: %v", v)
	}
}

// OutputSplunkBackpressureBehavior - Whether to block, drop, or queue events when all receivers are exerting backpressure.
type OutputSplunkBackpressureBehavior string

const (
	OutputSplunkBackpressureBehaviorBlock OutputSplunkBackpressureBehavior = "block"
	OutputSplunkBackpressureBehaviorDrop  OutputSplunkBackpressureBehavior = "drop"
	OutputSplunkBackpressureBehaviorQueue OutputSplunkBackpressureBehavior = "queue"
)

func (e OutputSplunkBackpressureBehavior) ToPointer() *OutputSplunkBackpressureBehavior {
	return &e
}
func (e *OutputSplunkBackpressureBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		fallthrough
	case "queue":
		*e = OutputSplunkBackpressureBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSplunkBackpressureBehavior: %v", v)
	}
}

// OutputSplunkAuthenticationMethod - Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
type OutputSplunkAuthenticationMethod string

const (
	OutputSplunkAuthenticationMethodManual OutputSplunkAuthenticationMethod = "manual"
	OutputSplunkAuthenticationMethodSecret OutputSplunkAuthenticationMethod = "secret"
)

func (e OutputSplunkAuthenticationMethod) ToPointer() *OutputSplunkAuthenticationMethod {
	return &e
}
func (e *OutputSplunkAuthenticationMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "manual":
		fallthrough
	case "secret":
		*e = OutputSplunkAuthenticationMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSplunkAuthenticationMethod: %v", v)
	}
}

// OutputSplunkCompression - Controls whether the sender should send compressed data to the server. Select 'Disabled' to reject compressed connections or 'Always' to ignore server's configuration and send compressed data.
type OutputSplunkCompression string

const (
	OutputSplunkCompressionDisabled OutputSplunkCompression = "disabled"
	OutputSplunkCompressionAuto     OutputSplunkCompression = "auto"
	OutputSplunkCompressionAlways   OutputSplunkCompression = "always"
)

func (e OutputSplunkCompression) ToPointer() *OutputSplunkCompression {
	return &e
}
func (e *OutputSplunkCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "disabled":
		fallthrough
	case "auto":
		fallthrough
	case "always":
		*e = OutputSplunkCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSplunkCompression: %v", v)
	}
}

// OutputSplunkOutputCompression - Codec to use to compress the persisted data.
type OutputSplunkOutputCompression string

const (
	OutputSplunkOutputCompressionNone OutputSplunkOutputCompression = "none"
	OutputSplunkOutputCompressionGzip OutputSplunkOutputCompression = "gzip"
)

func (e OutputSplunkOutputCompression) ToPointer() *OutputSplunkOutputCompression {
	return &e
}
func (e *OutputSplunkOutputCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = OutputSplunkOutputCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSplunkOutputCompression: %v", v)
	}
}

// OutputSplunkQueueFullBehavior - Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
type OutputSplunkQueueFullBehavior string

const (
	OutputSplunkQueueFullBehaviorBlock OutputSplunkQueueFullBehavior = "block"
	OutputSplunkQueueFullBehaviorDrop  OutputSplunkQueueFullBehavior = "drop"
)

func (e OutputSplunkQueueFullBehavior) ToPointer() *OutputSplunkQueueFullBehavior {
	return &e
}
func (e *OutputSplunkQueueFullBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputSplunkQueueFullBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSplunkQueueFullBehavior: %v", v)
	}
}

// OutputSplunkMode - In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
type OutputSplunkMode string

const (
	OutputSplunkModeError        OutputSplunkMode = "error"
	OutputSplunkModeBackpressure OutputSplunkMode = "backpressure"
	OutputSplunkModeAlways       OutputSplunkMode = "always"
)

func (e OutputSplunkMode) ToPointer() *OutputSplunkMode {
	return &e
}
func (e *OutputSplunkMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "error":
		fallthrough
	case "backpressure":
		fallthrough
	case "always":
		*e = OutputSplunkMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSplunkMode: %v", v)
	}
}

type OutputSplunkPqControls struct {
}

type OutputSplunk struct {
	// Unique ID for this output
	ID   *string           `json:"id,omitempty"`
	Type *OutputSplunkType `json:"type,omitempty"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// The hostname of the receiver
	Host string `json:"host"`
	// The port to connect to on the provided host
	Port *float64 `default:"9997" json:"port"`
	// How to serialize nested fields into index-time fields
	NestedFields *NestedFieldSerialization `default:"none" json:"nestedFields"`
	// Rate (in bytes per second) to throttle while writing to an output. Accepts values with multiple-byte units, such as KB, MB, and GB. (Example: 42 MB) Default value of 0 specifies no throttling.
	ThrottleRatePerSec *string `default:"0" json:"throttleRatePerSec"`
	// Amount of time (milliseconds) to wait for the connection to establish before retrying
	ConnectionTimeout *float64 `default:"10000" json:"connectionTimeout"`
	// Amount of time (milliseconds) to wait for a write to complete before assuming connection is dead
	WriteTimeout *float64                           `default:"60000" json:"writeTimeout"`
	TLS          *OutputSplunkTLSSettingsClientSide `json:"tls,omitempty"`
	// Output metrics in multiple-metric format in a single event. Supported in Splunk 8.0 and above.
	EnableMultiMetrics *bool `default:"false" json:"enableMultiMetrics"`
	// Check if indexer is shutting down and stop sending data. This helps minimize data loss during shutdown.
	EnableACK *bool `default:"true" json:"enableACK"`
	// Use to troubleshoot issues with sending data
	LogFailedRequests *bool `default:"false" json:"logFailedRequests"`
	// The highest S2S protocol version to advertise during handshake
	MaxS2Sversion *OutputSplunkMaxS2SVersion `default:"v3" json:"maxS2Sversion"`
	// Whether to block, drop, or queue events when all receivers are exerting backpressure.
	OnBackpressure *OutputSplunkBackpressureBehavior `default:"block" json:"onBackpressure"`
	// Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
	AuthType    *OutputSplunkAuthenticationMethod `default:"manual" json:"authType"`
	Description *string                           `json:"description,omitempty"`
	// Maximum number of times healthcheck can fail before we close connection. If set to 0 (disabled), and the connection to Splunk is forcibly closed, some data loss might occur.
	MaxFailedHealthChecks *float64 `default:"1" json:"maxFailedHealthChecks"`
	// Controls whether the sender should send compressed data to the server. Select 'Disabled' to reject compressed connections or 'Always' to ignore server's configuration and send compressed data.
	Compress *OutputSplunkCompression `default:"disabled" json:"compress"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.).
	PqMaxFileSize *string `default:"1 MB" json:"pqMaxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `default:"5GB" json:"pqMaxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `default:"\\$CRIBL_HOME/state/queues" json:"pqPath"`
	// Codec to use to compress the persisted data.
	PqCompress *OutputSplunkOutputCompression `default:"none" json:"pqCompress"`
	// Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *OutputSplunkQueueFullBehavior `default:"block" json:"pqOnBackpressure"`
	// In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
	PqMode     *OutputSplunkMode       `default:"error" json:"pqMode"`
	PqControls *OutputSplunkPqControls `json:"pqControls,omitempty"`
	// Shared secret token to use when establishing a connection to a Splunk indexer.
	AuthToken *string `default:"" json:"authToken"`
	// Select or create a stored text secret
	TextSecret *string   `json:"textSecret,omitempty"`
	Status     *TFStatus `json:"status,omitempty"`
}

func (o OutputSplunk) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputSplunk) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *OutputSplunk) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *OutputSplunk) GetType() *OutputSplunkType {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *OutputSplunk) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputSplunk) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputSplunk) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputSplunk) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputSplunk) GetHost() string {
	if o == nil {
		return ""
	}
	return o.Host
}

func (o *OutputSplunk) GetPort() *float64 {
	if o == nil {
		return nil
	}
	return o.Port
}

func (o *OutputSplunk) GetNestedFields() *NestedFieldSerialization {
	if o == nil {
		return nil
	}
	return o.NestedFields
}

func (o *OutputSplunk) GetThrottleRatePerSec() *string {
	if o == nil {
		return nil
	}
	return o.ThrottleRatePerSec
}

func (o *OutputSplunk) GetConnectionTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.ConnectionTimeout
}

func (o *OutputSplunk) GetWriteTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.WriteTimeout
}

func (o *OutputSplunk) GetTLS() *OutputSplunkTLSSettingsClientSide {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *OutputSplunk) GetEnableMultiMetrics() *bool {
	if o == nil {
		return nil
	}
	return o.EnableMultiMetrics
}

func (o *OutputSplunk) GetEnableACK() *bool {
	if o == nil {
		return nil
	}
	return o.EnableACK
}

func (o *OutputSplunk) GetLogFailedRequests() *bool {
	if o == nil {
		return nil
	}
	return o.LogFailedRequests
}

func (o *OutputSplunk) GetMaxS2Sversion() *OutputSplunkMaxS2SVersion {
	if o == nil {
		return nil
	}
	return o.MaxS2Sversion
}

func (o *OutputSplunk) GetOnBackpressure() *OutputSplunkBackpressureBehavior {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputSplunk) GetAuthType() *OutputSplunkAuthenticationMethod {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *OutputSplunk) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputSplunk) GetMaxFailedHealthChecks() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxFailedHealthChecks
}

func (o *OutputSplunk) GetCompress() *OutputSplunkCompression {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *OutputSplunk) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputSplunk) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputSplunk) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputSplunk) GetPqCompress() *OutputSplunkOutputCompression {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputSplunk) GetPqOnBackpressure() *OutputSplunkQueueFullBehavior {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputSplunk) GetPqMode() *OutputSplunkMode {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputSplunk) GetPqControls() *OutputSplunkPqControls {
	if o == nil {
		return nil
	}
	return o.PqControls
}

func (o *OutputSplunk) GetAuthToken() *string {
	if o == nil {
		return nil
	}
	return o.AuthToken
}

func (o *OutputSplunk) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *OutputSplunk) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type OutputSyslogType string

const (
	OutputSyslogTypeSyslog OutputSyslogType = "syslog"
)

func (e OutputSyslogType) ToPointer() *OutputSyslogType {
	return &e
}
func (e *OutputSyslogType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "syslog":
		*e = OutputSyslogType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSyslogType: %v", v)
	}
}

// OutputSyslogProtocol - The network protocol to use for sending out syslog messages
type OutputSyslogProtocol string

const (
	OutputSyslogProtocolTCP OutputSyslogProtocol = "tcp"
	OutputSyslogProtocolUDP OutputSyslogProtocol = "udp"
)

func (e OutputSyslogProtocol) ToPointer() *OutputSyslogProtocol {
	return &e
}
func (e *OutputSyslogProtocol) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "tcp":
		fallthrough
	case "udp":
		*e = OutputSyslogProtocol(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSyslogProtocol: %v", v)
	}
}

// Facility - Default value for message facility. Will be overwritten by value of __facility if set. Defaults to user.
type Facility int64

const (
	FacilityZero      Facility = 0
	FacilityOne       Facility = 1
	FacilityTwo       Facility = 2
	FacilityThree     Facility = 3
	FacilityFour      Facility = 4
	FacilityFive      Facility = 5
	FacilitySix       Facility = 6
	FacilitySeven     Facility = 7
	FacilityEight     Facility = 8
	FacilityNine      Facility = 9
	FacilityTen       Facility = 10
	FacilityEleven    Facility = 11
	FacilityTwelve    Facility = 12
	FacilityThirteen  Facility = 13
	FacilityFourteen  Facility = 14
	FacilityFifteen   Facility = 15
	FacilitySixteen   Facility = 16
	FacilitySeventeen Facility = 17
	FacilityEighteen  Facility = 18
	FacilityNineteen  Facility = 19
	FacilityTwenty    Facility = 20
	FacilityTwentyOne Facility = 21
)

func (e Facility) ToPointer() *Facility {
	return &e
}
func (e *Facility) UnmarshalJSON(data []byte) error {
	var v int64
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case 0:
		fallthrough
	case 1:
		fallthrough
	case 2:
		fallthrough
	case 3:
		fallthrough
	case 4:
		fallthrough
	case 5:
		fallthrough
	case 6:
		fallthrough
	case 7:
		fallthrough
	case 8:
		fallthrough
	case 9:
		fallthrough
	case 10:
		fallthrough
	case 11:
		fallthrough
	case 12:
		fallthrough
	case 13:
		fallthrough
	case 14:
		fallthrough
	case 15:
		fallthrough
	case 16:
		fallthrough
	case 17:
		fallthrough
	case 18:
		fallthrough
	case 19:
		fallthrough
	case 20:
		fallthrough
	case 21:
		*e = Facility(v)
		return nil
	default:
		return fmt.Errorf("invalid value for Facility: %v", v)
	}
}

// OutputSyslogSeverity - Default value for message severity. Will be overwritten by value of __severity if set. Defaults to notice.
type OutputSyslogSeverity int64

const (
	OutputSyslogSeverityZero  OutputSyslogSeverity = 0
	OutputSyslogSeverityOne   OutputSyslogSeverity = 1
	OutputSyslogSeverityTwo   OutputSyslogSeverity = 2
	OutputSyslogSeverityThree OutputSyslogSeverity = 3
	OutputSyslogSeverityFour  OutputSyslogSeverity = 4
	OutputSyslogSeverityFive  OutputSyslogSeverity = 5
	OutputSyslogSeveritySix   OutputSyslogSeverity = 6
	OutputSyslogSeveritySeven OutputSyslogSeverity = 7
)

func (e OutputSyslogSeverity) ToPointer() *OutputSyslogSeverity {
	return &e
}
func (e *OutputSyslogSeverity) UnmarshalJSON(data []byte) error {
	var v int64
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case 0:
		fallthrough
	case 1:
		fallthrough
	case 2:
		fallthrough
	case 3:
		fallthrough
	case 4:
		fallthrough
	case 5:
		fallthrough
	case 6:
		fallthrough
	case 7:
		*e = OutputSyslogSeverity(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSyslogSeverity: %v", v)
	}
}

// MessageFormat - The syslog message format depending on the receiver's support
type MessageFormat string

const (
	MessageFormatRfc3164 MessageFormat = "rfc3164"
	MessageFormatRfc5424 MessageFormat = "rfc5424"
)

func (e MessageFormat) ToPointer() *MessageFormat {
	return &e
}
func (e *MessageFormat) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "rfc3164":
		fallthrough
	case "rfc5424":
		*e = MessageFormat(v)
		return nil
	default:
		return fmt.Errorf("invalid value for MessageFormat: %v", v)
	}
}

// OutputSyslogTimestampFormat - Timestamp format to use when serializing event's time field
type OutputSyslogTimestampFormat string

const (
	OutputSyslogTimestampFormatSyslog  OutputSyslogTimestampFormat = "syslog"
	OutputSyslogTimestampFormatIso8601 OutputSyslogTimestampFormat = "iso8601"
)

func (e OutputSyslogTimestampFormat) ToPointer() *OutputSyslogTimestampFormat {
	return &e
}
func (e *OutputSyslogTimestampFormat) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "syslog":
		fallthrough
	case "iso8601":
		*e = OutputSyslogTimestampFormat(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSyslogTimestampFormat: %v", v)
	}
}

// OutputSyslogMinimumTLSVersion - Minimum TLS version to use when connecting
type OutputSyslogMinimumTLSVersion string

const (
	OutputSyslogMinimumTLSVersionTlSv1  OutputSyslogMinimumTLSVersion = "TLSv1"
	OutputSyslogMinimumTLSVersionTlSv11 OutputSyslogMinimumTLSVersion = "TLSv1.1"
	OutputSyslogMinimumTLSVersionTlSv12 OutputSyslogMinimumTLSVersion = "TLSv1.2"
	OutputSyslogMinimumTLSVersionTlSv13 OutputSyslogMinimumTLSVersion = "TLSv1.3"
)

func (e OutputSyslogMinimumTLSVersion) ToPointer() *OutputSyslogMinimumTLSVersion {
	return &e
}
func (e *OutputSyslogMinimumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = OutputSyslogMinimumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSyslogMinimumTLSVersion: %v", v)
	}
}

// OutputSyslogMaximumTLSVersion - Maximum TLS version to use when connecting
type OutputSyslogMaximumTLSVersion string

const (
	OutputSyslogMaximumTLSVersionTlSv1  OutputSyslogMaximumTLSVersion = "TLSv1"
	OutputSyslogMaximumTLSVersionTlSv11 OutputSyslogMaximumTLSVersion = "TLSv1.1"
	OutputSyslogMaximumTLSVersionTlSv12 OutputSyslogMaximumTLSVersion = "TLSv1.2"
	OutputSyslogMaximumTLSVersionTlSv13 OutputSyslogMaximumTLSVersion = "TLSv1.3"
)

func (e OutputSyslogMaximumTLSVersion) ToPointer() *OutputSyslogMaximumTLSVersion {
	return &e
}
func (e *OutputSyslogMaximumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = OutputSyslogMaximumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSyslogMaximumTLSVersion: %v", v)
	}
}

type OutputSyslogTLSSettingsClientSide struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Reject certs that are not authorized by a CA in the CA certificate path, or by another
	//                     trusted CA (e.g., the system's CA). Defaults to Yes. Overrides the toggle from Advanced Settings, when also present.
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.
	Servername *string `json:"servername,omitempty"`
	// The name of the predefined certificate.
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Passphrase to use to decrypt private key.
	Passphrase *string `json:"passphrase,omitempty"`
	// Minimum TLS version to use when connecting
	MinVersion *OutputSyslogMinimumTLSVersion `json:"minVersion,omitempty"`
	// Maximum TLS version to use when connecting
	MaxVersion *OutputSyslogMaximumTLSVersion `json:"maxVersion,omitempty"`
}

func (o OutputSyslogTLSSettingsClientSide) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputSyslogTLSSettingsClientSide) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputSyslogTLSSettingsClientSide) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *OutputSyslogTLSSettingsClientSide) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputSyslogTLSSettingsClientSide) GetServername() *string {
	if o == nil {
		return nil
	}
	return o.Servername
}

func (o *OutputSyslogTLSSettingsClientSide) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *OutputSyslogTLSSettingsClientSide) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *OutputSyslogTLSSettingsClientSide) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *OutputSyslogTLSSettingsClientSide) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *OutputSyslogTLSSettingsClientSide) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *OutputSyslogTLSSettingsClientSide) GetMinVersion() *OutputSyslogMinimumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *OutputSyslogTLSSettingsClientSide) GetMaxVersion() *OutputSyslogMaximumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

// OutputSyslogBackpressureBehavior - Whether to block, drop, or queue events when all receivers are exerting backpressure.
type OutputSyslogBackpressureBehavior string

const (
	OutputSyslogBackpressureBehaviorBlock OutputSyslogBackpressureBehavior = "block"
	OutputSyslogBackpressureBehaviorDrop  OutputSyslogBackpressureBehavior = "drop"
	OutputSyslogBackpressureBehaviorQueue OutputSyslogBackpressureBehavior = "queue"
)

func (e OutputSyslogBackpressureBehavior) ToPointer() *OutputSyslogBackpressureBehavior {
	return &e
}
func (e *OutputSyslogBackpressureBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		fallthrough
	case "queue":
		*e = OutputSyslogBackpressureBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSyslogBackpressureBehavior: %v", v)
	}
}

// OutputSyslogCompression - Codec to use to compress the persisted data.
type OutputSyslogCompression string

const (
	OutputSyslogCompressionNone OutputSyslogCompression = "none"
	OutputSyslogCompressionGzip OutputSyslogCompression = "gzip"
)

func (e OutputSyslogCompression) ToPointer() *OutputSyslogCompression {
	return &e
}
func (e *OutputSyslogCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = OutputSyslogCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSyslogCompression: %v", v)
	}
}

// OutputSyslogQueueFullBehavior - Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
type OutputSyslogQueueFullBehavior string

const (
	OutputSyslogQueueFullBehaviorBlock OutputSyslogQueueFullBehavior = "block"
	OutputSyslogQueueFullBehaviorDrop  OutputSyslogQueueFullBehavior = "drop"
)

func (e OutputSyslogQueueFullBehavior) ToPointer() *OutputSyslogQueueFullBehavior {
	return &e
}
func (e *OutputSyslogQueueFullBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputSyslogQueueFullBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSyslogQueueFullBehavior: %v", v)
	}
}

// OutputSyslogMode - In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
type OutputSyslogMode string

const (
	OutputSyslogModeError        OutputSyslogMode = "error"
	OutputSyslogModeBackpressure OutputSyslogMode = "backpressure"
	OutputSyslogModeAlways       OutputSyslogMode = "always"
)

func (e OutputSyslogMode) ToPointer() *OutputSyslogMode {
	return &e
}
func (e *OutputSyslogMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "error":
		fallthrough
	case "backpressure":
		fallthrough
	case "always":
		*e = OutputSyslogMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSyslogMode: %v", v)
	}
}

type OutputSyslogPqControls struct {
}

type OutputSyslog struct {
	// Unique ID for this output
	ID   string           `json:"id"`
	Type OutputSyslogType `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// The network protocol to use for sending out syslog messages
	Protocol *OutputSyslogProtocol `default:"tcp" json:"protocol"`
	// Default value for message facility. Will be overwritten by value of __facility if set. Defaults to user.
	Facility *Facility `default:"1" json:"facility"`
	// Default value for message severity. Will be overwritten by value of __severity if set. Defaults to notice.
	Severity *OutputSyslogSeverity `default:"5" json:"severity"`
	// Default name for device or application that originated the message. Defaults to Cribl, but will be overwritten by value of __appname if set.
	AppName *string `default:"Cribl" json:"appName"`
	// The syslog message format depending on the receiver's support
	MessageFormat *MessageFormat `default:"rfc3164" json:"messageFormat"`
	// Timestamp format to use when serializing event's time field
	TimestampFormat *OutputSyslogTimestampFormat `default:"syslog" json:"timestampFormat"`
	// Rate (in bytes per second) to throttle while writing to an output. Accepts values with multiple-byte units, such as KB, MB, and GB. (Example: 42 MB) Default value of 0 specifies no throttling.
	ThrottleRatePerSec *string `default:"0" json:"throttleRatePerSec"`
	// When enabled, messages will be prefixed with the byte count of the message. Otherwise, no prefix will be set, and the message will be appended with a \n.
	OctetCountFraming *bool `json:"octetCountFraming,omitempty"`
	// Use to troubleshoot issues with sending data
	LogFailedRequests *bool   `default:"false" json:"logFailedRequests"`
	Description       *string `json:"description,omitempty"`
	// For optimal performance, enable load balancing even if you have one hostname, as it can expand to multiple IPs.  If this setting is disabled, consider enabling round-robin DNS.
	LoadBalanced *bool `default:"true" json:"loadBalanced"`
	// Amount of time (milliseconds) to wait for the connection to establish before retrying
	ConnectionTimeout *float64 `default:"10000" json:"connectionTimeout"`
	// Amount of time (milliseconds) to wait for a write to complete before assuming connection is dead
	WriteTimeout *float64                           `default:"60000" json:"writeTimeout"`
	TLS          *OutputSyslogTLSSettingsClientSide `json:"tls,omitempty"`
	// Whether to block, drop, or queue events when all receivers are exerting backpressure.
	OnBackpressure *OutputSyslogBackpressureBehavior `default:"block" json:"onBackpressure"`
	// The hostname of the receiver
	Host *string `json:"host,omitempty"`
	// The port to connect to on the provided host
	Port *float64 `json:"port,omitempty"`
	// Maximum size of syslog messages. Make sure this value is less than or equal to the MTU to avoid UDP packet fragmentation.
	MaxRecordSize *float64 `default:"1500" json:"maxRecordSize"`
	// How often to resolve the destination hostname to an IP address. Ignored if the destination is an IP address. A value of 0 means every message sent will incur a DNS lookup.
	UDPDNSResolvePeriodSec *float64 `default:"0" json:"udpDnsResolvePeriodSec"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.).
	PqMaxFileSize *string `default:"1 MB" json:"pqMaxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `default:"5GB" json:"pqMaxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `default:"\\$CRIBL_HOME/state/queues" json:"pqPath"`
	// Codec to use to compress the persisted data.
	PqCompress *OutputSyslogCompression `default:"none" json:"pqCompress"`
	// Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *OutputSyslogQueueFullBehavior `default:"block" json:"pqOnBackpressure"`
	// In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
	PqMode     *OutputSyslogMode       `default:"error" json:"pqMode"`
	PqControls *OutputSyslogPqControls `json:"pqControls,omitempty"`
	Status     *TFStatus               `json:"status,omitempty"`
}

func (o OutputSyslog) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputSyslog) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *OutputSyslog) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *OutputSyslog) GetType() OutputSyslogType {
	if o == nil {
		return OutputSyslogType("")
	}
	return o.Type
}

func (o *OutputSyslog) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputSyslog) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputSyslog) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputSyslog) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputSyslog) GetProtocol() *OutputSyslogProtocol {
	if o == nil {
		return nil
	}
	return o.Protocol
}

func (o *OutputSyslog) GetFacility() *Facility {
	if o == nil {
		return nil
	}
	return o.Facility
}

func (o *OutputSyslog) GetSeverity() *OutputSyslogSeverity {
	if o == nil {
		return nil
	}
	return o.Severity
}

func (o *OutputSyslog) GetAppName() *string {
	if o == nil {
		return nil
	}
	return o.AppName
}

func (o *OutputSyslog) GetMessageFormat() *MessageFormat {
	if o == nil {
		return nil
	}
	return o.MessageFormat
}

func (o *OutputSyslog) GetTimestampFormat() *OutputSyslogTimestampFormat {
	if o == nil {
		return nil
	}
	return o.TimestampFormat
}

func (o *OutputSyslog) GetThrottleRatePerSec() *string {
	if o == nil {
		return nil
	}
	return o.ThrottleRatePerSec
}

func (o *OutputSyslog) GetOctetCountFraming() *bool {
	if o == nil {
		return nil
	}
	return o.OctetCountFraming
}

func (o *OutputSyslog) GetLogFailedRequests() *bool {
	if o == nil {
		return nil
	}
	return o.LogFailedRequests
}

func (o *OutputSyslog) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputSyslog) GetLoadBalanced() *bool {
	if o == nil {
		return nil
	}
	return o.LoadBalanced
}

func (o *OutputSyslog) GetConnectionTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.ConnectionTimeout
}

func (o *OutputSyslog) GetWriteTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.WriteTimeout
}

func (o *OutputSyslog) GetTLS() *OutputSyslogTLSSettingsClientSide {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *OutputSyslog) GetOnBackpressure() *OutputSyslogBackpressureBehavior {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputSyslog) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *OutputSyslog) GetPort() *float64 {
	if o == nil {
		return nil
	}
	return o.Port
}

func (o *OutputSyslog) GetMaxRecordSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxRecordSize
}

func (o *OutputSyslog) GetUDPDNSResolvePeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.UDPDNSResolvePeriodSec
}

func (o *OutputSyslog) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputSyslog) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputSyslog) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputSyslog) GetPqCompress() *OutputSyslogCompression {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputSyslog) GetPqOnBackpressure() *OutputSyslogQueueFullBehavior {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputSyslog) GetPqMode() *OutputSyslogMode {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputSyslog) GetPqControls() *OutputSyslogPqControls {
	if o == nil {
		return nil
	}
	return o.PqControls
}

func (o *OutputSyslog) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type OutputDevnullType string

const (
	OutputDevnullTypeDevnull OutputDevnullType = "devnull"
)

func (e OutputDevnullType) ToPointer() *OutputDevnullType {
	return &e
}
func (e *OutputDevnullType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "devnull":
		*e = OutputDevnullType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputDevnullType: %v", v)
	}
}

type OutputDevnull struct {
	// Unique ID for this output
	ID   string            `json:"id"`
	Type OutputDevnullType `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string  `json:"streamtags,omitempty"`
	Status     *TFStatus `json:"status,omitempty"`
}

func (o *OutputDevnull) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *OutputDevnull) GetType() OutputDevnullType {
	if o == nil {
		return OutputDevnullType("")
	}
	return o.Type
}

func (o *OutputDevnull) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputDevnull) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputDevnull) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputDevnull) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputDevnull) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type OutputSentinelType string

const (
	OutputSentinelTypeSentinel OutputSentinelType = "sentinel"
)

func (e OutputSentinelType) ToPointer() *OutputSentinelType {
	return &e
}
func (e *OutputSentinelType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "sentinel":
		*e = OutputSentinelType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSentinelType: %v", v)
	}
}

type OutputSentinelExtraHTTPHeaders struct {
	// Field name
	Name *string `json:"name,omitempty"`
	// Field value
	Value string `json:"value"`
}

func (o *OutputSentinelExtraHTTPHeaders) GetName() *string {
	if o == nil {
		return nil
	}
	return o.Name
}

func (o *OutputSentinelExtraHTTPHeaders) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// OutputSentinelFailedRequestLoggingMode - Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
type OutputSentinelFailedRequestLoggingMode string

const (
	OutputSentinelFailedRequestLoggingModePayload           OutputSentinelFailedRequestLoggingMode = "payload"
	OutputSentinelFailedRequestLoggingModePayloadAndHeaders OutputSentinelFailedRequestLoggingMode = "payloadAndHeaders"
	OutputSentinelFailedRequestLoggingModeNone              OutputSentinelFailedRequestLoggingMode = "none"
)

func (e OutputSentinelFailedRequestLoggingMode) ToPointer() *OutputSentinelFailedRequestLoggingMode {
	return &e
}
func (e *OutputSentinelFailedRequestLoggingMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "payload":
		fallthrough
	case "payloadAndHeaders":
		fallthrough
	case "none":
		*e = OutputSentinelFailedRequestLoggingMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSentinelFailedRequestLoggingMode: %v", v)
	}
}

type OutputSentinelResponseRetrySettings struct {
	// The HTTP response status code that will trigger retries
	HTTPStatus float64 `json:"httpStatus"`
	// How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"1000" json:"initialBackoff"`
	// Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackoff *float64 `default:"10000" json:"maxBackoff"`
}

func (o OutputSentinelResponseRetrySettings) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputSentinelResponseRetrySettings) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputSentinelResponseRetrySettings) GetHTTPStatus() float64 {
	if o == nil {
		return 0.0
	}
	return o.HTTPStatus
}

func (o *OutputSentinelResponseRetrySettings) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *OutputSentinelResponseRetrySettings) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *OutputSentinelResponseRetrySettings) GetMaxBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackoff
}

type OutputSentinelTimeoutRetrySettings struct {
	// Enable to retry on request timeout
	TimeoutRetry *bool `default:"false" json:"timeoutRetry"`
	// How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"1000" json:"initialBackoff"`
	// Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackoff *float64 `default:"10000" json:"maxBackoff"`
}

func (o OutputSentinelTimeoutRetrySettings) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputSentinelTimeoutRetrySettings) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputSentinelTimeoutRetrySettings) GetTimeoutRetry() *bool {
	if o == nil {
		return nil
	}
	return o.TimeoutRetry
}

func (o *OutputSentinelTimeoutRetrySettings) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *OutputSentinelTimeoutRetrySettings) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *OutputSentinelTimeoutRetrySettings) GetMaxBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackoff
}

// OutputSentinelBackpressureBehavior - Whether to block, drop, or queue events when all receivers are exerting backpressure.
type OutputSentinelBackpressureBehavior string

const (
	OutputSentinelBackpressureBehaviorBlock OutputSentinelBackpressureBehavior = "block"
	OutputSentinelBackpressureBehaviorDrop  OutputSentinelBackpressureBehavior = "drop"
	OutputSentinelBackpressureBehaviorQueue OutputSentinelBackpressureBehavior = "queue"
)

func (e OutputSentinelBackpressureBehavior) ToPointer() *OutputSentinelBackpressureBehavior {
	return &e
}
func (e *OutputSentinelBackpressureBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		fallthrough
	case "queue":
		*e = OutputSentinelBackpressureBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSentinelBackpressureBehavior: %v", v)
	}
}

type OutputSentinelAuthType string

const (
	OutputSentinelAuthTypeOauth OutputSentinelAuthType = "oauth"
)

func (e OutputSentinelAuthType) ToPointer() *OutputSentinelAuthType {
	return &e
}
func (e *OutputSentinelAuthType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "oauth":
		*e = OutputSentinelAuthType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSentinelAuthType: %v", v)
	}
}

type EndpointConfiguration string

const (
	EndpointConfigurationURL EndpointConfiguration = "url"
	EndpointConfigurationID  EndpointConfiguration = "ID"
)

func (e EndpointConfiguration) ToPointer() *EndpointConfiguration {
	return &e
}
func (e *EndpointConfiguration) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "url":
		fallthrough
	case "ID":
		*e = EndpointConfiguration(v)
		return nil
	default:
		return fmt.Errorf("invalid value for EndpointConfiguration: %v", v)
	}
}

type OutputSentinelFormat string

const (
	OutputSentinelFormatNdjson    OutputSentinelFormat = "ndjson"
	OutputSentinelFormatJSONArray OutputSentinelFormat = "json_array"
	OutputSentinelFormatCustom    OutputSentinelFormat = "custom"
	OutputSentinelFormatAdvanced  OutputSentinelFormat = "advanced"
)

func (e OutputSentinelFormat) ToPointer() *OutputSentinelFormat {
	return &e
}
func (e *OutputSentinelFormat) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "ndjson":
		fallthrough
	case "json_array":
		fallthrough
	case "custom":
		fallthrough
	case "advanced":
		*e = OutputSentinelFormat(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSentinelFormat: %v", v)
	}
}

// OutputSentinelCompression - Codec to use to compress the persisted data.
type OutputSentinelCompression string

const (
	OutputSentinelCompressionNone OutputSentinelCompression = "none"
	OutputSentinelCompressionGzip OutputSentinelCompression = "gzip"
)

func (e OutputSentinelCompression) ToPointer() *OutputSentinelCompression {
	return &e
}
func (e *OutputSentinelCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = OutputSentinelCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSentinelCompression: %v", v)
	}
}

// OutputSentinelQueueFullBehavior - Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
type OutputSentinelQueueFullBehavior string

const (
	OutputSentinelQueueFullBehaviorBlock OutputSentinelQueueFullBehavior = "block"
	OutputSentinelQueueFullBehaviorDrop  OutputSentinelQueueFullBehavior = "drop"
)

func (e OutputSentinelQueueFullBehavior) ToPointer() *OutputSentinelQueueFullBehavior {
	return &e
}
func (e *OutputSentinelQueueFullBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputSentinelQueueFullBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSentinelQueueFullBehavior: %v", v)
	}
}

// OutputSentinelMode - In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
type OutputSentinelMode string

const (
	OutputSentinelModeError        OutputSentinelMode = "error"
	OutputSentinelModeBackpressure OutputSentinelMode = "backpressure"
	OutputSentinelModeAlways       OutputSentinelMode = "always"
)

func (e OutputSentinelMode) ToPointer() *OutputSentinelMode {
	return &e
}
func (e *OutputSentinelMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "error":
		fallthrough
	case "backpressure":
		fallthrough
	case "always":
		*e = OutputSentinelMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSentinelMode: %v", v)
	}
}

type OutputSentinelPqControls struct {
}

type OutputSentinel struct {
	// Unique ID for this output
	ID   *string             `json:"id,omitempty"`
	Type *OutputSentinelType `json:"type,omitempty"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Disable to close the connection immediately after sending the outgoing request
	KeepAlive *bool `default:"true" json:"keepAlive"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `default:"5" json:"concurrency"`
	// Maximum size (KB) of the request body (defaults to the API's maximum limit of 1000 KB)
	MaxPayloadSizeKB *float64 `default:"1000" json:"maxPayloadSizeKB"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited).
	MaxPayloadEvents *float64 `default:"0" json:"maxPayloadEvents"`
	// Compress the payload body before sending
	Compress *bool `default:"true" json:"compress"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Defaults to Yes. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `default:"30" json:"timeoutSec"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Max body size.
	FlushPeriodSec *float64 `default:"1" json:"flushPeriodSec"`
	// Headers to add to all events. You can also add headers dynamically on a per-event basis in the __headers field, as explained [here](https://docs.cribl.io/stream/destinations-webhook/#internal-fields).
	ExtraHTTPHeaders []OutputSentinelExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// Enables round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `default:"false" json:"useRoundRobinDns"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *OutputSentinelFailedRequestLoggingMode `default:"none" json:"failedRequestLoggingMode"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable).
	ResponseRetrySettings []OutputSentinelResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *OutputSentinelTimeoutRetrySettings   `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `default:"false" json:"responseHonorRetryAfterHeader"`
	// Whether to block, drop, or queue events when all receivers are exerting backpressure.
	OnBackpressure *OutputSentinelBackpressureBehavior `default:"block" json:"onBackpressure"`
	AuthType       *OutputSentinelAuthType             `json:"authType,omitempty"`
	// URL for OAuth
	LoginURL string `json:"loginUrl"`
	// Secret parameter value to pass in request body
	Secret string `json:"secret"`
	// JavaScript expression to compute the Client ID for the Azure application. Can be a constant.
	ClientID string `json:"client_id"`
	// Scope to pass in the OAuth request
	Scope                    *string                `default:"https://monitor.azure.com/.default" json:"scope"`
	EndpointURLConfiguration *EndpointConfiguration `default:"url" json:"endpointURLConfiguration"`
	// Maximum total size of the batches waiting to be sent. If left blank, defaults to 5 times the max body size (if set). If 0, no limit is enforced.
	TotalMemoryLimitKB *float64              `json:"totalMemoryLimitKB,omitempty"`
	Description        *string               `json:"description,omitempty"`
	Format             *OutputSentinelFormat `json:"format,omitempty"`
	// Expression to evaluate on events to generate output. Example: `raw=${_raw}`. See [Cribl Docs](https://docs.cribl.io/stream/destinations-webhook#custom-format) for other examples. If empty, the full event is sent as stringified JSON.
	CustomSourceExpression *string `default:"__httpOut" json:"customSourceExpression"`
	// Whether to drop events when the source expression evaluates to null
	CustomDropWhenNull *bool `default:"false" json:"customDropWhenNull"`
	// Delimiter string to insert between individual events. Defaults to newline character.
	CustomEventDelimiter *string `default:"\\n" json:"customEventDelimiter"`
	// Content type to use for request. Defaults to application/x-ndjson. Any content types set in Advanced Settings > Extra HTTP headers will override this entry.
	CustomContentType *string `default:"application/x-ndjson" json:"customContentType"`
	// Expression specifying how to format the payload for each batch. To reference the events to send, use the `${events}` variable. Example expression: `{ "items" : [${events}] }` would send the batch inside a JSON object.
	CustomPayloadExpression *string `default:"\\${events}" json:"customPayloadExpression"`
	// HTTP content-type header value
	AdvancedContentType *string `default:"application/json" json:"advancedContentType"`
	// Custom JavaScript code to format incoming event data accessible through the __e variable. The formatted content is added to (__e['__eventOut']) if available. Otherwise, the original event is serialized as JSON. Caution: This function is evaluated in an unprotected context, allowing you to execute almost any JavaScript code.
	FormatEventCode *string `json:"formatEventCode,omitempty"`
	// Optional JavaScript code to format the payload sent to the Destination. The payload, containing a batch of formatted events, is accessible through the __e['payload'] variable. The formatted payload is returned in the __e['__payloadOut'] variable. Caution: This function is evaluated in an unprotected context, allowing you to execute almost any JavaScript code.
	FormatPayloadCode *string `json:"formatPayloadCode,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.).
	PqMaxFileSize *string `default:"1 MB" json:"pqMaxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `default:"5GB" json:"pqMaxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `default:"\\$CRIBL_HOME/state/queues" json:"pqPath"`
	// Codec to use to compress the persisted data.
	PqCompress *OutputSentinelCompression `default:"none" json:"pqCompress"`
	// Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *OutputSentinelQueueFullBehavior `default:"block" json:"pqOnBackpressure"`
	// In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
	PqMode     *OutputSentinelMode       `default:"error" json:"pqMode"`
	PqControls *OutputSentinelPqControls `json:"pqControls,omitempty"`
	// URL to send events to. Can be overwritten by an event's __url field.
	URL *string `json:"url,omitempty"`
	// Immutable ID for the Data collection rule (DCR).
	DcrID *string `json:"dcrID,omitempty"`
	// Data collection endpoint (DCE) URL. In the format: `https://<Endpoint-Name>-<Identifier>.<Region>.ingest.monitor.azure.com`.
	DceEndpoint *string `json:"dceEndpoint,omitempty"`
	// The name of the stream (Sentinel table) in which to store the events.
	StreamName *string   `json:"streamName,omitempty"`
	Status     *TFStatus `json:"status,omitempty"`
}

func (o OutputSentinel) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputSentinel) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *OutputSentinel) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *OutputSentinel) GetType() *OutputSentinelType {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *OutputSentinel) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputSentinel) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputSentinel) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputSentinel) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputSentinel) GetKeepAlive() *bool {
	if o == nil {
		return nil
	}
	return o.KeepAlive
}

func (o *OutputSentinel) GetConcurrency() *float64 {
	if o == nil {
		return nil
	}
	return o.Concurrency
}

func (o *OutputSentinel) GetMaxPayloadSizeKB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadSizeKB
}

func (o *OutputSentinel) GetMaxPayloadEvents() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadEvents
}

func (o *OutputSentinel) GetCompress() *bool {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *OutputSentinel) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputSentinel) GetTimeoutSec() *float64 {
	if o == nil {
		return nil
	}
	return o.TimeoutSec
}

func (o *OutputSentinel) GetFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushPeriodSec
}

func (o *OutputSentinel) GetExtraHTTPHeaders() []OutputSentinelExtraHTTPHeaders {
	if o == nil {
		return nil
	}
	return o.ExtraHTTPHeaders
}

func (o *OutputSentinel) GetUseRoundRobinDNS() *bool {
	if o == nil {
		return nil
	}
	return o.UseRoundRobinDNS
}

func (o *OutputSentinel) GetFailedRequestLoggingMode() *OutputSentinelFailedRequestLoggingMode {
	if o == nil {
		return nil
	}
	return o.FailedRequestLoggingMode
}

func (o *OutputSentinel) GetSafeHeaders() []string {
	if o == nil {
		return nil
	}
	return o.SafeHeaders
}

func (o *OutputSentinel) GetResponseRetrySettings() []OutputSentinelResponseRetrySettings {
	if o == nil {
		return nil
	}
	return o.ResponseRetrySettings
}

func (o *OutputSentinel) GetTimeoutRetrySettings() *OutputSentinelTimeoutRetrySettings {
	if o == nil {
		return nil
	}
	return o.TimeoutRetrySettings
}

func (o *OutputSentinel) GetResponseHonorRetryAfterHeader() *bool {
	if o == nil {
		return nil
	}
	return o.ResponseHonorRetryAfterHeader
}

func (o *OutputSentinel) GetOnBackpressure() *OutputSentinelBackpressureBehavior {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputSentinel) GetAuthType() *OutputSentinelAuthType {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *OutputSentinel) GetLoginURL() string {
	if o == nil {
		return ""
	}
	return o.LoginURL
}

func (o *OutputSentinel) GetSecret() string {
	if o == nil {
		return ""
	}
	return o.Secret
}

func (o *OutputSentinel) GetClientID() string {
	if o == nil {
		return ""
	}
	return o.ClientID
}

func (o *OutputSentinel) GetScope() *string {
	if o == nil {
		return nil
	}
	return o.Scope
}

func (o *OutputSentinel) GetEndpointURLConfiguration() *EndpointConfiguration {
	if o == nil {
		return nil
	}
	return o.EndpointURLConfiguration
}

func (o *OutputSentinel) GetTotalMemoryLimitKB() *float64 {
	if o == nil {
		return nil
	}
	return o.TotalMemoryLimitKB
}

func (o *OutputSentinel) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputSentinel) GetFormat() *OutputSentinelFormat {
	if o == nil {
		return nil
	}
	return o.Format
}

func (o *OutputSentinel) GetCustomSourceExpression() *string {
	if o == nil {
		return nil
	}
	return o.CustomSourceExpression
}

func (o *OutputSentinel) GetCustomDropWhenNull() *bool {
	if o == nil {
		return nil
	}
	return o.CustomDropWhenNull
}

func (o *OutputSentinel) GetCustomEventDelimiter() *string {
	if o == nil {
		return nil
	}
	return o.CustomEventDelimiter
}

func (o *OutputSentinel) GetCustomContentType() *string {
	if o == nil {
		return nil
	}
	return o.CustomContentType
}

func (o *OutputSentinel) GetCustomPayloadExpression() *string {
	if o == nil {
		return nil
	}
	return o.CustomPayloadExpression
}

func (o *OutputSentinel) GetAdvancedContentType() *string {
	if o == nil {
		return nil
	}
	return o.AdvancedContentType
}

func (o *OutputSentinel) GetFormatEventCode() *string {
	if o == nil {
		return nil
	}
	return o.FormatEventCode
}

func (o *OutputSentinel) GetFormatPayloadCode() *string {
	if o == nil {
		return nil
	}
	return o.FormatPayloadCode
}

func (o *OutputSentinel) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputSentinel) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputSentinel) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputSentinel) GetPqCompress() *OutputSentinelCompression {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputSentinel) GetPqOnBackpressure() *OutputSentinelQueueFullBehavior {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputSentinel) GetPqMode() *OutputSentinelMode {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputSentinel) GetPqControls() *OutputSentinelPqControls {
	if o == nil {
		return nil
	}
	return o.PqControls
}

func (o *OutputSentinel) GetURL() *string {
	if o == nil {
		return nil
	}
	return o.URL
}

func (o *OutputSentinel) GetDcrID() *string {
	if o == nil {
		return nil
	}
	return o.DcrID
}

func (o *OutputSentinel) GetDceEndpoint() *string {
	if o == nil {
		return nil
	}
	return o.DceEndpoint
}

func (o *OutputSentinel) GetStreamName() *string {
	if o == nil {
		return nil
	}
	return o.StreamName
}

func (o *OutputSentinel) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type OutputWebhookType string

const (
	OutputWebhookTypeWebhook OutputWebhookType = "webhook"
)

func (e OutputWebhookType) ToPointer() *OutputWebhookType {
	return &e
}
func (e *OutputWebhookType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "webhook":
		*e = OutputWebhookType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputWebhookType: %v", v)
	}
}

// Method - The method to use when sending events. Defaults to POST.
type Method string

const (
	MethodPost  Method = "POST"
	MethodPut   Method = "PUT"
	MethodPatch Method = "PATCH"
)

func (e Method) ToPointer() *Method {
	return &e
}
func (e *Method) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "POST":
		fallthrough
	case "PUT":
		fallthrough
	case "PATCH":
		*e = Method(v)
		return nil
	default:
		return fmt.Errorf("invalid value for Method: %v", v)
	}
}

// OutputWebhookFormat - Specifies how to format events before sending out. Defaults to NDJSON.
type OutputWebhookFormat string

const (
	OutputWebhookFormatNdjson    OutputWebhookFormat = "ndjson"
	OutputWebhookFormatJSONArray OutputWebhookFormat = "json_array"
	OutputWebhookFormatCustom    OutputWebhookFormat = "custom"
	OutputWebhookFormatAdvanced  OutputWebhookFormat = "advanced"
)

func (e OutputWebhookFormat) ToPointer() *OutputWebhookFormat {
	return &e
}
func (e *OutputWebhookFormat) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "ndjson":
		fallthrough
	case "json_array":
		fallthrough
	case "custom":
		fallthrough
	case "advanced":
		*e = OutputWebhookFormat(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputWebhookFormat: %v", v)
	}
}

type OutputWebhookExtraHTTPHeaders struct {
	// Field name
	Name *string `json:"name,omitempty"`
	// Field value
	Value string `json:"value"`
}

func (o *OutputWebhookExtraHTTPHeaders) GetName() *string {
	if o == nil {
		return nil
	}
	return o.Name
}

func (o *OutputWebhookExtraHTTPHeaders) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// FailedRequestLoggingMode - Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
type FailedRequestLoggingMode string

const (
	FailedRequestLoggingModePayload           FailedRequestLoggingMode = "payload"
	FailedRequestLoggingModePayloadAndHeaders FailedRequestLoggingMode = "payloadAndHeaders"
	FailedRequestLoggingModeNone              FailedRequestLoggingMode = "none"
)

func (e FailedRequestLoggingMode) ToPointer() *FailedRequestLoggingMode {
	return &e
}
func (e *FailedRequestLoggingMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "payload":
		fallthrough
	case "payloadAndHeaders":
		fallthrough
	case "none":
		*e = FailedRequestLoggingMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for FailedRequestLoggingMode: %v", v)
	}
}

type ResponseRetrySettings struct {
	// The HTTP response status code that will trigger retries
	HTTPStatus float64 `json:"httpStatus"`
	// How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"1000" json:"initialBackoff"`
	// Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackoff *float64 `default:"10000" json:"maxBackoff"`
}

func (r ResponseRetrySettings) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(r, "", false)
}

func (r *ResponseRetrySettings) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &r, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *ResponseRetrySettings) GetHTTPStatus() float64 {
	if o == nil {
		return 0.0
	}
	return o.HTTPStatus
}

func (o *ResponseRetrySettings) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *ResponseRetrySettings) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *ResponseRetrySettings) GetMaxBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackoff
}

type TimeoutRetrySettings struct {
	// Enable to retry on request timeout
	TimeoutRetry *bool `default:"false" json:"timeoutRetry"`
	// How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"1000" json:"initialBackoff"`
	// Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackoff *float64 `default:"10000" json:"maxBackoff"`
}

func (t TimeoutRetrySettings) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(t, "", false)
}

func (t *TimeoutRetrySettings) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &t, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *TimeoutRetrySettings) GetTimeoutRetry() *bool {
	if o == nil {
		return nil
	}
	return o.TimeoutRetry
}

func (o *TimeoutRetrySettings) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *TimeoutRetrySettings) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *TimeoutRetrySettings) GetMaxBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackoff
}

// BackpressureBehavior - Whether to block, drop, or queue events when all receivers are exerting backpressure.
type BackpressureBehavior string

const (
	BackpressureBehaviorBlock BackpressureBehavior = "block"
	BackpressureBehaviorDrop  BackpressureBehavior = "drop"
	BackpressureBehaviorQueue BackpressureBehavior = "queue"
)

func (e BackpressureBehavior) ToPointer() *BackpressureBehavior {
	return &e
}
func (e *BackpressureBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		fallthrough
	case "queue":
		*e = BackpressureBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for BackpressureBehavior: %v", v)
	}
}

// OutputWebhookAuthenticationType - The authentication method to use for the HTTP request. Defaults to None.
type OutputWebhookAuthenticationType string

const (
	OutputWebhookAuthenticationTypeNone              OutputWebhookAuthenticationType = "none"
	OutputWebhookAuthenticationTypeBasic             OutputWebhookAuthenticationType = "basic"
	OutputWebhookAuthenticationTypeCredentialsSecret OutputWebhookAuthenticationType = "credentialsSecret"
	OutputWebhookAuthenticationTypeToken             OutputWebhookAuthenticationType = "token"
	OutputWebhookAuthenticationTypeTextSecret        OutputWebhookAuthenticationType = "textSecret"
	OutputWebhookAuthenticationTypeOauth             OutputWebhookAuthenticationType = "oauth"
)

func (e OutputWebhookAuthenticationType) ToPointer() *OutputWebhookAuthenticationType {
	return &e
}
func (e *OutputWebhookAuthenticationType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "basic":
		fallthrough
	case "credentialsSecret":
		fallthrough
	case "token":
		fallthrough
	case "textSecret":
		fallthrough
	case "oauth":
		*e = OutputWebhookAuthenticationType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputWebhookAuthenticationType: %v", v)
	}
}

// OutputWebhookMinimumTLSVersion - Minimum TLS version to use when connecting
type OutputWebhookMinimumTLSVersion string

const (
	OutputWebhookMinimumTLSVersionTlSv1  OutputWebhookMinimumTLSVersion = "TLSv1"
	OutputWebhookMinimumTLSVersionTlSv11 OutputWebhookMinimumTLSVersion = "TLSv1.1"
	OutputWebhookMinimumTLSVersionTlSv12 OutputWebhookMinimumTLSVersion = "TLSv1.2"
	OutputWebhookMinimumTLSVersionTlSv13 OutputWebhookMinimumTLSVersion = "TLSv1.3"
)

func (e OutputWebhookMinimumTLSVersion) ToPointer() *OutputWebhookMinimumTLSVersion {
	return &e
}
func (e *OutputWebhookMinimumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = OutputWebhookMinimumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputWebhookMinimumTLSVersion: %v", v)
	}
}

// OutputWebhookMaximumTLSVersion - Maximum TLS version to use when connecting
type OutputWebhookMaximumTLSVersion string

const (
	OutputWebhookMaximumTLSVersionTlSv1  OutputWebhookMaximumTLSVersion = "TLSv1"
	OutputWebhookMaximumTLSVersionTlSv11 OutputWebhookMaximumTLSVersion = "TLSv1.1"
	OutputWebhookMaximumTLSVersionTlSv12 OutputWebhookMaximumTLSVersion = "TLSv1.2"
	OutputWebhookMaximumTLSVersionTlSv13 OutputWebhookMaximumTLSVersion = "TLSv1.3"
)

func (e OutputWebhookMaximumTLSVersion) ToPointer() *OutputWebhookMaximumTLSVersion {
	return &e
}
func (e *OutputWebhookMaximumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = OutputWebhookMaximumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputWebhookMaximumTLSVersion: %v", v)
	}
}

type OutputWebhookTLSSettingsClientSide struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.
	Servername *string `json:"servername,omitempty"`
	// The name of the predefined certificate.
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Passphrase to use to decrypt private key.
	Passphrase *string `json:"passphrase,omitempty"`
	// Minimum TLS version to use when connecting
	MinVersion *OutputWebhookMinimumTLSVersion `json:"minVersion,omitempty"`
	// Maximum TLS version to use when connecting
	MaxVersion *OutputWebhookMaximumTLSVersion `json:"maxVersion,omitempty"`
}

func (o OutputWebhookTLSSettingsClientSide) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputWebhookTLSSettingsClientSide) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputWebhookTLSSettingsClientSide) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *OutputWebhookTLSSettingsClientSide) GetServername() *string {
	if o == nil {
		return nil
	}
	return o.Servername
}

func (o *OutputWebhookTLSSettingsClientSide) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *OutputWebhookTLSSettingsClientSide) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *OutputWebhookTLSSettingsClientSide) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *OutputWebhookTLSSettingsClientSide) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *OutputWebhookTLSSettingsClientSide) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *OutputWebhookTLSSettingsClientSide) GetMinVersion() *OutputWebhookMinimumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *OutputWebhookTLSSettingsClientSide) GetMaxVersion() *OutputWebhookMaximumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

// OutputWebhookCompression - Codec to use to compress the persisted data.
type OutputWebhookCompression string

const (
	OutputWebhookCompressionNone OutputWebhookCompression = "none"
	OutputWebhookCompressionGzip OutputWebhookCompression = "gzip"
)

func (e OutputWebhookCompression) ToPointer() *OutputWebhookCompression {
	return &e
}
func (e *OutputWebhookCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = OutputWebhookCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputWebhookCompression: %v", v)
	}
}

// QueueFullBehavior - Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
type QueueFullBehavior string

const (
	QueueFullBehaviorBlock QueueFullBehavior = "block"
	QueueFullBehaviorDrop  QueueFullBehavior = "drop"
)

func (e QueueFullBehavior) ToPointer() *QueueFullBehavior {
	return &e
}
func (e *QueueFullBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = QueueFullBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for QueueFullBehavior: %v", v)
	}
}

// OutputWebhookMode - In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
type OutputWebhookMode string

const (
	OutputWebhookModeError        OutputWebhookMode = "error"
	OutputWebhookModeBackpressure OutputWebhookMode = "backpressure"
	OutputWebhookModeAlways       OutputWebhookMode = "always"
)

func (e OutputWebhookMode) ToPointer() *OutputWebhookMode {
	return &e
}
func (e *OutputWebhookMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "error":
		fallthrough
	case "backpressure":
		fallthrough
	case "always":
		*e = OutputWebhookMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputWebhookMode: %v", v)
	}
}

type PqControls struct {
}

type OutputWebhookOauthParams struct {
	// OAuth parameter name
	Name string `json:"name"`
	// OAuth parameter value
	Value string `json:"value"`
}

func (o *OutputWebhookOauthParams) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *OutputWebhookOauthParams) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type OutputWebhookOauthHeaders struct {
	// OAuth header name
	Name string `json:"name"`
	// OAuth header value
	Value string `json:"value"`
}

func (o *OutputWebhookOauthHeaders) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *OutputWebhookOauthHeaders) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type OutputWebhookUrls struct {
	// URL of a webhook endpoint to send events to, such as http://localhost:10200
	URL string `json:"url"`
	// Assign a weight (>0) to each endpoint to indicate its traffic-handling capability
	Weight *float64 `default:"1" json:"weight"`
}

func (o OutputWebhookUrls) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputWebhookUrls) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *OutputWebhookUrls) GetURL() string {
	if o == nil {
		return ""
	}
	return o.URL
}

func (o *OutputWebhookUrls) GetWeight() *float64 {
	if o == nil {
		return nil
	}
	return o.Weight
}

type OutputWebhook struct {
	// Unique ID for this output
	ID   string            `json:"id"`
	Type OutputWebhookType `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// The method to use when sending events. Defaults to POST.
	Method *Method `default:"POST" json:"method"`
	// Specifies how to format events before sending out. Defaults to NDJSON.
	Format *OutputWebhookFormat `default:"ndjson" json:"format"`
	// Disable to close the connection immediately after sending the outgoing request
	KeepAlive *bool `default:"true" json:"keepAlive"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `default:"5" json:"concurrency"`
	// Maximum size, in KB, of the request body
	MaxPayloadSizeKB *float64 `default:"4096" json:"maxPayloadSizeKB"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited).
	MaxPayloadEvents *float64 `default:"0" json:"maxPayloadEvents"`
	// Compress the payload body before sending
	Compress *bool `default:"true" json:"compress"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Defaults to Yes. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `default:"30" json:"timeoutSec"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Max body size.
	FlushPeriodSec *float64 `default:"1" json:"flushPeriodSec"`
	// Headers to add to all events. You can also add headers dynamically on a per-event basis in the __headers field, as explained [here](https://docs.cribl.io/stream/destinations-webhook/#internal-fields).
	ExtraHTTPHeaders []OutputWebhookExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// Enables round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
	UseRoundRobinDNS *bool `default:"false" json:"useRoundRobinDns"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *FailedRequestLoggingMode `default:"none" json:"failedRequestLoggingMode"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable).
	ResponseRetrySettings []ResponseRetrySettings `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *TimeoutRetrySettings   `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `default:"false" json:"responseHonorRetryAfterHeader"`
	// Whether to block, drop, or queue events when all receivers are exerting backpressure.
	OnBackpressure *BackpressureBehavior `default:"block" json:"onBackpressure"`
	// The authentication method to use for the HTTP request. Defaults to None.
	AuthType *OutputWebhookAuthenticationType    `default:"none" json:"authType"`
	TLS      *OutputWebhookTLSSettingsClientSide `json:"tls,omitempty"`
	// Maximum total size of the batches waiting to be sent. If left blank, defaults to 5 times the max body size (if set). If 0, no limit is enforced.
	TotalMemoryLimitKB *float64 `json:"totalMemoryLimitKB,omitempty"`
	// Enable for optimal performance. Even if you have one hostname, it can expand to multiple IPs. If disabled, consider enabling round-robin DNS.
	LoadBalanced *bool   `default:"false" json:"loadBalanced"`
	Description  *string `json:"description,omitempty"`
	// Expression to evaluate on events to generate output. Example: `raw=${_raw}`. See [Cribl Docs](https://docs.cribl.io/stream/destinations-webhook#custom-format) for other examples. If empty, the full event is sent as stringified JSON.
	CustomSourceExpression *string `default:"__httpOut" json:"customSourceExpression"`
	// Whether to drop events when the source expression evaluates to null
	CustomDropWhenNull *bool `default:"false" json:"customDropWhenNull"`
	// Delimiter string to insert between individual events. Defaults to newline character.
	CustomEventDelimiter *string `default:"\\n" json:"customEventDelimiter"`
	// Content type to use for request. Defaults to application/x-ndjson. Any content types set in Advanced Settings > Extra HTTP headers will override this entry.
	CustomContentType *string `default:"application/x-ndjson" json:"customContentType"`
	// Expression specifying how to format the payload for each batch. To reference the events to send, use the `${events}` variable. Example expression: `{ "items" : [${events}] }` would send the batch inside a JSON object.
	CustomPayloadExpression *string `default:"\\${events}" json:"customPayloadExpression"`
	// HTTP content-type header value
	AdvancedContentType *string `default:"application/json" json:"advancedContentType"`
	// Custom JavaScript code to format incoming event data accessible through the __e variable. The formatted content is added to (__e['__eventOut']) if available. Otherwise, the original event is serialized as JSON. Caution: This function is evaluated in an unprotected context, allowing you to execute almost any JavaScript code.
	FormatEventCode *string `json:"formatEventCode,omitempty"`
	// Optional JavaScript code to format the payload sent to the Destination. The payload, containing a batch of formatted events, is accessible through the __e['payload'] variable. The formatted payload is returned in the __e['__payloadOut'] variable. Caution: This function is evaluated in an unprotected context, allowing you to execute almost any JavaScript code.
	FormatPayloadCode *string `json:"formatPayloadCode,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.).
	PqMaxFileSize *string `default:"1 MB" json:"pqMaxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `default:"5GB" json:"pqMaxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `default:"\\$CRIBL_HOME/state/queues" json:"pqPath"`
	// Codec to use to compress the persisted data.
	PqCompress *OutputWebhookCompression `default:"none" json:"pqCompress"`
	// Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *QueueFullBehavior `default:"block" json:"pqOnBackpressure"`
	// In Error mode, PQ writes events to the filesystem only when it detects a non-retryable Destination error. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination or when there are non-retryable Destination errors. In Always On mode, PQ always writes events to the filesystem.
	PqMode     *OutputWebhookMode `default:"error" json:"pqMode"`
	PqControls *PqControls        `json:"pqControls,omitempty"`
	Username   *string            `json:"username,omitempty"`
	Password   *string            `json:"password,omitempty"`
	// Bearer token to include in the authorization header
	Token *string `json:"token,omitempty"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// URL for OAuth
	LoginURL *string `json:"loginUrl,omitempty"`
	// Secret parameter name to pass in request body
	SecretParamName *string `json:"secretParamName,omitempty"`
	// Secret parameter value to pass in request body
	Secret *string `json:"secret,omitempty"`
	// Name of the auth token attribute in the OAuth response. Can be top-level (e.g., 'token'); or nested, using a period (e.g., 'data.token').
	TokenAttributeName *string `json:"tokenAttributeName,omitempty"`
	// JavaScript expression to compute the Authorization header value to pass in requests. The value `${token}` is used to reference the token obtained from authentication, e.g.: `Bearer ${token}`.
	AuthHeaderExpr *string `default:"Bearer \\${token}" json:"authHeaderExpr"`
	// How often the OAuth token should be refreshed.
	TokenTimeoutSecs *float64 `default:"3600" json:"tokenTimeoutSecs"`
	// Additional parameters to send in the OAuth login request. @{product} will combine the secret with these parameters, and will send the URL-encoded result in a POST request to the endpoint specified in the 'Login URL'. We'll automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthParams []OutputWebhookOauthParams `json:"oauthParams,omitempty"`
	// Additional headers to send in the OAuth login request. @{product} will automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthHeaders []OutputWebhookOauthHeaders `json:"oauthHeaders,omitempty"`
	// URL of a webhook endpoint to send events to, such as http://localhost:10200
	URL *string `json:"url,omitempty"`
	// Exclude all IPs of the current host from the list of any resolved hostnames.
	ExcludeSelf *bool               `default:"false" json:"excludeSelf"`
	Urls        []OutputWebhookUrls `json:"urls,omitempty"`
	// Re-resolve any hostnames every this many seconds and pick up destinations from A records.
	DNSResolvePeriodSec *float64 `default:"600" json:"dnsResolvePeriodSec"`
	// How far back in time to keep traffic stats for load balancing purposes.
	LoadBalanceStatsPeriodSec *float64  `default:"300" json:"loadBalanceStatsPeriodSec"`
	Status                    *TFStatus `json:"status,omitempty"`
}

func (o OutputWebhook) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputWebhook) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *OutputWebhook) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *OutputWebhook) GetType() OutputWebhookType {
	if o == nil {
		return OutputWebhookType("")
	}
	return o.Type
}

func (o *OutputWebhook) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputWebhook) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputWebhook) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputWebhook) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputWebhook) GetMethod() *Method {
	if o == nil {
		return nil
	}
	return o.Method
}

func (o *OutputWebhook) GetFormat() *OutputWebhookFormat {
	if o == nil {
		return nil
	}
	return o.Format
}

func (o *OutputWebhook) GetKeepAlive() *bool {
	if o == nil {
		return nil
	}
	return o.KeepAlive
}

func (o *OutputWebhook) GetConcurrency() *float64 {
	if o == nil {
		return nil
	}
	return o.Concurrency
}

func (o *OutputWebhook) GetMaxPayloadSizeKB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadSizeKB
}

func (o *OutputWebhook) GetMaxPayloadEvents() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadEvents
}

func (o *OutputWebhook) GetCompress() *bool {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *OutputWebhook) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputWebhook) GetTimeoutSec() *float64 {
	if o == nil {
		return nil
	}
	return o.TimeoutSec
}

func (o *OutputWebhook) GetFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushPeriodSec
}

func (o *OutputWebhook) GetExtraHTTPHeaders() []OutputWebhookExtraHTTPHeaders {
	if o == nil {
		return nil
	}
	return o.ExtraHTTPHeaders
}

func (o *OutputWebhook) GetUseRoundRobinDNS() *bool {
	if o == nil {
		return nil
	}
	return o.UseRoundRobinDNS
}

func (o *OutputWebhook) GetFailedRequestLoggingMode() *FailedRequestLoggingMode {
	if o == nil {
		return nil
	}
	return o.FailedRequestLoggingMode
}

func (o *OutputWebhook) GetSafeHeaders() []string {
	if o == nil {
		return nil
	}
	return o.SafeHeaders
}

func (o *OutputWebhook) GetResponseRetrySettings() []ResponseRetrySettings {
	if o == nil {
		return nil
	}
	return o.ResponseRetrySettings
}

func (o *OutputWebhook) GetTimeoutRetrySettings() *TimeoutRetrySettings {
	if o == nil {
		return nil
	}
	return o.TimeoutRetrySettings
}

func (o *OutputWebhook) GetResponseHonorRetryAfterHeader() *bool {
	if o == nil {
		return nil
	}
	return o.ResponseHonorRetryAfterHeader
}

func (o *OutputWebhook) GetOnBackpressure() *BackpressureBehavior {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputWebhook) GetAuthType() *OutputWebhookAuthenticationType {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *OutputWebhook) GetTLS() *OutputWebhookTLSSettingsClientSide {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *OutputWebhook) GetTotalMemoryLimitKB() *float64 {
	if o == nil {
		return nil
	}
	return o.TotalMemoryLimitKB
}

func (o *OutputWebhook) GetLoadBalanced() *bool {
	if o == nil {
		return nil
	}
	return o.LoadBalanced
}

func (o *OutputWebhook) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputWebhook) GetCustomSourceExpression() *string {
	if o == nil {
		return nil
	}
	return o.CustomSourceExpression
}

func (o *OutputWebhook) GetCustomDropWhenNull() *bool {
	if o == nil {
		return nil
	}
	return o.CustomDropWhenNull
}

func (o *OutputWebhook) GetCustomEventDelimiter() *string {
	if o == nil {
		return nil
	}
	return o.CustomEventDelimiter
}

func (o *OutputWebhook) GetCustomContentType() *string {
	if o == nil {
		return nil
	}
	return o.CustomContentType
}

func (o *OutputWebhook) GetCustomPayloadExpression() *string {
	if o == nil {
		return nil
	}
	return o.CustomPayloadExpression
}

func (o *OutputWebhook) GetAdvancedContentType() *string {
	if o == nil {
		return nil
	}
	return o.AdvancedContentType
}

func (o *OutputWebhook) GetFormatEventCode() *string {
	if o == nil {
		return nil
	}
	return o.FormatEventCode
}

func (o *OutputWebhook) GetFormatPayloadCode() *string {
	if o == nil {
		return nil
	}
	return o.FormatPayloadCode
}

func (o *OutputWebhook) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputWebhook) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputWebhook) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputWebhook) GetPqCompress() *OutputWebhookCompression {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputWebhook) GetPqOnBackpressure() *QueueFullBehavior {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputWebhook) GetPqMode() *OutputWebhookMode {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputWebhook) GetPqControls() *PqControls {
	if o == nil {
		return nil
	}
	return o.PqControls
}

func (o *OutputWebhook) GetUsername() *string {
	if o == nil {
		return nil
	}
	return o.Username
}

func (o *OutputWebhook) GetPassword() *string {
	if o == nil {
		return nil
	}
	return o.Password
}

func (o *OutputWebhook) GetToken() *string {
	if o == nil {
		return nil
	}
	return o.Token
}

func (o *OutputWebhook) GetCredentialsSecret() *string {
	if o == nil {
		return nil
	}
	return o.CredentialsSecret
}

func (o *OutputWebhook) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *OutputWebhook) GetLoginURL() *string {
	if o == nil {
		return nil
	}
	return o.LoginURL
}

func (o *OutputWebhook) GetSecretParamName() *string {
	if o == nil {
		return nil
	}
	return o.SecretParamName
}

func (o *OutputWebhook) GetSecret() *string {
	if o == nil {
		return nil
	}
	return o.Secret
}

func (o *OutputWebhook) GetTokenAttributeName() *string {
	if o == nil {
		return nil
	}
	return o.TokenAttributeName
}

func (o *OutputWebhook) GetAuthHeaderExpr() *string {
	if o == nil {
		return nil
	}
	return o.AuthHeaderExpr
}

func (o *OutputWebhook) GetTokenTimeoutSecs() *float64 {
	if o == nil {
		return nil
	}
	return o.TokenTimeoutSecs
}

func (o *OutputWebhook) GetOauthParams() []OutputWebhookOauthParams {
	if o == nil {
		return nil
	}
	return o.OauthParams
}

func (o *OutputWebhook) GetOauthHeaders() []OutputWebhookOauthHeaders {
	if o == nil {
		return nil
	}
	return o.OauthHeaders
}

func (o *OutputWebhook) GetURL() *string {
	if o == nil {
		return nil
	}
	return o.URL
}

func (o *OutputWebhook) GetExcludeSelf() *bool {
	if o == nil {
		return nil
	}
	return o.ExcludeSelf
}

func (o *OutputWebhook) GetUrls() []OutputWebhookUrls {
	if o == nil {
		return nil
	}
	return o.Urls
}

func (o *OutputWebhook) GetDNSResolvePeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.DNSResolvePeriodSec
}

func (o *OutputWebhook) GetLoadBalanceStatsPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.LoadBalanceStatsPeriodSec
}

func (o *OutputWebhook) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type OutputDefaultType string

const (
	OutputDefaultTypeDefault OutputDefaultType = "default"
)

func (e OutputDefaultType) ToPointer() *OutputDefaultType {
	return &e
}
func (e *OutputDefaultType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "default":
		*e = OutputDefaultType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputDefaultType: %v", v)
	}
}

type OutputDefault struct {
	// Unique ID for this output
	ID   *string           `json:"id,omitempty"`
	Type OutputDefaultType `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// ID of the default output. This will be used whenever a nonexistent/deleted output is referenced.
	DefaultID string    `json:"defaultId"`
	Status    *TFStatus `json:"status,omitempty"`
}

func (o *OutputDefault) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *OutputDefault) GetType() OutputDefaultType {
	if o == nil {
		return OutputDefaultType("")
	}
	return o.Type
}

func (o *OutputDefault) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputDefault) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputDefault) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputDefault) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputDefault) GetDefaultID() string {
	if o == nil {
		return ""
	}
	return o.DefaultID
}

func (o *OutputDefault) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type OutputType string

const (
	OutputTypeOutputDefault                OutputType = "OutputDefault"
	OutputTypeOutputWebhook                OutputType = "OutputWebhook"
	OutputTypeOutputSentinel               OutputType = "OutputSentinel"
	OutputTypeOutputDevnull                OutputType = "OutputDevnull"
	OutputTypeOutputSyslog                 OutputType = "OutputSyslog"
	OutputTypeOutputSplunk                 OutputType = "OutputSplunk"
	OutputTypeOutputSplunkLb               OutputType = "OutputSplunkLb"
	OutputTypeOutputSplunkHec              OutputType = "OutputSplunkHec"
	OutputTypeOutputTcpjson                OutputType = "OutputTcpjson"
	OutputTypeOutputWavefront              OutputType = "OutputWavefront"
	OutputTypeOutputSignalfx               OutputType = "OutputSignalfx"
	OutputTypeOutputFilesystem             OutputType = "OutputFilesystem"
	OutputTypeOutputS3                     OutputType = "OutputS3"
	OutputTypeOutputAzureBlob              OutputType = "OutputAzureBlob"
	OutputTypeOutputAzureDataExplorer      OutputType = "OutputAzureDataExplorer"
	OutputTypeOutputAzureLogs              OutputType = "OutputAzureLogs"
	OutputTypeOutputKinesis                OutputType = "OutputKinesis"
	OutputTypeOutputHoneycomb              OutputType = "OutputHoneycomb"
	OutputTypeOutputAzureEventhub          OutputType = "OutputAzureEventhub"
	OutputTypeOutputGoogleChronicle        OutputType = "OutputGoogleChronicle"
	OutputTypeOutputGoogleCloudStorage     OutputType = "OutputGoogleCloudStorage"
	OutputTypeOutputGoogleCloudLogging     OutputType = "OutputGoogleCloudLogging"
	OutputTypeOutputGooglePubsub           OutputType = "OutputGooglePubsub"
	OutputTypeOutputExabeam                OutputType = "OutputExabeam"
	OutputTypeOutputKafka                  OutputType = "OutputKafka"
	OutputTypeOutputConfluentCloud         OutputType = "OutputConfluentCloud"
	OutputTypeOutputMsk                    OutputType = "OutputMsk"
	OutputTypeOutputElastic                OutputType = "OutputElastic"
	OutputTypeOutputElasticCloud           OutputType = "OutputElasticCloud"
	OutputTypeOutputNewrelic               OutputType = "OutputNewrelic"
	OutputTypeOutputNewrelicEvents         OutputType = "OutputNewrelicEvents"
	OutputTypeOutputInfluxdb               OutputType = "OutputInfluxdb"
	OutputTypeOutputCloudwatch             OutputType = "OutputCloudwatch"
	OutputTypeOutputMinio                  OutputType = "OutputMinio"
	OutputTypeOutputStatsd                 OutputType = "OutputStatsd"
	OutputTypeOutputStatsdExt              OutputType = "OutputStatsdExt"
	OutputTypeOutputGraphite               OutputType = "OutputGraphite"
	OutputTypeOutputRouter                 OutputType = "OutputRouter"
	OutputTypeOutputSns                    OutputType = "OutputSns"
	OutputTypeOutputSqs                    OutputType = "OutputSqs"
	OutputTypeOutputSnmp                   OutputType = "OutputSnmp"
	OutputTypeOutputSumoLogic              OutputType = "OutputSumoLogic"
	OutputTypeOutputDatadog                OutputType = "OutputDatadog"
	OutputTypeOutputGrafanaCloud           OutputType = "OutputGrafanaCloud"
	OutputTypeOutputLoki                   OutputType = "OutputLoki"
	OutputTypeOutputPrometheus             OutputType = "OutputPrometheus"
	OutputTypeOutputRing                   OutputType = "OutputRing"
	OutputTypeOutputOpenTelemetry          OutputType = "OutputOpenTelemetry"
	OutputTypeOutputServiceNow             OutputType = "OutputServiceNow"
	OutputTypeOutputDataset                OutputType = "OutputDataset"
	OutputTypeOutputCriblTCP               OutputType = "OutputCriblTcp"
	OutputTypeOutputCriblHTTP              OutputType = "OutputCriblHttp"
	OutputTypeOutputHumioHec               OutputType = "OutputHumioHec"
	OutputTypeOutputCrowdstrikeNextGenSiem OutputType = "OutputCrowdstrikeNextGenSiem"
	OutputTypeOutputDlS3                   OutputType = "OutputDlS3"
	OutputTypeOutputSecurityLake           OutputType = "OutputSecurityLake"
	OutputTypeOutputCriblLake              OutputType = "OutputCriblLake"
	OutputTypeOutputDiskSpool              OutputType = "OutputDiskSpool"
	OutputTypeOutputClickHouse             OutputType = "OutputClickHouse"
	OutputTypeOutputXsiam                  OutputType = "OutputXsiam"
	OutputTypeOutputNetflow                OutputType = "OutputNetflow"
	OutputTypeOutputDynatraceHTTP          OutputType = "OutputDynatraceHttp"
	OutputTypeOutputDynatraceOtlp          OutputType = "OutputDynatraceOtlp"
)

type Output struct {
	OutputDefault                *OutputDefault                `queryParam:"inline"`
	OutputWebhook                *OutputWebhook                `queryParam:"inline"`
	OutputSentinel               *OutputSentinel               `queryParam:"inline"`
	OutputDevnull                *OutputDevnull                `queryParam:"inline"`
	OutputSyslog                 *OutputSyslog                 `queryParam:"inline"`
	OutputSplunk                 *OutputSplunk                 `queryParam:"inline"`
	OutputSplunkLb               *OutputSplunkLb               `queryParam:"inline"`
	OutputSplunkHec              *OutputSplunkHec              `queryParam:"inline"`
	OutputTcpjson                *OutputTcpjson                `queryParam:"inline"`
	OutputWavefront              *OutputWavefront              `queryParam:"inline"`
	OutputSignalfx               *OutputSignalfx               `queryParam:"inline"`
	OutputFilesystem             *OutputFilesystem             `queryParam:"inline"`
	OutputS3                     *OutputS3                     `queryParam:"inline"`
	OutputAzureBlob              *OutputAzureBlob              `queryParam:"inline"`
	OutputAzureDataExplorer      *OutputAzureDataExplorer      `queryParam:"inline"`
	OutputAzureLogs              *OutputAzureLogs              `queryParam:"inline"`
	OutputKinesis                *OutputKinesis                `queryParam:"inline"`
	OutputHoneycomb              *OutputHoneycomb              `queryParam:"inline"`
	OutputAzureEventhub          *OutputAzureEventhub          `queryParam:"inline"`
	OutputGoogleChronicle        *OutputGoogleChronicle        `queryParam:"inline"`
	OutputGoogleCloudStorage     *OutputGoogleCloudStorage     `queryParam:"inline"`
	OutputGoogleCloudLogging     *OutputGoogleCloudLogging     `queryParam:"inline"`
	OutputGooglePubsub           *OutputGooglePubsub           `queryParam:"inline"`
	OutputExabeam                *OutputExabeam                `queryParam:"inline"`
	OutputKafka                  *OutputKafka                  `queryParam:"inline"`
	OutputConfluentCloud         *OutputConfluentCloud         `queryParam:"inline"`
	OutputMsk                    *OutputMsk                    `queryParam:"inline"`
	OutputElastic                *OutputElastic                `queryParam:"inline"`
	OutputElasticCloud           *OutputElasticCloud           `queryParam:"inline"`
	OutputNewrelic               *OutputNewrelic               `queryParam:"inline"`
	OutputNewrelicEvents         *OutputNewrelicEvents         `queryParam:"inline"`
	OutputInfluxdb               *OutputInfluxdb               `queryParam:"inline"`
	OutputCloudwatch             *OutputCloudwatch             `queryParam:"inline"`
	OutputMinio                  *OutputMinio                  `queryParam:"inline"`
	OutputStatsd                 *OutputStatsd                 `queryParam:"inline"`
	OutputStatsdExt              *OutputStatsdExt              `queryParam:"inline"`
	OutputGraphite               *OutputGraphite               `queryParam:"inline"`
	OutputRouter                 *OutputRouter                 `queryParam:"inline"`
	OutputSns                    *OutputSns                    `queryParam:"inline"`
	OutputSqs                    *OutputSqs                    `queryParam:"inline"`
	OutputSnmp                   *OutputSnmp                   `queryParam:"inline"`
	OutputSumoLogic              *OutputSumoLogic              `queryParam:"inline"`
	OutputDatadog                *OutputDatadog                `queryParam:"inline"`
	OutputGrafanaCloud           *OutputGrafanaCloud           `queryParam:"inline"`
	OutputLoki                   *OutputLoki                   `queryParam:"inline"`
	OutputPrometheus             *OutputPrometheus             `queryParam:"inline"`
	OutputRing                   *OutputRing                   `queryParam:"inline"`
	OutputOpenTelemetry          *OutputOpenTelemetry          `queryParam:"inline"`
	OutputServiceNow             *OutputServiceNow             `queryParam:"inline"`
	OutputDataset                *OutputDataset                `queryParam:"inline"`
	OutputCriblTCP               *OutputCriblTCP               `queryParam:"inline"`
	OutputCriblHTTP              *OutputCriblHTTP              `queryParam:"inline"`
	OutputHumioHec               *OutputHumioHec               `queryParam:"inline"`
	OutputCrowdstrikeNextGenSiem *OutputCrowdstrikeNextGenSiem `queryParam:"inline"`
	OutputDlS3                   *OutputDlS3                   `queryParam:"inline"`
	OutputSecurityLake           *OutputSecurityLake           `queryParam:"inline"`
	OutputCriblLake              *OutputCriblLake              `queryParam:"inline"`
	OutputDiskSpool              *OutputDiskSpool              `queryParam:"inline"`
	OutputClickHouse             *OutputClickHouse             `queryParam:"inline"`
	OutputXsiam                  *OutputXsiam                  `queryParam:"inline"`
	OutputNetflow                *OutputNetflow                `queryParam:"inline"`
	OutputDynatraceHTTP          *OutputDynatraceHTTP          `queryParam:"inline"`
	OutputDynatraceOtlp          *OutputDynatraceOtlp          `queryParam:"inline"`

	Type OutputType
}

func CreateOutputOutputDefault(outputDefault OutputDefault) Output {
	typ := OutputTypeOutputDefault

	return Output{
		OutputDefault: &outputDefault,
		Type:          typ,
	}
}

func CreateOutputOutputWebhook(outputWebhook OutputWebhook) Output {
	typ := OutputTypeOutputWebhook

	return Output{
		OutputWebhook: &outputWebhook,
		Type:          typ,
	}
}

func CreateOutputOutputSentinel(outputSentinel OutputSentinel) Output {
	typ := OutputTypeOutputSentinel

	return Output{
		OutputSentinel: &outputSentinel,
		Type:           typ,
	}
}

func CreateOutputOutputDevnull(outputDevnull OutputDevnull) Output {
	typ := OutputTypeOutputDevnull

	return Output{
		OutputDevnull: &outputDevnull,
		Type:          typ,
	}
}

func CreateOutputOutputSyslog(outputSyslog OutputSyslog) Output {
	typ := OutputTypeOutputSyslog

	return Output{
		OutputSyslog: &outputSyslog,
		Type:         typ,
	}
}

func CreateOutputOutputSplunk(outputSplunk OutputSplunk) Output {
	typ := OutputTypeOutputSplunk

	return Output{
		OutputSplunk: &outputSplunk,
		Type:         typ,
	}
}

func CreateOutputOutputSplunkLb(outputSplunkLb OutputSplunkLb) Output {
	typ := OutputTypeOutputSplunkLb

	return Output{
		OutputSplunkLb: &outputSplunkLb,
		Type:           typ,
	}
}

func CreateOutputOutputSplunkHec(outputSplunkHec OutputSplunkHec) Output {
	typ := OutputTypeOutputSplunkHec

	return Output{
		OutputSplunkHec: &outputSplunkHec,
		Type:            typ,
	}
}

func CreateOutputOutputTcpjson(outputTcpjson OutputTcpjson) Output {
	typ := OutputTypeOutputTcpjson

	return Output{
		OutputTcpjson: &outputTcpjson,
		Type:          typ,
	}
}

func CreateOutputOutputWavefront(outputWavefront OutputWavefront) Output {
	typ := OutputTypeOutputWavefront

	return Output{
		OutputWavefront: &outputWavefront,
		Type:            typ,
	}
}

func CreateOutputOutputSignalfx(outputSignalfx OutputSignalfx) Output {
	typ := OutputTypeOutputSignalfx

	return Output{
		OutputSignalfx: &outputSignalfx,
		Type:           typ,
	}
}

func CreateOutputOutputFilesystem(outputFilesystem OutputFilesystem) Output {
	typ := OutputTypeOutputFilesystem

	return Output{
		OutputFilesystem: &outputFilesystem,
		Type:             typ,
	}
}

func CreateOutputOutputS3(outputS3 OutputS3) Output {
	typ := OutputTypeOutputS3

	return Output{
		OutputS3: &outputS3,
		Type:     typ,
	}
}

func CreateOutputOutputAzureBlob(outputAzureBlob OutputAzureBlob) Output {
	typ := OutputTypeOutputAzureBlob

	return Output{
		OutputAzureBlob: &outputAzureBlob,
		Type:            typ,
	}
}

func CreateOutputOutputAzureDataExplorer(outputAzureDataExplorer OutputAzureDataExplorer) Output {
	typ := OutputTypeOutputAzureDataExplorer

	return Output{
		OutputAzureDataExplorer: &outputAzureDataExplorer,
		Type:                    typ,
	}
}

func CreateOutputOutputAzureLogs(outputAzureLogs OutputAzureLogs) Output {
	typ := OutputTypeOutputAzureLogs

	return Output{
		OutputAzureLogs: &outputAzureLogs,
		Type:            typ,
	}
}

func CreateOutputOutputKinesis(outputKinesis OutputKinesis) Output {
	typ := OutputTypeOutputKinesis

	return Output{
		OutputKinesis: &outputKinesis,
		Type:          typ,
	}
}

func CreateOutputOutputHoneycomb(outputHoneycomb OutputHoneycomb) Output {
	typ := OutputTypeOutputHoneycomb

	return Output{
		OutputHoneycomb: &outputHoneycomb,
		Type:            typ,
	}
}

func CreateOutputOutputAzureEventhub(outputAzureEventhub OutputAzureEventhub) Output {
	typ := OutputTypeOutputAzureEventhub

	return Output{
		OutputAzureEventhub: &outputAzureEventhub,
		Type:                typ,
	}
}

func CreateOutputOutputGoogleChronicle(outputGoogleChronicle OutputGoogleChronicle) Output {
	typ := OutputTypeOutputGoogleChronicle

	return Output{
		OutputGoogleChronicle: &outputGoogleChronicle,
		Type:                  typ,
	}
}

func CreateOutputOutputGoogleCloudStorage(outputGoogleCloudStorage OutputGoogleCloudStorage) Output {
	typ := OutputTypeOutputGoogleCloudStorage

	return Output{
		OutputGoogleCloudStorage: &outputGoogleCloudStorage,
		Type:                     typ,
	}
}

func CreateOutputOutputGoogleCloudLogging(outputGoogleCloudLogging OutputGoogleCloudLogging) Output {
	typ := OutputTypeOutputGoogleCloudLogging

	return Output{
		OutputGoogleCloudLogging: &outputGoogleCloudLogging,
		Type:                     typ,
	}
}

func CreateOutputOutputGooglePubsub(outputGooglePubsub OutputGooglePubsub) Output {
	typ := OutputTypeOutputGooglePubsub

	return Output{
		OutputGooglePubsub: &outputGooglePubsub,
		Type:               typ,
	}
}

func CreateOutputOutputExabeam(outputExabeam OutputExabeam) Output {
	typ := OutputTypeOutputExabeam

	return Output{
		OutputExabeam: &outputExabeam,
		Type:          typ,
	}
}

func CreateOutputOutputKafka(outputKafka OutputKafka) Output {
	typ := OutputTypeOutputKafka

	return Output{
		OutputKafka: &outputKafka,
		Type:        typ,
	}
}

func CreateOutputOutputConfluentCloud(outputConfluentCloud OutputConfluentCloud) Output {
	typ := OutputTypeOutputConfluentCloud

	return Output{
		OutputConfluentCloud: &outputConfluentCloud,
		Type:                 typ,
	}
}

func CreateOutputOutputMsk(outputMsk OutputMsk) Output {
	typ := OutputTypeOutputMsk

	return Output{
		OutputMsk: &outputMsk,
		Type:      typ,
	}
}

func CreateOutputOutputElastic(outputElastic OutputElastic) Output {
	typ := OutputTypeOutputElastic

	return Output{
		OutputElastic: &outputElastic,
		Type:          typ,
	}
}

func CreateOutputOutputElasticCloud(outputElasticCloud OutputElasticCloud) Output {
	typ := OutputTypeOutputElasticCloud

	return Output{
		OutputElasticCloud: &outputElasticCloud,
		Type:               typ,
	}
}

func CreateOutputOutputNewrelic(outputNewrelic OutputNewrelic) Output {
	typ := OutputTypeOutputNewrelic

	return Output{
		OutputNewrelic: &outputNewrelic,
		Type:           typ,
	}
}

func CreateOutputOutputNewrelicEvents(outputNewrelicEvents OutputNewrelicEvents) Output {
	typ := OutputTypeOutputNewrelicEvents

	return Output{
		OutputNewrelicEvents: &outputNewrelicEvents,
		Type:                 typ,
	}
}

func CreateOutputOutputInfluxdb(outputInfluxdb OutputInfluxdb) Output {
	typ := OutputTypeOutputInfluxdb

	return Output{
		OutputInfluxdb: &outputInfluxdb,
		Type:           typ,
	}
}

func CreateOutputOutputCloudwatch(outputCloudwatch OutputCloudwatch) Output {
	typ := OutputTypeOutputCloudwatch

	return Output{
		OutputCloudwatch: &outputCloudwatch,
		Type:             typ,
	}
}

func CreateOutputOutputMinio(outputMinio OutputMinio) Output {
	typ := OutputTypeOutputMinio

	return Output{
		OutputMinio: &outputMinio,
		Type:        typ,
	}
}

func CreateOutputOutputStatsd(outputStatsd OutputStatsd) Output {
	typ := OutputTypeOutputStatsd

	return Output{
		OutputStatsd: &outputStatsd,
		Type:         typ,
	}
}

func CreateOutputOutputStatsdExt(outputStatsdExt OutputStatsdExt) Output {
	typ := OutputTypeOutputStatsdExt

	return Output{
		OutputStatsdExt: &outputStatsdExt,
		Type:            typ,
	}
}

func CreateOutputOutputGraphite(outputGraphite OutputGraphite) Output {
	typ := OutputTypeOutputGraphite

	return Output{
		OutputGraphite: &outputGraphite,
		Type:           typ,
	}
}

func CreateOutputOutputRouter(outputRouter OutputRouter) Output {
	typ := OutputTypeOutputRouter

	return Output{
		OutputRouter: &outputRouter,
		Type:         typ,
	}
}

func CreateOutputOutputSns(outputSns OutputSns) Output {
	typ := OutputTypeOutputSns

	return Output{
		OutputSns: &outputSns,
		Type:      typ,
	}
}

func CreateOutputOutputSqs(outputSqs OutputSqs) Output {
	typ := OutputTypeOutputSqs

	return Output{
		OutputSqs: &outputSqs,
		Type:      typ,
	}
}

func CreateOutputOutputSnmp(outputSnmp OutputSnmp) Output {
	typ := OutputTypeOutputSnmp

	return Output{
		OutputSnmp: &outputSnmp,
		Type:       typ,
	}
}

func CreateOutputOutputSumoLogic(outputSumoLogic OutputSumoLogic) Output {
	typ := OutputTypeOutputSumoLogic

	return Output{
		OutputSumoLogic: &outputSumoLogic,
		Type:            typ,
	}
}

func CreateOutputOutputDatadog(outputDatadog OutputDatadog) Output {
	typ := OutputTypeOutputDatadog

	return Output{
		OutputDatadog: &outputDatadog,
		Type:          typ,
	}
}

func CreateOutputOutputGrafanaCloud(outputGrafanaCloud OutputGrafanaCloud) Output {
	typ := OutputTypeOutputGrafanaCloud

	return Output{
		OutputGrafanaCloud: &outputGrafanaCloud,
		Type:               typ,
	}
}

func CreateOutputOutputLoki(outputLoki OutputLoki) Output {
	typ := OutputTypeOutputLoki

	return Output{
		OutputLoki: &outputLoki,
		Type:       typ,
	}
}

func CreateOutputOutputPrometheus(outputPrometheus OutputPrometheus) Output {
	typ := OutputTypeOutputPrometheus

	return Output{
		OutputPrometheus: &outputPrometheus,
		Type:             typ,
	}
}

func CreateOutputOutputRing(outputRing OutputRing) Output {
	typ := OutputTypeOutputRing

	return Output{
		OutputRing: &outputRing,
		Type:       typ,
	}
}

func CreateOutputOutputOpenTelemetry(outputOpenTelemetry OutputOpenTelemetry) Output {
	typ := OutputTypeOutputOpenTelemetry

	return Output{
		OutputOpenTelemetry: &outputOpenTelemetry,
		Type:                typ,
	}
}

func CreateOutputOutputServiceNow(outputServiceNow OutputServiceNow) Output {
	typ := OutputTypeOutputServiceNow

	return Output{
		OutputServiceNow: &outputServiceNow,
		Type:             typ,
	}
}

func CreateOutputOutputDataset(outputDataset OutputDataset) Output {
	typ := OutputTypeOutputDataset

	return Output{
		OutputDataset: &outputDataset,
		Type:          typ,
	}
}

func CreateOutputOutputCriblTCP(outputCriblTCP OutputCriblTCP) Output {
	typ := OutputTypeOutputCriblTCP

	return Output{
		OutputCriblTCP: &outputCriblTCP,
		Type:           typ,
	}
}

func CreateOutputOutputCriblHTTP(outputCriblHTTP OutputCriblHTTP) Output {
	typ := OutputTypeOutputCriblHTTP

	return Output{
		OutputCriblHTTP: &outputCriblHTTP,
		Type:            typ,
	}
}

func CreateOutputOutputHumioHec(outputHumioHec OutputHumioHec) Output {
	typ := OutputTypeOutputHumioHec

	return Output{
		OutputHumioHec: &outputHumioHec,
		Type:           typ,
	}
}

func CreateOutputOutputCrowdstrikeNextGenSiem(outputCrowdstrikeNextGenSiem OutputCrowdstrikeNextGenSiem) Output {
	typ := OutputTypeOutputCrowdstrikeNextGenSiem

	return Output{
		OutputCrowdstrikeNextGenSiem: &outputCrowdstrikeNextGenSiem,
		Type:                         typ,
	}
}

func CreateOutputOutputDlS3(outputDlS3 OutputDlS3) Output {
	typ := OutputTypeOutputDlS3

	return Output{
		OutputDlS3: &outputDlS3,
		Type:       typ,
	}
}

func CreateOutputOutputSecurityLake(outputSecurityLake OutputSecurityLake) Output {
	typ := OutputTypeOutputSecurityLake

	return Output{
		OutputSecurityLake: &outputSecurityLake,
		Type:               typ,
	}
}

func CreateOutputOutputCriblLake(outputCriblLake OutputCriblLake) Output {
	typ := OutputTypeOutputCriblLake

	return Output{
		OutputCriblLake: &outputCriblLake,
		Type:            typ,
	}
}

func CreateOutputOutputDiskSpool(outputDiskSpool OutputDiskSpool) Output {
	typ := OutputTypeOutputDiskSpool

	return Output{
		OutputDiskSpool: &outputDiskSpool,
		Type:            typ,
	}
}

func CreateOutputOutputClickHouse(outputClickHouse OutputClickHouse) Output {
	typ := OutputTypeOutputClickHouse

	return Output{
		OutputClickHouse: &outputClickHouse,
		Type:             typ,
	}
}

func CreateOutputOutputXsiam(outputXsiam OutputXsiam) Output {
	typ := OutputTypeOutputXsiam

	return Output{
		OutputXsiam: &outputXsiam,
		Type:        typ,
	}
}

func CreateOutputOutputNetflow(outputNetflow OutputNetflow) Output {
	typ := OutputTypeOutputNetflow

	return Output{
		OutputNetflow: &outputNetflow,
		Type:          typ,
	}
}

func CreateOutputOutputDynatraceHTTP(outputDynatraceHTTP OutputDynatraceHTTP) Output {
	typ := OutputTypeOutputDynatraceHTTP

	return Output{
		OutputDynatraceHTTP: &outputDynatraceHTTP,
		Type:                typ,
	}
}

func CreateOutputOutputDynatraceOtlp(outputDynatraceOtlp OutputDynatraceOtlp) Output {
	typ := OutputTypeOutputDynatraceOtlp

	return Output{
		OutputDynatraceOtlp: &outputDynatraceOtlp,
		Type:                typ,
	}
}

func (u *Output) UnmarshalJSON(data []byte) error {

	var outputDevnull OutputDevnull = OutputDevnull{}
	if err := utils.UnmarshalJSON(data, &outputDevnull, "", true, true); err == nil {
		u.OutputDevnull = &outputDevnull
		u.Type = OutputTypeOutputDevnull
		return nil
	}

	var outputDefault OutputDefault = OutputDefault{}
	if err := utils.UnmarshalJSON(data, &outputDefault, "", true, true); err == nil {
		u.OutputDefault = &outputDefault
		u.Type = OutputTypeOutputDefault
		return nil
	}

	var outputRouter OutputRouter = OutputRouter{}
	if err := utils.UnmarshalJSON(data, &outputRouter, "", true, true); err == nil {
		u.OutputRouter = &outputRouter
		u.Type = OutputTypeOutputRouter
		return nil
	}

	var outputNetflow OutputNetflow = OutputNetflow{}
	if err := utils.UnmarshalJSON(data, &outputNetflow, "", true, true); err == nil {
		u.OutputNetflow = &outputNetflow
		u.Type = OutputTypeOutputNetflow
		return nil
	}

	var outputSnmp OutputSnmp = OutputSnmp{}
	if err := utils.UnmarshalJSON(data, &outputSnmp, "", true, true); err == nil {
		u.OutputSnmp = &outputSnmp
		u.Type = OutputTypeOutputSnmp
		return nil
	}

	var outputDiskSpool OutputDiskSpool = OutputDiskSpool{}
	if err := utils.UnmarshalJSON(data, &outputDiskSpool, "", true, true); err == nil {
		u.OutputDiskSpool = &outputDiskSpool
		u.Type = OutputTypeOutputDiskSpool
		return nil
	}

	var outputRing OutputRing = OutputRing{}
	if err := utils.UnmarshalJSON(data, &outputRing, "", true, true); err == nil {
		u.OutputRing = &outputRing
		u.Type = OutputTypeOutputRing
		return nil
	}

	var outputGraphite OutputGraphite = OutputGraphite{}
	if err := utils.UnmarshalJSON(data, &outputGraphite, "", true, true); err == nil {
		u.OutputGraphite = &outputGraphite
		u.Type = OutputTypeOutputGraphite
		return nil
	}

	var outputStatsdExt OutputStatsdExt = OutputStatsdExt{}
	if err := utils.UnmarshalJSON(data, &outputStatsdExt, "", true, true); err == nil {
		u.OutputStatsdExt = &outputStatsdExt
		u.Type = OutputTypeOutputStatsdExt
		return nil
	}

	var outputStatsd OutputStatsd = OutputStatsd{}
	if err := utils.UnmarshalJSON(data, &outputStatsd, "", true, true); err == nil {
		u.OutputStatsd = &outputStatsd
		u.Type = OutputTypeOutputStatsd
		return nil
	}

	var outputGooglePubsub OutputGooglePubsub = OutputGooglePubsub{}
	if err := utils.UnmarshalJSON(data, &outputGooglePubsub, "", true, true); err == nil {
		u.OutputGooglePubsub = &outputGooglePubsub
		u.Type = OutputTypeOutputGooglePubsub
		return nil
	}

	var outputSplunk OutputSplunk = OutputSplunk{}
	if err := utils.UnmarshalJSON(data, &outputSplunk, "", true, true); err == nil {
		u.OutputSplunk = &outputSplunk
		u.Type = OutputTypeOutputSplunk
		return nil
	}

	var outputSns OutputSns = OutputSns{}
	if err := utils.UnmarshalJSON(data, &outputSns, "", true, true); err == nil {
		u.OutputSns = &outputSns
		u.Type = OutputTypeOutputSns
		return nil
	}

	var outputCriblTCP OutputCriblTCP = OutputCriblTCP{}
	if err := utils.UnmarshalJSON(data, &outputCriblTCP, "", true, true); err == nil {
		u.OutputCriblTCP = &outputCriblTCP
		u.Type = OutputTypeOutputCriblTCP
		return nil
	}

	var outputCloudwatch OutputCloudwatch = OutputCloudwatch{}
	if err := utils.UnmarshalJSON(data, &outputCloudwatch, "", true, true); err == nil {
		u.OutputCloudwatch = &outputCloudwatch
		u.Type = OutputTypeOutputCloudwatch
		return nil
	}

	var outputAzureEventhub OutputAzureEventhub = OutputAzureEventhub{}
	if err := utils.UnmarshalJSON(data, &outputAzureEventhub, "", true, true); err == nil {
		u.OutputAzureEventhub = &outputAzureEventhub
		u.Type = OutputTypeOutputAzureEventhub
		return nil
	}

	var outputSyslog OutputSyslog = OutputSyslog{}
	if err := utils.UnmarshalJSON(data, &outputSyslog, "", true, true); err == nil {
		u.OutputSyslog = &outputSyslog
		u.Type = OutputTypeOutputSyslog
		return nil
	}

	var outputHoneycomb OutputHoneycomb = OutputHoneycomb{}
	if err := utils.UnmarshalJSON(data, &outputHoneycomb, "", true, true); err == nil {
		u.OutputHoneycomb = &outputHoneycomb
		u.Type = OutputTypeOutputHoneycomb
		return nil
	}

	var outputSignalfx OutputSignalfx = OutputSignalfx{}
	if err := utils.UnmarshalJSON(data, &outputSignalfx, "", true, true); err == nil {
		u.OutputSignalfx = &outputSignalfx
		u.Type = OutputTypeOutputSignalfx
		return nil
	}

	var outputWavefront OutputWavefront = OutputWavefront{}
	if err := utils.UnmarshalJSON(data, &outputWavefront, "", true, true); err == nil {
		u.OutputWavefront = &outputWavefront
		u.Type = OutputTypeOutputWavefront
		return nil
	}

	var outputSumoLogic OutputSumoLogic = OutputSumoLogic{}
	if err := utils.UnmarshalJSON(data, &outputSumoLogic, "", true, true); err == nil {
		u.OutputSumoLogic = &outputSumoLogic
		u.Type = OutputTypeOutputSumoLogic
		return nil
	}

	var outputHumioHec OutputHumioHec = OutputHumioHec{}
	if err := utils.UnmarshalJSON(data, &outputHumioHec, "", true, true); err == nil {
		u.OutputHumioHec = &outputHumioHec
		u.Type = OutputTypeOutputHumioHec
		return nil
	}

	var outputTcpjson OutputTcpjson = OutputTcpjson{}
	if err := utils.UnmarshalJSON(data, &outputTcpjson, "", true, true); err == nil {
		u.OutputTcpjson = &outputTcpjson
		u.Type = OutputTypeOutputTcpjson
		return nil
	}

	var outputCrowdstrikeNextGenSiem OutputCrowdstrikeNextGenSiem = OutputCrowdstrikeNextGenSiem{}
	if err := utils.UnmarshalJSON(data, &outputCrowdstrikeNextGenSiem, "", true, true); err == nil {
		u.OutputCrowdstrikeNextGenSiem = &outputCrowdstrikeNextGenSiem
		u.Type = OutputTypeOutputCrowdstrikeNextGenSiem
		return nil
	}

	var outputElasticCloud OutputElasticCloud = OutputElasticCloud{}
	if err := utils.UnmarshalJSON(data, &outputElasticCloud, "", true, true); err == nil {
		u.OutputElasticCloud = &outputElasticCloud
		u.Type = OutputTypeOutputElasticCloud
		return nil
	}

	var outputKinesis OutputKinesis = OutputKinesis{}
	if err := utils.UnmarshalJSON(data, &outputKinesis, "", true, true); err == nil {
		u.OutputKinesis = &outputKinesis
		u.Type = OutputTypeOutputKinesis
		return nil
	}

	var outputConfluentCloud OutputConfluentCloud = OutputConfluentCloud{}
	if err := utils.UnmarshalJSON(data, &outputConfluentCloud, "", true, true); err == nil {
		u.OutputConfluentCloud = &outputConfluentCloud
		u.Type = OutputTypeOutputConfluentCloud
		return nil
	}

	var outputKafka OutputKafka = OutputKafka{}
	if err := utils.UnmarshalJSON(data, &outputKafka, "", true, true); err == nil {
		u.OutputKafka = &outputKafka
		u.Type = OutputTypeOutputKafka
		return nil
	}

	var outputExabeam OutputExabeam = OutputExabeam{}
	if err := utils.UnmarshalJSON(data, &outputExabeam, "", true, true); err == nil {
		u.OutputExabeam = &outputExabeam
		u.Type = OutputTypeOutputExabeam
		return nil
	}

	var outputNewrelicEvents OutputNewrelicEvents = OutputNewrelicEvents{}
	if err := utils.UnmarshalJSON(data, &outputNewrelicEvents, "", true, true); err == nil {
		u.OutputNewrelicEvents = &outputNewrelicEvents
		u.Type = OutputTypeOutputNewrelicEvents
		return nil
	}

	var outputAzureLogs OutputAzureLogs = OutputAzureLogs{}
	if err := utils.UnmarshalJSON(data, &outputAzureLogs, "", true, true); err == nil {
		u.OutputAzureLogs = &outputAzureLogs
		u.Type = OutputTypeOutputAzureLogs
		return nil
	}

	var outputSqs OutputSqs = OutputSqs{}
	if err := utils.UnmarshalJSON(data, &outputSqs, "", true, true); err == nil {
		u.OutputSqs = &outputSqs
		u.Type = OutputTypeOutputSqs
		return nil
	}

	var outputSplunkLb OutputSplunkLb = OutputSplunkLb{}
	if err := utils.UnmarshalJSON(data, &outputSplunkLb, "", true, true); err == nil {
		u.OutputSplunkLb = &outputSplunkLb
		u.Type = OutputTypeOutputSplunkLb
		return nil
	}

	var outputNewrelic OutputNewrelic = OutputNewrelic{}
	if err := utils.UnmarshalJSON(data, &outputNewrelic, "", true, true); err == nil {
		u.OutputNewrelic = &outputNewrelic
		u.Type = OutputTypeOutputNewrelic
		return nil
	}

	var outputXsiam OutputXsiam = OutputXsiam{}
	if err := utils.UnmarshalJSON(data, &outputXsiam, "", true, true); err == nil {
		u.OutputXsiam = &outputXsiam
		u.Type = OutputTypeOutputXsiam
		return nil
	}

	var outputCriblHTTP OutputCriblHTTP = OutputCriblHTTP{}
	if err := utils.UnmarshalJSON(data, &outputCriblHTTP, "", true, true); err == nil {
		u.OutputCriblHTTP = &outputCriblHTTP
		u.Type = OutputTypeOutputCriblHTTP
		return nil
	}

	var outputFilesystem OutputFilesystem = OutputFilesystem{}
	if err := utils.UnmarshalJSON(data, &outputFilesystem, "", true, true); err == nil {
		u.OutputFilesystem = &outputFilesystem
		u.Type = OutputTypeOutputFilesystem
		return nil
	}

	var outputDataset OutputDataset = OutputDataset{}
	if err := utils.UnmarshalJSON(data, &outputDataset, "", true, true); err == nil {
		u.OutputDataset = &outputDataset
		u.Type = OutputTypeOutputDataset
		return nil
	}

	var outputLoki OutputLoki = OutputLoki{}
	if err := utils.UnmarshalJSON(data, &outputLoki, "", true, true); err == nil {
		u.OutputLoki = &outputLoki
		u.Type = OutputTypeOutputLoki
		return nil
	}

	var outputDynatraceHTTP OutputDynatraceHTTP = OutputDynatraceHTTP{}
	if err := utils.UnmarshalJSON(data, &outputDynatraceHTTP, "", true, true); err == nil {
		u.OutputDynatraceHTTP = &outputDynatraceHTTP
		u.Type = OutputTypeOutputDynatraceHTTP
		return nil
	}

	var outputSplunkHec OutputSplunkHec = OutputSplunkHec{}
	if err := utils.UnmarshalJSON(data, &outputSplunkHec, "", true, true); err == nil {
		u.OutputSplunkHec = &outputSplunkHec
		u.Type = OutputTypeOutputSplunkHec
		return nil
	}

	var outputDynatraceOtlp OutputDynatraceOtlp = OutputDynatraceOtlp{}
	if err := utils.UnmarshalJSON(data, &outputDynatraceOtlp, "", true, true); err == nil {
		u.OutputDynatraceOtlp = &outputDynatraceOtlp
		u.Type = OutputTypeOutputDynatraceOtlp
		return nil
	}

	var outputServiceNow OutputServiceNow = OutputServiceNow{}
	if err := utils.UnmarshalJSON(data, &outputServiceNow, "", true, true); err == nil {
		u.OutputServiceNow = &outputServiceNow
		u.Type = OutputTypeOutputServiceNow
		return nil
	}

	var outputGoogleChronicle OutputGoogleChronicle = OutputGoogleChronicle{}
	if err := utils.UnmarshalJSON(data, &outputGoogleChronicle, "", true, true); err == nil {
		u.OutputGoogleChronicle = &outputGoogleChronicle
		u.Type = OutputTypeOutputGoogleChronicle
		return nil
	}

	var outputElastic OutputElastic = OutputElastic{}
	if err := utils.UnmarshalJSON(data, &outputElastic, "", true, true); err == nil {
		u.OutputElastic = &outputElastic
		u.Type = OutputTypeOutputElastic
		return nil
	}

	var outputDatadog OutputDatadog = OutputDatadog{}
	if err := utils.UnmarshalJSON(data, &outputDatadog, "", true, true); err == nil {
		u.OutputDatadog = &outputDatadog
		u.Type = OutputTypeOutputDatadog
		return nil
	}

	var outputCriblLake OutputCriblLake = OutputCriblLake{}
	if err := utils.UnmarshalJSON(data, &outputCriblLake, "", true, true); err == nil {
		u.OutputCriblLake = &outputCriblLake
		u.Type = OutputTypeOutputCriblLake
		return nil
	}

	var outputPrometheus OutputPrometheus = OutputPrometheus{}
	if err := utils.UnmarshalJSON(data, &outputPrometheus, "", true, true); err == nil {
		u.OutputPrometheus = &outputPrometheus
		u.Type = OutputTypeOutputPrometheus
		return nil
	}

	var outputMsk OutputMsk = OutputMsk{}
	if err := utils.UnmarshalJSON(data, &outputMsk, "", true, true); err == nil {
		u.OutputMsk = &outputMsk
		u.Type = OutputTypeOutputMsk
		return nil
	}

	var outputSentinel OutputSentinel = OutputSentinel{}
	if err := utils.UnmarshalJSON(data, &outputSentinel, "", true, true); err == nil {
		u.OutputSentinel = &outputSentinel
		u.Type = OutputTypeOutputSentinel
		return nil
	}

	var outputInfluxdb OutputInfluxdb = OutputInfluxdb{}
	if err := utils.UnmarshalJSON(data, &outputInfluxdb, "", true, true); err == nil {
		u.OutputInfluxdb = &outputInfluxdb
		u.Type = OutputTypeOutputInfluxdb
		return nil
	}

	var outputAzureBlob OutputAzureBlob = OutputAzureBlob{}
	if err := utils.UnmarshalJSON(data, &outputAzureBlob, "", true, true); err == nil {
		u.OutputAzureBlob = &outputAzureBlob
		u.Type = OutputTypeOutputAzureBlob
		return nil
	}

	var outputGoogleCloudStorage OutputGoogleCloudStorage = OutputGoogleCloudStorage{}
	if err := utils.UnmarshalJSON(data, &outputGoogleCloudStorage, "", true, true); err == nil {
		u.OutputGoogleCloudStorage = &outputGoogleCloudStorage
		u.Type = OutputTypeOutputGoogleCloudStorage
		return nil
	}

	var outputOpenTelemetry OutputOpenTelemetry = OutputOpenTelemetry{}
	if err := utils.UnmarshalJSON(data, &outputOpenTelemetry, "", true, true); err == nil {
		u.OutputOpenTelemetry = &outputOpenTelemetry
		u.Type = OutputTypeOutputOpenTelemetry
		return nil
	}

	var outputMinio OutputMinio = OutputMinio{}
	if err := utils.UnmarshalJSON(data, &outputMinio, "", true, true); err == nil {
		u.OutputMinio = &outputMinio
		u.Type = OutputTypeOutputMinio
		return nil
	}

	var outputClickHouse OutputClickHouse = OutputClickHouse{}
	if err := utils.UnmarshalJSON(data, &outputClickHouse, "", true, true); err == nil {
		u.OutputClickHouse = &outputClickHouse
		u.Type = OutputTypeOutputClickHouse
		return nil
	}

	var outputSecurityLake OutputSecurityLake = OutputSecurityLake{}
	if err := utils.UnmarshalJSON(data, &outputSecurityLake, "", true, true); err == nil {
		u.OutputSecurityLake = &outputSecurityLake
		u.Type = OutputTypeOutputSecurityLake
		return nil
	}

	var outputDlS3 OutputDlS3 = OutputDlS3{}
	if err := utils.UnmarshalJSON(data, &outputDlS3, "", true, true); err == nil {
		u.OutputDlS3 = &outputDlS3
		u.Type = OutputTypeOutputDlS3
		return nil
	}

	var outputS3 OutputS3 = OutputS3{}
	if err := utils.UnmarshalJSON(data, &outputS3, "", true, true); err == nil {
		u.OutputS3 = &outputS3
		u.Type = OutputTypeOutputS3
		return nil
	}

	var outputWebhook OutputWebhook = OutputWebhook{}
	if err := utils.UnmarshalJSON(data, &outputWebhook, "", true, true); err == nil {
		u.OutputWebhook = &outputWebhook
		u.Type = OutputTypeOutputWebhook
		return nil
	}

	var outputAzureDataExplorer OutputAzureDataExplorer = OutputAzureDataExplorer{}
	if err := utils.UnmarshalJSON(data, &outputAzureDataExplorer, "", true, true); err == nil {
		u.OutputAzureDataExplorer = &outputAzureDataExplorer
		u.Type = OutputTypeOutputAzureDataExplorer
		return nil
	}

	var outputGoogleCloudLogging OutputGoogleCloudLogging = OutputGoogleCloudLogging{}
	if err := utils.UnmarshalJSON(data, &outputGoogleCloudLogging, "", true, true); err == nil {
		u.OutputGoogleCloudLogging = &outputGoogleCloudLogging
		u.Type = OutputTypeOutputGoogleCloudLogging
		return nil
	}

	var outputGrafanaCloud OutputGrafanaCloud = OutputGrafanaCloud{}
	if err := utils.UnmarshalJSON(data, &outputGrafanaCloud, "", true, true); err == nil {
		u.OutputGrafanaCloud = &outputGrafanaCloud
		u.Type = OutputTypeOutputGrafanaCloud
		return nil
	}

	return fmt.Errorf("could not unmarshal `%s` into any supported union types for Output", string(data))
}

func (u Output) MarshalJSON() ([]byte, error) {
	if u.OutputDefault != nil {
		return utils.MarshalJSON(u.OutputDefault, "", true)
	}

	if u.OutputWebhook != nil {
		return utils.MarshalJSON(u.OutputWebhook, "", true)
	}

	if u.OutputSentinel != nil {
		return utils.MarshalJSON(u.OutputSentinel, "", true)
	}

	if u.OutputDevnull != nil {
		return utils.MarshalJSON(u.OutputDevnull, "", true)
	}

	if u.OutputSyslog != nil {
		return utils.MarshalJSON(u.OutputSyslog, "", true)
	}

	if u.OutputSplunk != nil {
		return utils.MarshalJSON(u.OutputSplunk, "", true)
	}

	if u.OutputSplunkLb != nil {
		return utils.MarshalJSON(u.OutputSplunkLb, "", true)
	}

	if u.OutputSplunkHec != nil {
		return utils.MarshalJSON(u.OutputSplunkHec, "", true)
	}

	if u.OutputTcpjson != nil {
		return utils.MarshalJSON(u.OutputTcpjson, "", true)
	}

	if u.OutputWavefront != nil {
		return utils.MarshalJSON(u.OutputWavefront, "", true)
	}

	if u.OutputSignalfx != nil {
		return utils.MarshalJSON(u.OutputSignalfx, "", true)
	}

	if u.OutputFilesystem != nil {
		return utils.MarshalJSON(u.OutputFilesystem, "", true)
	}

	if u.OutputS3 != nil {
		return utils.MarshalJSON(u.OutputS3, "", true)
	}

	if u.OutputAzureBlob != nil {
		return utils.MarshalJSON(u.OutputAzureBlob, "", true)
	}

	if u.OutputAzureDataExplorer != nil {
		return utils.MarshalJSON(u.OutputAzureDataExplorer, "", true)
	}

	if u.OutputAzureLogs != nil {
		return utils.MarshalJSON(u.OutputAzureLogs, "", true)
	}

	if u.OutputKinesis != nil {
		return utils.MarshalJSON(u.OutputKinesis, "", true)
	}

	if u.OutputHoneycomb != nil {
		return utils.MarshalJSON(u.OutputHoneycomb, "", true)
	}

	if u.OutputAzureEventhub != nil {
		return utils.MarshalJSON(u.OutputAzureEventhub, "", true)
	}

	if u.OutputGoogleChronicle != nil {
		return utils.MarshalJSON(u.OutputGoogleChronicle, "", true)
	}

	if u.OutputGoogleCloudStorage != nil {
		return utils.MarshalJSON(u.OutputGoogleCloudStorage, "", true)
	}

	if u.OutputGoogleCloudLogging != nil {
		return utils.MarshalJSON(u.OutputGoogleCloudLogging, "", true)
	}

	if u.OutputGooglePubsub != nil {
		return utils.MarshalJSON(u.OutputGooglePubsub, "", true)
	}

	if u.OutputExabeam != nil {
		return utils.MarshalJSON(u.OutputExabeam, "", true)
	}

	if u.OutputKafka != nil {
		return utils.MarshalJSON(u.OutputKafka, "", true)
	}

	if u.OutputConfluentCloud != nil {
		return utils.MarshalJSON(u.OutputConfluentCloud, "", true)
	}

	if u.OutputMsk != nil {
		return utils.MarshalJSON(u.OutputMsk, "", true)
	}

	if u.OutputElastic != nil {
		return utils.MarshalJSON(u.OutputElastic, "", true)
	}

	if u.OutputElasticCloud != nil {
		return utils.MarshalJSON(u.OutputElasticCloud, "", true)
	}

	if u.OutputNewrelic != nil {
		return utils.MarshalJSON(u.OutputNewrelic, "", true)
	}

	if u.OutputNewrelicEvents != nil {
		return utils.MarshalJSON(u.OutputNewrelicEvents, "", true)
	}

	if u.OutputInfluxdb != nil {
		return utils.MarshalJSON(u.OutputInfluxdb, "", true)
	}

	if u.OutputCloudwatch != nil {
		return utils.MarshalJSON(u.OutputCloudwatch, "", true)
	}

	if u.OutputMinio != nil {
		return utils.MarshalJSON(u.OutputMinio, "", true)
	}

	if u.OutputStatsd != nil {
		return utils.MarshalJSON(u.OutputStatsd, "", true)
	}

	if u.OutputStatsdExt != nil {
		return utils.MarshalJSON(u.OutputStatsdExt, "", true)
	}

	if u.OutputGraphite != nil {
		return utils.MarshalJSON(u.OutputGraphite, "", true)
	}

	if u.OutputRouter != nil {
		return utils.MarshalJSON(u.OutputRouter, "", true)
	}

	if u.OutputSns != nil {
		return utils.MarshalJSON(u.OutputSns, "", true)
	}

	if u.OutputSqs != nil {
		return utils.MarshalJSON(u.OutputSqs, "", true)
	}

	if u.OutputSnmp != nil {
		return utils.MarshalJSON(u.OutputSnmp, "", true)
	}

	if u.OutputSumoLogic != nil {
		return utils.MarshalJSON(u.OutputSumoLogic, "", true)
	}

	if u.OutputDatadog != nil {
		return utils.MarshalJSON(u.OutputDatadog, "", true)
	}

	if u.OutputGrafanaCloud != nil {
		return utils.MarshalJSON(u.OutputGrafanaCloud, "", true)
	}

	if u.OutputLoki != nil {
		return utils.MarshalJSON(u.OutputLoki, "", true)
	}

	if u.OutputPrometheus != nil {
		return utils.MarshalJSON(u.OutputPrometheus, "", true)
	}

	if u.OutputRing != nil {
		return utils.MarshalJSON(u.OutputRing, "", true)
	}

	if u.OutputOpenTelemetry != nil {
		return utils.MarshalJSON(u.OutputOpenTelemetry, "", true)
	}

	if u.OutputServiceNow != nil {
		return utils.MarshalJSON(u.OutputServiceNow, "", true)
	}

	if u.OutputDataset != nil {
		return utils.MarshalJSON(u.OutputDataset, "", true)
	}

	if u.OutputCriblTCP != nil {
		return utils.MarshalJSON(u.OutputCriblTCP, "", true)
	}

	if u.OutputCriblHTTP != nil {
		return utils.MarshalJSON(u.OutputCriblHTTP, "", true)
	}

	if u.OutputHumioHec != nil {
		return utils.MarshalJSON(u.OutputHumioHec, "", true)
	}

	if u.OutputCrowdstrikeNextGenSiem != nil {
		return utils.MarshalJSON(u.OutputCrowdstrikeNextGenSiem, "", true)
	}

	if u.OutputDlS3 != nil {
		return utils.MarshalJSON(u.OutputDlS3, "", true)
	}

	if u.OutputSecurityLake != nil {
		return utils.MarshalJSON(u.OutputSecurityLake, "", true)
	}

	if u.OutputCriblLake != nil {
		return utils.MarshalJSON(u.OutputCriblLake, "", true)
	}

	if u.OutputDiskSpool != nil {
		return utils.MarshalJSON(u.OutputDiskSpool, "", true)
	}

	if u.OutputClickHouse != nil {
		return utils.MarshalJSON(u.OutputClickHouse, "", true)
	}

	if u.OutputXsiam != nil {
		return utils.MarshalJSON(u.OutputXsiam, "", true)
	}

	if u.OutputNetflow != nil {
		return utils.MarshalJSON(u.OutputNetflow, "", true)
	}

	if u.OutputDynatraceHTTP != nil {
		return utils.MarshalJSON(u.OutputDynatraceHTTP, "", true)
	}

	if u.OutputDynatraceOtlp != nil {
		return utils.MarshalJSON(u.OutputDynatraceOtlp, "", true)
	}

	return nil, errors.New("could not marshal union type Output: all fields are null")
}
