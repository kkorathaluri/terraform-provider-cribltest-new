// Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.

package shared

import (
	"encoding/json"
	"errors"
	"fmt"
	"github.com/speakeasy/terraform-provider-cribl-terraform/internal/sdk/internal/utils"
)

type InputZscalerHecType string

const (
	InputZscalerHecTypeZscalerHec InputZscalerHecType = "zscaler_hec"
)

func (e InputZscalerHecType) ToPointer() *InputZscalerHecType {
	return &e
}
func (e *InputZscalerHecType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "zscaler_hec":
		*e = InputZscalerHecType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputZscalerHecType: %v", v)
	}
}

type InputZscalerHecConnections struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *InputZscalerHecConnections) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputZscalerHecConnections) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// InputZscalerHecMode - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputZscalerHecMode string

const (
	InputZscalerHecModeSmart  InputZscalerHecMode = "smart"
	InputZscalerHecModeAlways InputZscalerHecMode = "always"
)

func (e InputZscalerHecMode) ToPointer() *InputZscalerHecMode {
	return &e
}
func (e *InputZscalerHecMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputZscalerHecMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputZscalerHecMode: %v", v)
	}
}

// InputZscalerHecCompression - Codec to use to compress the persisted data
type InputZscalerHecCompression string

const (
	InputZscalerHecCompressionNone InputZscalerHecCompression = "none"
	InputZscalerHecCompressionGzip InputZscalerHecCompression = "gzip"
)

func (e InputZscalerHecCompression) ToPointer() *InputZscalerHecCompression {
	return &e
}
func (e *InputZscalerHecCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputZscalerHecCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputZscalerHecCompression: %v", v)
	}
}

type InputZscalerHecPq struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputZscalerHecMode `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *InputZscalerHecCompression `default:"none" json:"compress"`
}

func (i InputZscalerHecPq) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputZscalerHecPq) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputZscalerHecPq) GetMode() *InputZscalerHecMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputZscalerHecPq) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputZscalerHecPq) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *InputZscalerHecPq) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *InputZscalerHecPq) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *InputZscalerHecPq) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *InputZscalerHecPq) GetCompress() *InputZscalerHecCompression {
	if o == nil {
		return nil
	}
	return o.Compress
}

// InputZscalerHecAuthenticationMethod - Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
type InputZscalerHecAuthenticationMethod string

const (
	InputZscalerHecAuthenticationMethodManual InputZscalerHecAuthenticationMethod = "manual"
	InputZscalerHecAuthenticationMethodSecret InputZscalerHecAuthenticationMethod = "secret"
)

func (e InputZscalerHecAuthenticationMethod) ToPointer() *InputZscalerHecAuthenticationMethod {
	return &e
}
func (e *InputZscalerHecAuthenticationMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "manual":
		fallthrough
	case "secret":
		*e = InputZscalerHecAuthenticationMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputZscalerHecAuthenticationMethod: %v", v)
	}
}

type InputZscalerHecInputMetadata struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputZscalerHecInputMetadata) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputZscalerHecInputMetadata) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputZscalerHecAuthTokens struct {
	// Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
	AuthType    *InputZscalerHecAuthenticationMethod `default:"manual" json:"authType"`
	TokenSecret any                                  `json:"tokenSecret,omitempty"`
	Token       any                                  `json:"token"`
	Enabled     *bool                                `default:"true" json:"enabled"`
	Description *string                              `json:"description,omitempty"`
	// Enter the values you want to allow in the HEC event index field at the token level. Supports wildcards. To skip validation, leave blank.
	AllowedIndexesAtToken []string `json:"allowedIndexesAtToken,omitempty"`
	// Fields to add to events referencing this token
	Metadata []InputZscalerHecInputMetadata `json:"metadata,omitempty"`
}

func (i InputZscalerHecAuthTokens) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputZscalerHecAuthTokens) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputZscalerHecAuthTokens) GetAuthType() *InputZscalerHecAuthenticationMethod {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *InputZscalerHecAuthTokens) GetTokenSecret() any {
	if o == nil {
		return nil
	}
	return o.TokenSecret
}

func (o *InputZscalerHecAuthTokens) GetToken() any {
	if o == nil {
		return nil
	}
	return o.Token
}

func (o *InputZscalerHecAuthTokens) GetEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.Enabled
}

func (o *InputZscalerHecAuthTokens) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputZscalerHecAuthTokens) GetAllowedIndexesAtToken() []string {
	if o == nil {
		return nil
	}
	return o.AllowedIndexesAtToken
}

func (o *InputZscalerHecAuthTokens) GetMetadata() []InputZscalerHecInputMetadata {
	if o == nil {
		return nil
	}
	return o.Metadata
}

// InputZscalerHecMinimumTLSVersion - Minimum TLS version to accept from connections
type InputZscalerHecMinimumTLSVersion string

const (
	InputZscalerHecMinimumTLSVersionTlSv1  InputZscalerHecMinimumTLSVersion = "TLSv1"
	InputZscalerHecMinimumTLSVersionTlSv11 InputZscalerHecMinimumTLSVersion = "TLSv1.1"
	InputZscalerHecMinimumTLSVersionTlSv12 InputZscalerHecMinimumTLSVersion = "TLSv1.2"
	InputZscalerHecMinimumTLSVersionTlSv13 InputZscalerHecMinimumTLSVersion = "TLSv1.3"
)

func (e InputZscalerHecMinimumTLSVersion) ToPointer() *InputZscalerHecMinimumTLSVersion {
	return &e
}
func (e *InputZscalerHecMinimumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputZscalerHecMinimumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputZscalerHecMinimumTLSVersion: %v", v)
	}
}

// InputZscalerHecMaximumTLSVersion - Maximum TLS version to accept from connections
type InputZscalerHecMaximumTLSVersion string

const (
	InputZscalerHecMaximumTLSVersionTlSv1  InputZscalerHecMaximumTLSVersion = "TLSv1"
	InputZscalerHecMaximumTLSVersionTlSv11 InputZscalerHecMaximumTLSVersion = "TLSv1.1"
	InputZscalerHecMaximumTLSVersionTlSv12 InputZscalerHecMaximumTLSVersion = "TLSv1.2"
	InputZscalerHecMaximumTLSVersionTlSv13 InputZscalerHecMaximumTLSVersion = "TLSv1.3"
)

func (e InputZscalerHecMaximumTLSVersion) ToPointer() *InputZscalerHecMaximumTLSVersion {
	return &e
}
func (e *InputZscalerHecMaximumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputZscalerHecMaximumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputZscalerHecMaximumTLSVersion: %v", v)
	}
}

type InputZscalerHecTLSSettingsServerSide struct {
	Disabled *bool `default:"true" json:"disabled"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert        *bool `default:"false" json:"requestCert"`
	RejectUnauthorized any   `json:"rejectUnauthorized,omitempty"`
	CommonNameRegex    any   `json:"commonNameRegex,omitempty"`
	// Minimum TLS version to accept from connections
	MinVersion *InputZscalerHecMinimumTLSVersion `json:"minVersion,omitempty"`
	// Maximum TLS version to accept from connections
	MaxVersion *InputZscalerHecMaximumTLSVersion `json:"maxVersion,omitempty"`
}

func (i InputZscalerHecTLSSettingsServerSide) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputZscalerHecTLSSettingsServerSide) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputZscalerHecTLSSettingsServerSide) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputZscalerHecTLSSettingsServerSide) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *InputZscalerHecTLSSettingsServerSide) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *InputZscalerHecTLSSettingsServerSide) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *InputZscalerHecTLSSettingsServerSide) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *InputZscalerHecTLSSettingsServerSide) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *InputZscalerHecTLSSettingsServerSide) GetRequestCert() *bool {
	if o == nil {
		return nil
	}
	return o.RequestCert
}

func (o *InputZscalerHecTLSSettingsServerSide) GetRejectUnauthorized() any {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *InputZscalerHecTLSSettingsServerSide) GetCommonNameRegex() any {
	if o == nil {
		return nil
	}
	return o.CommonNameRegex
}

func (o *InputZscalerHecTLSSettingsServerSide) GetMinVersion() *InputZscalerHecMinimumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *InputZscalerHecTLSSettingsServerSide) GetMaxVersion() *InputZscalerHecMaximumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

type InputZscalerHecMetadata struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputZscalerHecMetadata) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputZscalerHecMetadata) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputZscalerHec struct {
	// Unique ID for this input
	ID       *string              `json:"id,omitempty"`
	Type     *InputZscalerHecType `json:"type,omitempty"`
	Disabled *bool                `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputZscalerHecConnections `json:"connections,omitempty"`
	Pq          *InputZscalerHecPq           `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port float64 `json:"port"`
	// Shared secrets to be provided by any client (Authorization: <token>). If empty, unauthorized access is permitted.
	AuthTokens []InputZscalerHecAuthTokens           `json:"authTokens,omitempty"`
	TLS        *InputZscalerHecTLSSettingsServerSide `json:"tls,omitempty"`
	// Maximum number of active requests per Worker Process. Use 0 for unlimited.
	MaxActiveReq *float64 `default:"256" json:"maxActiveReq"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket *int64 `default:"0" json:"maxRequestsPerSocket"`
	// Enable when clients are connecting through a proxy that supports the x-forwarded-for header to keep the client's original IP address on the event instead of the proxy's IP address
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Add request headers to events, in the __headers field
	CaptureHeaders *bool `default:"false" json:"captureHeaders"`
	// How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
	ActivityLogSampleRate *float64 `default:"100" json:"activityLogSampleRate"`
	// How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
	RequestTimeout *float64 `default:"0" json:"requestTimeout"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `default:"0" json:"socketTimeout"`
	// After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 sec.; maximum 600 sec. (10 min.).
	KeepAliveTimeout  *float64 `default:"5" json:"keepAliveTimeout"`
	EnableHealthCheck any      `json:"enableHealthCheck,omitempty"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist
	IPAllowlistRegex *string `default:"/.*/" json:"ipAllowlistRegex"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `default:"/^\\$/" json:"ipDenylistRegex"`
	// Absolute path on which to listen for the Zscaler HTTP Event Collector API requests. This input supports the /event endpoint.
	HecAPI *string `default:"/services/collector" json:"hecAPI"`
	// Fields to add to every event. May be overridden by fields added at the token or request level.
	Metadata []InputZscalerHecMetadata `json:"metadata,omitempty"`
	// List values allowed in HEC event index field. Leave blank to skip validation. Supports wildcards. The values here can expand index validation at the token level.
	AllowedIndexes []string `json:"allowedIndexes,omitempty"`
	// Whether to enable zscaler HEC acknowledgements
	HecAcks *bool `default:"false" json:"hecAcks"`
	// Optionally, list HTTP origins to which @{product} should send CORS (cross-origin resource sharing) Access-Control-Allow-* headers. Supports wildcards.
	AccessControlAllowOrigin []string `json:"accessControlAllowOrigin,omitempty"`
	// Optionally, list HTTP headers that @{product} will send to allowed origins as "Access-Control-Allow-Headers" in a CORS preflight response. Use "*" to allow all headers.
	AccessControlAllowHeaders []string `json:"accessControlAllowHeaders,omitempty"`
	// Enable to emit per-token (<prefix>.http.perToken) and summary (<prefix>.http.summary) request metrics
	EmitTokenMetrics *bool     `default:"false" json:"emitTokenMetrics"`
	Description      *string   `json:"description,omitempty"`
	Status           *TFStatus `json:"status,omitempty"`
}

func (i InputZscalerHec) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputZscalerHec) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputZscalerHec) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputZscalerHec) GetType() *InputZscalerHecType {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputZscalerHec) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputZscalerHec) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputZscalerHec) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputZscalerHec) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputZscalerHec) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputZscalerHec) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputZscalerHec) GetConnections() []InputZscalerHecConnections {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputZscalerHec) GetPq() *InputZscalerHecPq {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputZscalerHec) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputZscalerHec) GetPort() float64 {
	if o == nil {
		return 0.0
	}
	return o.Port
}

func (o *InputZscalerHec) GetAuthTokens() []InputZscalerHecAuthTokens {
	if o == nil {
		return nil
	}
	return o.AuthTokens
}

func (o *InputZscalerHec) GetTLS() *InputZscalerHecTLSSettingsServerSide {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputZscalerHec) GetMaxActiveReq() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxActiveReq
}

func (o *InputZscalerHec) GetMaxRequestsPerSocket() *int64 {
	if o == nil {
		return nil
	}
	return o.MaxRequestsPerSocket
}

func (o *InputZscalerHec) GetEnableProxyHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableProxyHeader
}

func (o *InputZscalerHec) GetCaptureHeaders() *bool {
	if o == nil {
		return nil
	}
	return o.CaptureHeaders
}

func (o *InputZscalerHec) GetActivityLogSampleRate() *float64 {
	if o == nil {
		return nil
	}
	return o.ActivityLogSampleRate
}

func (o *InputZscalerHec) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *InputZscalerHec) GetSocketTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketTimeout
}

func (o *InputZscalerHec) GetKeepAliveTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.KeepAliveTimeout
}

func (o *InputZscalerHec) GetEnableHealthCheck() any {
	if o == nil {
		return nil
	}
	return o.EnableHealthCheck
}

func (o *InputZscalerHec) GetIPAllowlistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPAllowlistRegex
}

func (o *InputZscalerHec) GetIPDenylistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPDenylistRegex
}

func (o *InputZscalerHec) GetHecAPI() *string {
	if o == nil {
		return nil
	}
	return o.HecAPI
}

func (o *InputZscalerHec) GetMetadata() []InputZscalerHecMetadata {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputZscalerHec) GetAllowedIndexes() []string {
	if o == nil {
		return nil
	}
	return o.AllowedIndexes
}

func (o *InputZscalerHec) GetHecAcks() *bool {
	if o == nil {
		return nil
	}
	return o.HecAcks
}

func (o *InputZscalerHec) GetAccessControlAllowOrigin() []string {
	if o == nil {
		return nil
	}
	return o.AccessControlAllowOrigin
}

func (o *InputZscalerHec) GetAccessControlAllowHeaders() []string {
	if o == nil {
		return nil
	}
	return o.AccessControlAllowHeaders
}

func (o *InputZscalerHec) GetEmitTokenMetrics() *bool {
	if o == nil {
		return nil
	}
	return o.EmitTokenMetrics
}

func (o *InputZscalerHec) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputZscalerHec) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputSecurityLakeType string

const (
	InputSecurityLakeTypeSecurityLake InputSecurityLakeType = "security_lake"
)

func (e InputSecurityLakeType) ToPointer() *InputSecurityLakeType {
	return &e
}
func (e *InputSecurityLakeType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "security_lake":
		*e = InputSecurityLakeType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSecurityLakeType: %v", v)
	}
}

type InputSecurityLakeConnections struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *InputSecurityLakeConnections) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputSecurityLakeConnections) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// InputSecurityLakeMode - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputSecurityLakeMode string

const (
	InputSecurityLakeModeSmart  InputSecurityLakeMode = "smart"
	InputSecurityLakeModeAlways InputSecurityLakeMode = "always"
)

func (e InputSecurityLakeMode) ToPointer() *InputSecurityLakeMode {
	return &e
}
func (e *InputSecurityLakeMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputSecurityLakeMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSecurityLakeMode: %v", v)
	}
}

// InputSecurityLakeCompression - Codec to use to compress the persisted data
type InputSecurityLakeCompression string

const (
	InputSecurityLakeCompressionNone InputSecurityLakeCompression = "none"
	InputSecurityLakeCompressionGzip InputSecurityLakeCompression = "gzip"
)

func (e InputSecurityLakeCompression) ToPointer() *InputSecurityLakeCompression {
	return &e
}
func (e *InputSecurityLakeCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputSecurityLakeCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSecurityLakeCompression: %v", v)
	}
}

type InputSecurityLakePq struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputSecurityLakeMode `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *InputSecurityLakeCompression `default:"none" json:"compress"`
}

func (i InputSecurityLakePq) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSecurityLakePq) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputSecurityLakePq) GetMode() *InputSecurityLakeMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputSecurityLakePq) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputSecurityLakePq) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *InputSecurityLakePq) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *InputSecurityLakePq) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *InputSecurityLakePq) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *InputSecurityLakePq) GetCompress() *InputSecurityLakeCompression {
	if o == nil {
		return nil
	}
	return o.Compress
}

// InputSecurityLakeAuthenticationMethod - AWS authentication method. Choose Auto to use IAM roles.
type InputSecurityLakeAuthenticationMethod string

const (
	InputSecurityLakeAuthenticationMethodAuto   InputSecurityLakeAuthenticationMethod = "auto"
	InputSecurityLakeAuthenticationMethodManual InputSecurityLakeAuthenticationMethod = "manual"
	InputSecurityLakeAuthenticationMethodSecret InputSecurityLakeAuthenticationMethod = "secret"
)

func (e InputSecurityLakeAuthenticationMethod) ToPointer() *InputSecurityLakeAuthenticationMethod {
	return &e
}
func (e *InputSecurityLakeAuthenticationMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "auto":
		fallthrough
	case "manual":
		fallthrough
	case "secret":
		*e = InputSecurityLakeAuthenticationMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSecurityLakeAuthenticationMethod: %v", v)
	}
}

// InputSecurityLakeSignatureVersion - Signature version to use for signing S3 requests
type InputSecurityLakeSignatureVersion string

const (
	InputSecurityLakeSignatureVersionV2 InputSecurityLakeSignatureVersion = "v2"
	InputSecurityLakeSignatureVersionV4 InputSecurityLakeSignatureVersion = "v4"
)

func (e InputSecurityLakeSignatureVersion) ToPointer() *InputSecurityLakeSignatureVersion {
	return &e
}
func (e *InputSecurityLakeSignatureVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "v2":
		fallthrough
	case "v4":
		*e = InputSecurityLakeSignatureVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSecurityLakeSignatureVersion: %v", v)
	}
}

type InputSecurityLakePreprocess struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Command to feed the data through (via stdin) and process its output (stdout)
	Command *string `json:"command,omitempty"`
	// Arguments to be added to the custom command
	Args []string `json:"args,omitempty"`
}

func (i InputSecurityLakePreprocess) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSecurityLakePreprocess) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputSecurityLakePreprocess) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputSecurityLakePreprocess) GetCommand() *string {
	if o == nil {
		return nil
	}
	return o.Command
}

func (o *InputSecurityLakePreprocess) GetArgs() []string {
	if o == nil {
		return nil
	}
	return o.Args
}

type InputSecurityLakeMetadata struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputSecurityLakeMetadata) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputSecurityLakeMetadata) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputSecurityLakeCheckpointing struct {
	// Resume processing files after an interruption
	Enabled *bool `default:"false" json:"enabled"`
	// If checkpointing is enabled, the number of times to retry processing when a processing error occurs. If skip file on error is enabled, this setting is ignored.
	Retries *float64 `default:"5" json:"retries"`
}

func (i InputSecurityLakeCheckpointing) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSecurityLakeCheckpointing) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputSecurityLakeCheckpointing) GetEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.Enabled
}

func (o *InputSecurityLakeCheckpointing) GetRetries() *float64 {
	if o == nil {
		return nil
	}
	return o.Retries
}

type InputSecurityLake struct {
	// Unique ID for this input
	ID       *string               `json:"id,omitempty"`
	Type     InputSecurityLakeType `json:"type"`
	Disabled *bool                 `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputSecurityLakeConnections `json:"connections,omitempty"`
	Pq          *InputSecurityLakePq           `json:"pq,omitempty"`
	// The name, URL, or ARN of the SQS queue to read notifications from. When a non-AWS URL is specified, format must be: '{url}/myQueueName'. Example: 'https://host:port/myQueueName'. Value must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at init time. Example referencing a Global Variable: `https://host:port/myQueue-${C.vars.myVar}`.
	QueueName string `json:"queueName"`
	// Regex matching file names to download and process. Defaults to: .*
	FileFilter *string `default:"/.*/" json:"fileFilter"`
	// SQS queue owner's AWS account ID. Leave empty if SQS queue is in same AWS account.
	AwsAccountID *string `json:"awsAccountId,omitempty"`
	// AWS authentication method. Choose Auto to use IAM roles.
	AwsAuthenticationMethod *InputSecurityLakeAuthenticationMethod `default:"auto" json:"awsAuthenticationMethod"`
	AwsSecretKey            *string                                `json:"awsSecretKey,omitempty"`
	// AWS Region where the S3 bucket and SQS queue are located. Required, unless the Queue entry is a URL or ARN that includes a Region.
	Region *string `json:"region,omitempty"`
	// S3 service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to S3-compatible endpoint.
	Endpoint *string `json:"endpoint,omitempty"`
	// Signature version to use for signing S3 requests
	SignatureVersion *InputSecurityLakeSignatureVersion `default:"v4" json:"signatureVersion"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `default:"true" json:"reuseConnections"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitempty"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `default:"10000" json:"staleChannelFlushMs"`
	// The maximum number of messages SQS should return in a poll request. Amazon SQS never returns more messages than this value (however, fewer messages might be returned). Valid values: 1 to 10.
	MaxMessages *float64 `default:"1" json:"maxMessages"`
	// After messages are retrieved by a ReceiveMessage request, @{product} will hide them from subsequent retrieve requests for at least this duration. You can set this as high as 43200 sec. (12 hours).
	VisibilityTimeout *float64 `default:"600" json:"visibilityTimeout"`
	// How many receiver processes to run. The higher the number, the better the throughput - at the expense of CPU overhead.
	NumReceivers *float64 `default:"1" json:"numReceivers"`
	// Socket inactivity timeout (in seconds). Increase this value if timeouts occur due to backpressure.
	SocketTimeout *float64 `default:"300" json:"socketTimeout"`
	// Skip files that trigger a processing error. Disabled by default, which allows retries after processing errors.
	SkipOnError *bool `default:"false" json:"skipOnError"`
	// Use Assume Role credentials to access S3
	EnableAssumeRole *bool `default:"true" json:"enableAssumeRole"`
	// Amazon Resource Name (ARN) of the role to assume
	AssumeRoleArn *string `json:"assumeRoleArn,omitempty"`
	// External ID to use when assuming role
	AssumeRoleExternalID *string `json:"assumeRoleExternalId,omitempty"`
	// Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
	DurationSeconds *float64 `default:"3600" json:"durationSeconds"`
	// Use Assume Role credentials when accessing SQS
	EnableSQSAssumeRole *bool                        `default:"false" json:"enableSQSAssumeRole"`
	Preprocess          *InputSecurityLakePreprocess `json:"preprocess,omitempty"`
	// Fields to add to events from this input
	Metadata []InputSecurityLakeMetadata `json:"metadata,omitempty"`
	// Maximum file size for each Parquet chunk
	ParquetChunkSizeMB *float64 `default:"5" json:"parquetChunkSizeMB"`
	// The maximum time allowed for downloading a Parquet chunk. Processing will stop if a chunk cannot be downloaded within the time specified.
	ParquetChunkDownloadTimeout *float64                        `default:"600" json:"parquetChunkDownloadTimeout"`
	Checkpointing               *InputSecurityLakeCheckpointing `json:"checkpointing,omitempty"`
	// How long to wait for events before trying polling again. The lower the number the higher the AWS bill. The higher the number the longer it will take for the source to react to configuration changes and system restarts.
	PollTimeout *float64 `default:"10" json:"pollTimeout"`
	// Character encoding to use when parsing ingested data. When not set, @{product} will default to UTF-8 but may incorrectly interpret multi-byte characters.
	Encoding    *string `json:"encoding,omitempty"`
	Description *string `json:"description,omitempty"`
	AwsAPIKey   *string `json:"awsApiKey,omitempty"`
	// Select or create a stored secret that references your access key and secret key
	AwsSecret *string   `json:"awsSecret,omitempty"`
	Status    *TFStatus `json:"status,omitempty"`
}

func (i InputSecurityLake) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSecurityLake) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputSecurityLake) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputSecurityLake) GetType() InputSecurityLakeType {
	if o == nil {
		return InputSecurityLakeType("")
	}
	return o.Type
}

func (o *InputSecurityLake) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputSecurityLake) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputSecurityLake) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputSecurityLake) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputSecurityLake) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputSecurityLake) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputSecurityLake) GetConnections() []InputSecurityLakeConnections {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputSecurityLake) GetPq() *InputSecurityLakePq {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputSecurityLake) GetQueueName() string {
	if o == nil {
		return ""
	}
	return o.QueueName
}

func (o *InputSecurityLake) GetFileFilter() *string {
	if o == nil {
		return nil
	}
	return o.FileFilter
}

func (o *InputSecurityLake) GetAwsAccountID() *string {
	if o == nil {
		return nil
	}
	return o.AwsAccountID
}

func (o *InputSecurityLake) GetAwsAuthenticationMethod() *InputSecurityLakeAuthenticationMethod {
	if o == nil {
		return nil
	}
	return o.AwsAuthenticationMethod
}

func (o *InputSecurityLake) GetAwsSecretKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecretKey
}

func (o *InputSecurityLake) GetRegion() *string {
	if o == nil {
		return nil
	}
	return o.Region
}

func (o *InputSecurityLake) GetEndpoint() *string {
	if o == nil {
		return nil
	}
	return o.Endpoint
}

func (o *InputSecurityLake) GetSignatureVersion() *InputSecurityLakeSignatureVersion {
	if o == nil {
		return nil
	}
	return o.SignatureVersion
}

func (o *InputSecurityLake) GetReuseConnections() *bool {
	if o == nil {
		return nil
	}
	return o.ReuseConnections
}

func (o *InputSecurityLake) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *InputSecurityLake) GetBreakerRulesets() []string {
	if o == nil {
		return nil
	}
	return o.BreakerRulesets
}

func (o *InputSecurityLake) GetStaleChannelFlushMs() *float64 {
	if o == nil {
		return nil
	}
	return o.StaleChannelFlushMs
}

func (o *InputSecurityLake) GetMaxMessages() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxMessages
}

func (o *InputSecurityLake) GetVisibilityTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.VisibilityTimeout
}

func (o *InputSecurityLake) GetNumReceivers() *float64 {
	if o == nil {
		return nil
	}
	return o.NumReceivers
}

func (o *InputSecurityLake) GetSocketTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketTimeout
}

func (o *InputSecurityLake) GetSkipOnError() *bool {
	if o == nil {
		return nil
	}
	return o.SkipOnError
}

func (o *InputSecurityLake) GetEnableAssumeRole() *bool {
	if o == nil {
		return nil
	}
	return o.EnableAssumeRole
}

func (o *InputSecurityLake) GetAssumeRoleArn() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleArn
}

func (o *InputSecurityLake) GetAssumeRoleExternalID() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleExternalID
}

func (o *InputSecurityLake) GetDurationSeconds() *float64 {
	if o == nil {
		return nil
	}
	return o.DurationSeconds
}

func (o *InputSecurityLake) GetEnableSQSAssumeRole() *bool {
	if o == nil {
		return nil
	}
	return o.EnableSQSAssumeRole
}

func (o *InputSecurityLake) GetPreprocess() *InputSecurityLakePreprocess {
	if o == nil {
		return nil
	}
	return o.Preprocess
}

func (o *InputSecurityLake) GetMetadata() []InputSecurityLakeMetadata {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputSecurityLake) GetParquetChunkSizeMB() *float64 {
	if o == nil {
		return nil
	}
	return o.ParquetChunkSizeMB
}

func (o *InputSecurityLake) GetParquetChunkDownloadTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.ParquetChunkDownloadTimeout
}

func (o *InputSecurityLake) GetCheckpointing() *InputSecurityLakeCheckpointing {
	if o == nil {
		return nil
	}
	return o.Checkpointing
}

func (o *InputSecurityLake) GetPollTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.PollTimeout
}

func (o *InputSecurityLake) GetEncoding() *string {
	if o == nil {
		return nil
	}
	return o.Encoding
}

func (o *InputSecurityLake) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputSecurityLake) GetAwsAPIKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsAPIKey
}

func (o *InputSecurityLake) GetAwsSecret() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecret
}

func (o *InputSecurityLake) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputNetflowType string

const (
	InputNetflowTypeNetflow InputNetflowType = "netflow"
)

func (e InputNetflowType) ToPointer() *InputNetflowType {
	return &e
}
func (e *InputNetflowType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "netflow":
		*e = InputNetflowType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputNetflowType: %v", v)
	}
}

type InputNetflowConnections struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *InputNetflowConnections) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputNetflowConnections) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// InputNetflowMode - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputNetflowMode string

const (
	InputNetflowModeSmart  InputNetflowMode = "smart"
	InputNetflowModeAlways InputNetflowMode = "always"
)

func (e InputNetflowMode) ToPointer() *InputNetflowMode {
	return &e
}
func (e *InputNetflowMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputNetflowMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputNetflowMode: %v", v)
	}
}

// InputNetflowCompression - Codec to use to compress the persisted data
type InputNetflowCompression string

const (
	InputNetflowCompressionNone InputNetflowCompression = "none"
	InputNetflowCompressionGzip InputNetflowCompression = "gzip"
)

func (e InputNetflowCompression) ToPointer() *InputNetflowCompression {
	return &e
}
func (e *InputNetflowCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputNetflowCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputNetflowCompression: %v", v)
	}
}

type InputNetflowPq struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputNetflowMode `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *InputNetflowCompression `default:"none" json:"compress"`
}

func (i InputNetflowPq) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputNetflowPq) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputNetflowPq) GetMode() *InputNetflowMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputNetflowPq) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputNetflowPq) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *InputNetflowPq) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *InputNetflowPq) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *InputNetflowPq) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *InputNetflowPq) GetCompress() *InputNetflowCompression {
	if o == nil {
		return nil
	}
	return o.Compress
}

type InputNetflowMetadata struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputNetflowMetadata) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputNetflowMetadata) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputNetflow struct {
	// Unique ID for this input
	ID       *string           `json:"id,omitempty"`
	Type     *InputNetflowType `json:"type,omitempty"`
	Disabled *bool             `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputNetflowConnections `json:"connections,omitempty"`
	Pq          *InputNetflowPq           `json:"pq,omitempty"`
	// Address to bind on. For IPv4 (all addresses), use the default '0.0.0.0'. For IPv6, enter '::' (all addresses) or specify an IP address.
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port *float64 `default:"2055" json:"port"`
	// Allow forwarding of events to a NetFlow destination. Enabling this feature will generate an extra event containing __netflowRaw which can be routed to a NetFlow destination. Note that these events will not count against ingest quota.
	EnablePassThrough *bool `default:"false" json:"enablePassThrough"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist.
	IPAllowlistRegex *string `default:"/.*/" json:"ipAllowlistRegex"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `default:"/^\\$/" json:"ipDenylistRegex"`
	// Optionally, set the SO_RCVBUF socket option for the UDP socket. This value tells the operating system how many bytes can be buffered in the kernel before events are dropped. Leave blank to use the OS default. Caution: Increasing this value will affect OS memory utilization.
	UDPSocketRxBufSize *float64 `json:"udpSocketRxBufSize,omitempty"`
	// Specifies how many minutes NetFlow v9 templates are cached before being discarded if not refreshed. Adjust based on your network's template update frequency to optimize performance and memory usage.
	TemplateCacheMinutes *float64 `default:"30" json:"templateCacheMinutes"`
	// Accept messages in Netflow V5 format.
	V5Enabled *bool `default:"true" json:"v5Enabled"`
	// Accept messages in Netflow V9 format.
	V9Enabled *bool `default:"true" json:"v9Enabled"`
	// Accept messages in IPFIX format.
	IpfixEnabled *bool `default:"false" json:"ipfixEnabled"`
	// Fields to add to events from this input
	Metadata    []InputNetflowMetadata `json:"metadata,omitempty"`
	Description *string                `json:"description,omitempty"`
	Status      *TFStatus              `json:"status,omitempty"`
}

func (i InputNetflow) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputNetflow) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputNetflow) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputNetflow) GetType() *InputNetflowType {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputNetflow) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputNetflow) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputNetflow) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputNetflow) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputNetflow) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputNetflow) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputNetflow) GetConnections() []InputNetflowConnections {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputNetflow) GetPq() *InputNetflowPq {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputNetflow) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputNetflow) GetPort() *float64 {
	if o == nil {
		return nil
	}
	return o.Port
}

func (o *InputNetflow) GetEnablePassThrough() *bool {
	if o == nil {
		return nil
	}
	return o.EnablePassThrough
}

func (o *InputNetflow) GetIPAllowlistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPAllowlistRegex
}

func (o *InputNetflow) GetIPDenylistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPDenylistRegex
}

func (o *InputNetflow) GetUDPSocketRxBufSize() *float64 {
	if o == nil {
		return nil
	}
	return o.UDPSocketRxBufSize
}

func (o *InputNetflow) GetTemplateCacheMinutes() *float64 {
	if o == nil {
		return nil
	}
	return o.TemplateCacheMinutes
}

func (o *InputNetflow) GetV5Enabled() *bool {
	if o == nil {
		return nil
	}
	return o.V5Enabled
}

func (o *InputNetflow) GetV9Enabled() *bool {
	if o == nil {
		return nil
	}
	return o.V9Enabled
}

func (o *InputNetflow) GetIpfixEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.IpfixEnabled
}

func (o *InputNetflow) GetMetadata() []InputNetflowMetadata {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputNetflow) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputNetflow) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputWizType string

const (
	InputWizTypeWiz InputWizType = "wiz"
)

func (e InputWizType) ToPointer() *InputWizType {
	return &e
}
func (e *InputWizType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "wiz":
		*e = InputWizType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputWizType: %v", v)
	}
}

type InputWizConnections struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *InputWizConnections) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputWizConnections) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// InputWizMode - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputWizMode string

const (
	InputWizModeSmart  InputWizMode = "smart"
	InputWizModeAlways InputWizMode = "always"
)

func (e InputWizMode) ToPointer() *InputWizMode {
	return &e
}
func (e *InputWizMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputWizMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputWizMode: %v", v)
	}
}

// InputWizCompression - Codec to use to compress the persisted data
type InputWizCompression string

const (
	InputWizCompressionNone InputWizCompression = "none"
	InputWizCompressionGzip InputWizCompression = "gzip"
)

func (e InputWizCompression) ToPointer() *InputWizCompression {
	return &e
}
func (e *InputWizCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputWizCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputWizCompression: %v", v)
	}
}

type InputWizPq struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputWizMode `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *InputWizCompression `default:"none" json:"compress"`
}

func (i InputWizPq) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputWizPq) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputWizPq) GetMode() *InputWizMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputWizPq) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputWizPq) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *InputWizPq) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *InputWizPq) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *InputWizPq) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *InputWizPq) GetCompress() *InputWizCompression {
	if o == nil {
		return nil
	}
	return o.Compress
}

type InputWizContentConfig struct {
	// The name of the Wiz query
	ContentType        string  `json:"contentType"`
	ContentDescription *string `json:"contentDescription,omitempty"`
	Enabled            *bool   `default:"false" json:"enabled"`
}

func (i InputWizContentConfig) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputWizContentConfig) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputWizContentConfig) GetContentType() string {
	if o == nil {
		return ""
	}
	return o.ContentType
}

func (o *InputWizContentConfig) GetContentDescription() *string {
	if o == nil {
		return nil
	}
	return o.ContentDescription
}

func (o *InputWizContentConfig) GetEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.Enabled
}

type InputWizMetadata struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputWizMetadata) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputWizMetadata) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// InputWizRetryType - The algorithm to use when performing HTTP retries
type InputWizRetryType string

const (
	InputWizRetryTypeNone    InputWizRetryType = "none"
	InputWizRetryTypeBackoff InputWizRetryType = "backoff"
	InputWizRetryTypeStatic  InputWizRetryType = "static"
)

func (e InputWizRetryType) ToPointer() *InputWizRetryType {
	return &e
}
func (e *InputWizRetryType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "backoff":
		fallthrough
	case "static":
		*e = InputWizRetryType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputWizRetryType: %v", v)
	}
}

type InputWizRetryRules struct {
	// The algorithm to use when performing HTTP retries
	Type *InputWizRetryType `default:"backoff" json:"type"`
	// Time interval between failed request and first retry (kickoff). Maximum allowed value is 20,000 ms (1/3 minute).
	Interval *float64 `default:"1000" json:"interval"`
	// The maximum number of times to retry a failed HTTP request
	Limit *float64 `default:"5" json:"limit"`
	// Base for exponential backoff, e.g., base 2 means that retries will occur after 2, then 4, then 8 seconds, and so on
	Multiplier *float64 `default:"2" json:"multiplier"`
	// List of HTTP codes that trigger a retry. Leave empty to use the default list of 429 and 503.
	Codes []float64 `json:"codes,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) or a timestamp after which to retry the request. The delay is limited to 20 seconds, even if the Retry-After header specifies a longer delay. When disabled, all Retry-After headers are ignored.
	EnableHeader *bool `default:"true" json:"enableHeader"`
	// Make a single retry attempt when a connection timeout (ETIMEDOUT) error occurs
	RetryConnectTimeout *bool `default:"false" json:"retryConnectTimeout"`
	// Retry request when a connection reset (ECONNRESET) error occurs
	RetryConnectReset *bool `default:"false" json:"retryConnectReset"`
}

func (i InputWizRetryRules) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputWizRetryRules) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputWizRetryRules) GetType() *InputWizRetryType {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputWizRetryRules) GetInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.Interval
}

func (o *InputWizRetryRules) GetLimit() *float64 {
	if o == nil {
		return nil
	}
	return o.Limit
}

func (o *InputWizRetryRules) GetMultiplier() *float64 {
	if o == nil {
		return nil
	}
	return o.Multiplier
}

func (o *InputWizRetryRules) GetCodes() []float64 {
	if o == nil {
		return nil
	}
	return o.Codes
}

func (o *InputWizRetryRules) GetEnableHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableHeader
}

func (o *InputWizRetryRules) GetRetryConnectTimeout() *bool {
	if o == nil {
		return nil
	}
	return o.RetryConnectTimeout
}

func (o *InputWizRetryRules) GetRetryConnectReset() *bool {
	if o == nil {
		return nil
	}
	return o.RetryConnectReset
}

// InputWizAuthenticationMethod - Enter client secret directly, or select a stored secret
type InputWizAuthenticationMethod string

const (
	InputWizAuthenticationMethodManual InputWizAuthenticationMethod = "manual"
	InputWizAuthenticationMethodSecret InputWizAuthenticationMethod = "secret"
)

func (e InputWizAuthenticationMethod) ToPointer() *InputWizAuthenticationMethod {
	return &e
}
func (e *InputWizAuthenticationMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "manual":
		fallthrough
	case "secret":
		*e = InputWizAuthenticationMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputWizAuthenticationMethod: %v", v)
	}
}

type InputWiz struct {
	// Unique ID for this input
	ID       *string       `json:"id,omitempty"`
	Type     *InputWizType `json:"type,omitempty"`
	Disabled *bool         `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputWizConnections `json:"connections,omitempty"`
	Pq          *InputWizPq           `json:"pq,omitempty"`
	// The Wiz GraphQL API endpoint. Example: https://api.us1.app.wiz.io/graphql
	Endpoint *string `default:"https://api.<region>.app.wiz.io/graphql" json:"endpoint"`
	// The authentication URL to generate an OAuth token
	AuthURL string `json:"authUrl"`
	// The audience to use when requesting an OAuth token for a custom auth URL. When not specified, `wiz-api` will be used.
	AuthAudienceOverride *string `json:"authAudienceOverride,omitempty"`
	// The client ID of the Wiz application
	ClientID      string                  `json:"clientId"`
	ContentConfig []InputWizContentConfig `json:"contentConfig,omitempty"`
	// HTTP request inactivity timeout. Use 0 to disable.
	RequestTimeout *float64 `default:"300" json:"requestTimeout"`
	// How often workers should check in with the scheduler to keep job subscription alive
	KeepAliveTime *float64 `default:"30" json:"keepAliveTime"`
	// The number of Keep Alive Time periods before an inactive worker will have its job subscription revoked.
	MaxMissedKeepAlives *float64 `default:"3" json:"maxMissedKeepAlives"`
	// Time to keep the job's artifacts on disk after job completion. This also affects how long a job is listed in the Job Inspector.
	TTL *string `default:"4h" json:"ttl"`
	// Fields to add to events from this input
	Metadata   []InputWizMetadata  `json:"metadata,omitempty"`
	RetryRules *InputWizRetryRules `json:"retryRules,omitempty"`
	// Enter client secret directly, or select a stored secret
	AuthType    *InputWizAuthenticationMethod `default:"manual" json:"authType"`
	Description *string                       `json:"description,omitempty"`
	// The client secret of the Wiz application
	ClientSecret *string `json:"clientSecret,omitempty"`
	// Select or create a stored text secret
	TextSecret *string   `json:"textSecret,omitempty"`
	Status     *TFStatus `json:"status,omitempty"`
}

func (i InputWiz) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputWiz) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputWiz) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputWiz) GetType() *InputWizType {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputWiz) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputWiz) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputWiz) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputWiz) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputWiz) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputWiz) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputWiz) GetConnections() []InputWizConnections {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputWiz) GetPq() *InputWizPq {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputWiz) GetEndpoint() *string {
	if o == nil {
		return nil
	}
	return o.Endpoint
}

func (o *InputWiz) GetAuthURL() string {
	if o == nil {
		return ""
	}
	return o.AuthURL
}

func (o *InputWiz) GetAuthAudienceOverride() *string {
	if o == nil {
		return nil
	}
	return o.AuthAudienceOverride
}

func (o *InputWiz) GetClientID() string {
	if o == nil {
		return ""
	}
	return o.ClientID
}

func (o *InputWiz) GetContentConfig() []InputWizContentConfig {
	if o == nil {
		return nil
	}
	return o.ContentConfig
}

func (o *InputWiz) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *InputWiz) GetKeepAliveTime() *float64 {
	if o == nil {
		return nil
	}
	return o.KeepAliveTime
}

func (o *InputWiz) GetMaxMissedKeepAlives() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxMissedKeepAlives
}

func (o *InputWiz) GetTTL() *string {
	if o == nil {
		return nil
	}
	return o.TTL
}

func (o *InputWiz) GetMetadata() []InputWizMetadata {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputWiz) GetRetryRules() *InputWizRetryRules {
	if o == nil {
		return nil
	}
	return o.RetryRules
}

func (o *InputWiz) GetAuthType() *InputWizAuthenticationMethod {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *InputWiz) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputWiz) GetClientSecret() *string {
	if o == nil {
		return nil
	}
	return o.ClientSecret
}

func (o *InputWiz) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *InputWiz) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputJournalFilesType string

const (
	InputJournalFilesTypeJournalFiles InputJournalFilesType = "journal_files"
)

func (e InputJournalFilesType) ToPointer() *InputJournalFilesType {
	return &e
}
func (e *InputJournalFilesType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "journal_files":
		*e = InputJournalFilesType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputJournalFilesType: %v", v)
	}
}

type InputJournalFilesConnections struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *InputJournalFilesConnections) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputJournalFilesConnections) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// InputJournalFilesMode - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputJournalFilesMode string

const (
	InputJournalFilesModeSmart  InputJournalFilesMode = "smart"
	InputJournalFilesModeAlways InputJournalFilesMode = "always"
)

func (e InputJournalFilesMode) ToPointer() *InputJournalFilesMode {
	return &e
}
func (e *InputJournalFilesMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputJournalFilesMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputJournalFilesMode: %v", v)
	}
}

// InputJournalFilesCompression - Codec to use to compress the persisted data
type InputJournalFilesCompression string

const (
	InputJournalFilesCompressionNone InputJournalFilesCompression = "none"
	InputJournalFilesCompressionGzip InputJournalFilesCompression = "gzip"
)

func (e InputJournalFilesCompression) ToPointer() *InputJournalFilesCompression {
	return &e
}
func (e *InputJournalFilesCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputJournalFilesCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputJournalFilesCompression: %v", v)
	}
}

type InputJournalFilesPq struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputJournalFilesMode `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *InputJournalFilesCompression `default:"none" json:"compress"`
}

func (i InputJournalFilesPq) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputJournalFilesPq) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputJournalFilesPq) GetMode() *InputJournalFilesMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputJournalFilesPq) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputJournalFilesPq) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *InputJournalFilesPq) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *InputJournalFilesPq) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *InputJournalFilesPq) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *InputJournalFilesPq) GetCompress() *InputJournalFilesCompression {
	if o == nil {
		return nil
	}
	return o.Compress
}

type InputJournalFilesRules struct {
	// JavaScript expression applied to Journal objects. Return 'true' to include it.
	Filter string `json:"filter"`
	// Optional description of this rule's purpose
	Description *string `json:"description,omitempty"`
}

func (o *InputJournalFilesRules) GetFilter() string {
	if o == nil {
		return ""
	}
	return o.Filter
}

func (o *InputJournalFilesRules) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

type InputJournalFilesMetadata struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputJournalFilesMetadata) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputJournalFilesMetadata) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputJournalFiles struct {
	// Unique ID for this input
	ID       *string                `json:"id,omitempty"`
	Type     *InputJournalFilesType `json:"type,omitempty"`
	Disabled *bool                  `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputJournalFilesConnections `json:"connections,omitempty"`
	Pq          *InputJournalFilesPq           `json:"pq,omitempty"`
	// Directory path to search for journals. Environment variables will be resolved, e.g. $CRIBL_EDGE_FS_ROOT/var/log/journal/$MACHINE_ID.
	Path string `json:"path"`
	// Time, in seconds, between scanning for journals.
	Interval *float64 `default:"10" json:"interval"`
	// The full path of discovered journals are matched against this wildcard list.
	Journals []string `json:"journals,omitempty"`
	// Add rules to decide which journal objects to allow. Events are generated if no rules are given or if all the rules' expressions evaluate to true.
	Rules []InputJournalFilesRules `json:"rules,omitempty"`
	// Skip log messages that are not part of the current boot session.
	CurrentBoot *bool `default:"false" json:"currentBoot"`
	// The maximum log message age, in duration form (e.g,: 60s, 4h, 3d, 1w).  Default of no value will apply no max age filters.
	MaxAgeDur *string `json:"maxAgeDur,omitempty"`
	// Fields to add to events from this input
	Metadata    []InputJournalFilesMetadata `json:"metadata,omitempty"`
	Description *string                     `json:"description,omitempty"`
	Status      *TFStatus                   `json:"status,omitempty"`
}

func (i InputJournalFiles) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputJournalFiles) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputJournalFiles) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputJournalFiles) GetType() *InputJournalFilesType {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputJournalFiles) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputJournalFiles) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputJournalFiles) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputJournalFiles) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputJournalFiles) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputJournalFiles) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputJournalFiles) GetConnections() []InputJournalFilesConnections {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputJournalFiles) GetPq() *InputJournalFilesPq {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputJournalFiles) GetPath() string {
	if o == nil {
		return ""
	}
	return o.Path
}

func (o *InputJournalFiles) GetInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.Interval
}

func (o *InputJournalFiles) GetJournals() []string {
	if o == nil {
		return nil
	}
	return o.Journals
}

func (o *InputJournalFiles) GetRules() []InputJournalFilesRules {
	if o == nil {
		return nil
	}
	return o.Rules
}

func (o *InputJournalFiles) GetCurrentBoot() *bool {
	if o == nil {
		return nil
	}
	return o.CurrentBoot
}

func (o *InputJournalFiles) GetMaxAgeDur() *string {
	if o == nil {
		return nil
	}
	return o.MaxAgeDur
}

func (o *InputJournalFiles) GetMetadata() []InputJournalFilesMetadata {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputJournalFiles) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputJournalFiles) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputRawUDPType string

const (
	InputRawUDPTypeRawUDP InputRawUDPType = "raw_udp"
)

func (e InputRawUDPType) ToPointer() *InputRawUDPType {
	return &e
}
func (e *InputRawUDPType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "raw_udp":
		*e = InputRawUDPType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputRawUDPType: %v", v)
	}
}

type InputRawUDPConnections struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *InputRawUDPConnections) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputRawUDPConnections) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// InputRawUDPMode - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputRawUDPMode string

const (
	InputRawUDPModeSmart  InputRawUDPMode = "smart"
	InputRawUDPModeAlways InputRawUDPMode = "always"
)

func (e InputRawUDPMode) ToPointer() *InputRawUDPMode {
	return &e
}
func (e *InputRawUDPMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputRawUDPMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputRawUDPMode: %v", v)
	}
}

// InputRawUDPCompression - Codec to use to compress the persisted data
type InputRawUDPCompression string

const (
	InputRawUDPCompressionNone InputRawUDPCompression = "none"
	InputRawUDPCompressionGzip InputRawUDPCompression = "gzip"
)

func (e InputRawUDPCompression) ToPointer() *InputRawUDPCompression {
	return &e
}
func (e *InputRawUDPCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputRawUDPCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputRawUDPCompression: %v", v)
	}
}

type InputRawUDPPq struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputRawUDPMode `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *InputRawUDPCompression `default:"none" json:"compress"`
}

func (i InputRawUDPPq) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputRawUDPPq) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputRawUDPPq) GetMode() *InputRawUDPMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputRawUDPPq) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputRawUDPPq) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *InputRawUDPPq) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *InputRawUDPPq) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *InputRawUDPPq) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *InputRawUDPPq) GetCompress() *InputRawUDPCompression {
	if o == nil {
		return nil
	}
	return o.Compress
}

type InputRawUDPMetadata struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputRawUDPMetadata) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputRawUDPMetadata) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputRawUDP struct {
	// Unique ID for this input
	ID       *string          `json:"id,omitempty"`
	Type     *InputRawUDPType `json:"type,omitempty"`
	Disabled *bool            `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputRawUDPConnections `json:"connections,omitempty"`
	Pq          *InputRawUDPPq           `json:"pq,omitempty"`
	// Address to bind on. For IPv4 (all addresses), use the default '0.0.0.0'. For IPv6, enter '::' (all addresses) or specify an IP address.
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port float64 `json:"port"`
	// Maximum number of events to buffer when downstream is blocking.
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// Regex matching IP addresses that are allowed to send data
	IPWhitelistRegex *string `default:"/.*/" json:"ipWhitelistRegex"`
	// If true, each UDP packet is assumed to contain a single message. If false, each UDP packet is assumed to contain multiple messages, separated by newlines.
	SingleMsgUDPPackets *bool `default:"false" json:"singleMsgUdpPackets"`
	// If true, a __rawBytes field will be added to each event containing the raw bytes of the datagram.
	IngestRawBytes *bool `default:"false" json:"ingestRawBytes"`
	// Optionally, set the SO_RCVBUF socket option for the UDP socket. This value tells the operating system how many bytes can be buffered in the kernel before events are dropped. Leave blank to use the OS default. Caution: Increasing this value will affect OS memory utilization.
	UDPSocketRxBufSize *float64 `json:"udpSocketRxBufSize,omitempty"`
	// Fields to add to events from this input
	Metadata    []InputRawUDPMetadata `json:"metadata,omitempty"`
	Description *string               `json:"description,omitempty"`
	Status      *TFStatus             `json:"status,omitempty"`
}

func (i InputRawUDP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputRawUDP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputRawUDP) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputRawUDP) GetType() *InputRawUDPType {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputRawUDP) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputRawUDP) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputRawUDP) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputRawUDP) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputRawUDP) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputRawUDP) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputRawUDP) GetConnections() []InputRawUDPConnections {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputRawUDP) GetPq() *InputRawUDPPq {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputRawUDP) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputRawUDP) GetPort() float64 {
	if o == nil {
		return 0.0
	}
	return o.Port
}

func (o *InputRawUDP) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputRawUDP) GetIPWhitelistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPWhitelistRegex
}

func (o *InputRawUDP) GetSingleMsgUDPPackets() *bool {
	if o == nil {
		return nil
	}
	return o.SingleMsgUDPPackets
}

func (o *InputRawUDP) GetIngestRawBytes() *bool {
	if o == nil {
		return nil
	}
	return o.IngestRawBytes
}

func (o *InputRawUDP) GetUDPSocketRxBufSize() *float64 {
	if o == nil {
		return nil
	}
	return o.UDPSocketRxBufSize
}

func (o *InputRawUDP) GetMetadata() []InputRawUDPMetadata {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputRawUDP) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputRawUDP) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputWinEventLogsType string

const (
	InputWinEventLogsTypeWinEventLogs InputWinEventLogsType = "win_event_logs"
)

func (e InputWinEventLogsType) ToPointer() *InputWinEventLogsType {
	return &e
}
func (e *InputWinEventLogsType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "win_event_logs":
		*e = InputWinEventLogsType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputWinEventLogsType: %v", v)
	}
}

type InputWinEventLogsConnections struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *InputWinEventLogsConnections) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputWinEventLogsConnections) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// InputWinEventLogsMode - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputWinEventLogsMode string

const (
	InputWinEventLogsModeSmart  InputWinEventLogsMode = "smart"
	InputWinEventLogsModeAlways InputWinEventLogsMode = "always"
)

func (e InputWinEventLogsMode) ToPointer() *InputWinEventLogsMode {
	return &e
}
func (e *InputWinEventLogsMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputWinEventLogsMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputWinEventLogsMode: %v", v)
	}
}

// InputWinEventLogsCompression - Codec to use to compress the persisted data
type InputWinEventLogsCompression string

const (
	InputWinEventLogsCompressionNone InputWinEventLogsCompression = "none"
	InputWinEventLogsCompressionGzip InputWinEventLogsCompression = "gzip"
)

func (e InputWinEventLogsCompression) ToPointer() *InputWinEventLogsCompression {
	return &e
}
func (e *InputWinEventLogsCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputWinEventLogsCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputWinEventLogsCompression: %v", v)
	}
}

type InputWinEventLogsPq struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputWinEventLogsMode `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *InputWinEventLogsCompression `default:"none" json:"compress"`
}

func (i InputWinEventLogsPq) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputWinEventLogsPq) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputWinEventLogsPq) GetMode() *InputWinEventLogsMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputWinEventLogsPq) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputWinEventLogsPq) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *InputWinEventLogsPq) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *InputWinEventLogsPq) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *InputWinEventLogsPq) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *InputWinEventLogsPq) GetCompress() *InputWinEventLogsCompression {
	if o == nil {
		return nil
	}
	return o.Compress
}

// ReadMode - Read all stored and future event logs, or only future events
type ReadMode string

const (
	ReadModeOldest ReadMode = "oldest"
	ReadModeNewest ReadMode = "newest"
)

func (e ReadMode) ToPointer() *ReadMode {
	return &e
}
func (e *ReadMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "oldest":
		fallthrough
	case "newest":
		*e = ReadMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ReadMode: %v", v)
	}
}

// EventFormat - Format of individual events
type EventFormat string

const (
	EventFormatJSON EventFormat = "json"
	EventFormatXML  EventFormat = "xml"
)

func (e EventFormat) ToPointer() *EventFormat {
	return &e
}
func (e *EventFormat) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "json":
		fallthrough
	case "xml":
		*e = EventFormat(v)
		return nil
	default:
		return fmt.Errorf("invalid value for EventFormat: %v", v)
	}
}

type InputWinEventLogsMetadata struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputWinEventLogsMetadata) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputWinEventLogsMetadata) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputWinEventLogs struct {
	// Unique ID for this input
	ID       *string               `json:"id,omitempty"`
	Type     InputWinEventLogsType `json:"type"`
	Disabled *bool                 `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputWinEventLogsConnections `json:"connections,omitempty"`
	Pq          *InputWinEventLogsPq           `json:"pq,omitempty"`
	// Enter the event logs to collect. Run "Get-WinEvent -ListLog *" in PowerShell to see the available logs.
	LogNames []string `json:"logNames,omitempty"`
	// Read all stored and future event logs, or only future events
	ReadMode *ReadMode `default:"oldest" json:"readMode"`
	// Format of individual events
	EventFormat *EventFormat `default:"json" json:"eventFormat"`
	// Enable to use built-in tools (PowerShell for JSON, wevtutil for XML) to collect event logs instead of native API (default) [Learn more](https://docs.cribl.io/edge/sources-windows-event-logs/#advanced-settings)
	DisableNativeModule *bool `default:"false" json:"disableNativeModule"`
	// Time, in seconds, between checking for new entries (Applicable for pre-4.8.0 nodes that use Windows Tools)
	Interval *float64 `default:"10" json:"interval"`
	// The maximum number of events to read in one polling interval. A batch size higher than 500 can cause delays when pulling from multiple event logs. (Applicable for pre-4.8.0 nodes that use Windows Tools)
	BatchSize *float64 `default:"500" json:"batchSize"`
	// Fields to add to events from this input
	Metadata []InputWinEventLogsMetadata `json:"metadata,omitempty"`
	// The maximum number of bytes in an event before it is flushed to the pipelines
	MaxEventBytes *float64  `default:"51200" json:"maxEventBytes"`
	Description   *string   `json:"description,omitempty"`
	Status        *TFStatus `json:"status,omitempty"`
}

func (i InputWinEventLogs) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputWinEventLogs) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputWinEventLogs) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputWinEventLogs) GetType() InputWinEventLogsType {
	if o == nil {
		return InputWinEventLogsType("")
	}
	return o.Type
}

func (o *InputWinEventLogs) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputWinEventLogs) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputWinEventLogs) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputWinEventLogs) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputWinEventLogs) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputWinEventLogs) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputWinEventLogs) GetConnections() []InputWinEventLogsConnections {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputWinEventLogs) GetPq() *InputWinEventLogsPq {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputWinEventLogs) GetLogNames() []string {
	if o == nil {
		return nil
	}
	return o.LogNames
}

func (o *InputWinEventLogs) GetReadMode() *ReadMode {
	if o == nil {
		return nil
	}
	return o.ReadMode
}

func (o *InputWinEventLogs) GetEventFormat() *EventFormat {
	if o == nil {
		return nil
	}
	return o.EventFormat
}

func (o *InputWinEventLogs) GetDisableNativeModule() *bool {
	if o == nil {
		return nil
	}
	return o.DisableNativeModule
}

func (o *InputWinEventLogs) GetInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.Interval
}

func (o *InputWinEventLogs) GetBatchSize() *float64 {
	if o == nil {
		return nil
	}
	return o.BatchSize
}

func (o *InputWinEventLogs) GetMetadata() []InputWinEventLogsMetadata {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputWinEventLogs) GetMaxEventBytes() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxEventBytes
}

func (o *InputWinEventLogs) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputWinEventLogs) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputWefType string

const (
	InputWefTypeWef InputWefType = "wef"
)

func (e InputWefType) ToPointer() *InputWefType {
	return &e
}
func (e *InputWefType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "wef":
		*e = InputWefType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputWefType: %v", v)
	}
}

type InputWefConnections struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *InputWefConnections) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputWefConnections) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// InputWefMode - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputWefMode string

const (
	InputWefModeSmart  InputWefMode = "smart"
	InputWefModeAlways InputWefMode = "always"
)

func (e InputWefMode) ToPointer() *InputWefMode {
	return &e
}
func (e *InputWefMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputWefMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputWefMode: %v", v)
	}
}

// InputWefCompression - Codec to use to compress the persisted data
type InputWefCompression string

const (
	InputWefCompressionNone InputWefCompression = "none"
	InputWefCompressionGzip InputWefCompression = "gzip"
)

func (e InputWefCompression) ToPointer() *InputWefCompression {
	return &e
}
func (e *InputWefCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputWefCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputWefCompression: %v", v)
	}
}

type InputWefPq struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputWefMode `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *InputWefCompression `default:"none" json:"compress"`
}

func (i InputWefPq) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputWefPq) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputWefPq) GetMode() *InputWefMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputWefPq) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputWefPq) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *InputWefPq) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *InputWefPq) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *InputWefPq) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *InputWefPq) GetCompress() *InputWefCompression {
	if o == nil {
		return nil
	}
	return o.Compress
}

// InputWefAuthenticationMethod - Method by which to authenticate incoming client connections.
type InputWefAuthenticationMethod string

const (
	InputWefAuthenticationMethodClientCert InputWefAuthenticationMethod = "clientCert"
	InputWefAuthenticationMethodKerberos   InputWefAuthenticationMethod = "kerberos"
)

func (e InputWefAuthenticationMethod) ToPointer() *InputWefAuthenticationMethod {
	return &e
}
func (e *InputWefAuthenticationMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "clientCert":
		fallthrough
	case "kerberos":
		*e = InputWefAuthenticationMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputWefAuthenticationMethod: %v", v)
	}
}

// InputWefMinimumTLSVersion - Minimum TLS version to accept from connections.
type InputWefMinimumTLSVersion string

const (
	InputWefMinimumTLSVersionTlSv1  InputWefMinimumTLSVersion = "TLSv1"
	InputWefMinimumTLSVersionTlSv11 InputWefMinimumTLSVersion = "TLSv1.1"
	InputWefMinimumTLSVersionTlSv12 InputWefMinimumTLSVersion = "TLSv1.2"
	InputWefMinimumTLSVersionTlSv13 InputWefMinimumTLSVersion = "TLSv1.3"
)

func (e InputWefMinimumTLSVersion) ToPointer() *InputWefMinimumTLSVersion {
	return &e
}
func (e *InputWefMinimumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputWefMinimumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputWefMinimumTLSVersion: %v", v)
	}
}

// InputWefMaximumTLSVersion - Maximum TLS version to accept from connections
type InputWefMaximumTLSVersion string

const (
	InputWefMaximumTLSVersionTlSv1  InputWefMaximumTLSVersion = "TLSv1"
	InputWefMaximumTLSVersionTlSv11 InputWefMaximumTLSVersion = "TLSv1.1"
	InputWefMaximumTLSVersionTlSv12 InputWefMaximumTLSVersion = "TLSv1.2"
	InputWefMaximumTLSVersionTlSv13 InputWefMaximumTLSVersion = "TLSv1.3"
)

func (e InputWefMaximumTLSVersion) ToPointer() *InputWefMaximumTLSVersion {
	return &e
}
func (e *InputWefMaximumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputWefMaximumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputWefMaximumTLSVersion: %v", v)
	}
}

type MTLSSettings struct {
	// Enable TLS
	Disabled *bool `default:"false" json:"disabled"`
	// Required for WEF certificate authentication.
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Required for WEF certificate authentication.
	RequestCert *bool `default:"true" json:"requestCert"`
	// Name of the predefined certificate.
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath string `json:"privKeyPath"`
	// Passphrase to use to decrypt private key.
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath string `json:"certPath"`
	// Server path containing CA certificates (in PEM format) to use. Can reference $ENV_VARS. If multiple certificates are present in a .pem, each must directly certify the one preceding it.
	CaPath string `json:"caPath"`
	// Regex matching allowable common names in peer certificates' subject attribute.
	CommonNameRegex *string `default:"/.*/" json:"commonNameRegex"`
	// Minimum TLS version to accept from connections.
	MinVersion *InputWefMinimumTLSVersion `json:"minVersion,omitempty"`
	// Maximum TLS version to accept from connections
	MaxVersion *InputWefMaximumTLSVersion `json:"maxVersion,omitempty"`
	// Enable OCSP check of certificate
	OcspCheck *bool `default:"false" json:"ocspCheck"`
	Keytab    any   `json:"keytab,omitempty"`
	Principal any   `json:"principal,omitempty"`
	// If enabled, checks will fail on any OCSP error. Otherwise, checks will fail only when a certificate is revoked, ignoring other errors.
	OcspCheckFailClose *bool `default:"false" json:"ocspCheckFailClose"`
}

func (m MTLSSettings) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(m, "", false)
}

func (m *MTLSSettings) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &m, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *MTLSSettings) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *MTLSSettings) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *MTLSSettings) GetRequestCert() *bool {
	if o == nil {
		return nil
	}
	return o.RequestCert
}

func (o *MTLSSettings) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *MTLSSettings) GetPrivKeyPath() string {
	if o == nil {
		return ""
	}
	return o.PrivKeyPath
}

func (o *MTLSSettings) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *MTLSSettings) GetCertPath() string {
	if o == nil {
		return ""
	}
	return o.CertPath
}

func (o *MTLSSettings) GetCaPath() string {
	if o == nil {
		return ""
	}
	return o.CaPath
}

func (o *MTLSSettings) GetCommonNameRegex() *string {
	if o == nil {
		return nil
	}
	return o.CommonNameRegex
}

func (o *MTLSSettings) GetMinVersion() *InputWefMinimumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *MTLSSettings) GetMaxVersion() *InputWefMaximumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

func (o *MTLSSettings) GetOcspCheck() *bool {
	if o == nil {
		return nil
	}
	return o.OcspCheck
}

func (o *MTLSSettings) GetKeytab() any {
	if o == nil {
		return nil
	}
	return o.Keytab
}

func (o *MTLSSettings) GetPrincipal() any {
	if o == nil {
		return nil
	}
	return o.Principal
}

func (o *MTLSSettings) GetOcspCheckFailClose() *bool {
	if o == nil {
		return nil
	}
	return o.OcspCheckFailClose
}

// InputWefFormat - Content format in which the endpoint should deliver events.
type InputWefFormat string

const (
	InputWefFormatRaw          InputWefFormat = "Raw"
	InputWefFormatRenderedText InputWefFormat = "RenderedText"
)

func (e InputWefFormat) ToPointer() *InputWefFormat {
	return &e
}
func (e *InputWefFormat) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "Raw":
		fallthrough
	case "RenderedText":
		*e = InputWefFormat(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputWefFormat: %v", v)
	}
}

// QueryBuilderMode - Select the query builder mode.
type QueryBuilderMode string

const (
	QueryBuilderModeSimple QueryBuilderMode = "simple"
	QueryBuilderModeXML    QueryBuilderMode = "xml"
)

func (e QueryBuilderMode) ToPointer() *QueryBuilderMode {
	return &e
}
func (e *QueryBuilderMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "simple":
		fallthrough
	case "xml":
		*e = QueryBuilderMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for QueryBuilderMode: %v", v)
	}
}

type InputWefInputMetadata struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputWefInputMetadata) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputWefInputMetadata) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type Subscriptions struct {
	// Friendly name for this subscription.
	SubscriptionName string `json:"subscriptionName"`
	// Version UUID for this subscription. If any subscription parameters are modified, this value will change.
	Version *string `json:"version,omitempty"`
	// Content format in which the endpoint should deliver events.
	ContentFormat *InputWefFormat `default:"Raw" json:"contentFormat"`
	// Maximum time (in seconds) between endpoint checkins before considering it unavailable.
	HeartbeatInterval *float64 `default:"60" json:"heartbeatInterval"`
	// Interval (in seconds) over which the endpoint should collect events before sending them to Stream.
	BatchTimeout *float64 `default:"60" json:"batchTimeout"`
	// Set to Yes if a newly-subscribed endpoint should send previously existing events. Set to No to only receive new events
	ReadExistingEvents *bool `default:"false" json:"readExistingEvents"`
	// If toggled to Yes, @{product} will keep track of which events have been received, resuming from that point after a re-subscription. This setting takes precedence over 'Read existing events' -- see the documentation for details.
	SendBookmarks *bool `default:"true" json:"sendBookmarks"`
	// If toggled to Yes, Stream will receive compressed events from the source.
	Compress *bool `default:"true" json:"compress"`
	// Enter the DNS names of the endpoints that should forward these events. You may use wildcards, for example: *.mydomain.com
	Targets []string `json:"targets,omitempty"`
	// The RFC-3066 locale the Windows clients should use when sending events. Defaults to "en-US".
	Locale *string `default:"en-US" json:"locale"`
	// Select the query builder mode.
	QuerySelector *QueryBuilderMode `default:"simple" json:"querySelector"`
	// Fields to add to events ingested under this subscription
	Metadata []InputWefInputMetadata `json:"metadata,omitempty"`
}

func (s Subscriptions) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *Subscriptions) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *Subscriptions) GetSubscriptionName() string {
	if o == nil {
		return ""
	}
	return o.SubscriptionName
}

func (o *Subscriptions) GetVersion() *string {
	if o == nil {
		return nil
	}
	return o.Version
}

func (o *Subscriptions) GetContentFormat() *InputWefFormat {
	if o == nil {
		return nil
	}
	return o.ContentFormat
}

func (o *Subscriptions) GetHeartbeatInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.HeartbeatInterval
}

func (o *Subscriptions) GetBatchTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.BatchTimeout
}

func (o *Subscriptions) GetReadExistingEvents() *bool {
	if o == nil {
		return nil
	}
	return o.ReadExistingEvents
}

func (o *Subscriptions) GetSendBookmarks() *bool {
	if o == nil {
		return nil
	}
	return o.SendBookmarks
}

func (o *Subscriptions) GetCompress() *bool {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *Subscriptions) GetTargets() []string {
	if o == nil {
		return nil
	}
	return o.Targets
}

func (o *Subscriptions) GetLocale() *string {
	if o == nil {
		return nil
	}
	return o.Locale
}

func (o *Subscriptions) GetQuerySelector() *QueryBuilderMode {
	if o == nil {
		return nil
	}
	return o.QuerySelector
}

func (o *Subscriptions) GetMetadata() []InputWefInputMetadata {
	if o == nil {
		return nil
	}
	return o.Metadata
}

type InputWefMetadata struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputWefMetadata) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputWefMetadata) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputWef struct {
	// Unique ID for this input
	ID       *string       `json:"id,omitempty"`
	Type     *InputWefType `json:"type,omitempty"`
	Disabled *bool         `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputWefConnections `json:"connections,omitempty"`
	Pq          *InputWefPq           `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port *float64 `default:"5986" json:"port"`
	// Method by which to authenticate incoming client connections.
	AuthMethod *InputWefAuthenticationMethod `default:"clientCert" json:"authMethod"`
	TLS        *MTLSSettings                 `json:"tls,omitempty"`
	// Maximum number of active requests per Worker Process. Use 0 for unlimited.
	MaxActiveReq *float64 `default:"256" json:"maxActiveReq"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket *int64 `default:"0" json:"maxRequestsPerSocket"`
	// Enable when clients are connecting through a proxy that supports the x-forwarded-for header to keep the client's original IP address on the event instead of the proxy's IP address
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Add request headers to events in the __headers field
	CaptureHeaders *bool `default:"false" json:"captureHeaders"`
	// After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 sec.; maximum 600 sec. (10 min.).
	KeepAliveTimeout *float64 `default:"90" json:"keepAliveTimeout"`
	// Enable to expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
	EnableHealthCheck *bool `default:"false" json:"enableHealthCheck"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist.
	IPAllowlistRegex *string `default:"/.*/" json:"ipAllowlistRegex"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `default:"/^\\$/" json:"ipDenylistRegex"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `default:"0" json:"socketTimeout"`
	// SHA1 fingerprint expected by the client, if it does not match the first certificate in the configured CA chain
	CaFingerprint *string `json:"caFingerprint,omitempty"`
	// Path to the keytab file containing the service principal credentials. @{product} will use `/etc/krb5.keytab` if not provided.
	Keytab *string `json:"keytab,omitempty"`
	// Kerberos principal used for authentication, typically in the form HTTP/<hostname>@<REALM>.
	Principal *string `json:"principal,omitempty"`
	// Allow events to be ingested even if their MachineID does not match the client certificate CN.
	AllowMachineIDMismatch *bool `default:"false" json:"allowMachineIdMismatch"`
	// Subscriptions to events on forwarding endpoints.
	Subscriptions []Subscriptions `json:"subscriptions"`
	// Fields to add to events from this input
	Metadata    []InputWefMetadata `json:"metadata,omitempty"`
	Description *string            `json:"description,omitempty"`
	Status      *TFStatus          `json:"status,omitempty"`
}

func (i InputWef) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputWef) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputWef) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputWef) GetType() *InputWefType {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputWef) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputWef) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputWef) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputWef) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputWef) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputWef) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputWef) GetConnections() []InputWefConnections {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputWef) GetPq() *InputWefPq {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputWef) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputWef) GetPort() *float64 {
	if o == nil {
		return nil
	}
	return o.Port
}

func (o *InputWef) GetAuthMethod() *InputWefAuthenticationMethod {
	if o == nil {
		return nil
	}
	return o.AuthMethod
}

func (o *InputWef) GetTLS() *MTLSSettings {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputWef) GetMaxActiveReq() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxActiveReq
}

func (o *InputWef) GetMaxRequestsPerSocket() *int64 {
	if o == nil {
		return nil
	}
	return o.MaxRequestsPerSocket
}

func (o *InputWef) GetEnableProxyHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableProxyHeader
}

func (o *InputWef) GetCaptureHeaders() *bool {
	if o == nil {
		return nil
	}
	return o.CaptureHeaders
}

func (o *InputWef) GetKeepAliveTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.KeepAliveTimeout
}

func (o *InputWef) GetEnableHealthCheck() *bool {
	if o == nil {
		return nil
	}
	return o.EnableHealthCheck
}

func (o *InputWef) GetIPAllowlistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPAllowlistRegex
}

func (o *InputWef) GetIPDenylistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPDenylistRegex
}

func (o *InputWef) GetSocketTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketTimeout
}

func (o *InputWef) GetCaFingerprint() *string {
	if o == nil {
		return nil
	}
	return o.CaFingerprint
}

func (o *InputWef) GetKeytab() *string {
	if o == nil {
		return nil
	}
	return o.Keytab
}

func (o *InputWef) GetPrincipal() *string {
	if o == nil {
		return nil
	}
	return o.Principal
}

func (o *InputWef) GetAllowMachineIDMismatch() *bool {
	if o == nil {
		return nil
	}
	return o.AllowMachineIDMismatch
}

func (o *InputWef) GetSubscriptions() []Subscriptions {
	if o == nil {
		return []Subscriptions{}
	}
	return o.Subscriptions
}

func (o *InputWef) GetMetadata() []InputWefMetadata {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputWef) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputWef) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputAppscopeType string

const (
	InputAppscopeTypeAppscope InputAppscopeType = "appscope"
)

func (e InputAppscopeType) ToPointer() *InputAppscopeType {
	return &e
}
func (e *InputAppscopeType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "appscope":
		*e = InputAppscopeType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputAppscopeType: %v", v)
	}
}

type InputAppscopeConnections struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *InputAppscopeConnections) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputAppscopeConnections) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// InputAppscopeMode - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputAppscopeMode string

const (
	InputAppscopeModeSmart  InputAppscopeMode = "smart"
	InputAppscopeModeAlways InputAppscopeMode = "always"
)

func (e InputAppscopeMode) ToPointer() *InputAppscopeMode {
	return &e
}
func (e *InputAppscopeMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputAppscopeMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputAppscopeMode: %v", v)
	}
}

// InputAppscopeCompression - Codec to use to compress the persisted data
type InputAppscopeCompression string

const (
	InputAppscopeCompressionNone InputAppscopeCompression = "none"
	InputAppscopeCompressionGzip InputAppscopeCompression = "gzip"
)

func (e InputAppscopeCompression) ToPointer() *InputAppscopeCompression {
	return &e
}
func (e *InputAppscopeCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputAppscopeCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputAppscopeCompression: %v", v)
	}
}

type InputAppscopePq struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputAppscopeMode `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *InputAppscopeCompression `default:"none" json:"compress"`
}

func (i InputAppscopePq) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputAppscopePq) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputAppscopePq) GetMode() *InputAppscopeMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputAppscopePq) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputAppscopePq) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *InputAppscopePq) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *InputAppscopePq) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *InputAppscopePq) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *InputAppscopePq) GetCompress() *InputAppscopeCompression {
	if o == nil {
		return nil
	}
	return o.Compress
}

type InputAppscopeMetadata struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputAppscopeMetadata) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputAppscopeMetadata) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type Allow struct {
	// Specify the name of a process or family of processes.
	Procname string `json:"procname"`
	// Specify a string to substring-match against process command-line.
	Arg *string `json:"arg,omitempty"`
	// Choose a config to apply to processes that match the process name and/or argument.
	Config string `json:"config"`
}

func (o *Allow) GetProcname() string {
	if o == nil {
		return ""
	}
	return o.Procname
}

func (o *Allow) GetArg() *string {
	if o == nil {
		return nil
	}
	return o.Arg
}

func (o *Allow) GetConfig() string {
	if o == nil {
		return ""
	}
	return o.Config
}

type Filter struct {
	// Specify processes that AppScope should be loaded into, and the config to use.
	Allow []Allow `json:"allow,omitempty"`
	// To override the UNIX domain socket or address/port specified in General Settings (while leaving Authentication settings as is), enter a URL.
	TransportURL *string `json:"transportURL,omitempty"`
}

func (o *Filter) GetAllow() []Allow {
	if o == nil {
		return nil
	}
	return o.Allow
}

func (o *Filter) GetTransportURL() *string {
	if o == nil {
		return nil
	}
	return o.TransportURL
}

type InputAppscopeDataCompressionFormat string

const (
	InputAppscopeDataCompressionFormatNone InputAppscopeDataCompressionFormat = "none"
	InputAppscopeDataCompressionFormatGzip InputAppscopeDataCompressionFormat = "gzip"
)

func (e InputAppscopeDataCompressionFormat) ToPointer() *InputAppscopeDataCompressionFormat {
	return &e
}
func (e *InputAppscopeDataCompressionFormat) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputAppscopeDataCompressionFormat(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputAppscopeDataCompressionFormat: %v", v)
	}
}

type InputAppscopePersistence struct {
	// Spool events and metrics on disk for Cribl Edge and Search
	Enable *bool `default:"false" json:"enable"`
	// Time span for each file bucket
	TimeWindow *string `default:"10m" json:"timeWindow"`
	// Maximum disk space allowed to be consumed (examples: 420MB, 4GB). When limit is reached, older data will be deleted.
	MaxDataSize *string `default:"1GB" json:"maxDataSize"`
	// Maximum amount of time to retain data (examples: 2h, 4d). When limit is reached, older data will be deleted.
	MaxDataTime *string                             `default:"24h" json:"maxDataTime"`
	Compress    *InputAppscopeDataCompressionFormat `default:"gzip" json:"compress"`
	// Path to use to write metrics. Defaults to $CRIBL_HOME/state/appscope
	DestPath *string `default:"\\$CRIBL_HOME/state/appscope" json:"destPath"`
}

func (i InputAppscopePersistence) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputAppscopePersistence) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputAppscopePersistence) GetEnable() *bool {
	if o == nil {
		return nil
	}
	return o.Enable
}

func (o *InputAppscopePersistence) GetTimeWindow() *string {
	if o == nil {
		return nil
	}
	return o.TimeWindow
}

func (o *InputAppscopePersistence) GetMaxDataSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxDataSize
}

func (o *InputAppscopePersistence) GetMaxDataTime() *string {
	if o == nil {
		return nil
	}
	return o.MaxDataTime
}

func (o *InputAppscopePersistence) GetCompress() *InputAppscopeDataCompressionFormat {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *InputAppscopePersistence) GetDestPath() *string {
	if o == nil {
		return nil
	}
	return o.DestPath
}

// InputAppscopeAuthenticationMethod - Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
type InputAppscopeAuthenticationMethod string

const (
	InputAppscopeAuthenticationMethodManual InputAppscopeAuthenticationMethod = "manual"
	InputAppscopeAuthenticationMethodSecret InputAppscopeAuthenticationMethod = "secret"
)

func (e InputAppscopeAuthenticationMethod) ToPointer() *InputAppscopeAuthenticationMethod {
	return &e
}
func (e *InputAppscopeAuthenticationMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "manual":
		fallthrough
	case "secret":
		*e = InputAppscopeAuthenticationMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputAppscopeAuthenticationMethod: %v", v)
	}
}

// InputAppscopeMinimumTLSVersion - Minimum TLS version to accept from connections
type InputAppscopeMinimumTLSVersion string

const (
	InputAppscopeMinimumTLSVersionTlSv1  InputAppscopeMinimumTLSVersion = "TLSv1"
	InputAppscopeMinimumTLSVersionTlSv11 InputAppscopeMinimumTLSVersion = "TLSv1.1"
	InputAppscopeMinimumTLSVersionTlSv12 InputAppscopeMinimumTLSVersion = "TLSv1.2"
	InputAppscopeMinimumTLSVersionTlSv13 InputAppscopeMinimumTLSVersion = "TLSv1.3"
)

func (e InputAppscopeMinimumTLSVersion) ToPointer() *InputAppscopeMinimumTLSVersion {
	return &e
}
func (e *InputAppscopeMinimumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputAppscopeMinimumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputAppscopeMinimumTLSVersion: %v", v)
	}
}

// InputAppscopeMaximumTLSVersion - Maximum TLS version to accept from connections
type InputAppscopeMaximumTLSVersion string

const (
	InputAppscopeMaximumTLSVersionTlSv1  InputAppscopeMaximumTLSVersion = "TLSv1"
	InputAppscopeMaximumTLSVersionTlSv11 InputAppscopeMaximumTLSVersion = "TLSv1.1"
	InputAppscopeMaximumTLSVersionTlSv12 InputAppscopeMaximumTLSVersion = "TLSv1.2"
	InputAppscopeMaximumTLSVersionTlSv13 InputAppscopeMaximumTLSVersion = "TLSv1.3"
)

func (e InputAppscopeMaximumTLSVersion) ToPointer() *InputAppscopeMaximumTLSVersion {
	return &e
}
func (e *InputAppscopeMaximumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputAppscopeMaximumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputAppscopeMaximumTLSVersion: %v", v)
	}
}

type InputAppscopeTLSSettingsServerSide struct {
	Disabled *bool `default:"true" json:"disabled"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert        *bool `default:"false" json:"requestCert"`
	RejectUnauthorized any   `json:"rejectUnauthorized,omitempty"`
	CommonNameRegex    any   `json:"commonNameRegex,omitempty"`
	// Minimum TLS version to accept from connections
	MinVersion *InputAppscopeMinimumTLSVersion `json:"minVersion,omitempty"`
	// Maximum TLS version to accept from connections
	MaxVersion *InputAppscopeMaximumTLSVersion `json:"maxVersion,omitempty"`
}

func (i InputAppscopeTLSSettingsServerSide) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputAppscopeTLSSettingsServerSide) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputAppscopeTLSSettingsServerSide) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputAppscopeTLSSettingsServerSide) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *InputAppscopeTLSSettingsServerSide) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *InputAppscopeTLSSettingsServerSide) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *InputAppscopeTLSSettingsServerSide) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *InputAppscopeTLSSettingsServerSide) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *InputAppscopeTLSSettingsServerSide) GetRequestCert() *bool {
	if o == nil {
		return nil
	}
	return o.RequestCert
}

func (o *InputAppscopeTLSSettingsServerSide) GetRejectUnauthorized() any {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *InputAppscopeTLSSettingsServerSide) GetCommonNameRegex() any {
	if o == nil {
		return nil
	}
	return o.CommonNameRegex
}

func (o *InputAppscopeTLSSettingsServerSide) GetMinVersion() *InputAppscopeMinimumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *InputAppscopeTLSSettingsServerSide) GetMaxVersion() *InputAppscopeMaximumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

type InputAppscope struct {
	// Unique ID for this input
	ID       string            `json:"id"`
	Type     InputAppscopeType `json:"type"`
	Disabled *bool             `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputAppscopeConnections `json:"connections,omitempty"`
	Pq          *InputAppscopePq           `json:"pq,omitempty"`
	// Regex matching IP addresses that are allowed to establish a connection
	IPWhitelistRegex *string `default:"/.*/" json:"ipWhitelistRegex"`
	// Maximum number of active connections allowed per Worker Process. Use 0 for unlimited.
	MaxActiveCxn *float64 `default:"1000" json:"maxActiveCxn"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. After this time, the connection will be closed. Leave at 0 for no inactive socket monitoring.
	SocketIdleTimeout *float64 `default:"0" json:"socketIdleTimeout"`
	// How long the server will wait after initiating a closure for a client to close its end of the connection. If the client doesn't close the connection within this time, the server will forcefully terminate the socket to prevent resource leaks and ensure efficient connection cleanup and system stability. Leave at 0 for no inactive socket monitoring.
	SocketEndingMaxWait *float64 `default:"30" json:"socketEndingMaxWait"`
	// The maximum duration a socket can remain open, even if active. This helps manage resources and mitigate issues caused by TCP pinning. Set to 0 to disable.
	SocketMaxLifespan *float64 `default:"0" json:"socketMaxLifespan"`
	// Enable if the connection is proxied by a device that supports proxy protocol v1 or v2
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Fields to add to events from this input
	Metadata []InputAppscopeMetadata `json:"metadata,omitempty"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitempty"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `default:"10000" json:"staleChannelFlushMs"`
	// Toggle to Yes to specify a file-backed UNIX domain socket connection, instead of a network host and port.
	EnableUnixPath *bool                     `default:"false" json:"enableUnixPath"`
	Filter         *Filter                   `json:"filter,omitempty"`
	Persistence    *InputAppscopePersistence `json:"persistence,omitempty"`
	// Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
	AuthType    *InputAppscopeAuthenticationMethod `default:"manual" json:"authType"`
	Description *string                            `json:"description,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `json:"host,omitempty"`
	// Port to listen on
	Port *float64                            `json:"port,omitempty"`
	TLS  *InputAppscopeTLSSettingsServerSide `json:"tls,omitempty"`
	// Path to the UNIX domain socket to listen on.
	UnixSocketPath *string `default:"\\$CRIBL_HOME/state/appscope.sock" json:"unixSocketPath"`
	// Permissions to set for socket e.g., 777. If empty, falls back to the runtime user's default permissions.
	UnixSocketPerms *string `json:"unixSocketPerms,omitempty"`
	// Shared secret to be provided by any client (in authToken header field). If empty, unauthorized access is permitted.
	AuthToken *string `default:"" json:"authToken"`
	// Select or create a stored text secret
	TextSecret *string   `json:"textSecret,omitempty"`
	Status     *TFStatus `json:"status,omitempty"`
}

func (i InputAppscope) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputAppscope) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputAppscope) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *InputAppscope) GetType() InputAppscopeType {
	if o == nil {
		return InputAppscopeType("")
	}
	return o.Type
}

func (o *InputAppscope) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputAppscope) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputAppscope) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputAppscope) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputAppscope) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputAppscope) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputAppscope) GetConnections() []InputAppscopeConnections {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputAppscope) GetPq() *InputAppscopePq {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputAppscope) GetIPWhitelistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPWhitelistRegex
}

func (o *InputAppscope) GetMaxActiveCxn() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxActiveCxn
}

func (o *InputAppscope) GetSocketIdleTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketIdleTimeout
}

func (o *InputAppscope) GetSocketEndingMaxWait() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketEndingMaxWait
}

func (o *InputAppscope) GetSocketMaxLifespan() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketMaxLifespan
}

func (o *InputAppscope) GetEnableProxyHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableProxyHeader
}

func (o *InputAppscope) GetMetadata() []InputAppscopeMetadata {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputAppscope) GetBreakerRulesets() []string {
	if o == nil {
		return nil
	}
	return o.BreakerRulesets
}

func (o *InputAppscope) GetStaleChannelFlushMs() *float64 {
	if o == nil {
		return nil
	}
	return o.StaleChannelFlushMs
}

func (o *InputAppscope) GetEnableUnixPath() *bool {
	if o == nil {
		return nil
	}
	return o.EnableUnixPath
}

func (o *InputAppscope) GetFilter() *Filter {
	if o == nil {
		return nil
	}
	return o.Filter
}

func (o *InputAppscope) GetPersistence() *InputAppscopePersistence {
	if o == nil {
		return nil
	}
	return o.Persistence
}

func (o *InputAppscope) GetAuthType() *InputAppscopeAuthenticationMethod {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *InputAppscope) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputAppscope) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputAppscope) GetPort() *float64 {
	if o == nil {
		return nil
	}
	return o.Port
}

func (o *InputAppscope) GetTLS() *InputAppscopeTLSSettingsServerSide {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputAppscope) GetUnixSocketPath() *string {
	if o == nil {
		return nil
	}
	return o.UnixSocketPath
}

func (o *InputAppscope) GetUnixSocketPerms() *string {
	if o == nil {
		return nil
	}
	return o.UnixSocketPerms
}

func (o *InputAppscope) GetAuthToken() *string {
	if o == nil {
		return nil
	}
	return o.AuthToken
}

func (o *InputAppscope) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *InputAppscope) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputTCPType string

const (
	InputTCPTypeTCP InputTCPType = "tcp"
)

func (e InputTCPType) ToPointer() *InputTCPType {
	return &e
}
func (e *InputTCPType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "tcp":
		*e = InputTCPType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputTCPType: %v", v)
	}
}

type InputTCPConnections struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *InputTCPConnections) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputTCPConnections) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// InputTCPMode - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputTCPMode string

const (
	InputTCPModeSmart  InputTCPMode = "smart"
	InputTCPModeAlways InputTCPMode = "always"
)

func (e InputTCPMode) ToPointer() *InputTCPMode {
	return &e
}
func (e *InputTCPMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputTCPMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputTCPMode: %v", v)
	}
}

// InputTCPCompression - Codec to use to compress the persisted data
type InputTCPCompression string

const (
	InputTCPCompressionNone InputTCPCompression = "none"
	InputTCPCompressionGzip InputTCPCompression = "gzip"
)

func (e InputTCPCompression) ToPointer() *InputTCPCompression {
	return &e
}
func (e *InputTCPCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputTCPCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputTCPCompression: %v", v)
	}
}

type InputTCPPq struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputTCPMode `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *InputTCPCompression `default:"none" json:"compress"`
}

func (i InputTCPPq) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputTCPPq) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputTCPPq) GetMode() *InputTCPMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputTCPPq) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputTCPPq) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *InputTCPPq) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *InputTCPPq) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *InputTCPPq) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *InputTCPPq) GetCompress() *InputTCPCompression {
	if o == nil {
		return nil
	}
	return o.Compress
}

// InputTCPMinimumTLSVersion - Minimum TLS version to accept from connections
type InputTCPMinimumTLSVersion string

const (
	InputTCPMinimumTLSVersionTlSv1  InputTCPMinimumTLSVersion = "TLSv1"
	InputTCPMinimumTLSVersionTlSv11 InputTCPMinimumTLSVersion = "TLSv1.1"
	InputTCPMinimumTLSVersionTlSv12 InputTCPMinimumTLSVersion = "TLSv1.2"
	InputTCPMinimumTLSVersionTlSv13 InputTCPMinimumTLSVersion = "TLSv1.3"
)

func (e InputTCPMinimumTLSVersion) ToPointer() *InputTCPMinimumTLSVersion {
	return &e
}
func (e *InputTCPMinimumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputTCPMinimumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputTCPMinimumTLSVersion: %v", v)
	}
}

// InputTCPMaximumTLSVersion - Maximum TLS version to accept from connections
type InputTCPMaximumTLSVersion string

const (
	InputTCPMaximumTLSVersionTlSv1  InputTCPMaximumTLSVersion = "TLSv1"
	InputTCPMaximumTLSVersionTlSv11 InputTCPMaximumTLSVersion = "TLSv1.1"
	InputTCPMaximumTLSVersionTlSv12 InputTCPMaximumTLSVersion = "TLSv1.2"
	InputTCPMaximumTLSVersionTlSv13 InputTCPMaximumTLSVersion = "TLSv1.3"
)

func (e InputTCPMaximumTLSVersion) ToPointer() *InputTCPMaximumTLSVersion {
	return &e
}
func (e *InputTCPMaximumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputTCPMaximumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputTCPMaximumTLSVersion: %v", v)
	}
}

type InputTCPTLSSettingsServerSide struct {
	Disabled *bool `default:"true" json:"disabled"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert        *bool `default:"false" json:"requestCert"`
	RejectUnauthorized any   `json:"rejectUnauthorized,omitempty"`
	CommonNameRegex    any   `json:"commonNameRegex,omitempty"`
	// Minimum TLS version to accept from connections
	MinVersion *InputTCPMinimumTLSVersion `json:"minVersion,omitempty"`
	// Maximum TLS version to accept from connections
	MaxVersion *InputTCPMaximumTLSVersion `json:"maxVersion,omitempty"`
}

func (i InputTCPTLSSettingsServerSide) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputTCPTLSSettingsServerSide) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputTCPTLSSettingsServerSide) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputTCPTLSSettingsServerSide) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *InputTCPTLSSettingsServerSide) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *InputTCPTLSSettingsServerSide) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *InputTCPTLSSettingsServerSide) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *InputTCPTLSSettingsServerSide) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *InputTCPTLSSettingsServerSide) GetRequestCert() *bool {
	if o == nil {
		return nil
	}
	return o.RequestCert
}

func (o *InputTCPTLSSettingsServerSide) GetRejectUnauthorized() any {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *InputTCPTLSSettingsServerSide) GetCommonNameRegex() any {
	if o == nil {
		return nil
	}
	return o.CommonNameRegex
}

func (o *InputTCPTLSSettingsServerSide) GetMinVersion() *InputTCPMinimumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *InputTCPTLSSettingsServerSide) GetMaxVersion() *InputTCPMaximumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

type InputTCPMetadata struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputTCPMetadata) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputTCPMetadata) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputTCPPreprocess struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Command to feed the data through (via stdin) and process its output (stdout)
	Command *string `json:"command,omitempty"`
	// Arguments to be added to the custom command
	Args []string `json:"args,omitempty"`
}

func (i InputTCPPreprocess) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputTCPPreprocess) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputTCPPreprocess) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputTCPPreprocess) GetCommand() *string {
	if o == nil {
		return nil
	}
	return o.Command
}

func (o *InputTCPPreprocess) GetArgs() []string {
	if o == nil {
		return nil
	}
	return o.Args
}

// InputTCPAuthenticationMethod - Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
type InputTCPAuthenticationMethod string

const (
	InputTCPAuthenticationMethodManual InputTCPAuthenticationMethod = "manual"
	InputTCPAuthenticationMethodSecret InputTCPAuthenticationMethod = "secret"
)

func (e InputTCPAuthenticationMethod) ToPointer() *InputTCPAuthenticationMethod {
	return &e
}
func (e *InputTCPAuthenticationMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "manual":
		fallthrough
	case "secret":
		*e = InputTCPAuthenticationMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputTCPAuthenticationMethod: %v", v)
	}
}

type InputTCP struct {
	Status *TFStatus `json:"status,omitempty"`
	// Unique ID for this input
	ID       *string       `json:"id,omitempty"`
	Type     *InputTCPType `json:"type,omitempty"`
	Disabled *bool         `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputTCPConnections `json:"connections,omitempty"`
	Pq          *InputTCPPq           `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port float64                        `json:"port"`
	TLS  *InputTCPTLSSettingsServerSide `json:"tls,omitempty"`
	// Regex matching IP addresses that are allowed to establish a connection
	IPWhitelistRegex *string `default:"/.*/" json:"ipWhitelistRegex"`
	// Maximum number of active connections allowed per Worker Process. Use 0 for unlimited.
	MaxActiveCxn *float64 `default:"1000" json:"maxActiveCxn"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. After this time, the connection will be closed. Leave at 0 for no inactive socket monitoring.
	SocketIdleTimeout *float64 `default:"0" json:"socketIdleTimeout"`
	// How long the server will wait after initiating a closure for a client to close its end of the connection. If the client doesn't close the connection within this time, the server will forcefully terminate the socket to prevent resource leaks and ensure efficient connection cleanup and system stability. Leave at 0 for no inactive socket monitoring.
	SocketEndingMaxWait *float64 `default:"30" json:"socketEndingMaxWait"`
	// The maximum duration a socket can remain open, even if active. This helps manage resources and mitigate issues caused by TCP pinning. Set to 0 to disable.
	SocketMaxLifespan *float64 `default:"0" json:"socketMaxLifespan"`
	// Enable if the connection is proxied by a device that supports proxy protocol v1 or v2
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Fields to add to events from this input
	Metadata []InputTCPMetadata `json:"metadata,omitempty"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitempty"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `default:"10000" json:"staleChannelFlushMs"`
	// Client will pass the header record with every new connection. The header can contain an authToken, and an object with a list of fields and values to add to every event. These fields can be used to simplify Event Breaker selection, routing, etc. Header has this format, and must be followed by a newline: { "authToken" : "myToken", "fields": { "field1": "value1", "field2": "value2" } }
	EnableHeader *bool               `default:"false" json:"enableHeader"`
	Preprocess   *InputTCPPreprocess `json:"preprocess,omitempty"`
	Description  *string             `json:"description,omitempty"`
	// Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
	AuthType *InputTCPAuthenticationMethod `default:"manual" json:"authType"`
}

func (i InputTCP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputTCP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputTCP) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

func (o *InputTCP) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputTCP) GetType() *InputTCPType {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputTCP) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputTCP) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputTCP) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputTCP) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputTCP) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputTCP) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputTCP) GetConnections() []InputTCPConnections {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputTCP) GetPq() *InputTCPPq {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputTCP) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputTCP) GetPort() float64 {
	if o == nil {
		return 0.0
	}
	return o.Port
}

func (o *InputTCP) GetTLS() *InputTCPTLSSettingsServerSide {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputTCP) GetIPWhitelistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPWhitelistRegex
}

func (o *InputTCP) GetMaxActiveCxn() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxActiveCxn
}

func (o *InputTCP) GetSocketIdleTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketIdleTimeout
}

func (o *InputTCP) GetSocketEndingMaxWait() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketEndingMaxWait
}

func (o *InputTCP) GetSocketMaxLifespan() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketMaxLifespan
}

func (o *InputTCP) GetEnableProxyHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableProxyHeader
}

func (o *InputTCP) GetMetadata() []InputTCPMetadata {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputTCP) GetBreakerRulesets() []string {
	if o == nil {
		return nil
	}
	return o.BreakerRulesets
}

func (o *InputTCP) GetStaleChannelFlushMs() *float64 {
	if o == nil {
		return nil
	}
	return o.StaleChannelFlushMs
}

func (o *InputTCP) GetEnableHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableHeader
}

func (o *InputTCP) GetPreprocess() *InputTCPPreprocess {
	if o == nil {
		return nil
	}
	return o.Preprocess
}

func (o *InputTCP) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputTCP) GetAuthType() *InputTCPAuthenticationMethod {
	if o == nil {
		return nil
	}
	return o.AuthType
}

type InputFileType string

const (
	InputFileTypeFile InputFileType = "file"
)

func (e InputFileType) ToPointer() *InputFileType {
	return &e
}
func (e *InputFileType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "file":
		*e = InputFileType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputFileType: %v", v)
	}
}

type InputFileConnections struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *InputFileConnections) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputFileConnections) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// InputFileInputMode - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputFileInputMode string

const (
	InputFileInputModeSmart  InputFileInputMode = "smart"
	InputFileInputModeAlways InputFileInputMode = "always"
)

func (e InputFileInputMode) ToPointer() *InputFileInputMode {
	return &e
}
func (e *InputFileInputMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputFileInputMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputFileInputMode: %v", v)
	}
}

// InputFileCompression - Codec to use to compress the persisted data
type InputFileCompression string

const (
	InputFileCompressionNone InputFileCompression = "none"
	InputFileCompressionGzip InputFileCompression = "gzip"
)

func (e InputFileCompression) ToPointer() *InputFileCompression {
	return &e
}
func (e *InputFileCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputFileCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputFileCompression: %v", v)
	}
}

type InputFilePq struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputFileInputMode `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *InputFileCompression `default:"none" json:"compress"`
}

func (i InputFilePq) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputFilePq) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputFilePq) GetMode() *InputFileInputMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputFilePq) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputFilePq) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *InputFilePq) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *InputFilePq) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *InputFilePq) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *InputFilePq) GetCompress() *InputFileCompression {
	if o == nil {
		return nil
	}
	return o.Compress
}

// InputFileMode - Choose how to discover files to monitor
type InputFileMode string

const (
	InputFileModeAuto   InputFileMode = "auto"
	InputFileModeManual InputFileMode = "manual"
)

func (e InputFileMode) ToPointer() *InputFileMode {
	return &e
}
func (e *InputFileMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "auto":
		fallthrough
	case "manual":
		*e = InputFileMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputFileMode: %v", v)
	}
}

type InputFileMetadata struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputFileMetadata) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputFileMetadata) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputFile struct {
	// Unique ID for this input
	ID       string        `json:"id"`
	Type     InputFileType `json:"type"`
	Disabled *bool         `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputFileConnections `json:"connections,omitempty"`
	Pq          *InputFilePq           `json:"pq,omitempty"`
	// Choose how to discover files to monitor
	Mode *InputFileMode `default:"auto" json:"mode"`
	// Time, in seconds, between scanning for files
	Interval *float64 `default:"10" json:"interval"`
	// The full path of discovered files are matched against this wildcard list
	Filenames []string `json:"filenames,omitempty"`
	// Read only new entries at the end of all files discovered at next startup. @{product} will then read newly discovered files from the head. Disable this to resume reading all files from head.
	TailOnly *bool `default:"false" json:"tailOnly"`
	// Time, in seconds, before an idle file is closed
	IdleTimeout *float64 `default:"300" json:"idleTimeout"`
	// The maximum age of files to monitor. Format examples: 60s, 4h, 3d, 1w. Age is relative to file modification time. Leave empty to apply no age filters.
	MaxAgeDur *string `json:"maxAgeDur,omitempty"`
	// Skip files with modification times earlier than the maximum age duration
	CheckFileModTime *bool `default:"false" json:"checkFileModTime"`
	// Forces files containing binary data to be streamed as text
	ForceText *bool `default:"false" json:"forceText"`
	// Length of file header bytes to use in hash for unique file identification
	HashLen *float64 `default:"256" json:"hashLen"`
	// Fields to add to events from this input
	Metadata []InputFileMetadata `json:"metadata,omitempty"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitempty"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `default:"10000" json:"staleChannelFlushMs"`
	Description         *string  `json:"description,omitempty"`
	// Directory path to search for files. Environment variables will be resolved, e.g. $CRIBL_HOME/log/.
	Path *string `json:"path,omitempty"`
	// Set how many subdirectories deep to search. Use 0 to search only files in the given path, 1 to also look in its immediate subdirectories, etc. Leave it empty for unlimited depth.
	Depth                     *float64 `json:"depth,omitempty"`
	SuppressMissingPathErrors *bool    `default:"false" json:"suppressMissingPathErrors"`
	// Delete files after they have been collected
	DeleteFiles *bool `default:"false" json:"deleteFiles"`
	// Stream binary files as Base64-encoded chunks.
	IncludeUnidentifiableBinary *bool     `default:"false" json:"includeUnidentifiableBinary"`
	Status                      *TFStatus `json:"status,omitempty"`
}

func (i InputFile) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputFile) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputFile) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *InputFile) GetType() InputFileType {
	if o == nil {
		return InputFileType("")
	}
	return o.Type
}

func (o *InputFile) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputFile) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputFile) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputFile) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputFile) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputFile) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputFile) GetConnections() []InputFileConnections {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputFile) GetPq() *InputFilePq {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputFile) GetMode() *InputFileMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputFile) GetInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.Interval
}

func (o *InputFile) GetFilenames() []string {
	if o == nil {
		return nil
	}
	return o.Filenames
}

func (o *InputFile) GetTailOnly() *bool {
	if o == nil {
		return nil
	}
	return o.TailOnly
}

func (o *InputFile) GetIdleTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.IdleTimeout
}

func (o *InputFile) GetMaxAgeDur() *string {
	if o == nil {
		return nil
	}
	return o.MaxAgeDur
}

func (o *InputFile) GetCheckFileModTime() *bool {
	if o == nil {
		return nil
	}
	return o.CheckFileModTime
}

func (o *InputFile) GetForceText() *bool {
	if o == nil {
		return nil
	}
	return o.ForceText
}

func (o *InputFile) GetHashLen() *float64 {
	if o == nil {
		return nil
	}
	return o.HashLen
}

func (o *InputFile) GetMetadata() []InputFileMetadata {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputFile) GetBreakerRulesets() []string {
	if o == nil {
		return nil
	}
	return o.BreakerRulesets
}

func (o *InputFile) GetStaleChannelFlushMs() *float64 {
	if o == nil {
		return nil
	}
	return o.StaleChannelFlushMs
}

func (o *InputFile) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputFile) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *InputFile) GetDepth() *float64 {
	if o == nil {
		return nil
	}
	return o.Depth
}

func (o *InputFile) GetSuppressMissingPathErrors() *bool {
	if o == nil {
		return nil
	}
	return o.SuppressMissingPathErrors
}

func (o *InputFile) GetDeleteFiles() *bool {
	if o == nil {
		return nil
	}
	return o.DeleteFiles
}

func (o *InputFile) GetIncludeUnidentifiableBinary() *bool {
	if o == nil {
		return nil
	}
	return o.IncludeUnidentifiableBinary
}

func (o *InputFile) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputInputSyslogType string

const (
	InputInputSyslogTypeSyslog InputInputSyslogType = "syslog"
)

func (e InputInputSyslogType) ToPointer() *InputInputSyslogType {
	return &e
}
func (e *InputInputSyslogType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "syslog":
		*e = InputInputSyslogType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputInputSyslogType: %v", v)
	}
}

type InputInputSyslogConnections struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *InputInputSyslogConnections) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputInputSyslogConnections) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// InputInputSyslogMode - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputInputSyslogMode string

const (
	InputInputSyslogModeSmart  InputInputSyslogMode = "smart"
	InputInputSyslogModeAlways InputInputSyslogMode = "always"
)

func (e InputInputSyslogMode) ToPointer() *InputInputSyslogMode {
	return &e
}
func (e *InputInputSyslogMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputInputSyslogMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputInputSyslogMode: %v", v)
	}
}

// InputInputSyslogCompression - Codec to use to compress the persisted data
type InputInputSyslogCompression string

const (
	InputInputSyslogCompressionNone InputInputSyslogCompression = "none"
	InputInputSyslogCompressionGzip InputInputSyslogCompression = "gzip"
)

func (e InputInputSyslogCompression) ToPointer() *InputInputSyslogCompression {
	return &e
}
func (e *InputInputSyslogCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputInputSyslogCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputInputSyslogCompression: %v", v)
	}
}

type InputInputSyslogPq struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputInputSyslogMode `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *InputInputSyslogCompression `default:"none" json:"compress"`
}

func (i InputInputSyslogPq) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputInputSyslogPq) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputInputSyslogPq) GetMode() *InputInputSyslogMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputInputSyslogPq) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputInputSyslogPq) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *InputInputSyslogPq) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *InputInputSyslogPq) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *InputInputSyslogPq) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *InputInputSyslogPq) GetCompress() *InputInputSyslogCompression {
	if o == nil {
		return nil
	}
	return o.Compress
}

// InputInputSyslogMinimumTLSVersion - Minimum TLS version to accept from connections
type InputInputSyslogMinimumTLSVersion string

const (
	InputInputSyslogMinimumTLSVersionTlSv1  InputInputSyslogMinimumTLSVersion = "TLSv1"
	InputInputSyslogMinimumTLSVersionTlSv11 InputInputSyslogMinimumTLSVersion = "TLSv1.1"
	InputInputSyslogMinimumTLSVersionTlSv12 InputInputSyslogMinimumTLSVersion = "TLSv1.2"
	InputInputSyslogMinimumTLSVersionTlSv13 InputInputSyslogMinimumTLSVersion = "TLSv1.3"
)

func (e InputInputSyslogMinimumTLSVersion) ToPointer() *InputInputSyslogMinimumTLSVersion {
	return &e
}
func (e *InputInputSyslogMinimumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputInputSyslogMinimumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputInputSyslogMinimumTLSVersion: %v", v)
	}
}

// InputInputSyslogMaximumTLSVersion - Maximum TLS version to accept from connections
type InputInputSyslogMaximumTLSVersion string

const (
	InputInputSyslogMaximumTLSVersionTlSv1  InputInputSyslogMaximumTLSVersion = "TLSv1"
	InputInputSyslogMaximumTLSVersionTlSv11 InputInputSyslogMaximumTLSVersion = "TLSv1.1"
	InputInputSyslogMaximumTLSVersionTlSv12 InputInputSyslogMaximumTLSVersion = "TLSv1.2"
	InputInputSyslogMaximumTLSVersionTlSv13 InputInputSyslogMaximumTLSVersion = "TLSv1.3"
)

func (e InputInputSyslogMaximumTLSVersion) ToPointer() *InputInputSyslogMaximumTLSVersion {
	return &e
}
func (e *InputInputSyslogMaximumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputInputSyslogMaximumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputInputSyslogMaximumTLSVersion: %v", v)
	}
}

type InputInputSyslogTLSSettingsServerSide struct {
	Disabled *bool `default:"true" json:"disabled"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert        *bool `default:"false" json:"requestCert"`
	RejectUnauthorized any   `json:"rejectUnauthorized,omitempty"`
	CommonNameRegex    any   `json:"commonNameRegex,omitempty"`
	// Minimum TLS version to accept from connections
	MinVersion *InputInputSyslogMinimumTLSVersion `json:"minVersion,omitempty"`
	// Maximum TLS version to accept from connections
	MaxVersion *InputInputSyslogMaximumTLSVersion `json:"maxVersion,omitempty"`
}

func (i InputInputSyslogTLSSettingsServerSide) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputInputSyslogTLSSettingsServerSide) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputInputSyslogTLSSettingsServerSide) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputInputSyslogTLSSettingsServerSide) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *InputInputSyslogTLSSettingsServerSide) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *InputInputSyslogTLSSettingsServerSide) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *InputInputSyslogTLSSettingsServerSide) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *InputInputSyslogTLSSettingsServerSide) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *InputInputSyslogTLSSettingsServerSide) GetRequestCert() *bool {
	if o == nil {
		return nil
	}
	return o.RequestCert
}

func (o *InputInputSyslogTLSSettingsServerSide) GetRejectUnauthorized() any {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *InputInputSyslogTLSSettingsServerSide) GetCommonNameRegex() any {
	if o == nil {
		return nil
	}
	return o.CommonNameRegex
}

func (o *InputInputSyslogTLSSettingsServerSide) GetMinVersion() *InputInputSyslogMinimumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *InputInputSyslogTLSSettingsServerSide) GetMaxVersion() *InputInputSyslogMaximumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

type InputInputSyslogMetadata struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputInputSyslogMetadata) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputInputSyslogMetadata) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputSyslog2 struct {
	// Unique ID for this input
	ID       *string              `json:"id,omitempty"`
	Type     InputInputSyslogType `json:"type"`
	Disabled *bool                `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputInputSyslogConnections `json:"connections,omitempty"`
	Pq          *InputInputSyslogPq           `json:"pq,omitempty"`
	// Address to bind on. For IPv4 (all addresses), use the default '0.0.0.0'. For IPv6, enter '::' (all addresses) or specify an IP address.
	Host *string `default:"0.0.0.0" json:"host"`
	// Enter UDP port number to listen on. Not required if listening on TCP.
	UDPPort *float64 `json:"udpPort,omitempty"`
	// Enter TCP port number to listen on. Not required if listening on UDP.
	TCPPort float64 `json:"tcpPort"`
	// Maximum number of events to buffer when downstream is blocking. Only applies to UDP.
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// Regex matching IP addresses that are allowed to send data
	IPWhitelistRegex *string `default:"/.*/" json:"ipWhitelistRegex"`
	// Timezone to assign to timestamps without timezone info
	TimestampTimezone *string `default:"local" json:"timestampTimezone"`
	// Treat UDP packet data received as full syslog message
	SingleMsgUDPPackets *bool `default:"false" json:"singleMsgUdpPackets"`
	// Enable if the connection is proxied by a device that supports Proxy Protocol V1 or V2
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Wildcard list of fields to keep from source data; * = ALL (default)
	KeepFieldsList []string `json:"keepFieldsList,omitempty"`
	// Enable if incoming messages use octet counting per RFC 6587.
	OctetCounting *bool `default:"false" json:"octetCounting"`
	// Enable if we should infer the syslog framing of the incoming messages.
	InferFraming *bool `default:"true" json:"inferFraming"`
	// Enable if we should infer octet counting only if the messages comply with RFC 5424.
	StrictlyInferOctetCounting *bool `default:"true" json:"strictlyInferOctetCounting"`
	// Enable if RFC 3164-formatted messages have hyphens in the app name portion of the TAG section. If disabled, only alphanumeric characters and underscores are allowed. Ignored for RFC 5424-formatted messages.
	AllowNonStandardAppName *bool `default:"false" json:"allowNonStandardAppName"`
	// Maximum number of active connections allowed per Worker Process for TCP connections. Use 0 for unlimited.
	MaxActiveCxn *float64 `default:"1000" json:"maxActiveCxn"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. After this time, the connection will be closed. Leave at 0 for no inactive socket monitoring.
	SocketIdleTimeout *float64 `default:"0" json:"socketIdleTimeout"`
	// How long the server will wait after initiating a closure for a client to close its end of the connection. If the client doesn't close the connection within this time, the server will forcefully terminate the socket to prevent resource leaks and ensure efficient connection cleanup and system stability. Leave at 0 for no inactive socket monitoring.
	SocketEndingMaxWait *float64 `default:"30" json:"socketEndingMaxWait"`
	// The maximum duration a socket can remain open, even if active. This helps manage resources and mitigate issues caused by TCP pinning. Set to 0 to disable.
	SocketMaxLifespan *float64                               `default:"0" json:"socketMaxLifespan"`
	TLS               *InputInputSyslogTLSSettingsServerSide `json:"tls,omitempty"`
	// Fields to add to events from this input
	Metadata []InputInputSyslogMetadata `json:"metadata,omitempty"`
	// Optionally, set the SO_RCVBUF socket option for the UDP socket. This value tells the operating system how many bytes can be buffered in the kernel before events are dropped. Leave blank to use the OS default. Caution: Increasing this value will affect OS memory utilization.
	UDPSocketRxBufSize *float64 `json:"udpSocketRxBufSize,omitempty"`
	// Load balance traffic across all Worker Processes
	EnableLoadBalancing *bool     `default:"false" json:"enableLoadBalancing"`
	Description         *string   `json:"description,omitempty"`
	Status              *TFStatus `json:"status,omitempty"`
}

func (i InputSyslog2) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSyslog2) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputSyslog2) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputSyslog2) GetType() InputInputSyslogType {
	if o == nil {
		return InputInputSyslogType("")
	}
	return o.Type
}

func (o *InputSyslog2) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputSyslog2) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputSyslog2) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputSyslog2) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputSyslog2) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputSyslog2) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputSyslog2) GetConnections() []InputInputSyslogConnections {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputSyslog2) GetPq() *InputInputSyslogPq {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputSyslog2) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputSyslog2) GetUDPPort() *float64 {
	if o == nil {
		return nil
	}
	return o.UDPPort
}

func (o *InputSyslog2) GetTCPPort() float64 {
	if o == nil {
		return 0.0
	}
	return o.TCPPort
}

func (o *InputSyslog2) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputSyslog2) GetIPWhitelistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPWhitelistRegex
}

func (o *InputSyslog2) GetTimestampTimezone() *string {
	if o == nil {
		return nil
	}
	return o.TimestampTimezone
}

func (o *InputSyslog2) GetSingleMsgUDPPackets() *bool {
	if o == nil {
		return nil
	}
	return o.SingleMsgUDPPackets
}

func (o *InputSyslog2) GetEnableProxyHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableProxyHeader
}

func (o *InputSyslog2) GetKeepFieldsList() []string {
	if o == nil {
		return nil
	}
	return o.KeepFieldsList
}

func (o *InputSyslog2) GetOctetCounting() *bool {
	if o == nil {
		return nil
	}
	return o.OctetCounting
}

func (o *InputSyslog2) GetInferFraming() *bool {
	if o == nil {
		return nil
	}
	return o.InferFraming
}

func (o *InputSyslog2) GetStrictlyInferOctetCounting() *bool {
	if o == nil {
		return nil
	}
	return o.StrictlyInferOctetCounting
}

func (o *InputSyslog2) GetAllowNonStandardAppName() *bool {
	if o == nil {
		return nil
	}
	return o.AllowNonStandardAppName
}

func (o *InputSyslog2) GetMaxActiveCxn() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxActiveCxn
}

func (o *InputSyslog2) GetSocketIdleTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketIdleTimeout
}

func (o *InputSyslog2) GetSocketEndingMaxWait() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketEndingMaxWait
}

func (o *InputSyslog2) GetSocketMaxLifespan() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketMaxLifespan
}

func (o *InputSyslog2) GetTLS() *InputInputSyslogTLSSettingsServerSide {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputSyslog2) GetMetadata() []InputInputSyslogMetadata {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputSyslog2) GetUDPSocketRxBufSize() *float64 {
	if o == nil {
		return nil
	}
	return o.UDPSocketRxBufSize
}

func (o *InputSyslog2) GetEnableLoadBalancing() *bool {
	if o == nil {
		return nil
	}
	return o.EnableLoadBalancing
}

func (o *InputSyslog2) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputSyslog2) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputSyslogType string

const (
	InputSyslogTypeSyslog InputSyslogType = "syslog"
)

func (e InputSyslogType) ToPointer() *InputSyslogType {
	return &e
}
func (e *InputSyslogType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "syslog":
		*e = InputSyslogType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSyslogType: %v", v)
	}
}

type InputSyslogConnections struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *InputSyslogConnections) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputSyslogConnections) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// InputSyslogMode - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputSyslogMode string

const (
	InputSyslogModeSmart  InputSyslogMode = "smart"
	InputSyslogModeAlways InputSyslogMode = "always"
)

func (e InputSyslogMode) ToPointer() *InputSyslogMode {
	return &e
}
func (e *InputSyslogMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputSyslogMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSyslogMode: %v", v)
	}
}

// InputSyslogCompression - Codec to use to compress the persisted data
type InputSyslogCompression string

const (
	InputSyslogCompressionNone InputSyslogCompression = "none"
	InputSyslogCompressionGzip InputSyslogCompression = "gzip"
)

func (e InputSyslogCompression) ToPointer() *InputSyslogCompression {
	return &e
}
func (e *InputSyslogCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputSyslogCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSyslogCompression: %v", v)
	}
}

type InputSyslogPq struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputSyslogMode `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *InputSyslogCompression `default:"none" json:"compress"`
}

func (i InputSyslogPq) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSyslogPq) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputSyslogPq) GetMode() *InputSyslogMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputSyslogPq) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputSyslogPq) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *InputSyslogPq) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *InputSyslogPq) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *InputSyslogPq) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *InputSyslogPq) GetCompress() *InputSyslogCompression {
	if o == nil {
		return nil
	}
	return o.Compress
}

// InputSyslogMinimumTLSVersion - Minimum TLS version to accept from connections
type InputSyslogMinimumTLSVersion string

const (
	InputSyslogMinimumTLSVersionTlSv1  InputSyslogMinimumTLSVersion = "TLSv1"
	InputSyslogMinimumTLSVersionTlSv11 InputSyslogMinimumTLSVersion = "TLSv1.1"
	InputSyslogMinimumTLSVersionTlSv12 InputSyslogMinimumTLSVersion = "TLSv1.2"
	InputSyslogMinimumTLSVersionTlSv13 InputSyslogMinimumTLSVersion = "TLSv1.3"
)

func (e InputSyslogMinimumTLSVersion) ToPointer() *InputSyslogMinimumTLSVersion {
	return &e
}
func (e *InputSyslogMinimumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputSyslogMinimumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSyslogMinimumTLSVersion: %v", v)
	}
}

// InputSyslogMaximumTLSVersion - Maximum TLS version to accept from connections
type InputSyslogMaximumTLSVersion string

const (
	InputSyslogMaximumTLSVersionTlSv1  InputSyslogMaximumTLSVersion = "TLSv1"
	InputSyslogMaximumTLSVersionTlSv11 InputSyslogMaximumTLSVersion = "TLSv1.1"
	InputSyslogMaximumTLSVersionTlSv12 InputSyslogMaximumTLSVersion = "TLSv1.2"
	InputSyslogMaximumTLSVersionTlSv13 InputSyslogMaximumTLSVersion = "TLSv1.3"
)

func (e InputSyslogMaximumTLSVersion) ToPointer() *InputSyslogMaximumTLSVersion {
	return &e
}
func (e *InputSyslogMaximumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputSyslogMaximumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSyslogMaximumTLSVersion: %v", v)
	}
}

type InputSyslogTLSSettingsServerSide struct {
	Disabled *bool `default:"true" json:"disabled"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert        *bool `default:"false" json:"requestCert"`
	RejectUnauthorized any   `json:"rejectUnauthorized,omitempty"`
	CommonNameRegex    any   `json:"commonNameRegex,omitempty"`
	// Minimum TLS version to accept from connections
	MinVersion *InputSyslogMinimumTLSVersion `json:"minVersion,omitempty"`
	// Maximum TLS version to accept from connections
	MaxVersion *InputSyslogMaximumTLSVersion `json:"maxVersion,omitempty"`
}

func (i InputSyslogTLSSettingsServerSide) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSyslogTLSSettingsServerSide) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputSyslogTLSSettingsServerSide) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputSyslogTLSSettingsServerSide) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *InputSyslogTLSSettingsServerSide) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *InputSyslogTLSSettingsServerSide) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *InputSyslogTLSSettingsServerSide) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *InputSyslogTLSSettingsServerSide) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *InputSyslogTLSSettingsServerSide) GetRequestCert() *bool {
	if o == nil {
		return nil
	}
	return o.RequestCert
}

func (o *InputSyslogTLSSettingsServerSide) GetRejectUnauthorized() any {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *InputSyslogTLSSettingsServerSide) GetCommonNameRegex() any {
	if o == nil {
		return nil
	}
	return o.CommonNameRegex
}

func (o *InputSyslogTLSSettingsServerSide) GetMinVersion() *InputSyslogMinimumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *InputSyslogTLSSettingsServerSide) GetMaxVersion() *InputSyslogMaximumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

type InputSyslogMetadata struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputSyslogMetadata) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputSyslogMetadata) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputSyslog1 struct {
	// Unique ID for this input
	ID       *string         `json:"id,omitempty"`
	Type     InputSyslogType `json:"type"`
	Disabled *bool           `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputSyslogConnections `json:"connections,omitempty"`
	Pq          *InputSyslogPq           `json:"pq,omitempty"`
	// Address to bind on. For IPv4 (all addresses), use the default '0.0.0.0'. For IPv6, enter '::' (all addresses) or specify an IP address.
	Host *string `default:"0.0.0.0" json:"host"`
	// Enter UDP port number to listen on. Not required if listening on TCP.
	UDPPort float64 `json:"udpPort"`
	// Enter TCP port number to listen on. Not required if listening on UDP.
	TCPPort *float64 `json:"tcpPort,omitempty"`
	// Maximum number of events to buffer when downstream is blocking. Only applies to UDP.
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// Regex matching IP addresses that are allowed to send data
	IPWhitelistRegex *string `default:"/.*/" json:"ipWhitelistRegex"`
	// Timezone to assign to timestamps without timezone info
	TimestampTimezone *string `default:"local" json:"timestampTimezone"`
	// Treat UDP packet data received as full syslog message
	SingleMsgUDPPackets *bool `default:"false" json:"singleMsgUdpPackets"`
	// Enable if the connection is proxied by a device that supports Proxy Protocol V1 or V2
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Wildcard list of fields to keep from source data; * = ALL (default)
	KeepFieldsList []string `json:"keepFieldsList,omitempty"`
	// Enable if incoming messages use octet counting per RFC 6587.
	OctetCounting *bool `default:"false" json:"octetCounting"`
	// Enable if we should infer the syslog framing of the incoming messages.
	InferFraming *bool `default:"true" json:"inferFraming"`
	// Enable if we should infer octet counting only if the messages comply with RFC 5424.
	StrictlyInferOctetCounting *bool `default:"true" json:"strictlyInferOctetCounting"`
	// Enable if RFC 3164-formatted messages have hyphens in the app name portion of the TAG section. If disabled, only alphanumeric characters and underscores are allowed. Ignored for RFC 5424-formatted messages.
	AllowNonStandardAppName *bool `default:"false" json:"allowNonStandardAppName"`
	// Maximum number of active connections allowed per Worker Process for TCP connections. Use 0 for unlimited.
	MaxActiveCxn *float64 `default:"1000" json:"maxActiveCxn"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. After this time, the connection will be closed. Leave at 0 for no inactive socket monitoring.
	SocketIdleTimeout *float64 `default:"0" json:"socketIdleTimeout"`
	// How long the server will wait after initiating a closure for a client to close its end of the connection. If the client doesn't close the connection within this time, the server will forcefully terminate the socket to prevent resource leaks and ensure efficient connection cleanup and system stability. Leave at 0 for no inactive socket monitoring.
	SocketEndingMaxWait *float64 `default:"30" json:"socketEndingMaxWait"`
	// The maximum duration a socket can remain open, even if active. This helps manage resources and mitigate issues caused by TCP pinning. Set to 0 to disable.
	SocketMaxLifespan *float64                          `default:"0" json:"socketMaxLifespan"`
	TLS               *InputSyslogTLSSettingsServerSide `json:"tls,omitempty"`
	// Fields to add to events from this input
	Metadata []InputSyslogMetadata `json:"metadata,omitempty"`
	// Optionally, set the SO_RCVBUF socket option for the UDP socket. This value tells the operating system how many bytes can be buffered in the kernel before events are dropped. Leave blank to use the OS default. Caution: Increasing this value will affect OS memory utilization.
	UDPSocketRxBufSize *float64 `json:"udpSocketRxBufSize,omitempty"`
	// Load balance traffic across all Worker Processes
	EnableLoadBalancing *bool     `default:"false" json:"enableLoadBalancing"`
	Description         *string   `json:"description,omitempty"`
	Status              *TFStatus `json:"status,omitempty"`
}

func (i InputSyslog1) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSyslog1) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputSyslog1) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputSyslog1) GetType() InputSyslogType {
	if o == nil {
		return InputSyslogType("")
	}
	return o.Type
}

func (o *InputSyslog1) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputSyslog1) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputSyslog1) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputSyslog1) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputSyslog1) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputSyslog1) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputSyslog1) GetConnections() []InputSyslogConnections {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputSyslog1) GetPq() *InputSyslogPq {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputSyslog1) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputSyslog1) GetUDPPort() float64 {
	if o == nil {
		return 0.0
	}
	return o.UDPPort
}

func (o *InputSyslog1) GetTCPPort() *float64 {
	if o == nil {
		return nil
	}
	return o.TCPPort
}

func (o *InputSyslog1) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputSyslog1) GetIPWhitelistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPWhitelistRegex
}

func (o *InputSyslog1) GetTimestampTimezone() *string {
	if o == nil {
		return nil
	}
	return o.TimestampTimezone
}

func (o *InputSyslog1) GetSingleMsgUDPPackets() *bool {
	if o == nil {
		return nil
	}
	return o.SingleMsgUDPPackets
}

func (o *InputSyslog1) GetEnableProxyHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableProxyHeader
}

func (o *InputSyslog1) GetKeepFieldsList() []string {
	if o == nil {
		return nil
	}
	return o.KeepFieldsList
}

func (o *InputSyslog1) GetOctetCounting() *bool {
	if o == nil {
		return nil
	}
	return o.OctetCounting
}

func (o *InputSyslog1) GetInferFraming() *bool {
	if o == nil {
		return nil
	}
	return o.InferFraming
}

func (o *InputSyslog1) GetStrictlyInferOctetCounting() *bool {
	if o == nil {
		return nil
	}
	return o.StrictlyInferOctetCounting
}

func (o *InputSyslog1) GetAllowNonStandardAppName() *bool {
	if o == nil {
		return nil
	}
	return o.AllowNonStandardAppName
}

func (o *InputSyslog1) GetMaxActiveCxn() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxActiveCxn
}

func (o *InputSyslog1) GetSocketIdleTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketIdleTimeout
}

func (o *InputSyslog1) GetSocketEndingMaxWait() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketEndingMaxWait
}

func (o *InputSyslog1) GetSocketMaxLifespan() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketMaxLifespan
}

func (o *InputSyslog1) GetTLS() *InputSyslogTLSSettingsServerSide {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputSyslog1) GetMetadata() []InputSyslogMetadata {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputSyslog1) GetUDPSocketRxBufSize() *float64 {
	if o == nil {
		return nil
	}
	return o.UDPSocketRxBufSize
}

func (o *InputSyslog1) GetEnableLoadBalancing() *bool {
	if o == nil {
		return nil
	}
	return o.EnableLoadBalancing
}

func (o *InputSyslog1) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputSyslog1) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputSyslogUnionType string

const (
	InputSyslogUnionTypeInputSyslog1 InputSyslogUnionType = "InputSyslog_1"
	InputSyslogUnionTypeInputSyslog2 InputSyslogUnionType = "InputSyslog_2"
)

type InputSyslog struct {
	InputSyslog1 *InputSyslog1 `queryParam:"inline"`
	InputSyslog2 *InputSyslog2 `queryParam:"inline"`

	Type InputSyslogUnionType
}

func CreateInputSyslogInputSyslog1(inputSyslog1 InputSyslog1) InputSyslog {
	typ := InputSyslogUnionTypeInputSyslog1

	return InputSyslog{
		InputSyslog1: &inputSyslog1,
		Type:         typ,
	}
}

func CreateInputSyslogInputSyslog2(inputSyslog2 InputSyslog2) InputSyslog {
	typ := InputSyslogUnionTypeInputSyslog2

	return InputSyslog{
		InputSyslog2: &inputSyslog2,
		Type:         typ,
	}
}

func (u *InputSyslog) UnmarshalJSON(data []byte) error {

	var inputSyslog1 InputSyslog1 = InputSyslog1{}
	if err := utils.UnmarshalJSON(data, &inputSyslog1, "", true, true); err == nil {
		u.InputSyslog1 = &inputSyslog1
		u.Type = InputSyslogUnionTypeInputSyslog1
		return nil
	}

	var inputSyslog2 InputSyslog2 = InputSyslog2{}
	if err := utils.UnmarshalJSON(data, &inputSyslog2, "", true, true); err == nil {
		u.InputSyslog2 = &inputSyslog2
		u.Type = InputSyslogUnionTypeInputSyslog2
		return nil
	}

	return fmt.Errorf("could not unmarshal `%s` into any supported union types for InputSyslog", string(data))
}

func (u InputSyslog) MarshalJSON() ([]byte, error) {
	if u.InputSyslog1 != nil {
		return utils.MarshalJSON(u.InputSyslog1, "", true)
	}

	if u.InputSyslog2 != nil {
		return utils.MarshalJSON(u.InputSyslog2, "", true)
	}

	return nil, errors.New("could not marshal union type InputSyslog: all fields are null")
}

type InputSqsType string

const (
	InputSqsTypeSqs InputSqsType = "sqs"
)

func (e InputSqsType) ToPointer() *InputSqsType {
	return &e
}
func (e *InputSqsType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "sqs":
		*e = InputSqsType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSqsType: %v", v)
	}
}

type InputSqsConnections struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *InputSqsConnections) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputSqsConnections) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// InputSqsMode - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputSqsMode string

const (
	InputSqsModeSmart  InputSqsMode = "smart"
	InputSqsModeAlways InputSqsMode = "always"
)

func (e InputSqsMode) ToPointer() *InputSqsMode {
	return &e
}
func (e *InputSqsMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputSqsMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSqsMode: %v", v)
	}
}

// InputSqsCompression - Codec to use to compress the persisted data
type InputSqsCompression string

const (
	InputSqsCompressionNone InputSqsCompression = "none"
	InputSqsCompressionGzip InputSqsCompression = "gzip"
)

func (e InputSqsCompression) ToPointer() *InputSqsCompression {
	return &e
}
func (e *InputSqsCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputSqsCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSqsCompression: %v", v)
	}
}

type InputSqsPq struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputSqsMode `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *InputSqsCompression `default:"none" json:"compress"`
}

func (i InputSqsPq) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSqsPq) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputSqsPq) GetMode() *InputSqsMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputSqsPq) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputSqsPq) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *InputSqsPq) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *InputSqsPq) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *InputSqsPq) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *InputSqsPq) GetCompress() *InputSqsCompression {
	if o == nil {
		return nil
	}
	return o.Compress
}

// QueueType - The queue type used (or created). Defaults to Standard
type QueueType string

const (
	QueueTypeStandard QueueType = "standard"
	QueueTypeFifo     QueueType = "fifo"
)

func (e QueueType) ToPointer() *QueueType {
	return &e
}
func (e *QueueType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "standard":
		fallthrough
	case "fifo":
		*e = QueueType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for QueueType: %v", v)
	}
}

// InputSqsAuthenticationMethod - AWS authentication method. Choose Auto to use IAM roles.
type InputSqsAuthenticationMethod string

const (
	InputSqsAuthenticationMethodAuto   InputSqsAuthenticationMethod = "auto"
	InputSqsAuthenticationMethodManual InputSqsAuthenticationMethod = "manual"
	InputSqsAuthenticationMethodSecret InputSqsAuthenticationMethod = "secret"
)

func (e InputSqsAuthenticationMethod) ToPointer() *InputSqsAuthenticationMethod {
	return &e
}
func (e *InputSqsAuthenticationMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "auto":
		fallthrough
	case "manual":
		fallthrough
	case "secret":
		*e = InputSqsAuthenticationMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSqsAuthenticationMethod: %v", v)
	}
}

// InputSqsSignatureVersion - Signature version to use for signing SQS requests
type InputSqsSignatureVersion string

const (
	InputSqsSignatureVersionV2 InputSqsSignatureVersion = "v2"
	InputSqsSignatureVersionV4 InputSqsSignatureVersion = "v4"
)

func (e InputSqsSignatureVersion) ToPointer() *InputSqsSignatureVersion {
	return &e
}
func (e *InputSqsSignatureVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "v2":
		fallthrough
	case "v4":
		*e = InputSqsSignatureVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSqsSignatureVersion: %v", v)
	}
}

type InputSqsMetadata struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputSqsMetadata) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputSqsMetadata) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputSqs struct {
	// Unique ID for this input
	ID       *string       `json:"id,omitempty"`
	Type     *InputSqsType `json:"type,omitempty"`
	Disabled *bool         `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputSqsConnections `json:"connections,omitempty"`
	Pq          *InputSqsPq           `json:"pq,omitempty"`
	// The name, URL, or ARN of the SQS queue to read events from. When a non-AWS URL is specified, format must be: '{url}/myQueueName'. Example: 'https://host:port/myQueueName'. Value must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can only be evaluated at init time. Example referencing a Global Variable: `https://host:port/myQueue-${C.vars.myVar}`.
	QueueName string `json:"queueName"`
	// The queue type used (or created). Defaults to Standard
	QueueType *QueueType `default:"standard" json:"queueType"`
	// SQS queue owner's AWS account ID. Leave empty if SQS queue is in same AWS account.
	AwsAccountID *string `json:"awsAccountId,omitempty"`
	// Create queue if it does not exist.
	CreateQueue *bool `default:"false" json:"createQueue"`
	// AWS authentication method. Choose Auto to use IAM roles.
	AwsAuthenticationMethod *InputSqsAuthenticationMethod `default:"auto" json:"awsAuthenticationMethod"`
	AwsSecretKey            *string                       `json:"awsSecretKey,omitempty"`
	// AWS Region where the SQS queue is located. Required, unless the Queue entry is a URL or ARN that includes a Region.
	Region *string `json:"region,omitempty"`
	// SQS service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to SQS-compatible endpoint.
	Endpoint *string `json:"endpoint,omitempty"`
	// Signature version to use for signing SQS requests
	SignatureVersion *InputSqsSignatureVersion `default:"v4" json:"signatureVersion"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `default:"true" json:"reuseConnections"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Use Assume Role credentials to access SQS
	EnableAssumeRole *bool `default:"false" json:"enableAssumeRole"`
	// Amazon Resource Name (ARN) of the role to assume
	AssumeRoleArn *string `json:"assumeRoleArn,omitempty"`
	// External ID to use when assuming role
	AssumeRoleExternalID *string `json:"assumeRoleExternalId,omitempty"`
	// Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
	DurationSeconds *float64 `default:"3600" json:"durationSeconds"`
	// The maximum number of messages SQS should return in a poll request. Amazon SQS never returns more messages than this value (however, fewer messages might be returned). Valid values: 1 to 10.
	MaxMessages *float64 `default:"10" json:"maxMessages"`
	// After messages are retrieved by a ReceiveMessage request, @{product} will hide them from subsequent retrieve requests for at least this duration. You can set this as high as 43200 sec. (12 hours).
	VisibilityTimeout *float64 `default:"600" json:"visibilityTimeout"`
	// Fields to add to events from this input
	Metadata []InputSqsMetadata `json:"metadata,omitempty"`
	// How long to wait for events before trying polling again. The lower the number the higher the AWS bill. The higher the number the longer it will take for the source to react to configuration changes and system restarts.
	PollTimeout *float64 `default:"10" json:"pollTimeout"`
	Description *string  `json:"description,omitempty"`
	AwsAPIKey   *string  `json:"awsApiKey,omitempty"`
	// Select or create a stored secret that references your access key and secret key
	AwsSecret *string `json:"awsSecret,omitempty"`
	// How many receiver processes to run. The higher the number, the better the throughput - at the expense of CPU overhead.
	NumReceivers *float64  `default:"3" json:"numReceivers"`
	Status       *TFStatus `json:"status,omitempty"`
}

func (i InputSqs) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSqs) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputSqs) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputSqs) GetType() *InputSqsType {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputSqs) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputSqs) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputSqs) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputSqs) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputSqs) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputSqs) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputSqs) GetConnections() []InputSqsConnections {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputSqs) GetPq() *InputSqsPq {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputSqs) GetQueueName() string {
	if o == nil {
		return ""
	}
	return o.QueueName
}

func (o *InputSqs) GetQueueType() *QueueType {
	if o == nil {
		return nil
	}
	return o.QueueType
}

func (o *InputSqs) GetAwsAccountID() *string {
	if o == nil {
		return nil
	}
	return o.AwsAccountID
}

func (o *InputSqs) GetCreateQueue() *bool {
	if o == nil {
		return nil
	}
	return o.CreateQueue
}

func (o *InputSqs) GetAwsAuthenticationMethod() *InputSqsAuthenticationMethod {
	if o == nil {
		return nil
	}
	return o.AwsAuthenticationMethod
}

func (o *InputSqs) GetAwsSecretKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecretKey
}

func (o *InputSqs) GetRegion() *string {
	if o == nil {
		return nil
	}
	return o.Region
}

func (o *InputSqs) GetEndpoint() *string {
	if o == nil {
		return nil
	}
	return o.Endpoint
}

func (o *InputSqs) GetSignatureVersion() *InputSqsSignatureVersion {
	if o == nil {
		return nil
	}
	return o.SignatureVersion
}

func (o *InputSqs) GetReuseConnections() *bool {
	if o == nil {
		return nil
	}
	return o.ReuseConnections
}

func (o *InputSqs) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *InputSqs) GetEnableAssumeRole() *bool {
	if o == nil {
		return nil
	}
	return o.EnableAssumeRole
}

func (o *InputSqs) GetAssumeRoleArn() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleArn
}

func (o *InputSqs) GetAssumeRoleExternalID() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleExternalID
}

func (o *InputSqs) GetDurationSeconds() *float64 {
	if o == nil {
		return nil
	}
	return o.DurationSeconds
}

func (o *InputSqs) GetMaxMessages() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxMessages
}

func (o *InputSqs) GetVisibilityTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.VisibilityTimeout
}

func (o *InputSqs) GetMetadata() []InputSqsMetadata {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputSqs) GetPollTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.PollTimeout
}

func (o *InputSqs) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputSqs) GetAwsAPIKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsAPIKey
}

func (o *InputSqs) GetAwsSecret() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecret
}

func (o *InputSqs) GetNumReceivers() *float64 {
	if o == nil {
		return nil
	}
	return o.NumReceivers
}

func (o *InputSqs) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputModelDrivenTelemetryType string

const (
	InputModelDrivenTelemetryTypeModelDrivenTelemetry InputModelDrivenTelemetryType = "model_driven_telemetry"
)

func (e InputModelDrivenTelemetryType) ToPointer() *InputModelDrivenTelemetryType {
	return &e
}
func (e *InputModelDrivenTelemetryType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "model_driven_telemetry":
		*e = InputModelDrivenTelemetryType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputModelDrivenTelemetryType: %v", v)
	}
}

type InputModelDrivenTelemetryConnections struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *InputModelDrivenTelemetryConnections) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputModelDrivenTelemetryConnections) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// InputModelDrivenTelemetryMode - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputModelDrivenTelemetryMode string

const (
	InputModelDrivenTelemetryModeSmart  InputModelDrivenTelemetryMode = "smart"
	InputModelDrivenTelemetryModeAlways InputModelDrivenTelemetryMode = "always"
)

func (e InputModelDrivenTelemetryMode) ToPointer() *InputModelDrivenTelemetryMode {
	return &e
}
func (e *InputModelDrivenTelemetryMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputModelDrivenTelemetryMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputModelDrivenTelemetryMode: %v", v)
	}
}

// InputModelDrivenTelemetryCompression - Codec to use to compress the persisted data
type InputModelDrivenTelemetryCompression string

const (
	InputModelDrivenTelemetryCompressionNone InputModelDrivenTelemetryCompression = "none"
	InputModelDrivenTelemetryCompressionGzip InputModelDrivenTelemetryCompression = "gzip"
)

func (e InputModelDrivenTelemetryCompression) ToPointer() *InputModelDrivenTelemetryCompression {
	return &e
}
func (e *InputModelDrivenTelemetryCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputModelDrivenTelemetryCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputModelDrivenTelemetryCompression: %v", v)
	}
}

type InputModelDrivenTelemetryPq struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputModelDrivenTelemetryMode `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *InputModelDrivenTelemetryCompression `default:"none" json:"compress"`
}

func (i InputModelDrivenTelemetryPq) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputModelDrivenTelemetryPq) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputModelDrivenTelemetryPq) GetMode() *InputModelDrivenTelemetryMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputModelDrivenTelemetryPq) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputModelDrivenTelemetryPq) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *InputModelDrivenTelemetryPq) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *InputModelDrivenTelemetryPq) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *InputModelDrivenTelemetryPq) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *InputModelDrivenTelemetryPq) GetCompress() *InputModelDrivenTelemetryCompression {
	if o == nil {
		return nil
	}
	return o.Compress
}

// InputModelDrivenTelemetryMinimumTLSVersion - Minimum TLS version to accept from connections
type InputModelDrivenTelemetryMinimumTLSVersion string

const (
	InputModelDrivenTelemetryMinimumTLSVersionTlSv1  InputModelDrivenTelemetryMinimumTLSVersion = "TLSv1"
	InputModelDrivenTelemetryMinimumTLSVersionTlSv11 InputModelDrivenTelemetryMinimumTLSVersion = "TLSv1.1"
	InputModelDrivenTelemetryMinimumTLSVersionTlSv12 InputModelDrivenTelemetryMinimumTLSVersion = "TLSv1.2"
	InputModelDrivenTelemetryMinimumTLSVersionTlSv13 InputModelDrivenTelemetryMinimumTLSVersion = "TLSv1.3"
)

func (e InputModelDrivenTelemetryMinimumTLSVersion) ToPointer() *InputModelDrivenTelemetryMinimumTLSVersion {
	return &e
}
func (e *InputModelDrivenTelemetryMinimumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputModelDrivenTelemetryMinimumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputModelDrivenTelemetryMinimumTLSVersion: %v", v)
	}
}

// InputModelDrivenTelemetryMaximumTLSVersion - Maximum TLS version to accept from connections
type InputModelDrivenTelemetryMaximumTLSVersion string

const (
	InputModelDrivenTelemetryMaximumTLSVersionTlSv1  InputModelDrivenTelemetryMaximumTLSVersion = "TLSv1"
	InputModelDrivenTelemetryMaximumTLSVersionTlSv11 InputModelDrivenTelemetryMaximumTLSVersion = "TLSv1.1"
	InputModelDrivenTelemetryMaximumTLSVersionTlSv12 InputModelDrivenTelemetryMaximumTLSVersion = "TLSv1.2"
	InputModelDrivenTelemetryMaximumTLSVersionTlSv13 InputModelDrivenTelemetryMaximumTLSVersion = "TLSv1.3"
)

func (e InputModelDrivenTelemetryMaximumTLSVersion) ToPointer() *InputModelDrivenTelemetryMaximumTLSVersion {
	return &e
}
func (e *InputModelDrivenTelemetryMaximumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputModelDrivenTelemetryMaximumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputModelDrivenTelemetryMaximumTLSVersion: %v", v)
	}
}

type InputModelDrivenTelemetryTLSSettingsServerSide struct {
	Disabled *bool `default:"true" json:"disabled"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert        *bool `default:"false" json:"requestCert"`
	RejectUnauthorized any   `json:"rejectUnauthorized,omitempty"`
	CommonNameRegex    any   `json:"commonNameRegex,omitempty"`
	// Minimum TLS version to accept from connections
	MinVersion *InputModelDrivenTelemetryMinimumTLSVersion `json:"minVersion,omitempty"`
	// Maximum TLS version to accept from connections
	MaxVersion *InputModelDrivenTelemetryMaximumTLSVersion `json:"maxVersion,omitempty"`
}

func (i InputModelDrivenTelemetryTLSSettingsServerSide) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputModelDrivenTelemetryTLSSettingsServerSide) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputModelDrivenTelemetryTLSSettingsServerSide) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputModelDrivenTelemetryTLSSettingsServerSide) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *InputModelDrivenTelemetryTLSSettingsServerSide) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *InputModelDrivenTelemetryTLSSettingsServerSide) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *InputModelDrivenTelemetryTLSSettingsServerSide) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *InputModelDrivenTelemetryTLSSettingsServerSide) GetRequestCert() *bool {
	if o == nil {
		return nil
	}
	return o.RequestCert
}

func (o *InputModelDrivenTelemetryTLSSettingsServerSide) GetRejectUnauthorized() any {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *InputModelDrivenTelemetryTLSSettingsServerSide) GetCommonNameRegex() any {
	if o == nil {
		return nil
	}
	return o.CommonNameRegex
}

func (o *InputModelDrivenTelemetryTLSSettingsServerSide) GetMinVersion() *InputModelDrivenTelemetryMinimumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *InputModelDrivenTelemetryTLSSettingsServerSide) GetMaxVersion() *InputModelDrivenTelemetryMaximumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

type InputModelDrivenTelemetryMetadata struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputModelDrivenTelemetryMetadata) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputModelDrivenTelemetryMetadata) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputModelDrivenTelemetry struct {
	// Unique ID for this input
	ID       *string                        `json:"id,omitempty"`
	Type     *InputModelDrivenTelemetryType `json:"type,omitempty"`
	Disabled *bool                          `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputModelDrivenTelemetryConnections `json:"connections,omitempty"`
	Pq          *InputModelDrivenTelemetryPq           `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port *float64                                        `default:"57000" json:"port"`
	TLS  *InputModelDrivenTelemetryTLSSettingsServerSide `json:"tls,omitempty"`
	// Fields to add to events from this input
	Metadata []InputModelDrivenTelemetryMetadata `json:"metadata,omitempty"`
	// Maximum number of active connections allowed per Worker Process. Use 0 for unlimited.
	MaxActiveCxn *float64 `default:"1000" json:"maxActiveCxn"`
	// Time in milliseconds to allow the server to shutdown gracefully before forcing shutdown. Defaults to 5000.
	ShutdownTimeoutMs *float64  `default:"5000" json:"shutdownTimeoutMs"`
	Description       *string   `json:"description,omitempty"`
	Status            *TFStatus `json:"status,omitempty"`
}

func (i InputModelDrivenTelemetry) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputModelDrivenTelemetry) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputModelDrivenTelemetry) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputModelDrivenTelemetry) GetType() *InputModelDrivenTelemetryType {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputModelDrivenTelemetry) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputModelDrivenTelemetry) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputModelDrivenTelemetry) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputModelDrivenTelemetry) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputModelDrivenTelemetry) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputModelDrivenTelemetry) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputModelDrivenTelemetry) GetConnections() []InputModelDrivenTelemetryConnections {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputModelDrivenTelemetry) GetPq() *InputModelDrivenTelemetryPq {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputModelDrivenTelemetry) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputModelDrivenTelemetry) GetPort() *float64 {
	if o == nil {
		return nil
	}
	return o.Port
}

func (o *InputModelDrivenTelemetry) GetTLS() *InputModelDrivenTelemetryTLSSettingsServerSide {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputModelDrivenTelemetry) GetMetadata() []InputModelDrivenTelemetryMetadata {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputModelDrivenTelemetry) GetMaxActiveCxn() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxActiveCxn
}

func (o *InputModelDrivenTelemetry) GetShutdownTimeoutMs() *float64 {
	if o == nil {
		return nil
	}
	return o.ShutdownTimeoutMs
}

func (o *InputModelDrivenTelemetry) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputModelDrivenTelemetry) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputOpenTelemetryType string

const (
	InputOpenTelemetryTypeOpenTelemetry InputOpenTelemetryType = "open_telemetry"
)

func (e InputOpenTelemetryType) ToPointer() *InputOpenTelemetryType {
	return &e
}
func (e *InputOpenTelemetryType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "open_telemetry":
		*e = InputOpenTelemetryType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputOpenTelemetryType: %v", v)
	}
}

type InputOpenTelemetryConnections struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *InputOpenTelemetryConnections) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputOpenTelemetryConnections) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// InputOpenTelemetryMode - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputOpenTelemetryMode string

const (
	InputOpenTelemetryModeSmart  InputOpenTelemetryMode = "smart"
	InputOpenTelemetryModeAlways InputOpenTelemetryMode = "always"
)

func (e InputOpenTelemetryMode) ToPointer() *InputOpenTelemetryMode {
	return &e
}
func (e *InputOpenTelemetryMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputOpenTelemetryMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputOpenTelemetryMode: %v", v)
	}
}

// InputOpenTelemetryCompression - Codec to use to compress the persisted data
type InputOpenTelemetryCompression string

const (
	InputOpenTelemetryCompressionNone InputOpenTelemetryCompression = "none"
	InputOpenTelemetryCompressionGzip InputOpenTelemetryCompression = "gzip"
)

func (e InputOpenTelemetryCompression) ToPointer() *InputOpenTelemetryCompression {
	return &e
}
func (e *InputOpenTelemetryCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputOpenTelemetryCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputOpenTelemetryCompression: %v", v)
	}
}

type InputOpenTelemetryPq struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputOpenTelemetryMode `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *InputOpenTelemetryCompression `default:"none" json:"compress"`
}

func (i InputOpenTelemetryPq) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputOpenTelemetryPq) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputOpenTelemetryPq) GetMode() *InputOpenTelemetryMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputOpenTelemetryPq) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputOpenTelemetryPq) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *InputOpenTelemetryPq) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *InputOpenTelemetryPq) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *InputOpenTelemetryPq) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *InputOpenTelemetryPq) GetCompress() *InputOpenTelemetryCompression {
	if o == nil {
		return nil
	}
	return o.Compress
}

// InputOpenTelemetryMinimumTLSVersion - Minimum TLS version to accept from connections
type InputOpenTelemetryMinimumTLSVersion string

const (
	InputOpenTelemetryMinimumTLSVersionTlSv1  InputOpenTelemetryMinimumTLSVersion = "TLSv1"
	InputOpenTelemetryMinimumTLSVersionTlSv11 InputOpenTelemetryMinimumTLSVersion = "TLSv1.1"
	InputOpenTelemetryMinimumTLSVersionTlSv12 InputOpenTelemetryMinimumTLSVersion = "TLSv1.2"
	InputOpenTelemetryMinimumTLSVersionTlSv13 InputOpenTelemetryMinimumTLSVersion = "TLSv1.3"
)

func (e InputOpenTelemetryMinimumTLSVersion) ToPointer() *InputOpenTelemetryMinimumTLSVersion {
	return &e
}
func (e *InputOpenTelemetryMinimumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputOpenTelemetryMinimumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputOpenTelemetryMinimumTLSVersion: %v", v)
	}
}

// InputOpenTelemetryMaximumTLSVersion - Maximum TLS version to accept from connections
type InputOpenTelemetryMaximumTLSVersion string

const (
	InputOpenTelemetryMaximumTLSVersionTlSv1  InputOpenTelemetryMaximumTLSVersion = "TLSv1"
	InputOpenTelemetryMaximumTLSVersionTlSv11 InputOpenTelemetryMaximumTLSVersion = "TLSv1.1"
	InputOpenTelemetryMaximumTLSVersionTlSv12 InputOpenTelemetryMaximumTLSVersion = "TLSv1.2"
	InputOpenTelemetryMaximumTLSVersionTlSv13 InputOpenTelemetryMaximumTLSVersion = "TLSv1.3"
)

func (e InputOpenTelemetryMaximumTLSVersion) ToPointer() *InputOpenTelemetryMaximumTLSVersion {
	return &e
}
func (e *InputOpenTelemetryMaximumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputOpenTelemetryMaximumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputOpenTelemetryMaximumTLSVersion: %v", v)
	}
}

type InputOpenTelemetryTLSSettingsServerSide struct {
	Disabled *bool `default:"true" json:"disabled"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert        *bool `default:"false" json:"requestCert"`
	RejectUnauthorized any   `json:"rejectUnauthorized,omitempty"`
	CommonNameRegex    any   `json:"commonNameRegex,omitempty"`
	// Minimum TLS version to accept from connections
	MinVersion *InputOpenTelemetryMinimumTLSVersion `json:"minVersion,omitempty"`
	// Maximum TLS version to accept from connections
	MaxVersion *InputOpenTelemetryMaximumTLSVersion `json:"maxVersion,omitempty"`
}

func (i InputOpenTelemetryTLSSettingsServerSide) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputOpenTelemetryTLSSettingsServerSide) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputOpenTelemetryTLSSettingsServerSide) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputOpenTelemetryTLSSettingsServerSide) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *InputOpenTelemetryTLSSettingsServerSide) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *InputOpenTelemetryTLSSettingsServerSide) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *InputOpenTelemetryTLSSettingsServerSide) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *InputOpenTelemetryTLSSettingsServerSide) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *InputOpenTelemetryTLSSettingsServerSide) GetRequestCert() *bool {
	if o == nil {
		return nil
	}
	return o.RequestCert
}

func (o *InputOpenTelemetryTLSSettingsServerSide) GetRejectUnauthorized() any {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *InputOpenTelemetryTLSSettingsServerSide) GetCommonNameRegex() any {
	if o == nil {
		return nil
	}
	return o.CommonNameRegex
}

func (o *InputOpenTelemetryTLSSettingsServerSide) GetMinVersion() *InputOpenTelemetryMinimumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *InputOpenTelemetryTLSSettingsServerSide) GetMaxVersion() *InputOpenTelemetryMaximumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

// InputOpenTelemetryProtocol - Select whether to leverage gRPC or HTTP for OpenTelemetry
type InputOpenTelemetryProtocol string

const (
	InputOpenTelemetryProtocolGrpc InputOpenTelemetryProtocol = "grpc"
	InputOpenTelemetryProtocolHTTP InputOpenTelemetryProtocol = "http"
)

func (e InputOpenTelemetryProtocol) ToPointer() *InputOpenTelemetryProtocol {
	return &e
}
func (e *InputOpenTelemetryProtocol) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "grpc":
		fallthrough
	case "http":
		*e = InputOpenTelemetryProtocol(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputOpenTelemetryProtocol: %v", v)
	}
}

// OTLPVersion - The version of OTLP Protobuf definitions to use when interpreting received data
type OTLPVersion string

const (
	OTLPVersionZeroDot10Dot0 OTLPVersion = "0.10.0"
	OTLPVersionOneDot3Dot1   OTLPVersion = "1.3.1"
)

func (e OTLPVersion) ToPointer() *OTLPVersion {
	return &e
}
func (e *OTLPVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "0.10.0":
		fallthrough
	case "1.3.1":
		*e = OTLPVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OTLPVersion: %v", v)
	}
}

// InputOpenTelemetryAuthenticationType - OpenTelemetry authentication type
type InputOpenTelemetryAuthenticationType string

const (
	InputOpenTelemetryAuthenticationTypeNone              InputOpenTelemetryAuthenticationType = "none"
	InputOpenTelemetryAuthenticationTypeBasic             InputOpenTelemetryAuthenticationType = "basic"
	InputOpenTelemetryAuthenticationTypeCredentialsSecret InputOpenTelemetryAuthenticationType = "credentialsSecret"
	InputOpenTelemetryAuthenticationTypeToken             InputOpenTelemetryAuthenticationType = "token"
	InputOpenTelemetryAuthenticationTypeTextSecret        InputOpenTelemetryAuthenticationType = "textSecret"
	InputOpenTelemetryAuthenticationTypeOauth             InputOpenTelemetryAuthenticationType = "oauth"
)

func (e InputOpenTelemetryAuthenticationType) ToPointer() *InputOpenTelemetryAuthenticationType {
	return &e
}
func (e *InputOpenTelemetryAuthenticationType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "basic":
		fallthrough
	case "credentialsSecret":
		fallthrough
	case "token":
		fallthrough
	case "textSecret":
		fallthrough
	case "oauth":
		*e = InputOpenTelemetryAuthenticationType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputOpenTelemetryAuthenticationType: %v", v)
	}
}

type InputOpenTelemetryMetadata struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputOpenTelemetryMetadata) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputOpenTelemetryMetadata) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputOpenTelemetryOauthParams struct {
	// OAuth parameter name
	Name string `json:"name"`
	// OAuth parameter value
	Value string `json:"value"`
}

func (o *InputOpenTelemetryOauthParams) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputOpenTelemetryOauthParams) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputOpenTelemetryOauthHeaders struct {
	// OAuth header name
	Name string `json:"name"`
	// OAuth header value
	Value string `json:"value"`
}

func (o *InputOpenTelemetryOauthHeaders) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputOpenTelemetryOauthHeaders) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputOpenTelemetry struct {
	// Unique ID for this input
	ID       *string                 `json:"id,omitempty"`
	Type     *InputOpenTelemetryType `json:"type,omitempty"`
	Disabled *bool                   `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputOpenTelemetryConnections `json:"connections,omitempty"`
	Pq          *InputOpenTelemetryPq           `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port *float64                                 `default:"4317" json:"port"`
	TLS  *InputOpenTelemetryTLSSettingsServerSide `json:"tls,omitempty"`
	// Maximum number of active requests per Worker Process. Use 0 for unlimited.
	MaxActiveReq *float64 `default:"256" json:"maxActiveReq"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket  *int64 `default:"0" json:"maxRequestsPerSocket"`
	EnableProxyHeader     any    `json:"enableProxyHeader,omitempty"`
	CaptureHeaders        any    `json:"captureHeaders,omitempty"`
	ActivityLogSampleRate any    `json:"activityLogSampleRate,omitempty"`
	// How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
	RequestTimeout *float64 `default:"0" json:"requestTimeout"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `default:"0" json:"socketTimeout"`
	// After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 sec.; maximum 600 sec. (10 min.).
	KeepAliveTimeout *float64 `default:"15" json:"keepAliveTimeout"`
	// Enable to expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
	EnableHealthCheck *bool `default:"false" json:"enableHealthCheck"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist.
	IPAllowlistRegex *string `default:"/.*/" json:"ipAllowlistRegex"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `default:"/^\\$/" json:"ipDenylistRegex"`
	// Select whether to leverage gRPC or HTTP for OpenTelemetry
	Protocol *InputOpenTelemetryProtocol `default:"grpc" json:"protocol"`
	// Enable to extract each incoming span to a separate event
	ExtractSpans *bool `default:"false" json:"extractSpans"`
	// Enable to extract each incoming Gauge or IntGauge metric to multiple events, one per data point
	ExtractMetrics *bool `default:"false" json:"extractMetrics"`
	// The version of OTLP Protobuf definitions to use when interpreting received data
	OtlpVersion *OTLPVersion `default:"0.10.0" json:"otlpVersion"`
	// OpenTelemetry authentication type
	AuthType *InputOpenTelemetryAuthenticationType `default:"none" json:"authType"`
	// Fields to add to events from this input
	Metadata []InputOpenTelemetryMetadata `json:"metadata,omitempty"`
	// Maximum number of active connections allowed per Worker Process. Use 0 for unlimited.
	MaxActiveCxn *float64 `default:"1000" json:"maxActiveCxn"`
	Description  *string  `json:"description,omitempty"`
	Username     *string  `json:"username,omitempty"`
	Password     *string  `json:"password,omitempty"`
	// Bearer token to include in the authorization header
	Token *string `json:"token,omitempty"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// URL for OAuth
	LoginURL *string `json:"loginUrl,omitempty"`
	// Secret parameter name to pass in request body
	SecretParamName *string `json:"secretParamName,omitempty"`
	// Secret parameter value to pass in request body
	Secret *string `json:"secret,omitempty"`
	// Name of the auth token attribute in the OAuth response. Can be top-level (e.g., 'token'); or nested, using a period (e.g., 'data.token').
	TokenAttributeName *string `json:"tokenAttributeName,omitempty"`
	// JavaScript expression to compute the Authorization header value to pass in requests. The value `${token}` is used to reference the token obtained from authentication, e.g.: `Bearer ${token}`.
	AuthHeaderExpr *string `default:"Bearer \\${token}" json:"authHeaderExpr"`
	// How often the OAuth token should be refreshed.
	TokenTimeoutSecs *float64 `default:"3600" json:"tokenTimeoutSecs"`
	// Additional parameters to send in the OAuth login request. @{product} will combine the secret with these parameters, and will send the URL-encoded result in a POST request to the endpoint specified in the 'Login URL'. We'll automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthParams []InputOpenTelemetryOauthParams `json:"oauthParams,omitempty"`
	// Additional headers to send in the OAuth login request. @{product} will automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthHeaders []InputOpenTelemetryOauthHeaders `json:"oauthHeaders,omitempty"`
	// Enable to extract each incoming log record to a separate event
	ExtractLogs *bool     `default:"false" json:"extractLogs"`
	Status      *TFStatus `json:"status,omitempty"`
}

func (i InputOpenTelemetry) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputOpenTelemetry) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputOpenTelemetry) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputOpenTelemetry) GetType() *InputOpenTelemetryType {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputOpenTelemetry) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputOpenTelemetry) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputOpenTelemetry) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputOpenTelemetry) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputOpenTelemetry) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputOpenTelemetry) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputOpenTelemetry) GetConnections() []InputOpenTelemetryConnections {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputOpenTelemetry) GetPq() *InputOpenTelemetryPq {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputOpenTelemetry) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputOpenTelemetry) GetPort() *float64 {
	if o == nil {
		return nil
	}
	return o.Port
}

func (o *InputOpenTelemetry) GetTLS() *InputOpenTelemetryTLSSettingsServerSide {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputOpenTelemetry) GetMaxActiveReq() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxActiveReq
}

func (o *InputOpenTelemetry) GetMaxRequestsPerSocket() *int64 {
	if o == nil {
		return nil
	}
	return o.MaxRequestsPerSocket
}

func (o *InputOpenTelemetry) GetEnableProxyHeader() any {
	if o == nil {
		return nil
	}
	return o.EnableProxyHeader
}

func (o *InputOpenTelemetry) GetCaptureHeaders() any {
	if o == nil {
		return nil
	}
	return o.CaptureHeaders
}

func (o *InputOpenTelemetry) GetActivityLogSampleRate() any {
	if o == nil {
		return nil
	}
	return o.ActivityLogSampleRate
}

func (o *InputOpenTelemetry) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *InputOpenTelemetry) GetSocketTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketTimeout
}

func (o *InputOpenTelemetry) GetKeepAliveTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.KeepAliveTimeout
}

func (o *InputOpenTelemetry) GetEnableHealthCheck() *bool {
	if o == nil {
		return nil
	}
	return o.EnableHealthCheck
}

func (o *InputOpenTelemetry) GetIPAllowlistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPAllowlistRegex
}

func (o *InputOpenTelemetry) GetIPDenylistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPDenylistRegex
}

func (o *InputOpenTelemetry) GetProtocol() *InputOpenTelemetryProtocol {
	if o == nil {
		return nil
	}
	return o.Protocol
}

func (o *InputOpenTelemetry) GetExtractSpans() *bool {
	if o == nil {
		return nil
	}
	return o.ExtractSpans
}

func (o *InputOpenTelemetry) GetExtractMetrics() *bool {
	if o == nil {
		return nil
	}
	return o.ExtractMetrics
}

func (o *InputOpenTelemetry) GetOtlpVersion() *OTLPVersion {
	if o == nil {
		return nil
	}
	return o.OtlpVersion
}

func (o *InputOpenTelemetry) GetAuthType() *InputOpenTelemetryAuthenticationType {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *InputOpenTelemetry) GetMetadata() []InputOpenTelemetryMetadata {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputOpenTelemetry) GetMaxActiveCxn() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxActiveCxn
}

func (o *InputOpenTelemetry) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputOpenTelemetry) GetUsername() *string {
	if o == nil {
		return nil
	}
	return o.Username
}

func (o *InputOpenTelemetry) GetPassword() *string {
	if o == nil {
		return nil
	}
	return o.Password
}

func (o *InputOpenTelemetry) GetToken() *string {
	if o == nil {
		return nil
	}
	return o.Token
}

func (o *InputOpenTelemetry) GetCredentialsSecret() *string {
	if o == nil {
		return nil
	}
	return o.CredentialsSecret
}

func (o *InputOpenTelemetry) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *InputOpenTelemetry) GetLoginURL() *string {
	if o == nil {
		return nil
	}
	return o.LoginURL
}

func (o *InputOpenTelemetry) GetSecretParamName() *string {
	if o == nil {
		return nil
	}
	return o.SecretParamName
}

func (o *InputOpenTelemetry) GetSecret() *string {
	if o == nil {
		return nil
	}
	return o.Secret
}

func (o *InputOpenTelemetry) GetTokenAttributeName() *string {
	if o == nil {
		return nil
	}
	return o.TokenAttributeName
}

func (o *InputOpenTelemetry) GetAuthHeaderExpr() *string {
	if o == nil {
		return nil
	}
	return o.AuthHeaderExpr
}

func (o *InputOpenTelemetry) GetTokenTimeoutSecs() *float64 {
	if o == nil {
		return nil
	}
	return o.TokenTimeoutSecs
}

func (o *InputOpenTelemetry) GetOauthParams() []InputOpenTelemetryOauthParams {
	if o == nil {
		return nil
	}
	return o.OauthParams
}

func (o *InputOpenTelemetry) GetOauthHeaders() []InputOpenTelemetryOauthHeaders {
	if o == nil {
		return nil
	}
	return o.OauthHeaders
}

func (o *InputOpenTelemetry) GetExtractLogs() *bool {
	if o == nil {
		return nil
	}
	return o.ExtractLogs
}

func (o *InputOpenTelemetry) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputSnmpType string

const (
	InputSnmpTypeSnmp InputSnmpType = "snmp"
)

func (e InputSnmpType) ToPointer() *InputSnmpType {
	return &e
}
func (e *InputSnmpType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "snmp":
		*e = InputSnmpType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSnmpType: %v", v)
	}
}

type InputSnmpConnections struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *InputSnmpConnections) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputSnmpConnections) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// InputSnmpMode - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputSnmpMode string

const (
	InputSnmpModeSmart  InputSnmpMode = "smart"
	InputSnmpModeAlways InputSnmpMode = "always"
)

func (e InputSnmpMode) ToPointer() *InputSnmpMode {
	return &e
}
func (e *InputSnmpMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputSnmpMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSnmpMode: %v", v)
	}
}

// InputSnmpCompression - Codec to use to compress the persisted data
type InputSnmpCompression string

const (
	InputSnmpCompressionNone InputSnmpCompression = "none"
	InputSnmpCompressionGzip InputSnmpCompression = "gzip"
)

func (e InputSnmpCompression) ToPointer() *InputSnmpCompression {
	return &e
}
func (e *InputSnmpCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputSnmpCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSnmpCompression: %v", v)
	}
}

type InputSnmpPq struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputSnmpMode `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *InputSnmpCompression `default:"none" json:"compress"`
}

func (i InputSnmpPq) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSnmpPq) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputSnmpPq) GetMode() *InputSnmpMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputSnmpPq) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputSnmpPq) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *InputSnmpPq) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *InputSnmpPq) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *InputSnmpPq) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *InputSnmpPq) GetCompress() *InputSnmpCompression {
	if o == nil {
		return nil
	}
	return o.Compress
}

type AuthenticationProtocol string

const (
	AuthenticationProtocolNone   AuthenticationProtocol = "none"
	AuthenticationProtocolMd5    AuthenticationProtocol = "md5"
	AuthenticationProtocolSha    AuthenticationProtocol = "sha"
	AuthenticationProtocolSha224 AuthenticationProtocol = "sha224"
	AuthenticationProtocolSha256 AuthenticationProtocol = "sha256"
	AuthenticationProtocolSha384 AuthenticationProtocol = "sha384"
	AuthenticationProtocolSha512 AuthenticationProtocol = "sha512"
)

func (e AuthenticationProtocol) ToPointer() *AuthenticationProtocol {
	return &e
}
func (e *AuthenticationProtocol) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "md5":
		fallthrough
	case "sha":
		fallthrough
	case "sha224":
		fallthrough
	case "sha256":
		fallthrough
	case "sha384":
		fallthrough
	case "sha512":
		*e = AuthenticationProtocol(v)
		return nil
	default:
		return fmt.Errorf("invalid value for AuthenticationProtocol: %v", v)
	}
}

type V3Users struct {
	Name         string                  `json:"name"`
	AuthProtocol *AuthenticationProtocol `default:"none" json:"authProtocol"`
	AuthKey      any                     `json:"authKey,omitempty"`
	PrivProtocol *string                 `default:"none" json:"privProtocol"`
}

func (v V3Users) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(v, "", false)
}

func (v *V3Users) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &v, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *V3Users) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *V3Users) GetAuthProtocol() *AuthenticationProtocol {
	if o == nil {
		return nil
	}
	return o.AuthProtocol
}

func (o *V3Users) GetAuthKey() any {
	if o == nil {
		return nil
	}
	return o.AuthKey
}

func (o *V3Users) GetPrivProtocol() *string {
	if o == nil {
		return nil
	}
	return o.PrivProtocol
}

// SNMPv3Authentication - Authentication parameters for SNMPv3 trap. Set the log level to debug if you are experiencing authentication or decryption issues.
type SNMPv3Authentication struct {
	V3AuthEnabled *bool `default:"false" json:"v3AuthEnabled"`
	// Pass through traps that don't match any of the configured users. @{product} will not attempt to decrypt these traps.
	AllowUnmatchedTrap *bool `default:"false" json:"allowUnmatchedTrap"`
	// User credentials for receiving v3 traps
	V3Users []V3Users `json:"v3Users,omitempty"`
}

func (s SNMPv3Authentication) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *SNMPv3Authentication) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *SNMPv3Authentication) GetV3AuthEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.V3AuthEnabled
}

func (o *SNMPv3Authentication) GetAllowUnmatchedTrap() *bool {
	if o == nil {
		return nil
	}
	return o.AllowUnmatchedTrap
}

func (o *SNMPv3Authentication) GetV3Users() []V3Users {
	if o == nil {
		return nil
	}
	return o.V3Users
}

type InputSnmpMetadata struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputSnmpMetadata) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputSnmpMetadata) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputSnmp struct {
	// Unique ID for this input
	ID       *string        `json:"id,omitempty"`
	Type     *InputSnmpType `json:"type,omitempty"`
	Disabled *bool          `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputSnmpConnections `json:"connections,omitempty"`
	Pq          *InputSnmpPq           `json:"pq,omitempty"`
	// Address to bind on. For IPv4 (all addresses), use the default '0.0.0.0'. For IPv6, enter '::' (all addresses) or specify an IP address.
	Host *string `default:"0.0.0.0" json:"host"`
	// UDP port to receive SNMP traps on. Defaults to 162.
	Port *float64 `default:"162" json:"port"`
	// Authentication parameters for SNMPv3 trap. Set the log level to debug if you are experiencing authentication or decryption issues.
	SnmpV3Auth *SNMPv3Authentication `json:"snmpV3Auth,omitempty"`
	// Maximum number of events to buffer when downstream is blocking.
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// Regex matching IP addresses that are allowed to send data
	IPWhitelistRegex *string `default:"/.*/" json:"ipWhitelistRegex"`
	// Fields to add to events from this input
	Metadata []InputSnmpMetadata `json:"metadata,omitempty"`
	// Optionally, set the SO_RCVBUF socket option for the UDP socket. This value tells the operating system how many bytes can be buffered in the kernel before events are dropped. Leave blank to use the OS default. Caution: Increasing this value will affect OS memory utilization.
	UDPSocketRxBufSize *float64 `json:"udpSocketRxBufSize,omitempty"`
	// If enabled, parses varbinds as an array of objects that include OID, value, and type
	VarbindsWithTypes *bool     `default:"false" json:"varbindsWithTypes"`
	Description       *string   `json:"description,omitempty"`
	Status            *TFStatus `json:"status,omitempty"`
}

func (i InputSnmp) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSnmp) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputSnmp) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputSnmp) GetType() *InputSnmpType {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputSnmp) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputSnmp) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputSnmp) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputSnmp) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputSnmp) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputSnmp) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputSnmp) GetConnections() []InputSnmpConnections {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputSnmp) GetPq() *InputSnmpPq {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputSnmp) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputSnmp) GetPort() *float64 {
	if o == nil {
		return nil
	}
	return o.Port
}

func (o *InputSnmp) GetSnmpV3Auth() *SNMPv3Authentication {
	if o == nil {
		return nil
	}
	return o.SnmpV3Auth
}

func (o *InputSnmp) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputSnmp) GetIPWhitelistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPWhitelistRegex
}

func (o *InputSnmp) GetMetadata() []InputSnmpMetadata {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputSnmp) GetUDPSocketRxBufSize() *float64 {
	if o == nil {
		return nil
	}
	return o.UDPSocketRxBufSize
}

func (o *InputSnmp) GetVarbindsWithTypes() *bool {
	if o == nil {
		return nil
	}
	return o.VarbindsWithTypes
}

func (o *InputSnmp) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputSnmp) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputS3InventoryType string

const (
	InputS3InventoryTypeS3Inventory InputS3InventoryType = "s3_inventory"
)

func (e InputS3InventoryType) ToPointer() *InputS3InventoryType {
	return &e
}
func (e *InputS3InventoryType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "s3_inventory":
		*e = InputS3InventoryType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputS3InventoryType: %v", v)
	}
}

type InputS3InventoryConnections struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *InputS3InventoryConnections) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputS3InventoryConnections) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// InputS3InventoryMode - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputS3InventoryMode string

const (
	InputS3InventoryModeSmart  InputS3InventoryMode = "smart"
	InputS3InventoryModeAlways InputS3InventoryMode = "always"
)

func (e InputS3InventoryMode) ToPointer() *InputS3InventoryMode {
	return &e
}
func (e *InputS3InventoryMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputS3InventoryMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputS3InventoryMode: %v", v)
	}
}

// InputS3InventoryCompression - Codec to use to compress the persisted data
type InputS3InventoryCompression string

const (
	InputS3InventoryCompressionNone InputS3InventoryCompression = "none"
	InputS3InventoryCompressionGzip InputS3InventoryCompression = "gzip"
)

func (e InputS3InventoryCompression) ToPointer() *InputS3InventoryCompression {
	return &e
}
func (e *InputS3InventoryCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputS3InventoryCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputS3InventoryCompression: %v", v)
	}
}

type InputS3InventoryPq struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputS3InventoryMode `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *InputS3InventoryCompression `default:"none" json:"compress"`
}

func (i InputS3InventoryPq) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputS3InventoryPq) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputS3InventoryPq) GetMode() *InputS3InventoryMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputS3InventoryPq) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputS3InventoryPq) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *InputS3InventoryPq) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *InputS3InventoryPq) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *InputS3InventoryPq) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *InputS3InventoryPq) GetCompress() *InputS3InventoryCompression {
	if o == nil {
		return nil
	}
	return o.Compress
}

// InputS3InventoryAuthenticationMethod - AWS authentication method. Choose Auto to use IAM roles.
type InputS3InventoryAuthenticationMethod string

const (
	InputS3InventoryAuthenticationMethodAuto   InputS3InventoryAuthenticationMethod = "auto"
	InputS3InventoryAuthenticationMethodManual InputS3InventoryAuthenticationMethod = "manual"
	InputS3InventoryAuthenticationMethodSecret InputS3InventoryAuthenticationMethod = "secret"
)

func (e InputS3InventoryAuthenticationMethod) ToPointer() *InputS3InventoryAuthenticationMethod {
	return &e
}
func (e *InputS3InventoryAuthenticationMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "auto":
		fallthrough
	case "manual":
		fallthrough
	case "secret":
		*e = InputS3InventoryAuthenticationMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputS3InventoryAuthenticationMethod: %v", v)
	}
}

// InputS3InventorySignatureVersion - Signature version to use for signing S3 requests
type InputS3InventorySignatureVersion string

const (
	InputS3InventorySignatureVersionV2 InputS3InventorySignatureVersion = "v2"
	InputS3InventorySignatureVersionV4 InputS3InventorySignatureVersion = "v4"
)

func (e InputS3InventorySignatureVersion) ToPointer() *InputS3InventorySignatureVersion {
	return &e
}
func (e *InputS3InventorySignatureVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "v2":
		fallthrough
	case "v4":
		*e = InputS3InventorySignatureVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputS3InventorySignatureVersion: %v", v)
	}
}

type InputS3InventoryPreprocess struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Command to feed the data through (via stdin) and process its output (stdout)
	Command *string `json:"command,omitempty"`
	// Arguments to be added to the custom command
	Args []string `json:"args,omitempty"`
}

func (i InputS3InventoryPreprocess) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputS3InventoryPreprocess) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputS3InventoryPreprocess) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputS3InventoryPreprocess) GetCommand() *string {
	if o == nil {
		return nil
	}
	return o.Command
}

func (o *InputS3InventoryPreprocess) GetArgs() []string {
	if o == nil {
		return nil
	}
	return o.Args
}

type InputS3InventoryMetadata struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputS3InventoryMetadata) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputS3InventoryMetadata) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputS3InventoryCheckpointing struct {
	// Resume processing files after an interruption
	Enabled *bool `default:"false" json:"enabled"`
	// If checkpointing is enabled, the number of times to retry processing when a processing error occurs. If skip file on error is enabled, this setting is ignored.
	Retries *float64 `default:"5" json:"retries"`
}

func (i InputS3InventoryCheckpointing) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputS3InventoryCheckpointing) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputS3InventoryCheckpointing) GetEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.Enabled
}

func (o *InputS3InventoryCheckpointing) GetRetries() *float64 {
	if o == nil {
		return nil
	}
	return o.Retries
}

type InputS3Inventory struct {
	// Unique ID for this input
	ID       *string              `json:"id,omitempty"`
	Type     InputS3InventoryType `json:"type"`
	Disabled *bool                `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputS3InventoryConnections `json:"connections,omitempty"`
	Pq          *InputS3InventoryPq           `json:"pq,omitempty"`
	// The name, URL, or ARN of the SQS queue to read notifications from. When a non-AWS URL is specified, format must be: '{url}/myQueueName'. Example: 'https://host:port/myQueueName'. Value must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at init time. Example referencing a Global Variable: `https://host:port/myQueue-${C.vars.myVar}`.
	QueueName string `json:"queueName"`
	// Regex matching file names to download and process. Defaults to: .*
	FileFilter *string `default:"/.*/" json:"fileFilter"`
	// SQS queue owner's AWS account ID. Leave empty if SQS queue is in same AWS account.
	AwsAccountID *string `json:"awsAccountId,omitempty"`
	// AWS authentication method. Choose Auto to use IAM roles.
	AwsAuthenticationMethod *InputS3InventoryAuthenticationMethod `default:"auto" json:"awsAuthenticationMethod"`
	AwsSecretKey            *string                               `json:"awsSecretKey,omitempty"`
	// AWS Region where the S3 bucket and SQS queue are located. Required, unless the Queue entry is a URL or ARN that includes a Region.
	Region *string `json:"region,omitempty"`
	// S3 service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to S3-compatible endpoint.
	Endpoint *string `json:"endpoint,omitempty"`
	// Signature version to use for signing S3 requests
	SignatureVersion *InputS3InventorySignatureVersion `default:"v4" json:"signatureVersion"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `default:"true" json:"reuseConnections"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitempty"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `default:"10000" json:"staleChannelFlushMs"`
	// The maximum number of messages SQS should return in a poll request. Amazon SQS never returns more messages than this value (however, fewer messages might be returned). Valid values: 1 to 10.
	MaxMessages *float64 `default:"1" json:"maxMessages"`
	// After messages are retrieved by a ReceiveMessage request, @{product} will hide them from subsequent retrieve requests for at least this duration. You can set this as high as 43200 sec. (12 hours).
	VisibilityTimeout *float64 `default:"600" json:"visibilityTimeout"`
	// How many receiver processes to run. The higher the number, the better the throughput - at the expense of CPU overhead.
	NumReceivers *float64 `default:"1" json:"numReceivers"`
	// Socket inactivity timeout (in seconds). Increase this value if timeouts occur due to backpressure.
	SocketTimeout *float64 `default:"300" json:"socketTimeout"`
	// Skip files that trigger a processing error. Disabled by default, which allows retries after processing errors.
	SkipOnError *bool `default:"false" json:"skipOnError"`
	// Use Assume Role credentials to access S3
	EnableAssumeRole *bool `default:"true" json:"enableAssumeRole"`
	// Amazon Resource Name (ARN) of the role to assume
	AssumeRoleArn *string `json:"assumeRoleArn,omitempty"`
	// External ID to use when assuming role
	AssumeRoleExternalID *string `json:"assumeRoleExternalId,omitempty"`
	// Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
	DurationSeconds *float64 `default:"3600" json:"durationSeconds"`
	// Use Assume Role credentials when accessing SQS
	EnableSQSAssumeRole *bool                       `default:"false" json:"enableSQSAssumeRole"`
	Preprocess          *InputS3InventoryPreprocess `json:"preprocess,omitempty"`
	// Fields to add to events from this input
	Metadata []InputS3InventoryMetadata `json:"metadata,omitempty"`
	// Maximum file size for each Parquet chunk
	ParquetChunkSizeMB *float64 `default:"5" json:"parquetChunkSizeMB"`
	// The maximum time allowed for downloading a Parquet chunk. Processing will stop if a chunk cannot be downloaded within the time specified.
	ParquetChunkDownloadTimeout *float64                       `default:"600" json:"parquetChunkDownloadTimeout"`
	Checkpointing               *InputS3InventoryCheckpointing `json:"checkpointing,omitempty"`
	// How long to wait for events before trying polling again. The lower the number the higher the AWS bill. The higher the number the longer it will take for the source to react to configuration changes and system restarts.
	PollTimeout *float64 `default:"10" json:"pollTimeout"`
	// Filename suffix of the manifest checksum file. If a filename matching this suffix is received        in the queue, the matching manifest file will be downloaded and validated against its value. Defaults to "checksum"
	ChecksumSuffix *string `default:"checksum" json:"checksumSuffix"`
	// Maximum download size (KB) of each manifest or checksum file. Manifest files larger than this size will not be read.        Defaults to 4096.
	MaxManifestSizeKB *int64 `default:"4096" json:"maxManifestSizeKB"`
	// If set to Yes, each inventory file in the manifest will be validated against its checksum. Defaults to false
	ValidateInventoryFiles *bool   `default:"false" json:"validateInventoryFiles"`
	Description            *string `json:"description,omitempty"`
	AwsAPIKey              *string `json:"awsApiKey,omitempty"`
	// Select or create a stored secret that references your access key and secret key
	AwsSecret *string   `json:"awsSecret,omitempty"`
	Status    *TFStatus `json:"status,omitempty"`
}

func (i InputS3Inventory) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputS3Inventory) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputS3Inventory) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputS3Inventory) GetType() InputS3InventoryType {
	if o == nil {
		return InputS3InventoryType("")
	}
	return o.Type
}

func (o *InputS3Inventory) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputS3Inventory) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputS3Inventory) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputS3Inventory) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputS3Inventory) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputS3Inventory) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputS3Inventory) GetConnections() []InputS3InventoryConnections {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputS3Inventory) GetPq() *InputS3InventoryPq {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputS3Inventory) GetQueueName() string {
	if o == nil {
		return ""
	}
	return o.QueueName
}

func (o *InputS3Inventory) GetFileFilter() *string {
	if o == nil {
		return nil
	}
	return o.FileFilter
}

func (o *InputS3Inventory) GetAwsAccountID() *string {
	if o == nil {
		return nil
	}
	return o.AwsAccountID
}

func (o *InputS3Inventory) GetAwsAuthenticationMethod() *InputS3InventoryAuthenticationMethod {
	if o == nil {
		return nil
	}
	return o.AwsAuthenticationMethod
}

func (o *InputS3Inventory) GetAwsSecretKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecretKey
}

func (o *InputS3Inventory) GetRegion() *string {
	if o == nil {
		return nil
	}
	return o.Region
}

func (o *InputS3Inventory) GetEndpoint() *string {
	if o == nil {
		return nil
	}
	return o.Endpoint
}

func (o *InputS3Inventory) GetSignatureVersion() *InputS3InventorySignatureVersion {
	if o == nil {
		return nil
	}
	return o.SignatureVersion
}

func (o *InputS3Inventory) GetReuseConnections() *bool {
	if o == nil {
		return nil
	}
	return o.ReuseConnections
}

func (o *InputS3Inventory) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *InputS3Inventory) GetBreakerRulesets() []string {
	if o == nil {
		return nil
	}
	return o.BreakerRulesets
}

func (o *InputS3Inventory) GetStaleChannelFlushMs() *float64 {
	if o == nil {
		return nil
	}
	return o.StaleChannelFlushMs
}

func (o *InputS3Inventory) GetMaxMessages() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxMessages
}

func (o *InputS3Inventory) GetVisibilityTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.VisibilityTimeout
}

func (o *InputS3Inventory) GetNumReceivers() *float64 {
	if o == nil {
		return nil
	}
	return o.NumReceivers
}

func (o *InputS3Inventory) GetSocketTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketTimeout
}

func (o *InputS3Inventory) GetSkipOnError() *bool {
	if o == nil {
		return nil
	}
	return o.SkipOnError
}

func (o *InputS3Inventory) GetEnableAssumeRole() *bool {
	if o == nil {
		return nil
	}
	return o.EnableAssumeRole
}

func (o *InputS3Inventory) GetAssumeRoleArn() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleArn
}

func (o *InputS3Inventory) GetAssumeRoleExternalID() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleExternalID
}

func (o *InputS3Inventory) GetDurationSeconds() *float64 {
	if o == nil {
		return nil
	}
	return o.DurationSeconds
}

func (o *InputS3Inventory) GetEnableSQSAssumeRole() *bool {
	if o == nil {
		return nil
	}
	return o.EnableSQSAssumeRole
}

func (o *InputS3Inventory) GetPreprocess() *InputS3InventoryPreprocess {
	if o == nil {
		return nil
	}
	return o.Preprocess
}

func (o *InputS3Inventory) GetMetadata() []InputS3InventoryMetadata {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputS3Inventory) GetParquetChunkSizeMB() *float64 {
	if o == nil {
		return nil
	}
	return o.ParquetChunkSizeMB
}

func (o *InputS3Inventory) GetParquetChunkDownloadTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.ParquetChunkDownloadTimeout
}

func (o *InputS3Inventory) GetCheckpointing() *InputS3InventoryCheckpointing {
	if o == nil {
		return nil
	}
	return o.Checkpointing
}

func (o *InputS3Inventory) GetPollTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.PollTimeout
}

func (o *InputS3Inventory) GetChecksumSuffix() *string {
	if o == nil {
		return nil
	}
	return o.ChecksumSuffix
}

func (o *InputS3Inventory) GetMaxManifestSizeKB() *int64 {
	if o == nil {
		return nil
	}
	return o.MaxManifestSizeKB
}

func (o *InputS3Inventory) GetValidateInventoryFiles() *bool {
	if o == nil {
		return nil
	}
	return o.ValidateInventoryFiles
}

func (o *InputS3Inventory) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputS3Inventory) GetAwsAPIKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsAPIKey
}

func (o *InputS3Inventory) GetAwsSecret() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecret
}

func (o *InputS3Inventory) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputS3Type string

const (
	InputS3TypeS3 InputS3Type = "s3"
)

func (e InputS3Type) ToPointer() *InputS3Type {
	return &e
}
func (e *InputS3Type) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "s3":
		*e = InputS3Type(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputS3Type: %v", v)
	}
}

type InputS3Connections struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *InputS3Connections) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputS3Connections) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// InputS3Mode - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputS3Mode string

const (
	InputS3ModeSmart  InputS3Mode = "smart"
	InputS3ModeAlways InputS3Mode = "always"
)

func (e InputS3Mode) ToPointer() *InputS3Mode {
	return &e
}
func (e *InputS3Mode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputS3Mode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputS3Mode: %v", v)
	}
}

// InputS3Compression - Codec to use to compress the persisted data
type InputS3Compression string

const (
	InputS3CompressionNone InputS3Compression = "none"
	InputS3CompressionGzip InputS3Compression = "gzip"
)

func (e InputS3Compression) ToPointer() *InputS3Compression {
	return &e
}
func (e *InputS3Compression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputS3Compression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputS3Compression: %v", v)
	}
}

type InputS3Pq struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputS3Mode `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *InputS3Compression `default:"none" json:"compress"`
}

func (i InputS3Pq) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputS3Pq) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputS3Pq) GetMode() *InputS3Mode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputS3Pq) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputS3Pq) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *InputS3Pq) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *InputS3Pq) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *InputS3Pq) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *InputS3Pq) GetCompress() *InputS3Compression {
	if o == nil {
		return nil
	}
	return o.Compress
}

// InputS3AuthenticationMethod - AWS authentication method. Choose Auto to use IAM roles.
type InputS3AuthenticationMethod string

const (
	InputS3AuthenticationMethodAuto   InputS3AuthenticationMethod = "auto"
	InputS3AuthenticationMethodManual InputS3AuthenticationMethod = "manual"
	InputS3AuthenticationMethodSecret InputS3AuthenticationMethod = "secret"
)

func (e InputS3AuthenticationMethod) ToPointer() *InputS3AuthenticationMethod {
	return &e
}
func (e *InputS3AuthenticationMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "auto":
		fallthrough
	case "manual":
		fallthrough
	case "secret":
		*e = InputS3AuthenticationMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputS3AuthenticationMethod: %v", v)
	}
}

// InputS3SignatureVersion - Signature version to use for signing S3 requests
type InputS3SignatureVersion string

const (
	InputS3SignatureVersionV2 InputS3SignatureVersion = "v2"
	InputS3SignatureVersionV4 InputS3SignatureVersion = "v4"
)

func (e InputS3SignatureVersion) ToPointer() *InputS3SignatureVersion {
	return &e
}
func (e *InputS3SignatureVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "v2":
		fallthrough
	case "v4":
		*e = InputS3SignatureVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputS3SignatureVersion: %v", v)
	}
}

type InputS3Preprocess struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Command to feed the data through (via stdin) and process its output (stdout)
	Command *string `json:"command,omitempty"`
	// Arguments to be added to the custom command
	Args []string `json:"args,omitempty"`
}

func (i InputS3Preprocess) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputS3Preprocess) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputS3Preprocess) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputS3Preprocess) GetCommand() *string {
	if o == nil {
		return nil
	}
	return o.Command
}

func (o *InputS3Preprocess) GetArgs() []string {
	if o == nil {
		return nil
	}
	return o.Args
}

type InputS3Metadata struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputS3Metadata) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputS3Metadata) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputS3Checkpointing struct {
	// Resume processing files after an interruption
	Enabled *bool `default:"false" json:"enabled"`
	// If checkpointing is enabled, the number of times to retry processing when a processing error occurs. If skip file on error is enabled, this setting is ignored.
	Retries *float64 `default:"5" json:"retries"`
}

func (i InputS3Checkpointing) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputS3Checkpointing) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputS3Checkpointing) GetEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.Enabled
}

func (o *InputS3Checkpointing) GetRetries() *float64 {
	if o == nil {
		return nil
	}
	return o.Retries
}

type InputS3 struct {
	// Unique ID for this input
	ID       *string     `json:"id,omitempty"`
	Type     InputS3Type `json:"type"`
	Disabled *bool       `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputS3Connections `json:"connections,omitempty"`
	Pq          *InputS3Pq           `json:"pq,omitempty"`
	// The name, URL, or ARN of the SQS queue to read notifications from. When a non-AWS URL is specified, format must be: '{url}/myQueueName'. Example: 'https://host:port/myQueueName'. Value must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at init time. Example referencing a Global Variable: `https://host:port/myQueue-${C.vars.myVar}`.
	QueueName string `json:"queueName"`
	// Regex matching file names to download and process. Defaults to: .*
	FileFilter *string `default:"/.*/" json:"fileFilter"`
	// SQS queue owner's AWS account ID. Leave empty if SQS queue is in same AWS account.
	AwsAccountID *string `json:"awsAccountId,omitempty"`
	// AWS authentication method. Choose Auto to use IAM roles.
	AwsAuthenticationMethod *InputS3AuthenticationMethod `default:"auto" json:"awsAuthenticationMethod"`
	AwsSecretKey            *string                      `json:"awsSecretKey,omitempty"`
	// AWS Region where the S3 bucket and SQS queue are located. Required, unless the Queue entry is a URL or ARN that includes a Region.
	Region *string `json:"region,omitempty"`
	// S3 service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to S3-compatible endpoint.
	Endpoint *string `json:"endpoint,omitempty"`
	// Signature version to use for signing S3 requests
	SignatureVersion *InputS3SignatureVersion `default:"v4" json:"signatureVersion"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `default:"true" json:"reuseConnections"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitempty"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `default:"10000" json:"staleChannelFlushMs"`
	// The maximum number of messages SQS should return in a poll request. Amazon SQS never returns more messages than this value (however, fewer messages might be returned). Valid values: 1 to 10.
	MaxMessages *float64 `default:"1" json:"maxMessages"`
	// After messages are retrieved by a ReceiveMessage request, @{product} will hide them from subsequent retrieve requests for at least this duration. You can set this as high as 43200 sec. (12 hours).
	VisibilityTimeout *float64 `default:"600" json:"visibilityTimeout"`
	// How many receiver processes to run. The higher the number, the better the throughput - at the expense of CPU overhead.
	NumReceivers *float64 `default:"1" json:"numReceivers"`
	// Socket inactivity timeout (in seconds). Increase this value if timeouts occur due to backpressure.
	SocketTimeout *float64 `default:"300" json:"socketTimeout"`
	// Skip files that trigger a processing error. Disabled by default, which allows retries after processing errors.
	SkipOnError *bool `default:"false" json:"skipOnError"`
	// Use Assume Role credentials to access S3
	EnableAssumeRole *bool `default:"true" json:"enableAssumeRole"`
	// Amazon Resource Name (ARN) of the role to assume
	AssumeRoleArn *string `json:"assumeRoleArn,omitempty"`
	// External ID to use when assuming role
	AssumeRoleExternalID *string `json:"assumeRoleExternalId,omitempty"`
	// Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
	DurationSeconds *float64 `default:"3600" json:"durationSeconds"`
	// Use Assume Role credentials when accessing SQS
	EnableSQSAssumeRole *bool              `default:"false" json:"enableSQSAssumeRole"`
	Preprocess          *InputS3Preprocess `json:"preprocess,omitempty"`
	// Fields to add to events from this input
	Metadata []InputS3Metadata `json:"metadata,omitempty"`
	// Maximum file size for each Parquet chunk
	ParquetChunkSizeMB *float64 `default:"5" json:"parquetChunkSizeMB"`
	// The maximum time allowed for downloading a Parquet chunk. Processing will stop if a chunk cannot be downloaded within the time specified.
	ParquetChunkDownloadTimeout *float64              `default:"600" json:"parquetChunkDownloadTimeout"`
	Checkpointing               *InputS3Checkpointing `json:"checkpointing,omitempty"`
	// How long to wait for events before trying polling again. The lower the number the higher the AWS bill. The higher the number the longer it will take for the source to react to configuration changes and system restarts.
	PollTimeout *float64 `default:"10" json:"pollTimeout"`
	// Character encoding to use when parsing ingested data. When not set, @{product} will default to UTF-8 but may incorrectly interpret multi-byte characters.
	Encoding    *string `json:"encoding,omitempty"`
	Description *string `json:"description,omitempty"`
	AwsAPIKey   *string `json:"awsApiKey,omitempty"`
	// Select or create a stored secret that references your access key and secret key
	AwsSecret *string   `json:"awsSecret,omitempty"`
	Status    *TFStatus `json:"status,omitempty"`
}

func (i InputS3) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputS3) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputS3) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputS3) GetType() InputS3Type {
	if o == nil {
		return InputS3Type("")
	}
	return o.Type
}

func (o *InputS3) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputS3) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputS3) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputS3) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputS3) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputS3) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputS3) GetConnections() []InputS3Connections {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputS3) GetPq() *InputS3Pq {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputS3) GetQueueName() string {
	if o == nil {
		return ""
	}
	return o.QueueName
}

func (o *InputS3) GetFileFilter() *string {
	if o == nil {
		return nil
	}
	return o.FileFilter
}

func (o *InputS3) GetAwsAccountID() *string {
	if o == nil {
		return nil
	}
	return o.AwsAccountID
}

func (o *InputS3) GetAwsAuthenticationMethod() *InputS3AuthenticationMethod {
	if o == nil {
		return nil
	}
	return o.AwsAuthenticationMethod
}

func (o *InputS3) GetAwsSecretKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecretKey
}

func (o *InputS3) GetRegion() *string {
	if o == nil {
		return nil
	}
	return o.Region
}

func (o *InputS3) GetEndpoint() *string {
	if o == nil {
		return nil
	}
	return o.Endpoint
}

func (o *InputS3) GetSignatureVersion() *InputS3SignatureVersion {
	if o == nil {
		return nil
	}
	return o.SignatureVersion
}

func (o *InputS3) GetReuseConnections() *bool {
	if o == nil {
		return nil
	}
	return o.ReuseConnections
}

func (o *InputS3) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *InputS3) GetBreakerRulesets() []string {
	if o == nil {
		return nil
	}
	return o.BreakerRulesets
}

func (o *InputS3) GetStaleChannelFlushMs() *float64 {
	if o == nil {
		return nil
	}
	return o.StaleChannelFlushMs
}

func (o *InputS3) GetMaxMessages() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxMessages
}

func (o *InputS3) GetVisibilityTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.VisibilityTimeout
}

func (o *InputS3) GetNumReceivers() *float64 {
	if o == nil {
		return nil
	}
	return o.NumReceivers
}

func (o *InputS3) GetSocketTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketTimeout
}

func (o *InputS3) GetSkipOnError() *bool {
	if o == nil {
		return nil
	}
	return o.SkipOnError
}

func (o *InputS3) GetEnableAssumeRole() *bool {
	if o == nil {
		return nil
	}
	return o.EnableAssumeRole
}

func (o *InputS3) GetAssumeRoleArn() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleArn
}

func (o *InputS3) GetAssumeRoleExternalID() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleExternalID
}

func (o *InputS3) GetDurationSeconds() *float64 {
	if o == nil {
		return nil
	}
	return o.DurationSeconds
}

func (o *InputS3) GetEnableSQSAssumeRole() *bool {
	if o == nil {
		return nil
	}
	return o.EnableSQSAssumeRole
}

func (o *InputS3) GetPreprocess() *InputS3Preprocess {
	if o == nil {
		return nil
	}
	return o.Preprocess
}

func (o *InputS3) GetMetadata() []InputS3Metadata {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputS3) GetParquetChunkSizeMB() *float64 {
	if o == nil {
		return nil
	}
	return o.ParquetChunkSizeMB
}

func (o *InputS3) GetParquetChunkDownloadTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.ParquetChunkDownloadTimeout
}

func (o *InputS3) GetCheckpointing() *InputS3Checkpointing {
	if o == nil {
		return nil
	}
	return o.Checkpointing
}

func (o *InputS3) GetPollTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.PollTimeout
}

func (o *InputS3) GetEncoding() *string {
	if o == nil {
		return nil
	}
	return o.Encoding
}

func (o *InputS3) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputS3) GetAwsAPIKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsAPIKey
}

func (o *InputS3) GetAwsSecret() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecret
}

func (o *InputS3) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputMetricsType string

const (
	InputMetricsTypeMetrics InputMetricsType = "metrics"
)

func (e InputMetricsType) ToPointer() *InputMetricsType {
	return &e
}
func (e *InputMetricsType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "metrics":
		*e = InputMetricsType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputMetricsType: %v", v)
	}
}

type InputMetricsConnections struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *InputMetricsConnections) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputMetricsConnections) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// InputMetricsMode - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputMetricsMode string

const (
	InputMetricsModeSmart  InputMetricsMode = "smart"
	InputMetricsModeAlways InputMetricsMode = "always"
)

func (e InputMetricsMode) ToPointer() *InputMetricsMode {
	return &e
}
func (e *InputMetricsMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputMetricsMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputMetricsMode: %v", v)
	}
}

// InputMetricsCompression - Codec to use to compress the persisted data
type InputMetricsCompression string

const (
	InputMetricsCompressionNone InputMetricsCompression = "none"
	InputMetricsCompressionGzip InputMetricsCompression = "gzip"
)

func (e InputMetricsCompression) ToPointer() *InputMetricsCompression {
	return &e
}
func (e *InputMetricsCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputMetricsCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputMetricsCompression: %v", v)
	}
}

type InputMetricsPq struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputMetricsMode `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *InputMetricsCompression `default:"none" json:"compress"`
}

func (i InputMetricsPq) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputMetricsPq) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputMetricsPq) GetMode() *InputMetricsMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputMetricsPq) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputMetricsPq) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *InputMetricsPq) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *InputMetricsPq) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *InputMetricsPq) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *InputMetricsPq) GetCompress() *InputMetricsCompression {
	if o == nil {
		return nil
	}
	return o.Compress
}

// InputMetricsMinimumTLSVersion - Minimum TLS version to accept from connections
type InputMetricsMinimumTLSVersion string

const (
	InputMetricsMinimumTLSVersionTlSv1  InputMetricsMinimumTLSVersion = "TLSv1"
	InputMetricsMinimumTLSVersionTlSv11 InputMetricsMinimumTLSVersion = "TLSv1.1"
	InputMetricsMinimumTLSVersionTlSv12 InputMetricsMinimumTLSVersion = "TLSv1.2"
	InputMetricsMinimumTLSVersionTlSv13 InputMetricsMinimumTLSVersion = "TLSv1.3"
)

func (e InputMetricsMinimumTLSVersion) ToPointer() *InputMetricsMinimumTLSVersion {
	return &e
}
func (e *InputMetricsMinimumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputMetricsMinimumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputMetricsMinimumTLSVersion: %v", v)
	}
}

// InputMetricsMaximumTLSVersion - Maximum TLS version to accept from connections
type InputMetricsMaximumTLSVersion string

const (
	InputMetricsMaximumTLSVersionTlSv1  InputMetricsMaximumTLSVersion = "TLSv1"
	InputMetricsMaximumTLSVersionTlSv11 InputMetricsMaximumTLSVersion = "TLSv1.1"
	InputMetricsMaximumTLSVersionTlSv12 InputMetricsMaximumTLSVersion = "TLSv1.2"
	InputMetricsMaximumTLSVersionTlSv13 InputMetricsMaximumTLSVersion = "TLSv1.3"
)

func (e InputMetricsMaximumTLSVersion) ToPointer() *InputMetricsMaximumTLSVersion {
	return &e
}
func (e *InputMetricsMaximumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputMetricsMaximumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputMetricsMaximumTLSVersion: %v", v)
	}
}

type InputMetricsTLSSettingsServerSide struct {
	Disabled *bool `default:"true" json:"disabled"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert        *bool `default:"false" json:"requestCert"`
	RejectUnauthorized any   `json:"rejectUnauthorized,omitempty"`
	CommonNameRegex    any   `json:"commonNameRegex,omitempty"`
	// Minimum TLS version to accept from connections
	MinVersion *InputMetricsMinimumTLSVersion `json:"minVersion,omitempty"`
	// Maximum TLS version to accept from connections
	MaxVersion *InputMetricsMaximumTLSVersion `json:"maxVersion,omitempty"`
}

func (i InputMetricsTLSSettingsServerSide) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputMetricsTLSSettingsServerSide) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputMetricsTLSSettingsServerSide) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputMetricsTLSSettingsServerSide) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *InputMetricsTLSSettingsServerSide) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *InputMetricsTLSSettingsServerSide) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *InputMetricsTLSSettingsServerSide) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *InputMetricsTLSSettingsServerSide) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *InputMetricsTLSSettingsServerSide) GetRequestCert() *bool {
	if o == nil {
		return nil
	}
	return o.RequestCert
}

func (o *InputMetricsTLSSettingsServerSide) GetRejectUnauthorized() any {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *InputMetricsTLSSettingsServerSide) GetCommonNameRegex() any {
	if o == nil {
		return nil
	}
	return o.CommonNameRegex
}

func (o *InputMetricsTLSSettingsServerSide) GetMinVersion() *InputMetricsMinimumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *InputMetricsTLSSettingsServerSide) GetMaxVersion() *InputMetricsMaximumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

type InputMetricsMetadata struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputMetricsMetadata) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputMetricsMetadata) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputMetrics struct {
	// Unique ID for this input
	ID       *string          `json:"id,omitempty"`
	Type     InputMetricsType `json:"type"`
	Disabled *bool            `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputMetricsConnections `json:"connections,omitempty"`
	Pq          *InputMetricsPq           `json:"pq,omitempty"`
	// Address to bind on. For IPv4 (all addresses), use the default '0.0.0.0'. For IPv6, enter '::' (all addresses) or specify an IP address.
	Host *string `default:"0.0.0.0" json:"host"`
	// Enter UDP port number to listen on. Not required if listening on TCP.
	UDPPort *float64 `json:"udpPort,omitempty"`
	// Enter TCP port number to listen on. Not required if listening on UDP.
	TCPPort *float64 `json:"tcpPort,omitempty"`
	// Maximum number of events to buffer when downstream is blocking. Only applies to UDP.
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// Regex matching IP addresses that are allowed to send data
	IPWhitelistRegex *string `default:"/.*/" json:"ipWhitelistRegex"`
	// Enable if the connection is proxied by a device that supports Proxy Protocol V1 or V2
	EnableProxyHeader *bool                              `default:"false" json:"enableProxyHeader"`
	TLS               *InputMetricsTLSSettingsServerSide `json:"tls,omitempty"`
	// Fields to add to events from this input
	Metadata []InputMetricsMetadata `json:"metadata,omitempty"`
	// Optionally, set the SO_RCVBUF socket option for the UDP socket. This value tells the operating system how many bytes can be buffered in the kernel before events are dropped. Leave blank to use the OS default. Caution: Increasing this value will affect OS memory utilization.
	UDPSocketRxBufSize *float64  `json:"udpSocketRxBufSize,omitempty"`
	Description        *string   `json:"description,omitempty"`
	Status             *TFStatus `json:"status,omitempty"`
}

func (i InputMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputMetrics) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputMetrics) GetType() InputMetricsType {
	if o == nil {
		return InputMetricsType("")
	}
	return o.Type
}

func (o *InputMetrics) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputMetrics) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputMetrics) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputMetrics) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputMetrics) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputMetrics) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputMetrics) GetConnections() []InputMetricsConnections {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputMetrics) GetPq() *InputMetricsPq {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputMetrics) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputMetrics) GetUDPPort() *float64 {
	if o == nil {
		return nil
	}
	return o.UDPPort
}

func (o *InputMetrics) GetTCPPort() *float64 {
	if o == nil {
		return nil
	}
	return o.TCPPort
}

func (o *InputMetrics) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputMetrics) GetIPWhitelistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPWhitelistRegex
}

func (o *InputMetrics) GetEnableProxyHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableProxyHeader
}

func (o *InputMetrics) GetTLS() *InputMetricsTLSSettingsServerSide {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputMetrics) GetMetadata() []InputMetricsMetadata {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputMetrics) GetUDPSocketRxBufSize() *float64 {
	if o == nil {
		return nil
	}
	return o.UDPSocketRxBufSize
}

func (o *InputMetrics) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputMetrics) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputCriblmetricsType string

const (
	InputCriblmetricsTypeCriblmetrics InputCriblmetricsType = "criblmetrics"
)

func (e InputCriblmetricsType) ToPointer() *InputCriblmetricsType {
	return &e
}
func (e *InputCriblmetricsType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "criblmetrics":
		*e = InputCriblmetricsType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputCriblmetricsType: %v", v)
	}
}

type InputCriblmetricsConnections struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *InputCriblmetricsConnections) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputCriblmetricsConnections) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// InputCriblmetricsMode - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputCriblmetricsMode string

const (
	InputCriblmetricsModeSmart  InputCriblmetricsMode = "smart"
	InputCriblmetricsModeAlways InputCriblmetricsMode = "always"
)

func (e InputCriblmetricsMode) ToPointer() *InputCriblmetricsMode {
	return &e
}
func (e *InputCriblmetricsMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputCriblmetricsMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputCriblmetricsMode: %v", v)
	}
}

// InputCriblmetricsCompression - Codec to use to compress the persisted data
type InputCriblmetricsCompression string

const (
	InputCriblmetricsCompressionNone InputCriblmetricsCompression = "none"
	InputCriblmetricsCompressionGzip InputCriblmetricsCompression = "gzip"
)

func (e InputCriblmetricsCompression) ToPointer() *InputCriblmetricsCompression {
	return &e
}
func (e *InputCriblmetricsCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputCriblmetricsCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputCriblmetricsCompression: %v", v)
	}
}

type InputCriblmetricsPq struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputCriblmetricsMode `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *InputCriblmetricsCompression `default:"none" json:"compress"`
}

func (i InputCriblmetricsPq) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputCriblmetricsPq) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputCriblmetricsPq) GetMode() *InputCriblmetricsMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputCriblmetricsPq) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputCriblmetricsPq) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *InputCriblmetricsPq) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *InputCriblmetricsPq) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *InputCriblmetricsPq) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *InputCriblmetricsPq) GetCompress() *InputCriblmetricsCompression {
	if o == nil {
		return nil
	}
	return o.Compress
}

type InputCriblmetricsMetadata struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputCriblmetricsMetadata) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputCriblmetricsMetadata) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputCriblmetrics struct {
	// Unique ID for this input
	ID       string                `json:"id"`
	Type     InputCriblmetricsType `json:"type"`
	Disabled *bool                 `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputCriblmetricsConnections `json:"connections,omitempty"`
	Pq          *InputCriblmetricsPq           `json:"pq,omitempty"`
	// A prefix that is applied to the metrics provided by Cribl Stream
	Prefix *string `default:"cribl.logstream." json:"prefix"`
	// Include granular metrics.  Disabling this will drop the following metrics events: `cribl.logstream.host.(in_bytes,in_events,out_bytes,out_events)`, `cribl.logstream.index.(in_bytes,in_events,out_bytes,out_events)`, `cribl.logstream.source.(in_bytes,in_events,out_bytes,out_events)`, `cribl.logstream.sourcetype.(in_bytes,in_events,out_bytes,out_events)`.
	FullFidelity *bool `default:"true" json:"fullFidelity"`
	// Fields to add to events from this input
	Metadata    []InputCriblmetricsMetadata `json:"metadata,omitempty"`
	Description *string                     `json:"description,omitempty"`
	Status      *TFStatus                   `json:"status,omitempty"`
}

func (i InputCriblmetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputCriblmetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputCriblmetrics) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *InputCriblmetrics) GetType() InputCriblmetricsType {
	if o == nil {
		return InputCriblmetricsType("")
	}
	return o.Type
}

func (o *InputCriblmetrics) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputCriblmetrics) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputCriblmetrics) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputCriblmetrics) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputCriblmetrics) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputCriblmetrics) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputCriblmetrics) GetConnections() []InputCriblmetricsConnections {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputCriblmetrics) GetPq() *InputCriblmetricsPq {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputCriblmetrics) GetPrefix() *string {
	if o == nil {
		return nil
	}
	return o.Prefix
}

func (o *InputCriblmetrics) GetFullFidelity() *bool {
	if o == nil {
		return nil
	}
	return o.FullFidelity
}

func (o *InputCriblmetrics) GetMetadata() []InputCriblmetricsMetadata {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputCriblmetrics) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputCriblmetrics) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputKinesisType string

const (
	InputKinesisTypeKinesis InputKinesisType = "kinesis"
)

func (e InputKinesisType) ToPointer() *InputKinesisType {
	return &e
}
func (e *InputKinesisType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "kinesis":
		*e = InputKinesisType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputKinesisType: %v", v)
	}
}

type InputKinesisConnections struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *InputKinesisConnections) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputKinesisConnections) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// InputKinesisMode - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputKinesisMode string

const (
	InputKinesisModeSmart  InputKinesisMode = "smart"
	InputKinesisModeAlways InputKinesisMode = "always"
)

func (e InputKinesisMode) ToPointer() *InputKinesisMode {
	return &e
}
func (e *InputKinesisMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputKinesisMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputKinesisMode: %v", v)
	}
}

// InputKinesisCompression - Codec to use to compress the persisted data
type InputKinesisCompression string

const (
	InputKinesisCompressionNone InputKinesisCompression = "none"
	InputKinesisCompressionGzip InputKinesisCompression = "gzip"
)

func (e InputKinesisCompression) ToPointer() *InputKinesisCompression {
	return &e
}
func (e *InputKinesisCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputKinesisCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputKinesisCompression: %v", v)
	}
}

type InputKinesisPq struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputKinesisMode `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *InputKinesisCompression `default:"none" json:"compress"`
}

func (i InputKinesisPq) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputKinesisPq) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputKinesisPq) GetMode() *InputKinesisMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputKinesisPq) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputKinesisPq) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *InputKinesisPq) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *InputKinesisPq) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *InputKinesisPq) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *InputKinesisPq) GetCompress() *InputKinesisCompression {
	if o == nil {
		return nil
	}
	return o.Compress
}

// ShardIteratorStart - Location at which to start reading a shard for the first time.
type ShardIteratorStart string

const (
	ShardIteratorStartTrimHorizon ShardIteratorStart = "TRIM_HORIZON"
	ShardIteratorStartLatest      ShardIteratorStart = "LATEST"
)

func (e ShardIteratorStart) ToPointer() *ShardIteratorStart {
	return &e
}
func (e *ShardIteratorStart) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TRIM_HORIZON":
		fallthrough
	case "LATEST":
		*e = ShardIteratorStart(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ShardIteratorStart: %v", v)
	}
}

// RecordDataFormat - Format of data inside the Kinesis Stream records. Gzip compression is automatically detected.
type RecordDataFormat string

const (
	RecordDataFormatCribl      RecordDataFormat = "cribl"
	RecordDataFormatNdjson     RecordDataFormat = "ndjson"
	RecordDataFormatCloudwatch RecordDataFormat = "cloudwatch"
	RecordDataFormatLine       RecordDataFormat = "line"
)

func (e RecordDataFormat) ToPointer() *RecordDataFormat {
	return &e
}
func (e *RecordDataFormat) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "cribl":
		fallthrough
	case "ndjson":
		fallthrough
	case "cloudwatch":
		fallthrough
	case "line":
		*e = RecordDataFormat(v)
		return nil
	default:
		return fmt.Errorf("invalid value for RecordDataFormat: %v", v)
	}
}

// ShardLoadBalancing - The load-balancing algorithm to use for spreading out shards across Workers and Worker Processes
type ShardLoadBalancing string

const (
	ShardLoadBalancingConsistentHashing ShardLoadBalancing = "ConsistentHashing"
	ShardLoadBalancingRoundRobin        ShardLoadBalancing = "RoundRobin"
)

func (e ShardLoadBalancing) ToPointer() *ShardLoadBalancing {
	return &e
}
func (e *ShardLoadBalancing) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "ConsistentHashing":
		fallthrough
	case "RoundRobin":
		*e = ShardLoadBalancing(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ShardLoadBalancing: %v", v)
	}
}

// InputKinesisAuthenticationMethod - AWS authentication method. Choose Auto to use IAM roles.
type InputKinesisAuthenticationMethod string

const (
	InputKinesisAuthenticationMethodAuto   InputKinesisAuthenticationMethod = "auto"
	InputKinesisAuthenticationMethodManual InputKinesisAuthenticationMethod = "manual"
	InputKinesisAuthenticationMethodSecret InputKinesisAuthenticationMethod = "secret"
)

func (e InputKinesisAuthenticationMethod) ToPointer() *InputKinesisAuthenticationMethod {
	return &e
}
func (e *InputKinesisAuthenticationMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "auto":
		fallthrough
	case "manual":
		fallthrough
	case "secret":
		*e = InputKinesisAuthenticationMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputKinesisAuthenticationMethod: %v", v)
	}
}

// InputKinesisSignatureVersion - Signature version to use for signing Kinesis stream requests
type InputKinesisSignatureVersion string

const (
	InputKinesisSignatureVersionV2 InputKinesisSignatureVersion = "v2"
	InputKinesisSignatureVersionV4 InputKinesisSignatureVersion = "v4"
)

func (e InputKinesisSignatureVersion) ToPointer() *InputKinesisSignatureVersion {
	return &e
}
func (e *InputKinesisSignatureVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "v2":
		fallthrough
	case "v4":
		*e = InputKinesisSignatureVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputKinesisSignatureVersion: %v", v)
	}
}

type InputKinesisMetadata struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputKinesisMetadata) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputKinesisMetadata) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputKinesis struct {
	// Unique ID for this input
	ID       *string           `json:"id,omitempty"`
	Type     *InputKinesisType `json:"type,omitempty"`
	Disabled *bool             `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputKinesisConnections `json:"connections,omitempty"`
	Pq          *InputKinesisPq           `json:"pq,omitempty"`
	// Kinesis stream name to read data from.
	StreamName string `json:"streamName"`
	// Time interval in minutes between consecutive service calls
	ServiceInterval *float64 `default:"1" json:"serviceInterval"`
	// A JS expression to be called with each shardId for the stream, if the expression evalutates to a truthy value the shard will be processed.
	ShardExpr *string `default:"true" json:"shardExpr"`
	// Location at which to start reading a shard for the first time.
	ShardIteratorType *ShardIteratorStart `default:"TRIM_HORIZON" json:"shardIteratorType"`
	// Format of data inside the Kinesis Stream records. Gzip compression is automatically detected.
	PayloadFormat *RecordDataFormat `default:"cribl" json:"payloadFormat"`
	// Maximum number of records per getRecords call
	GetRecordsLimit *float64 `default:"5000" json:"getRecordsLimit"`
	// Maximum number of records, across all shards, to pull down at once per Worker Process
	GetRecordsLimitTotal *float64 `default:"20000" json:"getRecordsLimitTotal"`
	// The load-balancing algorithm to use for spreading out shards across Workers and Worker Processes
	LoadBalancingAlgorithm *ShardLoadBalancing `default:"ConsistentHashing" json:"loadBalancingAlgorithm"`
	// AWS authentication method. Choose Auto to use IAM roles.
	AwsAuthenticationMethod *InputKinesisAuthenticationMethod `default:"auto" json:"awsAuthenticationMethod"`
	AwsSecretKey            *string                           `json:"awsSecretKey,omitempty"`
	// Region where the Kinesis stream is located
	Region string `json:"region"`
	// Kinesis stream service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to Kinesis stream-compatible endpoint.
	Endpoint *string `json:"endpoint,omitempty"`
	// Signature version to use for signing Kinesis stream requests
	SignatureVersion *InputKinesisSignatureVersion `default:"v4" json:"signatureVersion"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `default:"true" json:"reuseConnections"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Use Assume Role credentials to access Kinesis stream
	EnableAssumeRole *bool `default:"false" json:"enableAssumeRole"`
	// Amazon Resource Name (ARN) of the role to assume
	AssumeRoleArn *string `json:"assumeRoleArn,omitempty"`
	// External ID to use when assuming role
	AssumeRoleExternalID *string `json:"assumeRoleExternalId,omitempty"`
	// Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
	DurationSeconds *float64 `default:"3600" json:"durationSeconds"`
	// Verify Kinesis Producer Library (KPL) event checksums
	VerifyKPLCheckSums *bool `default:"false" json:"verifyKPLCheckSums"`
	// Yes means: when resuming streaming from a stored state, Stream will read the next available record, rather than rereading the last-read record. Enabling this can cause data loss after a Worker Node's unexpected shutdown or restart.
	AvoidDuplicates *bool `default:"false" json:"avoidDuplicates"`
	// Fields to add to events from this input
	Metadata    []InputKinesisMetadata `json:"metadata,omitempty"`
	Description *string                `json:"description,omitempty"`
	AwsAPIKey   *string                `json:"awsApiKey,omitempty"`
	// Select or create a stored secret that references your access key and secret key
	AwsSecret *string   `json:"awsSecret,omitempty"`
	Status    *TFStatus `json:"status,omitempty"`
}

func (i InputKinesis) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputKinesis) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputKinesis) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputKinesis) GetType() *InputKinesisType {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputKinesis) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputKinesis) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputKinesis) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputKinesis) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputKinesis) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputKinesis) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputKinesis) GetConnections() []InputKinesisConnections {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputKinesis) GetPq() *InputKinesisPq {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputKinesis) GetStreamName() string {
	if o == nil {
		return ""
	}
	return o.StreamName
}

func (o *InputKinesis) GetServiceInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.ServiceInterval
}

func (o *InputKinesis) GetShardExpr() *string {
	if o == nil {
		return nil
	}
	return o.ShardExpr
}

func (o *InputKinesis) GetShardIteratorType() *ShardIteratorStart {
	if o == nil {
		return nil
	}
	return o.ShardIteratorType
}

func (o *InputKinesis) GetPayloadFormat() *RecordDataFormat {
	if o == nil {
		return nil
	}
	return o.PayloadFormat
}

func (o *InputKinesis) GetGetRecordsLimit() *float64 {
	if o == nil {
		return nil
	}
	return o.GetRecordsLimit
}

func (o *InputKinesis) GetGetRecordsLimitTotal() *float64 {
	if o == nil {
		return nil
	}
	return o.GetRecordsLimitTotal
}

func (o *InputKinesis) GetLoadBalancingAlgorithm() *ShardLoadBalancing {
	if o == nil {
		return nil
	}
	return o.LoadBalancingAlgorithm
}

func (o *InputKinesis) GetAwsAuthenticationMethod() *InputKinesisAuthenticationMethod {
	if o == nil {
		return nil
	}
	return o.AwsAuthenticationMethod
}

func (o *InputKinesis) GetAwsSecretKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecretKey
}

func (o *InputKinesis) GetRegion() string {
	if o == nil {
		return ""
	}
	return o.Region
}

func (o *InputKinesis) GetEndpoint() *string {
	if o == nil {
		return nil
	}
	return o.Endpoint
}

func (o *InputKinesis) GetSignatureVersion() *InputKinesisSignatureVersion {
	if o == nil {
		return nil
	}
	return o.SignatureVersion
}

func (o *InputKinesis) GetReuseConnections() *bool {
	if o == nil {
		return nil
	}
	return o.ReuseConnections
}

func (o *InputKinesis) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *InputKinesis) GetEnableAssumeRole() *bool {
	if o == nil {
		return nil
	}
	return o.EnableAssumeRole
}

func (o *InputKinesis) GetAssumeRoleArn() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleArn
}

func (o *InputKinesis) GetAssumeRoleExternalID() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleExternalID
}

func (o *InputKinesis) GetDurationSeconds() *float64 {
	if o == nil {
		return nil
	}
	return o.DurationSeconds
}

func (o *InputKinesis) GetVerifyKPLCheckSums() *bool {
	if o == nil {
		return nil
	}
	return o.VerifyKPLCheckSums
}

func (o *InputKinesis) GetAvoidDuplicates() *bool {
	if o == nil {
		return nil
	}
	return o.AvoidDuplicates
}

func (o *InputKinesis) GetMetadata() []InputKinesisMetadata {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputKinesis) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputKinesis) GetAwsAPIKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsAPIKey
}

func (o *InputKinesis) GetAwsSecret() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecret
}

func (o *InputKinesis) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputHTTPRawType string

const (
	InputHTTPRawTypeHTTPRaw InputHTTPRawType = "http_raw"
)

func (e InputHTTPRawType) ToPointer() *InputHTTPRawType {
	return &e
}
func (e *InputHTTPRawType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "http_raw":
		*e = InputHTTPRawType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputHTTPRawType: %v", v)
	}
}

type InputHTTPRawConnections struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *InputHTTPRawConnections) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputHTTPRawConnections) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// InputHTTPRawMode - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputHTTPRawMode string

const (
	InputHTTPRawModeSmart  InputHTTPRawMode = "smart"
	InputHTTPRawModeAlways InputHTTPRawMode = "always"
)

func (e InputHTTPRawMode) ToPointer() *InputHTTPRawMode {
	return &e
}
func (e *InputHTTPRawMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputHTTPRawMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputHTTPRawMode: %v", v)
	}
}

// InputHTTPRawCompression - Codec to use to compress the persisted data
type InputHTTPRawCompression string

const (
	InputHTTPRawCompressionNone InputHTTPRawCompression = "none"
	InputHTTPRawCompressionGzip InputHTTPRawCompression = "gzip"
)

func (e InputHTTPRawCompression) ToPointer() *InputHTTPRawCompression {
	return &e
}
func (e *InputHTTPRawCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputHTTPRawCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputHTTPRawCompression: %v", v)
	}
}

type InputHTTPRawPq struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputHTTPRawMode `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *InputHTTPRawCompression `default:"none" json:"compress"`
}

func (i InputHTTPRawPq) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputHTTPRawPq) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputHTTPRawPq) GetMode() *InputHTTPRawMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputHTTPRawPq) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputHTTPRawPq) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *InputHTTPRawPq) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *InputHTTPRawPq) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *InputHTTPRawPq) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *InputHTTPRawPq) GetCompress() *InputHTTPRawCompression {
	if o == nil {
		return nil
	}
	return o.Compress
}

// InputHTTPRawMinimumTLSVersion - Minimum TLS version to accept from connections
type InputHTTPRawMinimumTLSVersion string

const (
	InputHTTPRawMinimumTLSVersionTlSv1  InputHTTPRawMinimumTLSVersion = "TLSv1"
	InputHTTPRawMinimumTLSVersionTlSv11 InputHTTPRawMinimumTLSVersion = "TLSv1.1"
	InputHTTPRawMinimumTLSVersionTlSv12 InputHTTPRawMinimumTLSVersion = "TLSv1.2"
	InputHTTPRawMinimumTLSVersionTlSv13 InputHTTPRawMinimumTLSVersion = "TLSv1.3"
)

func (e InputHTTPRawMinimumTLSVersion) ToPointer() *InputHTTPRawMinimumTLSVersion {
	return &e
}
func (e *InputHTTPRawMinimumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputHTTPRawMinimumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputHTTPRawMinimumTLSVersion: %v", v)
	}
}

// InputHTTPRawMaximumTLSVersion - Maximum TLS version to accept from connections
type InputHTTPRawMaximumTLSVersion string

const (
	InputHTTPRawMaximumTLSVersionTlSv1  InputHTTPRawMaximumTLSVersion = "TLSv1"
	InputHTTPRawMaximumTLSVersionTlSv11 InputHTTPRawMaximumTLSVersion = "TLSv1.1"
	InputHTTPRawMaximumTLSVersionTlSv12 InputHTTPRawMaximumTLSVersion = "TLSv1.2"
	InputHTTPRawMaximumTLSVersionTlSv13 InputHTTPRawMaximumTLSVersion = "TLSv1.3"
)

func (e InputHTTPRawMaximumTLSVersion) ToPointer() *InputHTTPRawMaximumTLSVersion {
	return &e
}
func (e *InputHTTPRawMaximumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputHTTPRawMaximumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputHTTPRawMaximumTLSVersion: %v", v)
	}
}

type InputHTTPRawTLSSettingsServerSide struct {
	Disabled *bool `default:"true" json:"disabled"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert        *bool `default:"false" json:"requestCert"`
	RejectUnauthorized any   `json:"rejectUnauthorized,omitempty"`
	CommonNameRegex    any   `json:"commonNameRegex,omitempty"`
	// Minimum TLS version to accept from connections
	MinVersion *InputHTTPRawMinimumTLSVersion `json:"minVersion,omitempty"`
	// Maximum TLS version to accept from connections
	MaxVersion *InputHTTPRawMaximumTLSVersion `json:"maxVersion,omitempty"`
}

func (i InputHTTPRawTLSSettingsServerSide) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputHTTPRawTLSSettingsServerSide) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputHTTPRawTLSSettingsServerSide) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputHTTPRawTLSSettingsServerSide) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *InputHTTPRawTLSSettingsServerSide) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *InputHTTPRawTLSSettingsServerSide) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *InputHTTPRawTLSSettingsServerSide) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *InputHTTPRawTLSSettingsServerSide) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *InputHTTPRawTLSSettingsServerSide) GetRequestCert() *bool {
	if o == nil {
		return nil
	}
	return o.RequestCert
}

func (o *InputHTTPRawTLSSettingsServerSide) GetRejectUnauthorized() any {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *InputHTTPRawTLSSettingsServerSide) GetCommonNameRegex() any {
	if o == nil {
		return nil
	}
	return o.CommonNameRegex
}

func (o *InputHTTPRawTLSSettingsServerSide) GetMinVersion() *InputHTTPRawMinimumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *InputHTTPRawTLSSettingsServerSide) GetMaxVersion() *InputHTTPRawMaximumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

type InputHTTPRawMetadata struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputHTTPRawMetadata) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputHTTPRawMetadata) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputHTTPRawInputMetadata struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputHTTPRawInputMetadata) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputHTTPRawInputMetadata) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputHTTPRawAuthTokensExt struct {
	// Shared secret to be provided by any client (Authorization: <token>)
	Token       string  `json:"token"`
	Description *string `json:"description,omitempty"`
	// Fields to add to events referencing this token
	Metadata []InputHTTPRawInputMetadata `json:"metadata,omitempty"`
}

func (o *InputHTTPRawAuthTokensExt) GetToken() string {
	if o == nil {
		return ""
	}
	return o.Token
}

func (o *InputHTTPRawAuthTokensExt) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputHTTPRawAuthTokensExt) GetMetadata() []InputHTTPRawInputMetadata {
	if o == nil {
		return nil
	}
	return o.Metadata
}

type InputHTTPRaw struct {
	// Unique ID for this input
	ID       *string           `json:"id,omitempty"`
	Type     *InputHTTPRawType `json:"type,omitempty"`
	Disabled *bool             `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputHTTPRawConnections `json:"connections,omitempty"`
	Pq          *InputHTTPRawPq           `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port float64 `json:"port"`
	// Shared secrets to be provided by any client (Authorization: <token>). If empty, unauthorized access is permitted.
	AuthTokens []string                           `json:"authTokens,omitempty"`
	TLS        *InputHTTPRawTLSSettingsServerSide `json:"tls,omitempty"`
	// Maximum number of active requests per Worker Process. Use 0 for unlimited.
	MaxActiveReq *float64 `default:"256" json:"maxActiveReq"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket *int64 `default:"0" json:"maxRequestsPerSocket"`
	// Enable when clients are connecting through a proxy that supports the x-forwarded-for header to keep the client's original IP address on the event instead of the proxy's IP address
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Add request headers to events, in the __headers field
	CaptureHeaders *bool `default:"false" json:"captureHeaders"`
	// How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
	ActivityLogSampleRate *float64 `default:"100" json:"activityLogSampleRate"`
	// How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
	RequestTimeout *float64 `default:"0" json:"requestTimeout"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `default:"0" json:"socketTimeout"`
	// After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 sec.; maximum 600 sec. (10 min.).
	KeepAliveTimeout *float64 `default:"5" json:"keepAliveTimeout"`
	// Enable to expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
	EnableHealthCheck *bool `default:"false" json:"enableHealthCheck"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist
	IPAllowlistRegex *string `default:"/.*/" json:"ipAllowlistRegex"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `default:"/^\\$/" json:"ipDenylistRegex"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitempty"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `default:"10000" json:"staleChannelFlushMs"`
	// Fields to add to events from this input
	Metadata []InputHTTPRawMetadata `json:"metadata,omitempty"`
	// List of URI paths accepted by this input, wildcards are supported, e.g /api/v*/hook. Defaults to allow all.
	AllowedPaths []string `json:"allowedPaths,omitempty"`
	// List of HTTP methods accepted by this input, wildcards are supported, e.g. P*, GET. Defaults to allow all.
	AllowedMethods []string `json:"allowedMethods,omitempty"`
	// Shared secrets to be provided by any client (Authorization: <token>). If empty, unauthorized access is permitted.
	AuthTokensExt []InputHTTPRawAuthTokensExt `json:"authTokensExt,omitempty"`
	Description   *string                     `json:"description,omitempty"`
	Status        *TFStatus                   `json:"status,omitempty"`
}

func (i InputHTTPRaw) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputHTTPRaw) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputHTTPRaw) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputHTTPRaw) GetType() *InputHTTPRawType {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputHTTPRaw) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputHTTPRaw) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputHTTPRaw) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputHTTPRaw) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputHTTPRaw) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputHTTPRaw) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputHTTPRaw) GetConnections() []InputHTTPRawConnections {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputHTTPRaw) GetPq() *InputHTTPRawPq {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputHTTPRaw) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputHTTPRaw) GetPort() float64 {
	if o == nil {
		return 0.0
	}
	return o.Port
}

func (o *InputHTTPRaw) GetAuthTokens() []string {
	if o == nil {
		return nil
	}
	return o.AuthTokens
}

func (o *InputHTTPRaw) GetTLS() *InputHTTPRawTLSSettingsServerSide {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputHTTPRaw) GetMaxActiveReq() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxActiveReq
}

func (o *InputHTTPRaw) GetMaxRequestsPerSocket() *int64 {
	if o == nil {
		return nil
	}
	return o.MaxRequestsPerSocket
}

func (o *InputHTTPRaw) GetEnableProxyHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableProxyHeader
}

func (o *InputHTTPRaw) GetCaptureHeaders() *bool {
	if o == nil {
		return nil
	}
	return o.CaptureHeaders
}

func (o *InputHTTPRaw) GetActivityLogSampleRate() *float64 {
	if o == nil {
		return nil
	}
	return o.ActivityLogSampleRate
}

func (o *InputHTTPRaw) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *InputHTTPRaw) GetSocketTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketTimeout
}

func (o *InputHTTPRaw) GetKeepAliveTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.KeepAliveTimeout
}

func (o *InputHTTPRaw) GetEnableHealthCheck() *bool {
	if o == nil {
		return nil
	}
	return o.EnableHealthCheck
}

func (o *InputHTTPRaw) GetIPAllowlistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPAllowlistRegex
}

func (o *InputHTTPRaw) GetIPDenylistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPDenylistRegex
}

func (o *InputHTTPRaw) GetBreakerRulesets() []string {
	if o == nil {
		return nil
	}
	return o.BreakerRulesets
}

func (o *InputHTTPRaw) GetStaleChannelFlushMs() *float64 {
	if o == nil {
		return nil
	}
	return o.StaleChannelFlushMs
}

func (o *InputHTTPRaw) GetMetadata() []InputHTTPRawMetadata {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputHTTPRaw) GetAllowedPaths() []string {
	if o == nil {
		return nil
	}
	return o.AllowedPaths
}

func (o *InputHTTPRaw) GetAllowedMethods() []string {
	if o == nil {
		return nil
	}
	return o.AllowedMethods
}

func (o *InputHTTPRaw) GetAuthTokensExt() []InputHTTPRawAuthTokensExt {
	if o == nil {
		return nil
	}
	return o.AuthTokensExt
}

func (o *InputHTTPRaw) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputHTTPRaw) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputDatagenType string

const (
	InputDatagenTypeDatagen InputDatagenType = "datagen"
)

func (e InputDatagenType) ToPointer() *InputDatagenType {
	return &e
}
func (e *InputDatagenType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "datagen":
		*e = InputDatagenType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputDatagenType: %v", v)
	}
}

type InputDatagenConnections struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *InputDatagenConnections) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputDatagenConnections) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// InputDatagenMode - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputDatagenMode string

const (
	InputDatagenModeSmart  InputDatagenMode = "smart"
	InputDatagenModeAlways InputDatagenMode = "always"
)

func (e InputDatagenMode) ToPointer() *InputDatagenMode {
	return &e
}
func (e *InputDatagenMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputDatagenMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputDatagenMode: %v", v)
	}
}

// InputDatagenCompression - Codec to use to compress the persisted data
type InputDatagenCompression string

const (
	InputDatagenCompressionNone InputDatagenCompression = "none"
	InputDatagenCompressionGzip InputDatagenCompression = "gzip"
)

func (e InputDatagenCompression) ToPointer() *InputDatagenCompression {
	return &e
}
func (e *InputDatagenCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputDatagenCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputDatagenCompression: %v", v)
	}
}

type InputDatagenPq struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputDatagenMode `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *InputDatagenCompression `default:"none" json:"compress"`
}

func (i InputDatagenPq) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputDatagenPq) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputDatagenPq) GetMode() *InputDatagenMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputDatagenPq) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputDatagenPq) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *InputDatagenPq) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *InputDatagenPq) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *InputDatagenPq) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *InputDatagenPq) GetCompress() *InputDatagenCompression {
	if o == nil {
		return nil
	}
	return o.Compress
}

type InputDatagenSamples struct {
	// Name of the datagen file
	Sample string `json:"sample"`
	// Maximum no. of events to generate per second per worker node. Defaults to 10.
	EventsPerSec *float64 `default:"10" json:"eventsPerSec"`
}

func (i InputDatagenSamples) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputDatagenSamples) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputDatagenSamples) GetSample() string {
	if o == nil {
		return ""
	}
	return o.Sample
}

func (o *InputDatagenSamples) GetEventsPerSec() *float64 {
	if o == nil {
		return nil
	}
	return o.EventsPerSec
}

type InputDatagenMetadata struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputDatagenMetadata) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputDatagenMetadata) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputDatagen struct {
	// Unique ID for this input
	ID       *string          `json:"id,omitempty"`
	Type     InputDatagenType `json:"type"`
	Disabled *bool            `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputDatagenConnections `json:"connections,omitempty"`
	Pq          *InputDatagenPq           `json:"pq,omitempty"`
	// List of datagens
	Samples []InputDatagenSamples `json:"samples"`
	// Fields to add to events from this input
	Metadata    []InputDatagenMetadata `json:"metadata,omitempty"`
	Description *string                `json:"description,omitempty"`
	Status      *TFStatus              `json:"status,omitempty"`
}

func (i InputDatagen) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputDatagen) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputDatagen) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputDatagen) GetType() InputDatagenType {
	if o == nil {
		return InputDatagenType("")
	}
	return o.Type
}

func (o *InputDatagen) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputDatagen) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputDatagen) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputDatagen) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputDatagen) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputDatagen) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputDatagen) GetConnections() []InputDatagenConnections {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputDatagen) GetPq() *InputDatagenPq {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputDatagen) GetSamples() []InputDatagenSamples {
	if o == nil {
		return []InputDatagenSamples{}
	}
	return o.Samples
}

func (o *InputDatagen) GetMetadata() []InputDatagenMetadata {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputDatagen) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputDatagen) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputDatadogAgentType string

const (
	InputDatadogAgentTypeDatadogAgent InputDatadogAgentType = "datadog_agent"
)

func (e InputDatadogAgentType) ToPointer() *InputDatadogAgentType {
	return &e
}
func (e *InputDatadogAgentType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "datadog_agent":
		*e = InputDatadogAgentType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputDatadogAgentType: %v", v)
	}
}

type InputDatadogAgentConnections struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *InputDatadogAgentConnections) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputDatadogAgentConnections) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// InputDatadogAgentMode - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputDatadogAgentMode string

const (
	InputDatadogAgentModeSmart  InputDatadogAgentMode = "smart"
	InputDatadogAgentModeAlways InputDatadogAgentMode = "always"
)

func (e InputDatadogAgentMode) ToPointer() *InputDatadogAgentMode {
	return &e
}
func (e *InputDatadogAgentMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputDatadogAgentMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputDatadogAgentMode: %v", v)
	}
}

// InputDatadogAgentCompression - Codec to use to compress the persisted data
type InputDatadogAgentCompression string

const (
	InputDatadogAgentCompressionNone InputDatadogAgentCompression = "none"
	InputDatadogAgentCompressionGzip InputDatadogAgentCompression = "gzip"
)

func (e InputDatadogAgentCompression) ToPointer() *InputDatadogAgentCompression {
	return &e
}
func (e *InputDatadogAgentCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputDatadogAgentCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputDatadogAgentCompression: %v", v)
	}
}

type InputDatadogAgentPq struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputDatadogAgentMode `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *InputDatadogAgentCompression `default:"none" json:"compress"`
}

func (i InputDatadogAgentPq) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputDatadogAgentPq) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputDatadogAgentPq) GetMode() *InputDatadogAgentMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputDatadogAgentPq) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputDatadogAgentPq) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *InputDatadogAgentPq) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *InputDatadogAgentPq) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *InputDatadogAgentPq) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *InputDatadogAgentPq) GetCompress() *InputDatadogAgentCompression {
	if o == nil {
		return nil
	}
	return o.Compress
}

// InputDatadogAgentMinimumTLSVersion - Minimum TLS version to accept from connections
type InputDatadogAgentMinimumTLSVersion string

const (
	InputDatadogAgentMinimumTLSVersionTlSv1  InputDatadogAgentMinimumTLSVersion = "TLSv1"
	InputDatadogAgentMinimumTLSVersionTlSv11 InputDatadogAgentMinimumTLSVersion = "TLSv1.1"
	InputDatadogAgentMinimumTLSVersionTlSv12 InputDatadogAgentMinimumTLSVersion = "TLSv1.2"
	InputDatadogAgentMinimumTLSVersionTlSv13 InputDatadogAgentMinimumTLSVersion = "TLSv1.3"
)

func (e InputDatadogAgentMinimumTLSVersion) ToPointer() *InputDatadogAgentMinimumTLSVersion {
	return &e
}
func (e *InputDatadogAgentMinimumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputDatadogAgentMinimumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputDatadogAgentMinimumTLSVersion: %v", v)
	}
}

// InputDatadogAgentMaximumTLSVersion - Maximum TLS version to accept from connections
type InputDatadogAgentMaximumTLSVersion string

const (
	InputDatadogAgentMaximumTLSVersionTlSv1  InputDatadogAgentMaximumTLSVersion = "TLSv1"
	InputDatadogAgentMaximumTLSVersionTlSv11 InputDatadogAgentMaximumTLSVersion = "TLSv1.1"
	InputDatadogAgentMaximumTLSVersionTlSv12 InputDatadogAgentMaximumTLSVersion = "TLSv1.2"
	InputDatadogAgentMaximumTLSVersionTlSv13 InputDatadogAgentMaximumTLSVersion = "TLSv1.3"
)

func (e InputDatadogAgentMaximumTLSVersion) ToPointer() *InputDatadogAgentMaximumTLSVersion {
	return &e
}
func (e *InputDatadogAgentMaximumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputDatadogAgentMaximumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputDatadogAgentMaximumTLSVersion: %v", v)
	}
}

type InputDatadogAgentTLSSettingsServerSide struct {
	Disabled *bool `default:"true" json:"disabled"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert        *bool `default:"false" json:"requestCert"`
	RejectUnauthorized any   `json:"rejectUnauthorized,omitempty"`
	CommonNameRegex    any   `json:"commonNameRegex,omitempty"`
	// Minimum TLS version to accept from connections
	MinVersion *InputDatadogAgentMinimumTLSVersion `json:"minVersion,omitempty"`
	// Maximum TLS version to accept from connections
	MaxVersion *InputDatadogAgentMaximumTLSVersion `json:"maxVersion,omitempty"`
}

func (i InputDatadogAgentTLSSettingsServerSide) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputDatadogAgentTLSSettingsServerSide) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputDatadogAgentTLSSettingsServerSide) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputDatadogAgentTLSSettingsServerSide) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *InputDatadogAgentTLSSettingsServerSide) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *InputDatadogAgentTLSSettingsServerSide) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *InputDatadogAgentTLSSettingsServerSide) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *InputDatadogAgentTLSSettingsServerSide) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *InputDatadogAgentTLSSettingsServerSide) GetRequestCert() *bool {
	if o == nil {
		return nil
	}
	return o.RequestCert
}

func (o *InputDatadogAgentTLSSettingsServerSide) GetRejectUnauthorized() any {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *InputDatadogAgentTLSSettingsServerSide) GetCommonNameRegex() any {
	if o == nil {
		return nil
	}
	return o.CommonNameRegex
}

func (o *InputDatadogAgentTLSSettingsServerSide) GetMinVersion() *InputDatadogAgentMinimumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *InputDatadogAgentTLSSettingsServerSide) GetMaxVersion() *InputDatadogAgentMaximumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

type InputDatadogAgentMetadata struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputDatadogAgentMetadata) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputDatadogAgentMetadata) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputDatadogAgentProxyMode struct {
	// Toggle to Yes to send key validation requests from Datadog Agent to the Datadog API. If toggled to No (the default), Stream handles key validation requests by always responding that the key is valid.
	Enabled *bool `default:"false" json:"enabled"`
	// Whether to reject certificates that cannot be verified against a valid CA (e.g., self-signed certificates).
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
}

func (i InputDatadogAgentProxyMode) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputDatadogAgentProxyMode) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputDatadogAgentProxyMode) GetEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.Enabled
}

func (o *InputDatadogAgentProxyMode) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

type InputDatadogAgent struct {
	// Unique ID for this input
	ID       *string                `json:"id,omitempty"`
	Type     *InputDatadogAgentType `json:"type,omitempty"`
	Disabled *bool                  `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputDatadogAgentConnections `json:"connections,omitempty"`
	Pq          *InputDatadogAgentPq           `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port float64                                 `json:"port"`
	TLS  *InputDatadogAgentTLSSettingsServerSide `json:"tls,omitempty"`
	// Maximum number of active requests per Worker Process. Use 0 for unlimited.
	MaxActiveReq *float64 `default:"256" json:"maxActiveReq"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket *int64 `default:"0" json:"maxRequestsPerSocket"`
	// Enable when clients are connecting through a proxy that supports the x-forwarded-for header to keep the client's original IP address on the event instead of the proxy's IP address
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Add request headers to events, in the __headers field
	CaptureHeaders *bool `default:"false" json:"captureHeaders"`
	// How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
	ActivityLogSampleRate *float64 `default:"100" json:"activityLogSampleRate"`
	// How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
	RequestTimeout *float64 `default:"0" json:"requestTimeout"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `default:"0" json:"socketTimeout"`
	// After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 sec.; maximum 600 sec. (10 min.).
	KeepAliveTimeout *float64 `default:"5" json:"keepAliveTimeout"`
	// Enable to expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
	EnableHealthCheck *bool `default:"false" json:"enableHealthCheck"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist
	IPAllowlistRegex *string `default:"/.*/" json:"ipAllowlistRegex"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `default:"/^\\$/" json:"ipDenylistRegex"`
	// Toggle to Yes to extract each incoming metric to multiple events, one per data point. This works well when sending metrics to a statsd-type output. If sending metrics to DatadogHQ or any destination that accepts arbitrary JSON, leave toggled to No (the default).
	ExtractMetrics *bool `default:"false" json:"extractMetrics"`
	// Fields to add to events from this input
	Metadata    []InputDatadogAgentMetadata `json:"metadata,omitempty"`
	ProxyMode   *InputDatadogAgentProxyMode `json:"proxyMode,omitempty"`
	Description *string                     `json:"description,omitempty"`
	Status      *TFStatus                   `json:"status,omitempty"`
}

func (i InputDatadogAgent) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputDatadogAgent) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputDatadogAgent) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputDatadogAgent) GetType() *InputDatadogAgentType {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputDatadogAgent) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputDatadogAgent) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputDatadogAgent) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputDatadogAgent) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputDatadogAgent) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputDatadogAgent) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputDatadogAgent) GetConnections() []InputDatadogAgentConnections {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputDatadogAgent) GetPq() *InputDatadogAgentPq {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputDatadogAgent) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputDatadogAgent) GetPort() float64 {
	if o == nil {
		return 0.0
	}
	return o.Port
}

func (o *InputDatadogAgent) GetTLS() *InputDatadogAgentTLSSettingsServerSide {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputDatadogAgent) GetMaxActiveReq() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxActiveReq
}

func (o *InputDatadogAgent) GetMaxRequestsPerSocket() *int64 {
	if o == nil {
		return nil
	}
	return o.MaxRequestsPerSocket
}

func (o *InputDatadogAgent) GetEnableProxyHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableProxyHeader
}

func (o *InputDatadogAgent) GetCaptureHeaders() *bool {
	if o == nil {
		return nil
	}
	return o.CaptureHeaders
}

func (o *InputDatadogAgent) GetActivityLogSampleRate() *float64 {
	if o == nil {
		return nil
	}
	return o.ActivityLogSampleRate
}

func (o *InputDatadogAgent) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *InputDatadogAgent) GetSocketTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketTimeout
}

func (o *InputDatadogAgent) GetKeepAliveTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.KeepAliveTimeout
}

func (o *InputDatadogAgent) GetEnableHealthCheck() *bool {
	if o == nil {
		return nil
	}
	return o.EnableHealthCheck
}

func (o *InputDatadogAgent) GetIPAllowlistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPAllowlistRegex
}

func (o *InputDatadogAgent) GetIPDenylistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPDenylistRegex
}

func (o *InputDatadogAgent) GetExtractMetrics() *bool {
	if o == nil {
		return nil
	}
	return o.ExtractMetrics
}

func (o *InputDatadogAgent) GetMetadata() []InputDatadogAgentMetadata {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputDatadogAgent) GetProxyMode() *InputDatadogAgentProxyMode {
	if o == nil {
		return nil
	}
	return o.ProxyMode
}

func (o *InputDatadogAgent) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputDatadogAgent) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputCrowdstrikeType string

const (
	InputCrowdstrikeTypeCrowdstrike InputCrowdstrikeType = "crowdstrike"
)

func (e InputCrowdstrikeType) ToPointer() *InputCrowdstrikeType {
	return &e
}
func (e *InputCrowdstrikeType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "crowdstrike":
		*e = InputCrowdstrikeType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputCrowdstrikeType: %v", v)
	}
}

type InputCrowdstrikeConnections struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *InputCrowdstrikeConnections) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputCrowdstrikeConnections) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// InputCrowdstrikeMode - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputCrowdstrikeMode string

const (
	InputCrowdstrikeModeSmart  InputCrowdstrikeMode = "smart"
	InputCrowdstrikeModeAlways InputCrowdstrikeMode = "always"
)

func (e InputCrowdstrikeMode) ToPointer() *InputCrowdstrikeMode {
	return &e
}
func (e *InputCrowdstrikeMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputCrowdstrikeMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputCrowdstrikeMode: %v", v)
	}
}

// InputCrowdstrikeCompression - Codec to use to compress the persisted data
type InputCrowdstrikeCompression string

const (
	InputCrowdstrikeCompressionNone InputCrowdstrikeCompression = "none"
	InputCrowdstrikeCompressionGzip InputCrowdstrikeCompression = "gzip"
)

func (e InputCrowdstrikeCompression) ToPointer() *InputCrowdstrikeCompression {
	return &e
}
func (e *InputCrowdstrikeCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputCrowdstrikeCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputCrowdstrikeCompression: %v", v)
	}
}

type InputCrowdstrikePq struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputCrowdstrikeMode `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *InputCrowdstrikeCompression `default:"none" json:"compress"`
}

func (i InputCrowdstrikePq) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputCrowdstrikePq) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputCrowdstrikePq) GetMode() *InputCrowdstrikeMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputCrowdstrikePq) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputCrowdstrikePq) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *InputCrowdstrikePq) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *InputCrowdstrikePq) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *InputCrowdstrikePq) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *InputCrowdstrikePq) GetCompress() *InputCrowdstrikeCompression {
	if o == nil {
		return nil
	}
	return o.Compress
}

// InputCrowdstrikeAuthenticationMethod - AWS authentication method. Choose Auto to use IAM roles.
type InputCrowdstrikeAuthenticationMethod string

const (
	InputCrowdstrikeAuthenticationMethodAuto   InputCrowdstrikeAuthenticationMethod = "auto"
	InputCrowdstrikeAuthenticationMethodManual InputCrowdstrikeAuthenticationMethod = "manual"
	InputCrowdstrikeAuthenticationMethodSecret InputCrowdstrikeAuthenticationMethod = "secret"
)

func (e InputCrowdstrikeAuthenticationMethod) ToPointer() *InputCrowdstrikeAuthenticationMethod {
	return &e
}
func (e *InputCrowdstrikeAuthenticationMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "auto":
		fallthrough
	case "manual":
		fallthrough
	case "secret":
		*e = InputCrowdstrikeAuthenticationMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputCrowdstrikeAuthenticationMethod: %v", v)
	}
}

// InputCrowdstrikeSignatureVersion - Signature version to use for signing S3 requests
type InputCrowdstrikeSignatureVersion string

const (
	InputCrowdstrikeSignatureVersionV2 InputCrowdstrikeSignatureVersion = "v2"
	InputCrowdstrikeSignatureVersionV4 InputCrowdstrikeSignatureVersion = "v4"
)

func (e InputCrowdstrikeSignatureVersion) ToPointer() *InputCrowdstrikeSignatureVersion {
	return &e
}
func (e *InputCrowdstrikeSignatureVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "v2":
		fallthrough
	case "v4":
		*e = InputCrowdstrikeSignatureVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputCrowdstrikeSignatureVersion: %v", v)
	}
}

type InputCrowdstrikePreprocess struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Command to feed the data through (via stdin) and process its output (stdout)
	Command *string `json:"command,omitempty"`
	// Arguments to be added to the custom command
	Args []string `json:"args,omitempty"`
}

func (i InputCrowdstrikePreprocess) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputCrowdstrikePreprocess) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputCrowdstrikePreprocess) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputCrowdstrikePreprocess) GetCommand() *string {
	if o == nil {
		return nil
	}
	return o.Command
}

func (o *InputCrowdstrikePreprocess) GetArgs() []string {
	if o == nil {
		return nil
	}
	return o.Args
}

type InputCrowdstrikeMetadata struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputCrowdstrikeMetadata) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputCrowdstrikeMetadata) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type Checkpointing struct {
	// Resume processing files after an interruption
	Enabled *bool `default:"false" json:"enabled"`
	// If checkpointing is enabled, the number of times to retry processing when a processing error occurs. If skip file on error is enabled, this setting is ignored.
	Retries *float64 `default:"5" json:"retries"`
}

func (c Checkpointing) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *Checkpointing) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *Checkpointing) GetEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.Enabled
}

func (o *Checkpointing) GetRetries() *float64 {
	if o == nil {
		return nil
	}
	return o.Retries
}

type InputCrowdstrike struct {
	// Unique ID for this input
	ID       *string              `json:"id,omitempty"`
	Type     InputCrowdstrikeType `json:"type"`
	Disabled *bool                `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputCrowdstrikeConnections `json:"connections,omitempty"`
	Pq          *InputCrowdstrikePq           `json:"pq,omitempty"`
	// The name, URL, or ARN of the SQS queue to read notifications from. When a non-AWS URL is specified, format must be: '{url}/myQueueName'. Example: 'https://host:port/myQueueName'. Value must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at init time. Example referencing a Global Variable: `https://host:port/myQueue-${C.vars.myVar}`.
	QueueName string `json:"queueName"`
	// Regex matching file names to download and process. Defaults to: .*
	FileFilter *string `default:"/.*/" json:"fileFilter"`
	// SQS queue owner's AWS account ID. Leave empty if SQS queue is in same AWS account.
	AwsAccountID *string `json:"awsAccountId,omitempty"`
	// AWS authentication method. Choose Auto to use IAM roles.
	AwsAuthenticationMethod *InputCrowdstrikeAuthenticationMethod `default:"auto" json:"awsAuthenticationMethod"`
	AwsSecretKey            *string                               `json:"awsSecretKey,omitempty"`
	// AWS Region where the S3 bucket and SQS queue are located. Required, unless the Queue entry is a URL or ARN that includes a Region.
	Region *string `json:"region,omitempty"`
	// S3 service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to S3-compatible endpoint.
	Endpoint *string `json:"endpoint,omitempty"`
	// Signature version to use for signing S3 requests
	SignatureVersion *InputCrowdstrikeSignatureVersion `default:"v4" json:"signatureVersion"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `default:"true" json:"reuseConnections"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitempty"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `default:"10000" json:"staleChannelFlushMs"`
	// The maximum number of messages SQS should return in a poll request. Amazon SQS never returns more messages than this value (however, fewer messages might be returned). Valid values: 1 to 10.
	MaxMessages *float64 `default:"1" json:"maxMessages"`
	// After messages are retrieved by a ReceiveMessage request, @{product} will hide them from subsequent retrieve requests for at least this duration. You can set this as high as 43200 sec. (12 hours).
	VisibilityTimeout *float64 `default:"21600" json:"visibilityTimeout"`
	// How many receiver processes to run. The higher the number, the better the throughput - at the expense of CPU overhead.
	NumReceivers *float64 `default:"1" json:"numReceivers"`
	// Socket inactivity timeout (in seconds). Increase this value if timeouts occur due to backpressure.
	SocketTimeout *float64 `default:"300" json:"socketTimeout"`
	// Skip files that trigger a processing error. Disabled by default, which allows retries after processing errors.
	SkipOnError *bool `default:"false" json:"skipOnError"`
	// Use Assume Role credentials to access S3
	EnableAssumeRole *bool `default:"true" json:"enableAssumeRole"`
	// Amazon Resource Name (ARN) of the role to assume
	AssumeRoleArn *string `json:"assumeRoleArn,omitempty"`
	// External ID to use when assuming role
	AssumeRoleExternalID *string `json:"assumeRoleExternalId,omitempty"`
	// Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
	DurationSeconds *float64 `default:"3600" json:"durationSeconds"`
	// Use Assume Role credentials when accessing SQS
	EnableSQSAssumeRole *bool                       `default:"false" json:"enableSQSAssumeRole"`
	Preprocess          *InputCrowdstrikePreprocess `json:"preprocess,omitempty"`
	// Fields to add to events from this input
	Metadata      []InputCrowdstrikeMetadata `json:"metadata,omitempty"`
	Checkpointing *Checkpointing             `json:"checkpointing,omitempty"`
	// How long to wait for events before trying polling again. The lower the number the higher the AWS bill. The higher the number the longer it will take for the source to react to configuration changes and system restarts.
	PollTimeout *float64 `default:"10" json:"pollTimeout"`
	// Character encoding to use when parsing ingested data. When not set, @{product} will default to UTF-8 but may incorrectly interpret multi-byte characters.
	Encoding    *string `json:"encoding,omitempty"`
	Description *string `json:"description,omitempty"`
	AwsAPIKey   *string `json:"awsApiKey,omitempty"`
	// Select or create a stored secret that references your access key and secret key
	AwsSecret *string   `json:"awsSecret,omitempty"`
	Status    *TFStatus `json:"status,omitempty"`
}

func (i InputCrowdstrike) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputCrowdstrike) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputCrowdstrike) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputCrowdstrike) GetType() InputCrowdstrikeType {
	if o == nil {
		return InputCrowdstrikeType("")
	}
	return o.Type
}

func (o *InputCrowdstrike) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputCrowdstrike) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputCrowdstrike) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputCrowdstrike) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputCrowdstrike) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputCrowdstrike) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputCrowdstrike) GetConnections() []InputCrowdstrikeConnections {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputCrowdstrike) GetPq() *InputCrowdstrikePq {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputCrowdstrike) GetQueueName() string {
	if o == nil {
		return ""
	}
	return o.QueueName
}

func (o *InputCrowdstrike) GetFileFilter() *string {
	if o == nil {
		return nil
	}
	return o.FileFilter
}

func (o *InputCrowdstrike) GetAwsAccountID() *string {
	if o == nil {
		return nil
	}
	return o.AwsAccountID
}

func (o *InputCrowdstrike) GetAwsAuthenticationMethod() *InputCrowdstrikeAuthenticationMethod {
	if o == nil {
		return nil
	}
	return o.AwsAuthenticationMethod
}

func (o *InputCrowdstrike) GetAwsSecretKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecretKey
}

func (o *InputCrowdstrike) GetRegion() *string {
	if o == nil {
		return nil
	}
	return o.Region
}

func (o *InputCrowdstrike) GetEndpoint() *string {
	if o == nil {
		return nil
	}
	return o.Endpoint
}

func (o *InputCrowdstrike) GetSignatureVersion() *InputCrowdstrikeSignatureVersion {
	if o == nil {
		return nil
	}
	return o.SignatureVersion
}

func (o *InputCrowdstrike) GetReuseConnections() *bool {
	if o == nil {
		return nil
	}
	return o.ReuseConnections
}

func (o *InputCrowdstrike) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *InputCrowdstrike) GetBreakerRulesets() []string {
	if o == nil {
		return nil
	}
	return o.BreakerRulesets
}

func (o *InputCrowdstrike) GetStaleChannelFlushMs() *float64 {
	if o == nil {
		return nil
	}
	return o.StaleChannelFlushMs
}

func (o *InputCrowdstrike) GetMaxMessages() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxMessages
}

func (o *InputCrowdstrike) GetVisibilityTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.VisibilityTimeout
}

func (o *InputCrowdstrike) GetNumReceivers() *float64 {
	if o == nil {
		return nil
	}
	return o.NumReceivers
}

func (o *InputCrowdstrike) GetSocketTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketTimeout
}

func (o *InputCrowdstrike) GetSkipOnError() *bool {
	if o == nil {
		return nil
	}
	return o.SkipOnError
}

func (o *InputCrowdstrike) GetEnableAssumeRole() *bool {
	if o == nil {
		return nil
	}
	return o.EnableAssumeRole
}

func (o *InputCrowdstrike) GetAssumeRoleArn() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleArn
}

func (o *InputCrowdstrike) GetAssumeRoleExternalID() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleExternalID
}

func (o *InputCrowdstrike) GetDurationSeconds() *float64 {
	if o == nil {
		return nil
	}
	return o.DurationSeconds
}

func (o *InputCrowdstrike) GetEnableSQSAssumeRole() *bool {
	if o == nil {
		return nil
	}
	return o.EnableSQSAssumeRole
}

func (o *InputCrowdstrike) GetPreprocess() *InputCrowdstrikePreprocess {
	if o == nil {
		return nil
	}
	return o.Preprocess
}

func (o *InputCrowdstrike) GetMetadata() []InputCrowdstrikeMetadata {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputCrowdstrike) GetCheckpointing() *Checkpointing {
	if o == nil {
		return nil
	}
	return o.Checkpointing
}

func (o *InputCrowdstrike) GetPollTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.PollTimeout
}

func (o *InputCrowdstrike) GetEncoding() *string {
	if o == nil {
		return nil
	}
	return o.Encoding
}

func (o *InputCrowdstrike) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputCrowdstrike) GetAwsAPIKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsAPIKey
}

func (o *InputCrowdstrike) GetAwsSecret() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecret
}

func (o *InputCrowdstrike) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputWindowsMetricsType string

const (
	InputWindowsMetricsTypeWindowsMetrics InputWindowsMetricsType = "windows_metrics"
)

func (e InputWindowsMetricsType) ToPointer() *InputWindowsMetricsType {
	return &e
}
func (e *InputWindowsMetricsType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "windows_metrics":
		*e = InputWindowsMetricsType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputWindowsMetricsType: %v", v)
	}
}

type InputWindowsMetricsConnections struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *InputWindowsMetricsConnections) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputWindowsMetricsConnections) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// InputWindowsMetricsInputMode - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputWindowsMetricsInputMode string

const (
	InputWindowsMetricsInputModeSmart  InputWindowsMetricsInputMode = "smart"
	InputWindowsMetricsInputModeAlways InputWindowsMetricsInputMode = "always"
)

func (e InputWindowsMetricsInputMode) ToPointer() *InputWindowsMetricsInputMode {
	return &e
}
func (e *InputWindowsMetricsInputMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputWindowsMetricsInputMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputWindowsMetricsInputMode: %v", v)
	}
}

// InputWindowsMetricsCompression - Codec to use to compress the persisted data
type InputWindowsMetricsCompression string

const (
	InputWindowsMetricsCompressionNone InputWindowsMetricsCompression = "none"
	InputWindowsMetricsCompressionGzip InputWindowsMetricsCompression = "gzip"
)

func (e InputWindowsMetricsCompression) ToPointer() *InputWindowsMetricsCompression {
	return &e
}
func (e *InputWindowsMetricsCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputWindowsMetricsCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputWindowsMetricsCompression: %v", v)
	}
}

type InputWindowsMetricsPq struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputWindowsMetricsInputMode `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *InputWindowsMetricsCompression `default:"none" json:"compress"`
}

func (i InputWindowsMetricsPq) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputWindowsMetricsPq) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputWindowsMetricsPq) GetMode() *InputWindowsMetricsInputMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputWindowsMetricsPq) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputWindowsMetricsPq) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *InputWindowsMetricsPq) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *InputWindowsMetricsPq) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *InputWindowsMetricsPq) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *InputWindowsMetricsPq) GetCompress() *InputWindowsMetricsCompression {
	if o == nil {
		return nil
	}
	return o.Compress
}

// InputWindowsMetricsMode - Select level of detail for host metrics
type InputWindowsMetricsMode string

const (
	InputWindowsMetricsModeBasic    InputWindowsMetricsMode = "basic"
	InputWindowsMetricsModeAll      InputWindowsMetricsMode = "all"
	InputWindowsMetricsModeCustom   InputWindowsMetricsMode = "custom"
	InputWindowsMetricsModeDisabled InputWindowsMetricsMode = "disabled"
)

func (e InputWindowsMetricsMode) ToPointer() *InputWindowsMetricsMode {
	return &e
}
func (e *InputWindowsMetricsMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "basic":
		fallthrough
	case "all":
		fallthrough
	case "custom":
		fallthrough
	case "disabled":
		*e = InputWindowsMetricsMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputWindowsMetricsMode: %v", v)
	}
}

// InputWindowsMetricsInputHostMode - Select the level of details for system metrics
type InputWindowsMetricsInputHostMode string

const (
	InputWindowsMetricsInputHostModeBasic    InputWindowsMetricsInputHostMode = "basic"
	InputWindowsMetricsInputHostModeAll      InputWindowsMetricsInputHostMode = "all"
	InputWindowsMetricsInputHostModeCustom   InputWindowsMetricsInputHostMode = "custom"
	InputWindowsMetricsInputHostModeDisabled InputWindowsMetricsInputHostMode = "disabled"
)

func (e InputWindowsMetricsInputHostMode) ToPointer() *InputWindowsMetricsInputHostMode {
	return &e
}
func (e *InputWindowsMetricsInputHostMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "basic":
		fallthrough
	case "all":
		fallthrough
	case "custom":
		fallthrough
	case "disabled":
		*e = InputWindowsMetricsInputHostMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputWindowsMetricsInputHostMode: %v", v)
	}
}

type InputWindowsMetricsSystem struct {
	// Select the level of details for system metrics
	Mode *InputWindowsMetricsInputHostMode `default:"basic" json:"mode"`
	// Generate metrics for all system information
	Detail *bool `default:"false" json:"detail"`
}

func (i InputWindowsMetricsSystem) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputWindowsMetricsSystem) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputWindowsMetricsSystem) GetMode() *InputWindowsMetricsInputHostMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputWindowsMetricsSystem) GetDetail() *bool {
	if o == nil {
		return nil
	}
	return o.Detail
}

// InputWindowsMetricsInputHostCustomMode - Select the level of details for CPU metrics
type InputWindowsMetricsInputHostCustomMode string

const (
	InputWindowsMetricsInputHostCustomModeBasic    InputWindowsMetricsInputHostCustomMode = "basic"
	InputWindowsMetricsInputHostCustomModeAll      InputWindowsMetricsInputHostCustomMode = "all"
	InputWindowsMetricsInputHostCustomModeCustom   InputWindowsMetricsInputHostCustomMode = "custom"
	InputWindowsMetricsInputHostCustomModeDisabled InputWindowsMetricsInputHostCustomMode = "disabled"
)

func (e InputWindowsMetricsInputHostCustomMode) ToPointer() *InputWindowsMetricsInputHostCustomMode {
	return &e
}
func (e *InputWindowsMetricsInputHostCustomMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "basic":
		fallthrough
	case "all":
		fallthrough
	case "custom":
		fallthrough
	case "disabled":
		*e = InputWindowsMetricsInputHostCustomMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputWindowsMetricsInputHostCustomMode: %v", v)
	}
}

type InputWindowsMetricsCPU struct {
	// Select the level of details for CPU metrics
	Mode *InputWindowsMetricsInputHostCustomMode `default:"basic" json:"mode"`
	// Generate metrics for each CPU
	PerCPU *bool `default:"false" json:"perCpu"`
	// Generate metrics for all CPU states
	Detail *bool `default:"false" json:"detail"`
	// Generate raw, monotonic CPU time counters
	Time *bool `default:"false" json:"time"`
}

func (i InputWindowsMetricsCPU) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputWindowsMetricsCPU) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputWindowsMetricsCPU) GetMode() *InputWindowsMetricsInputHostCustomMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputWindowsMetricsCPU) GetPerCPU() *bool {
	if o == nil {
		return nil
	}
	return o.PerCPU
}

func (o *InputWindowsMetricsCPU) GetDetail() *bool {
	if o == nil {
		return nil
	}
	return o.Detail
}

func (o *InputWindowsMetricsCPU) GetTime() *bool {
	if o == nil {
		return nil
	}
	return o.Time
}

// InputWindowsMetricsInputHostCustomMemoryMode - Select the level of details for memory metrics
type InputWindowsMetricsInputHostCustomMemoryMode string

const (
	InputWindowsMetricsInputHostCustomMemoryModeBasic    InputWindowsMetricsInputHostCustomMemoryMode = "basic"
	InputWindowsMetricsInputHostCustomMemoryModeAll      InputWindowsMetricsInputHostCustomMemoryMode = "all"
	InputWindowsMetricsInputHostCustomMemoryModeCustom   InputWindowsMetricsInputHostCustomMemoryMode = "custom"
	InputWindowsMetricsInputHostCustomMemoryModeDisabled InputWindowsMetricsInputHostCustomMemoryMode = "disabled"
)

func (e InputWindowsMetricsInputHostCustomMemoryMode) ToPointer() *InputWindowsMetricsInputHostCustomMemoryMode {
	return &e
}
func (e *InputWindowsMetricsInputHostCustomMemoryMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "basic":
		fallthrough
	case "all":
		fallthrough
	case "custom":
		fallthrough
	case "disabled":
		*e = InputWindowsMetricsInputHostCustomMemoryMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputWindowsMetricsInputHostCustomMemoryMode: %v", v)
	}
}

type InputWindowsMetricsMemory struct {
	// Select the level of details for memory metrics
	Mode *InputWindowsMetricsInputHostCustomMemoryMode `default:"basic" json:"mode"`
	// Generate metrics for all memory states
	Detail *bool `default:"false" json:"detail"`
}

func (i InputWindowsMetricsMemory) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputWindowsMetricsMemory) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputWindowsMetricsMemory) GetMode() *InputWindowsMetricsInputHostCustomMemoryMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputWindowsMetricsMemory) GetDetail() *bool {
	if o == nil {
		return nil
	}
	return o.Detail
}

// InputWindowsMetricsInputHostCustomNetworkMode - Select the level of details for network metrics
type InputWindowsMetricsInputHostCustomNetworkMode string

const (
	InputWindowsMetricsInputHostCustomNetworkModeBasic    InputWindowsMetricsInputHostCustomNetworkMode = "basic"
	InputWindowsMetricsInputHostCustomNetworkModeAll      InputWindowsMetricsInputHostCustomNetworkMode = "all"
	InputWindowsMetricsInputHostCustomNetworkModeCustom   InputWindowsMetricsInputHostCustomNetworkMode = "custom"
	InputWindowsMetricsInputHostCustomNetworkModeDisabled InputWindowsMetricsInputHostCustomNetworkMode = "disabled"
)

func (e InputWindowsMetricsInputHostCustomNetworkMode) ToPointer() *InputWindowsMetricsInputHostCustomNetworkMode {
	return &e
}
func (e *InputWindowsMetricsInputHostCustomNetworkMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "basic":
		fallthrough
	case "all":
		fallthrough
	case "custom":
		fallthrough
	case "disabled":
		*e = InputWindowsMetricsInputHostCustomNetworkMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputWindowsMetricsInputHostCustomNetworkMode: %v", v)
	}
}

type InputWindowsMetricsNetwork struct {
	// Select the level of details for network metrics
	Mode *InputWindowsMetricsInputHostCustomNetworkMode `default:"basic" json:"mode"`
	// Network interfaces to include/exclude. All interfaces are included if this list is empty.
	Devices []string `json:"devices,omitempty"`
	// Generate separate metrics for each interface
	PerInterface *bool `default:"false" json:"perInterface"`
	// Generate full network metrics
	Detail *bool `default:"false" json:"detail"`
}

func (i InputWindowsMetricsNetwork) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputWindowsMetricsNetwork) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputWindowsMetricsNetwork) GetMode() *InputWindowsMetricsInputHostCustomNetworkMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputWindowsMetricsNetwork) GetDevices() []string {
	if o == nil {
		return nil
	}
	return o.Devices
}

func (o *InputWindowsMetricsNetwork) GetPerInterface() *bool {
	if o == nil {
		return nil
	}
	return o.PerInterface
}

func (o *InputWindowsMetricsNetwork) GetDetail() *bool {
	if o == nil {
		return nil
	}
	return o.Detail
}

// InputWindowsMetricsInputHostCustomDiskMode - Select the level of details for disk metrics
type InputWindowsMetricsInputHostCustomDiskMode string

const (
	InputWindowsMetricsInputHostCustomDiskModeBasic    InputWindowsMetricsInputHostCustomDiskMode = "basic"
	InputWindowsMetricsInputHostCustomDiskModeAll      InputWindowsMetricsInputHostCustomDiskMode = "all"
	InputWindowsMetricsInputHostCustomDiskModeCustom   InputWindowsMetricsInputHostCustomDiskMode = "custom"
	InputWindowsMetricsInputHostCustomDiskModeDisabled InputWindowsMetricsInputHostCustomDiskMode = "disabled"
)

func (e InputWindowsMetricsInputHostCustomDiskMode) ToPointer() *InputWindowsMetricsInputHostCustomDiskMode {
	return &e
}
func (e *InputWindowsMetricsInputHostCustomDiskMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "basic":
		fallthrough
	case "all":
		fallthrough
	case "custom":
		fallthrough
	case "disabled":
		*e = InputWindowsMetricsInputHostCustomDiskMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputWindowsMetricsInputHostCustomDiskMode: %v", v)
	}
}

type InputWindowsMetricsDisk struct {
	// Select the level of details for disk metrics
	Mode *InputWindowsMetricsInputHostCustomDiskMode `default:"basic" json:"mode"`
	// Windows volumes to include/exclude. E.g.: C:, !E:, etc. Wildcards and ! (not) operators are supported. All volumes are included if this list is empty.
	Volumes []string `json:"volumes,omitempty"`
	// Generate separate metrics for each volume
	PerVolume *bool `default:"false" json:"perVolume"`
}

func (i InputWindowsMetricsDisk) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputWindowsMetricsDisk) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputWindowsMetricsDisk) GetMode() *InputWindowsMetricsInputHostCustomDiskMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputWindowsMetricsDisk) GetVolumes() []string {
	if o == nil {
		return nil
	}
	return o.Volumes
}

func (o *InputWindowsMetricsDisk) GetPerVolume() *bool {
	if o == nil {
		return nil
	}
	return o.PerVolume
}

type InputWindowsMetricsCustom struct {
	System  *InputWindowsMetricsSystem  `json:"system,omitempty"`
	CPU     *InputWindowsMetricsCPU     `json:"cpu,omitempty"`
	Memory  *InputWindowsMetricsMemory  `json:"memory,omitempty"`
	Network *InputWindowsMetricsNetwork `json:"network,omitempty"`
	Disk    *InputWindowsMetricsDisk    `json:"disk,omitempty"`
}

func (o *InputWindowsMetricsCustom) GetSystem() *InputWindowsMetricsSystem {
	if o == nil {
		return nil
	}
	return o.System
}

func (o *InputWindowsMetricsCustom) GetCPU() *InputWindowsMetricsCPU {
	if o == nil {
		return nil
	}
	return o.CPU
}

func (o *InputWindowsMetricsCustom) GetMemory() *InputWindowsMetricsMemory {
	if o == nil {
		return nil
	}
	return o.Memory
}

func (o *InputWindowsMetricsCustom) GetNetwork() *InputWindowsMetricsNetwork {
	if o == nil {
		return nil
	}
	return o.Network
}

func (o *InputWindowsMetricsCustom) GetDisk() *InputWindowsMetricsDisk {
	if o == nil {
		return nil
	}
	return o.Disk
}

type InputWindowsMetricsHost struct {
	// Select level of detail for host metrics
	Mode   *InputWindowsMetricsMode   `default:"basic" json:"mode"`
	Custom *InputWindowsMetricsCustom `json:"custom,omitempty"`
}

func (i InputWindowsMetricsHost) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputWindowsMetricsHost) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputWindowsMetricsHost) GetMode() *InputWindowsMetricsMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputWindowsMetricsHost) GetCustom() *InputWindowsMetricsCustom {
	if o == nil {
		return nil
	}
	return o.Custom
}

type InputWindowsMetricsSets struct {
	Name            string `json:"name"`
	Filter          string `json:"filter"`
	IncludeChildren *bool  `default:"false" json:"includeChildren"`
}

func (i InputWindowsMetricsSets) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputWindowsMetricsSets) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputWindowsMetricsSets) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputWindowsMetricsSets) GetFilter() string {
	if o == nil {
		return ""
	}
	return o.Filter
}

func (o *InputWindowsMetricsSets) GetIncludeChildren() *bool {
	if o == nil {
		return nil
	}
	return o.IncludeChildren
}

type InputWindowsMetricsProcess struct {
	// Configure sets to collect process metrics
	Sets []InputWindowsMetricsSets `json:"sets,omitempty"`
}

func (o *InputWindowsMetricsProcess) GetSets() []InputWindowsMetricsSets {
	if o == nil {
		return nil
	}
	return o.Sets
}

type InputWindowsMetricsMetadata struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputWindowsMetricsMetadata) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputWindowsMetricsMetadata) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputWindowsMetricsDataCompressionFormat string

const (
	InputWindowsMetricsDataCompressionFormatNone InputWindowsMetricsDataCompressionFormat = "none"
	InputWindowsMetricsDataCompressionFormatGzip InputWindowsMetricsDataCompressionFormat = "gzip"
)

func (e InputWindowsMetricsDataCompressionFormat) ToPointer() *InputWindowsMetricsDataCompressionFormat {
	return &e
}
func (e *InputWindowsMetricsDataCompressionFormat) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputWindowsMetricsDataCompressionFormat(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputWindowsMetricsDataCompressionFormat: %v", v)
	}
}

type InputWindowsMetricsPersistence struct {
	// Spool metrics to disk for Cribl Edge and Search
	Enable *bool `default:"false" json:"enable"`
	// Time span for each file bucket
	TimeWindow *string `default:"10m" json:"timeWindow"`
	// Maximum disk space allowed to be consumed (examples: 420MB, 4GB). When limit is reached, older data will be deleted.
	MaxDataSize *string `default:"1GB" json:"maxDataSize"`
	// Maximum amount of time to retain data (examples: 2h, 4d). When limit is reached, older data will be deleted.
	MaxDataTime *string                                   `default:"24h" json:"maxDataTime"`
	Compress    *InputWindowsMetricsDataCompressionFormat `default:"gzip" json:"compress"`
	// Path to use to write metrics. Defaults to $CRIBL_HOME/state/windows_metrics
	DestPath *string `default:"\\$CRIBL_HOME/state/windows_metrics" json:"destPath"`
}

func (i InputWindowsMetricsPersistence) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputWindowsMetricsPersistence) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputWindowsMetricsPersistence) GetEnable() *bool {
	if o == nil {
		return nil
	}
	return o.Enable
}

func (o *InputWindowsMetricsPersistence) GetTimeWindow() *string {
	if o == nil {
		return nil
	}
	return o.TimeWindow
}

func (o *InputWindowsMetricsPersistence) GetMaxDataSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxDataSize
}

func (o *InputWindowsMetricsPersistence) GetMaxDataTime() *string {
	if o == nil {
		return nil
	}
	return o.MaxDataTime
}

func (o *InputWindowsMetricsPersistence) GetCompress() *InputWindowsMetricsDataCompressionFormat {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *InputWindowsMetricsPersistence) GetDestPath() *string {
	if o == nil {
		return nil
	}
	return o.DestPath
}

type InputWindowsMetrics struct {
	// Unique ID for this input
	ID       string                  `json:"id"`
	Type     InputWindowsMetricsType `json:"type"`
	Disabled *bool                   `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputWindowsMetricsConnections `json:"connections,omitempty"`
	Pq          *InputWindowsMetricsPq           `json:"pq,omitempty"`
	// Time, in seconds, between consecutive metric collections. Default is 10 seconds.
	Interval *float64                    `default:"10" json:"interval"`
	Host     *InputWindowsMetricsHost    `json:"host,omitempty"`
	Process  *InputWindowsMetricsProcess `json:"process,omitempty"`
	// Fields to add to events from this input
	Metadata    []InputWindowsMetricsMetadata   `json:"metadata,omitempty"`
	Persistence *InputWindowsMetricsPersistence `json:"persistence,omitempty"`
	// Enable to use built-in tools (PowerShell) to collect metrics instead of native API (default) [Learn more](https://docs.cribl.io/edge/sources-windows-metrics/#advanced-tab)
	DisableNativeModule *bool     `default:"false" json:"disableNativeModule"`
	Description         *string   `json:"description,omitempty"`
	Status              *TFStatus `json:"status,omitempty"`
}

func (i InputWindowsMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputWindowsMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputWindowsMetrics) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *InputWindowsMetrics) GetType() InputWindowsMetricsType {
	if o == nil {
		return InputWindowsMetricsType("")
	}
	return o.Type
}

func (o *InputWindowsMetrics) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputWindowsMetrics) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputWindowsMetrics) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputWindowsMetrics) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputWindowsMetrics) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputWindowsMetrics) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputWindowsMetrics) GetConnections() []InputWindowsMetricsConnections {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputWindowsMetrics) GetPq() *InputWindowsMetricsPq {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputWindowsMetrics) GetInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.Interval
}

func (o *InputWindowsMetrics) GetHost() *InputWindowsMetricsHost {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputWindowsMetrics) GetProcess() *InputWindowsMetricsProcess {
	if o == nil {
		return nil
	}
	return o.Process
}

func (o *InputWindowsMetrics) GetMetadata() []InputWindowsMetricsMetadata {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputWindowsMetrics) GetPersistence() *InputWindowsMetricsPersistence {
	if o == nil {
		return nil
	}
	return o.Persistence
}

func (o *InputWindowsMetrics) GetDisableNativeModule() *bool {
	if o == nil {
		return nil
	}
	return o.DisableNativeModule
}

func (o *InputWindowsMetrics) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputWindowsMetrics) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputKubeEventsType string

const (
	InputKubeEventsTypeKubeEvents InputKubeEventsType = "kube_events"
)

func (e InputKubeEventsType) ToPointer() *InputKubeEventsType {
	return &e
}
func (e *InputKubeEventsType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "kube_events":
		*e = InputKubeEventsType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputKubeEventsType: %v", v)
	}
}

type InputKubeEventsConnections struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *InputKubeEventsConnections) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputKubeEventsConnections) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// InputKubeEventsMode - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputKubeEventsMode string

const (
	InputKubeEventsModeSmart  InputKubeEventsMode = "smart"
	InputKubeEventsModeAlways InputKubeEventsMode = "always"
)

func (e InputKubeEventsMode) ToPointer() *InputKubeEventsMode {
	return &e
}
func (e *InputKubeEventsMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputKubeEventsMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputKubeEventsMode: %v", v)
	}
}

// InputKubeEventsCompression - Codec to use to compress the persisted data
type InputKubeEventsCompression string

const (
	InputKubeEventsCompressionNone InputKubeEventsCompression = "none"
	InputKubeEventsCompressionGzip InputKubeEventsCompression = "gzip"
)

func (e InputKubeEventsCompression) ToPointer() *InputKubeEventsCompression {
	return &e
}
func (e *InputKubeEventsCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputKubeEventsCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputKubeEventsCompression: %v", v)
	}
}

type InputKubeEventsPq struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputKubeEventsMode `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *InputKubeEventsCompression `default:"none" json:"compress"`
}

func (i InputKubeEventsPq) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputKubeEventsPq) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputKubeEventsPq) GetMode() *InputKubeEventsMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputKubeEventsPq) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputKubeEventsPq) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *InputKubeEventsPq) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *InputKubeEventsPq) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *InputKubeEventsPq) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *InputKubeEventsPq) GetCompress() *InputKubeEventsCompression {
	if o == nil {
		return nil
	}
	return o.Compress
}

type InputKubeEventsRules struct {
	// JavaScript expression applied to Kubernetes objects. Return 'true' to include it.
	Filter string `json:"filter"`
	// Optional description of this rule's purpose
	Description *string `json:"description,omitempty"`
}

func (o *InputKubeEventsRules) GetFilter() string {
	if o == nil {
		return ""
	}
	return o.Filter
}

func (o *InputKubeEventsRules) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

type InputKubeEventsMetadata struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputKubeEventsMetadata) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputKubeEventsMetadata) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputKubeEvents struct {
	// Unique ID for this input
	ID       string              `json:"id"`
	Type     InputKubeEventsType `json:"type"`
	Disabled *bool               `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputKubeEventsConnections `json:"connections,omitempty"`
	Pq          *InputKubeEventsPq           `json:"pq,omitempty"`
	// Filtering on event fields
	Rules []InputKubeEventsRules `json:"rules,omitempty"`
	// Fields to add to events from this input
	Metadata    []InputKubeEventsMetadata `json:"metadata,omitempty"`
	Description *string                   `json:"description,omitempty"`
	Status      *TFStatus                 `json:"status,omitempty"`
}

func (i InputKubeEvents) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputKubeEvents) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputKubeEvents) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *InputKubeEvents) GetType() InputKubeEventsType {
	if o == nil {
		return InputKubeEventsType("")
	}
	return o.Type
}

func (o *InputKubeEvents) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputKubeEvents) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputKubeEvents) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputKubeEvents) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputKubeEvents) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputKubeEvents) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputKubeEvents) GetConnections() []InputKubeEventsConnections {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputKubeEvents) GetPq() *InputKubeEventsPq {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputKubeEvents) GetRules() []InputKubeEventsRules {
	if o == nil {
		return nil
	}
	return o.Rules
}

func (o *InputKubeEvents) GetMetadata() []InputKubeEventsMetadata {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputKubeEvents) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputKubeEvents) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputKubeLogsType string

const (
	InputKubeLogsTypeKubeLogs InputKubeLogsType = "kube_logs"
)

func (e InputKubeLogsType) ToPointer() *InputKubeLogsType {
	return &e
}
func (e *InputKubeLogsType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "kube_logs":
		*e = InputKubeLogsType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputKubeLogsType: %v", v)
	}
}

type InputKubeLogsConnections struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *InputKubeLogsConnections) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputKubeLogsConnections) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// InputKubeLogsMode - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputKubeLogsMode string

const (
	InputKubeLogsModeSmart  InputKubeLogsMode = "smart"
	InputKubeLogsModeAlways InputKubeLogsMode = "always"
)

func (e InputKubeLogsMode) ToPointer() *InputKubeLogsMode {
	return &e
}
func (e *InputKubeLogsMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputKubeLogsMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputKubeLogsMode: %v", v)
	}
}

// InputKubeLogsCompression - Codec to use to compress the persisted data
type InputKubeLogsCompression string

const (
	InputKubeLogsCompressionNone InputKubeLogsCompression = "none"
	InputKubeLogsCompressionGzip InputKubeLogsCompression = "gzip"
)

func (e InputKubeLogsCompression) ToPointer() *InputKubeLogsCompression {
	return &e
}
func (e *InputKubeLogsCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputKubeLogsCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputKubeLogsCompression: %v", v)
	}
}

type InputKubeLogsPq struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputKubeLogsMode `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *InputKubeLogsCompression `default:"none" json:"compress"`
}

func (i InputKubeLogsPq) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputKubeLogsPq) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputKubeLogsPq) GetMode() *InputKubeLogsMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputKubeLogsPq) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputKubeLogsPq) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *InputKubeLogsPq) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *InputKubeLogsPq) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *InputKubeLogsPq) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *InputKubeLogsPq) GetCompress() *InputKubeLogsCompression {
	if o == nil {
		return nil
	}
	return o.Compress
}

type InputKubeLogsRules struct {
	// JavaScript expression applied to Pod objects. Return 'true' to include it.
	Filter string `json:"filter"`
	// Optional description of this rule's purpose
	Description *string `json:"description,omitempty"`
}

func (o *InputKubeLogsRules) GetFilter() string {
	if o == nil {
		return ""
	}
	return o.Filter
}

func (o *InputKubeLogsRules) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

type InputKubeLogsMetadata struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputKubeLogsMetadata) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputKubeLogsMetadata) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// InputKubeLogsInputCompression - Data compression format. Default is gzip.
type InputKubeLogsInputCompression string

const (
	InputKubeLogsInputCompressionNone InputKubeLogsInputCompression = "none"
	InputKubeLogsInputCompressionGzip InputKubeLogsInputCompression = "gzip"
)

func (e InputKubeLogsInputCompression) ToPointer() *InputKubeLogsInputCompression {
	return &e
}
func (e *InputKubeLogsInputCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputKubeLogsInputCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputKubeLogsInputCompression: %v", v)
	}
}

type InputKubeLogsDiskSpooling struct {
	// Spool events on disk for Cribl Edge and Search. Default is disabled.
	Enable *bool `default:"false" json:"enable"`
	// Time period for grouping spooled events. Default is 10m.
	TimeWindow *string `default:"10m" json:"timeWindow"`
	// Maximum disk space that can be consumed before older buckets are deleted. Examples: 420MB, 4GB. Default is 1GB.
	MaxDataSize *string `default:"1GB" json:"maxDataSize"`
	// Maximum amount of time to retain data before older buckets are deleted. Examples: 2h, 4d. Default is 24h.
	MaxDataTime *string `default:"24h" json:"maxDataTime"`
	// Data compression format. Default is gzip.
	Compress *InputKubeLogsInputCompression `default:"gzip" json:"compress"`
}

func (i InputKubeLogsDiskSpooling) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputKubeLogsDiskSpooling) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputKubeLogsDiskSpooling) GetEnable() *bool {
	if o == nil {
		return nil
	}
	return o.Enable
}

func (o *InputKubeLogsDiskSpooling) GetTimeWindow() *string {
	if o == nil {
		return nil
	}
	return o.TimeWindow
}

func (o *InputKubeLogsDiskSpooling) GetMaxDataSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxDataSize
}

func (o *InputKubeLogsDiskSpooling) GetMaxDataTime() *string {
	if o == nil {
		return nil
	}
	return o.MaxDataTime
}

func (o *InputKubeLogsDiskSpooling) GetCompress() *InputKubeLogsInputCompression {
	if o == nil {
		return nil
	}
	return o.Compress
}

type InputKubeLogs struct {
	// Unique ID for this input
	ID       string            `json:"id"`
	Type     InputKubeLogsType `json:"type"`
	Disabled *bool             `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputKubeLogsConnections `json:"connections,omitempty"`
	Pq          *InputKubeLogsPq           `json:"pq,omitempty"`
	// Time, in seconds, between checks for new containers. Default is 15 secs.
	Interval *float64 `default:"15" json:"interval"`
	// Add rules to decide which Pods to collect logs from. Logs are collected if no rules are given or if all the rules' expressions evaluate to true.
	Rules []InputKubeLogsRules `json:"rules,omitempty"`
	// For use when containers do not emit a timestamp, prefix each line of output with a timestamp. If you enable this setting, you can use the Kubernetes Logs Event Breaker and the kubernetes_logs Pre-processing Pipeline to remove them from the events after the timestamps are extracted.
	Timestamps *bool `default:"false" json:"timestamps"`
	// Fields to add to events from this input
	Metadata    []InputKubeLogsMetadata    `json:"metadata,omitempty"`
	Persistence *InputKubeLogsDiskSpooling `json:"persistence,omitempty"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitempty"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `default:"10000" json:"staleChannelFlushMs"`
	// Load balance traffic across all Worker Processes
	EnableLoadBalancing *bool     `default:"false" json:"enableLoadBalancing"`
	Description         *string   `json:"description,omitempty"`
	Status              *TFStatus `json:"status,omitempty"`
}

func (i InputKubeLogs) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputKubeLogs) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputKubeLogs) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *InputKubeLogs) GetType() InputKubeLogsType {
	if o == nil {
		return InputKubeLogsType("")
	}
	return o.Type
}

func (o *InputKubeLogs) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputKubeLogs) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputKubeLogs) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputKubeLogs) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputKubeLogs) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputKubeLogs) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputKubeLogs) GetConnections() []InputKubeLogsConnections {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputKubeLogs) GetPq() *InputKubeLogsPq {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputKubeLogs) GetInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.Interval
}

func (o *InputKubeLogs) GetRules() []InputKubeLogsRules {
	if o == nil {
		return nil
	}
	return o.Rules
}

func (o *InputKubeLogs) GetTimestamps() *bool {
	if o == nil {
		return nil
	}
	return o.Timestamps
}

func (o *InputKubeLogs) GetMetadata() []InputKubeLogsMetadata {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputKubeLogs) GetPersistence() *InputKubeLogsDiskSpooling {
	if o == nil {
		return nil
	}
	return o.Persistence
}

func (o *InputKubeLogs) GetBreakerRulesets() []string {
	if o == nil {
		return nil
	}
	return o.BreakerRulesets
}

func (o *InputKubeLogs) GetStaleChannelFlushMs() *float64 {
	if o == nil {
		return nil
	}
	return o.StaleChannelFlushMs
}

func (o *InputKubeLogs) GetEnableLoadBalancing() *bool {
	if o == nil {
		return nil
	}
	return o.EnableLoadBalancing
}

func (o *InputKubeLogs) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputKubeLogs) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputKubeMetricsType string

const (
	InputKubeMetricsTypeKubeMetrics InputKubeMetricsType = "kube_metrics"
)

func (e InputKubeMetricsType) ToPointer() *InputKubeMetricsType {
	return &e
}
func (e *InputKubeMetricsType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "kube_metrics":
		*e = InputKubeMetricsType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputKubeMetricsType: %v", v)
	}
}

type InputKubeMetricsConnections struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *InputKubeMetricsConnections) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputKubeMetricsConnections) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// InputKubeMetricsMode - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputKubeMetricsMode string

const (
	InputKubeMetricsModeSmart  InputKubeMetricsMode = "smart"
	InputKubeMetricsModeAlways InputKubeMetricsMode = "always"
)

func (e InputKubeMetricsMode) ToPointer() *InputKubeMetricsMode {
	return &e
}
func (e *InputKubeMetricsMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputKubeMetricsMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputKubeMetricsMode: %v", v)
	}
}

// InputKubeMetricsCompression - Codec to use to compress the persisted data
type InputKubeMetricsCompression string

const (
	InputKubeMetricsCompressionNone InputKubeMetricsCompression = "none"
	InputKubeMetricsCompressionGzip InputKubeMetricsCompression = "gzip"
)

func (e InputKubeMetricsCompression) ToPointer() *InputKubeMetricsCompression {
	return &e
}
func (e *InputKubeMetricsCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputKubeMetricsCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputKubeMetricsCompression: %v", v)
	}
}

type InputKubeMetricsPq struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputKubeMetricsMode `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *InputKubeMetricsCompression `default:"none" json:"compress"`
}

func (i InputKubeMetricsPq) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputKubeMetricsPq) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputKubeMetricsPq) GetMode() *InputKubeMetricsMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputKubeMetricsPq) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputKubeMetricsPq) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *InputKubeMetricsPq) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *InputKubeMetricsPq) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *InputKubeMetricsPq) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *InputKubeMetricsPq) GetCompress() *InputKubeMetricsCompression {
	if o == nil {
		return nil
	}
	return o.Compress
}

type InputKubeMetricsRules struct {
	// JavaScript expression applied to Kubernetes objects. Return 'true' to include it.
	Filter string `json:"filter"`
	// Optional description of this rule's purpose
	Description *string `json:"description,omitempty"`
}

func (o *InputKubeMetricsRules) GetFilter() string {
	if o == nil {
		return ""
	}
	return o.Filter
}

func (o *InputKubeMetricsRules) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

type InputKubeMetricsMetadata struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputKubeMetricsMetadata) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputKubeMetricsMetadata) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputKubeMetricsDataCompressionFormat string

const (
	InputKubeMetricsDataCompressionFormatNone InputKubeMetricsDataCompressionFormat = "none"
	InputKubeMetricsDataCompressionFormatGzip InputKubeMetricsDataCompressionFormat = "gzip"
)

func (e InputKubeMetricsDataCompressionFormat) ToPointer() *InputKubeMetricsDataCompressionFormat {
	return &e
}
func (e *InputKubeMetricsDataCompressionFormat) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputKubeMetricsDataCompressionFormat(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputKubeMetricsDataCompressionFormat: %v", v)
	}
}

type InputKubeMetricsPersistence struct {
	// Spool metrics on disk for Cribl Search
	Enable *bool `default:"false" json:"enable"`
	// Time span for each file bucket
	TimeWindow *string `default:"10m" json:"timeWindow"`
	// Maximum disk space allowed to be consumed (examples: 420MB, 4GB). When limit is reached, older data will be deleted.
	MaxDataSize *string `default:"1GB" json:"maxDataSize"`
	// Maximum amount of time to retain data (examples: 2h, 4d). When limit is reached, older data will be deleted.
	MaxDataTime *string                                `default:"24h" json:"maxDataTime"`
	Compress    *InputKubeMetricsDataCompressionFormat `default:"gzip" json:"compress"`
	// Path to use to write metrics. Defaults to $CRIBL_HOME/state/<id>
	DestPath *string `default:"\\$CRIBL_HOME/state/kube_metrics" json:"destPath"`
}

func (i InputKubeMetricsPersistence) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputKubeMetricsPersistence) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputKubeMetricsPersistence) GetEnable() *bool {
	if o == nil {
		return nil
	}
	return o.Enable
}

func (o *InputKubeMetricsPersistence) GetTimeWindow() *string {
	if o == nil {
		return nil
	}
	return o.TimeWindow
}

func (o *InputKubeMetricsPersistence) GetMaxDataSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxDataSize
}

func (o *InputKubeMetricsPersistence) GetMaxDataTime() *string {
	if o == nil {
		return nil
	}
	return o.MaxDataTime
}

func (o *InputKubeMetricsPersistence) GetCompress() *InputKubeMetricsDataCompressionFormat {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *InputKubeMetricsPersistence) GetDestPath() *string {
	if o == nil {
		return nil
	}
	return o.DestPath
}

type InputKubeMetrics struct {
	// Unique ID for this input
	ID       string               `json:"id"`
	Type     InputKubeMetricsType `json:"type"`
	Disabled *bool                `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputKubeMetricsConnections `json:"connections,omitempty"`
	Pq          *InputKubeMetricsPq           `json:"pq,omitempty"`
	// Time, in seconds, between consecutive metrics collections. Default is 15 secs.
	Interval *float64 `default:"15" json:"interval"`
	// Add rules to decide which Kubernetes objects to generate metrics for. Events are generated if no rules are given or of all the rules' expressions evaluate to true.
	Rules []InputKubeMetricsRules `json:"rules,omitempty"`
	// Fields to add to events from this input
	Metadata    []InputKubeMetricsMetadata   `json:"metadata,omitempty"`
	Persistence *InputKubeMetricsPersistence `json:"persistence,omitempty"`
	Description *string                      `json:"description,omitempty"`
	Status      *TFStatus                    `json:"status,omitempty"`
}

func (i InputKubeMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputKubeMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputKubeMetrics) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *InputKubeMetrics) GetType() InputKubeMetricsType {
	if o == nil {
		return InputKubeMetricsType("")
	}
	return o.Type
}

func (o *InputKubeMetrics) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputKubeMetrics) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputKubeMetrics) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputKubeMetrics) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputKubeMetrics) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputKubeMetrics) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputKubeMetrics) GetConnections() []InputKubeMetricsConnections {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputKubeMetrics) GetPq() *InputKubeMetricsPq {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputKubeMetrics) GetInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.Interval
}

func (o *InputKubeMetrics) GetRules() []InputKubeMetricsRules {
	if o == nil {
		return nil
	}
	return o.Rules
}

func (o *InputKubeMetrics) GetMetadata() []InputKubeMetricsMetadata {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputKubeMetrics) GetPersistence() *InputKubeMetricsPersistence {
	if o == nil {
		return nil
	}
	return o.Persistence
}

func (o *InputKubeMetrics) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputKubeMetrics) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputSystemStateType string

const (
	InputSystemStateTypeSystemState InputSystemStateType = "system_state"
)

func (e InputSystemStateType) ToPointer() *InputSystemStateType {
	return &e
}
func (e *InputSystemStateType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "system_state":
		*e = InputSystemStateType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSystemStateType: %v", v)
	}
}

type InputSystemStateConnections struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *InputSystemStateConnections) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputSystemStateConnections) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// InputSystemStateMode - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputSystemStateMode string

const (
	InputSystemStateModeSmart  InputSystemStateMode = "smart"
	InputSystemStateModeAlways InputSystemStateMode = "always"
)

func (e InputSystemStateMode) ToPointer() *InputSystemStateMode {
	return &e
}
func (e *InputSystemStateMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputSystemStateMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSystemStateMode: %v", v)
	}
}

// InputSystemStateCompression - Codec to use to compress the persisted data
type InputSystemStateCompression string

const (
	InputSystemStateCompressionNone InputSystemStateCompression = "none"
	InputSystemStateCompressionGzip InputSystemStateCompression = "gzip"
)

func (e InputSystemStateCompression) ToPointer() *InputSystemStateCompression {
	return &e
}
func (e *InputSystemStateCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputSystemStateCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSystemStateCompression: %v", v)
	}
}

type InputSystemStatePq struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputSystemStateMode `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *InputSystemStateCompression `default:"none" json:"compress"`
}

func (i InputSystemStatePq) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSystemStatePq) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputSystemStatePq) GetMode() *InputSystemStateMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputSystemStatePq) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputSystemStatePq) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *InputSystemStatePq) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *InputSystemStatePq) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *InputSystemStatePq) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *InputSystemStatePq) GetCompress() *InputSystemStateCompression {
	if o == nil {
		return nil
	}
	return o.Compress
}

type InputSystemStateMetadata struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputSystemStateMetadata) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputSystemStateMetadata) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// HostsFile - Creates events based on entries collected from the hosts file
type HostsFile struct {
	Enable *bool `default:"true" json:"enable"`
}

func (h HostsFile) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(h, "", false)
}

func (h *HostsFile) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &h, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *HostsFile) GetEnable() *bool {
	if o == nil {
		return nil
	}
	return o.Enable
}

// InputSystemStateInterfaces - Creates events for each of the hosts network interfaces
type InputSystemStateInterfaces struct {
	Enable *bool `default:"true" json:"enable"`
}

func (i InputSystemStateInterfaces) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSystemStateInterfaces) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputSystemStateInterfaces) GetEnable() *bool {
	if o == nil {
		return nil
	}
	return o.Enable
}

// DisksAndFileSystems - Creates events for physical disks, partitions, and file systems
type DisksAndFileSystems struct {
	Enable *bool `default:"true" json:"enable"`
}

func (d DisksAndFileSystems) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(d, "", false)
}

func (d *DisksAndFileSystems) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &d, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *DisksAndFileSystems) GetEnable() *bool {
	if o == nil {
		return nil
	}
	return o.Enable
}

// HostInfo - Creates events based on the host systems current state
type HostInfo struct {
	Enable *bool `default:"true" json:"enable"`
}

func (h HostInfo) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(h, "", false)
}

func (h *HostInfo) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &h, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *HostInfo) GetEnable() *bool {
	if o == nil {
		return nil
	}
	return o.Enable
}

// InputSystemStateRoutes - Creates events based on entries collected from the hosts network routes
type InputSystemStateRoutes struct {
	Enable *bool `default:"true" json:"enable"`
}

func (i InputSystemStateRoutes) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSystemStateRoutes) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputSystemStateRoutes) GetEnable() *bool {
	if o == nil {
		return nil
	}
	return o.Enable
}

// DNS - Creates events for DNS resolvers and search entries
type DNS struct {
	Enable *bool `default:"true" json:"enable"`
}

func (d DNS) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(d, "", false)
}

func (d *DNS) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &d, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *DNS) GetEnable() *bool {
	if o == nil {
		return nil
	}
	return o.Enable
}

// UsersAndGroups - Creates events for local users and groups
type UsersAndGroups struct {
	Enable *bool `default:"true" json:"enable"`
}

func (u UsersAndGroups) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(u, "", false)
}

func (u *UsersAndGroups) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &u, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *UsersAndGroups) GetEnable() *bool {
	if o == nil {
		return nil
	}
	return o.Enable
}

// Firewall - Creates events for Firewall rules entries
type Firewall struct {
	Enable *bool `default:"true" json:"enable"`
}

func (f Firewall) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(f, "", false)
}

func (f *Firewall) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &f, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *Firewall) GetEnable() *bool {
	if o == nil {
		return nil
	}
	return o.Enable
}

// Services - Creates events from the list of services
type Services struct {
	Enable *bool `default:"true" json:"enable"`
}

func (s Services) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *Services) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *Services) GetEnable() *bool {
	if o == nil {
		return nil
	}
	return o.Enable
}

// ListeningPorts - Creates events from list of listening ports
type ListeningPorts struct {
	Enable *bool `default:"true" json:"enable"`
}

func (l ListeningPorts) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(l, "", false)
}

func (l *ListeningPorts) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &l, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *ListeningPorts) GetEnable() *bool {
	if o == nil {
		return nil
	}
	return o.Enable
}

// LoggedInUsers - Creates events from list of logged-in users
type LoggedInUsers struct {
	Enable *bool `default:"true" json:"enable"`
}

func (l LoggedInUsers) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(l, "", false)
}

func (l *LoggedInUsers) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &l, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *LoggedInUsers) GetEnable() *bool {
	if o == nil {
		return nil
	}
	return o.Enable
}

type Collectors struct {
	// Creates events based on entries collected from the hosts file
	Hostsfile *HostsFile `json:"hostsfile,omitempty"`
	// Creates events for each of the hosts network interfaces
	Interfaces *InputSystemStateInterfaces `json:"interfaces,omitempty"`
	// Creates events for physical disks, partitions, and file systems
	Disk *DisksAndFileSystems `json:"disk,omitempty"`
	// Creates events based on the host systems current state
	Metadata *HostInfo `json:"metadata,omitempty"`
	// Creates events based on entries collected from the hosts network routes
	Routes *InputSystemStateRoutes `json:"routes,omitempty"`
	// Creates events for DNS resolvers and search entries
	DNS *DNS `json:"dns,omitempty"`
	// Creates events for local users and groups
	User *UsersAndGroups `json:"user,omitempty"`
	// Creates events for Firewall rules entries
	Firewall *Firewall `json:"firewall,omitempty"`
	// Creates events from the list of services
	Services *Services `json:"services,omitempty"`
	// Creates events from list of listening ports
	Ports *ListeningPorts `json:"ports,omitempty"`
	// Creates events from list of logged-in users
	LoginUsers *LoggedInUsers `json:"loginUsers,omitempty"`
}

func (o *Collectors) GetHostsfile() *HostsFile {
	if o == nil {
		return nil
	}
	return o.Hostsfile
}

func (o *Collectors) GetInterfaces() *InputSystemStateInterfaces {
	if o == nil {
		return nil
	}
	return o.Interfaces
}

func (o *Collectors) GetDisk() *DisksAndFileSystems {
	if o == nil {
		return nil
	}
	return o.Disk
}

func (o *Collectors) GetMetadata() *HostInfo {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *Collectors) GetRoutes() *InputSystemStateRoutes {
	if o == nil {
		return nil
	}
	return o.Routes
}

func (o *Collectors) GetDNS() *DNS {
	if o == nil {
		return nil
	}
	return o.DNS
}

func (o *Collectors) GetUser() *UsersAndGroups {
	if o == nil {
		return nil
	}
	return o.User
}

func (o *Collectors) GetFirewall() *Firewall {
	if o == nil {
		return nil
	}
	return o.Firewall
}

func (o *Collectors) GetServices() *Services {
	if o == nil {
		return nil
	}
	return o.Services
}

func (o *Collectors) GetPorts() *ListeningPorts {
	if o == nil {
		return nil
	}
	return o.Ports
}

func (o *Collectors) GetLoginUsers() *LoggedInUsers {
	if o == nil {
		return nil
	}
	return o.LoginUsers
}

type InputSystemStateDataCompressionFormat string

const (
	InputSystemStateDataCompressionFormatNone InputSystemStateDataCompressionFormat = "none"
	InputSystemStateDataCompressionFormatGzip InputSystemStateDataCompressionFormat = "gzip"
)

func (e InputSystemStateDataCompressionFormat) ToPointer() *InputSystemStateDataCompressionFormat {
	return &e
}
func (e *InputSystemStateDataCompressionFormat) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputSystemStateDataCompressionFormat(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSystemStateDataCompressionFormat: %v", v)
	}
}

type Persistence struct {
	// Spool metrics to disk for Cribl Edge and Search
	Enable *bool `default:"false" json:"enable"`
	// Time span for each file bucket
	TimeWindow *string `default:"10m" json:"timeWindow"`
	// Maximum disk space allowed to be consumed (examples: 420MB, 4GB). When limit is reached, older data will be deleted.
	MaxDataSize *string `default:"1GB" json:"maxDataSize"`
	// Maximum amount of time to retain data (examples: 2h, 4d). When limit is reached, older data will be deleted.
	MaxDataTime *string                                `default:"24h" json:"maxDataTime"`
	Compress    *InputSystemStateDataCompressionFormat `default:"none" json:"compress"`
	// Path to use to write metrics. Defaults to $CRIBL_HOME/state/system_state
	DestPath *string `default:"\\$CRIBL_HOME/state/system_state" json:"destPath"`
}

func (p Persistence) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *Persistence) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *Persistence) GetEnable() *bool {
	if o == nil {
		return nil
	}
	return o.Enable
}

func (o *Persistence) GetTimeWindow() *string {
	if o == nil {
		return nil
	}
	return o.TimeWindow
}

func (o *Persistence) GetMaxDataSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxDataSize
}

func (o *Persistence) GetMaxDataTime() *string {
	if o == nil {
		return nil
	}
	return o.MaxDataTime
}

func (o *Persistence) GetCompress() *InputSystemStateDataCompressionFormat {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *Persistence) GetDestPath() *string {
	if o == nil {
		return nil
	}
	return o.DestPath
}

type InputSystemState struct {
	// Unique ID for this input
	ID       string               `json:"id"`
	Type     InputSystemStateType `json:"type"`
	Disabled *bool                `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputSystemStateConnections `json:"connections,omitempty"`
	Pq          *InputSystemStatePq           `json:"pq,omitempty"`
	// Time, in seconds, between consecutive state collections. Default is 300 seconds (5 minutes).
	Interval *float64 `default:"300" json:"interval"`
	// Fields to add to events from this input
	Metadata    []InputSystemStateMetadata `json:"metadata,omitempty"`
	Collectors  *Collectors                `json:"collectors,omitempty"`
	Persistence *Persistence               `json:"persistence,omitempty"`
	Description *string                    `json:"description,omitempty"`
	Status      *TFStatus                  `json:"status,omitempty"`
}

func (i InputSystemState) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSystemState) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputSystemState) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *InputSystemState) GetType() InputSystemStateType {
	if o == nil {
		return InputSystemStateType("")
	}
	return o.Type
}

func (o *InputSystemState) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputSystemState) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputSystemState) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputSystemState) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputSystemState) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputSystemState) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputSystemState) GetConnections() []InputSystemStateConnections {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputSystemState) GetPq() *InputSystemStatePq {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputSystemState) GetInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.Interval
}

func (o *InputSystemState) GetMetadata() []InputSystemStateMetadata {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputSystemState) GetCollectors() *Collectors {
	if o == nil {
		return nil
	}
	return o.Collectors
}

func (o *InputSystemState) GetPersistence() *Persistence {
	if o == nil {
		return nil
	}
	return o.Persistence
}

func (o *InputSystemState) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputSystemState) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputSystemMetricsType string

const (
	InputSystemMetricsTypeSystemMetrics InputSystemMetricsType = "system_metrics"
)

func (e InputSystemMetricsType) ToPointer() *InputSystemMetricsType {
	return &e
}
func (e *InputSystemMetricsType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "system_metrics":
		*e = InputSystemMetricsType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSystemMetricsType: %v", v)
	}
}

type InputSystemMetricsConnections struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *InputSystemMetricsConnections) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputSystemMetricsConnections) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// InputSystemMetricsInputPqMode - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputSystemMetricsInputPqMode string

const (
	InputSystemMetricsInputPqModeSmart  InputSystemMetricsInputPqMode = "smart"
	InputSystemMetricsInputPqModeAlways InputSystemMetricsInputPqMode = "always"
)

func (e InputSystemMetricsInputPqMode) ToPointer() *InputSystemMetricsInputPqMode {
	return &e
}
func (e *InputSystemMetricsInputPqMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputSystemMetricsInputPqMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSystemMetricsInputPqMode: %v", v)
	}
}

// InputSystemMetricsCompression - Codec to use to compress the persisted data
type InputSystemMetricsCompression string

const (
	InputSystemMetricsCompressionNone InputSystemMetricsCompression = "none"
	InputSystemMetricsCompressionGzip InputSystemMetricsCompression = "gzip"
)

func (e InputSystemMetricsCompression) ToPointer() *InputSystemMetricsCompression {
	return &e
}
func (e *InputSystemMetricsCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputSystemMetricsCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSystemMetricsCompression: %v", v)
	}
}

type InputSystemMetricsPq struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputSystemMetricsInputPqMode `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *InputSystemMetricsCompression `default:"none" json:"compress"`
}

func (i InputSystemMetricsPq) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSystemMetricsPq) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputSystemMetricsPq) GetMode() *InputSystemMetricsInputPqMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputSystemMetricsPq) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputSystemMetricsPq) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *InputSystemMetricsPq) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *InputSystemMetricsPq) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *InputSystemMetricsPq) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *InputSystemMetricsPq) GetCompress() *InputSystemMetricsCompression {
	if o == nil {
		return nil
	}
	return o.Compress
}

// InputSystemMetricsMode - Select level of detail for host metrics
type InputSystemMetricsMode string

const (
	InputSystemMetricsModeBasic    InputSystemMetricsMode = "basic"
	InputSystemMetricsModeAll      InputSystemMetricsMode = "all"
	InputSystemMetricsModeCustom   InputSystemMetricsMode = "custom"
	InputSystemMetricsModeDisabled InputSystemMetricsMode = "disabled"
)

func (e InputSystemMetricsMode) ToPointer() *InputSystemMetricsMode {
	return &e
}
func (e *InputSystemMetricsMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "basic":
		fallthrough
	case "all":
		fallthrough
	case "custom":
		fallthrough
	case "disabled":
		*e = InputSystemMetricsMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSystemMetricsMode: %v", v)
	}
}

// InputSystemMetricsInputHostMode - Select the level of detail for system metrics
type InputSystemMetricsInputHostMode string

const (
	InputSystemMetricsInputHostModeBasic    InputSystemMetricsInputHostMode = "basic"
	InputSystemMetricsInputHostModeAll      InputSystemMetricsInputHostMode = "all"
	InputSystemMetricsInputHostModeCustom   InputSystemMetricsInputHostMode = "custom"
	InputSystemMetricsInputHostModeDisabled InputSystemMetricsInputHostMode = "disabled"
)

func (e InputSystemMetricsInputHostMode) ToPointer() *InputSystemMetricsInputHostMode {
	return &e
}
func (e *InputSystemMetricsInputHostMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "basic":
		fallthrough
	case "all":
		fallthrough
	case "custom":
		fallthrough
	case "disabled":
		*e = InputSystemMetricsInputHostMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSystemMetricsInputHostMode: %v", v)
	}
}

type InputSystemMetricsSystem struct {
	// Select the level of detail for system metrics
	Mode *InputSystemMetricsInputHostMode `default:"basic" json:"mode"`
	// Generate metrics for the numbers of processes in various states
	Processes *bool `default:"false" json:"processes"`
}

func (i InputSystemMetricsSystem) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSystemMetricsSystem) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputSystemMetricsSystem) GetMode() *InputSystemMetricsInputHostMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputSystemMetricsSystem) GetProcesses() *bool {
	if o == nil {
		return nil
	}
	return o.Processes
}

// InputSystemMetricsInputHostCustomMode - Select the level of detail for CPU metrics
type InputSystemMetricsInputHostCustomMode string

const (
	InputSystemMetricsInputHostCustomModeBasic    InputSystemMetricsInputHostCustomMode = "basic"
	InputSystemMetricsInputHostCustomModeAll      InputSystemMetricsInputHostCustomMode = "all"
	InputSystemMetricsInputHostCustomModeCustom   InputSystemMetricsInputHostCustomMode = "custom"
	InputSystemMetricsInputHostCustomModeDisabled InputSystemMetricsInputHostCustomMode = "disabled"
)

func (e InputSystemMetricsInputHostCustomMode) ToPointer() *InputSystemMetricsInputHostCustomMode {
	return &e
}
func (e *InputSystemMetricsInputHostCustomMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "basic":
		fallthrough
	case "all":
		fallthrough
	case "custom":
		fallthrough
	case "disabled":
		*e = InputSystemMetricsInputHostCustomMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSystemMetricsInputHostCustomMode: %v", v)
	}
}

type CPU struct {
	// Select the level of detail for CPU metrics
	Mode *InputSystemMetricsInputHostCustomMode `default:"basic" json:"mode"`
	// Generate metrics for each CPU
	PerCPU *bool `default:"false" json:"perCpu"`
	// Generate metrics for all CPU states
	Detail *bool `default:"false" json:"detail"`
	// Generate raw, monotonic CPU time counters
	Time *bool `default:"false" json:"time"`
}

func (c CPU) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CPU) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *CPU) GetMode() *InputSystemMetricsInputHostCustomMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *CPU) GetPerCPU() *bool {
	if o == nil {
		return nil
	}
	return o.PerCPU
}

func (o *CPU) GetDetail() *bool {
	if o == nil {
		return nil
	}
	return o.Detail
}

func (o *CPU) GetTime() *bool {
	if o == nil {
		return nil
	}
	return o.Time
}

// InputSystemMetricsInputHostCustomMemoryMode - Select the level of detail for memory metrics
type InputSystemMetricsInputHostCustomMemoryMode string

const (
	InputSystemMetricsInputHostCustomMemoryModeBasic    InputSystemMetricsInputHostCustomMemoryMode = "basic"
	InputSystemMetricsInputHostCustomMemoryModeAll      InputSystemMetricsInputHostCustomMemoryMode = "all"
	InputSystemMetricsInputHostCustomMemoryModeCustom   InputSystemMetricsInputHostCustomMemoryMode = "custom"
	InputSystemMetricsInputHostCustomMemoryModeDisabled InputSystemMetricsInputHostCustomMemoryMode = "disabled"
)

func (e InputSystemMetricsInputHostCustomMemoryMode) ToPointer() *InputSystemMetricsInputHostCustomMemoryMode {
	return &e
}
func (e *InputSystemMetricsInputHostCustomMemoryMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "basic":
		fallthrough
	case "all":
		fallthrough
	case "custom":
		fallthrough
	case "disabled":
		*e = InputSystemMetricsInputHostCustomMemoryMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSystemMetricsInputHostCustomMemoryMode: %v", v)
	}
}

type InputSystemMetricsMemory struct {
	// Select the level of detail for memory metrics
	Mode *InputSystemMetricsInputHostCustomMemoryMode `default:"basic" json:"mode"`
	// Generate metrics for all memory states
	Detail *bool `default:"false" json:"detail"`
}

func (i InputSystemMetricsMemory) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSystemMetricsMemory) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputSystemMetricsMemory) GetMode() *InputSystemMetricsInputHostCustomMemoryMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputSystemMetricsMemory) GetDetail() *bool {
	if o == nil {
		return nil
	}
	return o.Detail
}

// InputSystemMetricsInputHostCustomNetworkMode - Select the level of detail for network metrics
type InputSystemMetricsInputHostCustomNetworkMode string

const (
	InputSystemMetricsInputHostCustomNetworkModeBasic    InputSystemMetricsInputHostCustomNetworkMode = "basic"
	InputSystemMetricsInputHostCustomNetworkModeAll      InputSystemMetricsInputHostCustomNetworkMode = "all"
	InputSystemMetricsInputHostCustomNetworkModeCustom   InputSystemMetricsInputHostCustomNetworkMode = "custom"
	InputSystemMetricsInputHostCustomNetworkModeDisabled InputSystemMetricsInputHostCustomNetworkMode = "disabled"
)

func (e InputSystemMetricsInputHostCustomNetworkMode) ToPointer() *InputSystemMetricsInputHostCustomNetworkMode {
	return &e
}
func (e *InputSystemMetricsInputHostCustomNetworkMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "basic":
		fallthrough
	case "all":
		fallthrough
	case "custom":
		fallthrough
	case "disabled":
		*e = InputSystemMetricsInputHostCustomNetworkMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSystemMetricsInputHostCustomNetworkMode: %v", v)
	}
}

type Network struct {
	// Select the level of detail for network metrics
	Mode *InputSystemMetricsInputHostCustomNetworkMode `default:"basic" json:"mode"`
	// Network interfaces to include/exclude. Examples: eth0, !lo. All interfaces are included if this list is empty.
	Devices []string `json:"devices,omitempty"`
	// Generate separate metrics for each interface
	PerInterface *bool `default:"false" json:"perInterface"`
	// Generate full network metrics
	Detail *bool `default:"false" json:"detail"`
}

func (n Network) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(n, "", false)
}

func (n *Network) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &n, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *Network) GetMode() *InputSystemMetricsInputHostCustomNetworkMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *Network) GetDevices() []string {
	if o == nil {
		return nil
	}
	return o.Devices
}

func (o *Network) GetPerInterface() *bool {
	if o == nil {
		return nil
	}
	return o.PerInterface
}

func (o *Network) GetDetail() *bool {
	if o == nil {
		return nil
	}
	return o.Detail
}

// InputSystemMetricsInputHostCustomDiskMode - Select the level of detail for disk metrics
type InputSystemMetricsInputHostCustomDiskMode string

const (
	InputSystemMetricsInputHostCustomDiskModeBasic    InputSystemMetricsInputHostCustomDiskMode = "basic"
	InputSystemMetricsInputHostCustomDiskModeAll      InputSystemMetricsInputHostCustomDiskMode = "all"
	InputSystemMetricsInputHostCustomDiskModeCustom   InputSystemMetricsInputHostCustomDiskMode = "custom"
	InputSystemMetricsInputHostCustomDiskModeDisabled InputSystemMetricsInputHostCustomDiskMode = "disabled"
)

func (e InputSystemMetricsInputHostCustomDiskMode) ToPointer() *InputSystemMetricsInputHostCustomDiskMode {
	return &e
}
func (e *InputSystemMetricsInputHostCustomDiskMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "basic":
		fallthrough
	case "all":
		fallthrough
	case "custom":
		fallthrough
	case "disabled":
		*e = InputSystemMetricsInputHostCustomDiskMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSystemMetricsInputHostCustomDiskMode: %v", v)
	}
}

type Disk struct {
	// Select the level of detail for disk metrics
	Mode *InputSystemMetricsInputHostCustomDiskMode `default:"basic" json:"mode"`
	// Block devices to include/exclude. Examples: sda*, !loop*. Wildcards and ! (not) operators are supported. All devices are included if this list is empty.
	Devices []string `json:"devices,omitempty"`
	// Filesystem mountpoints to include/exclude. Examples: /, /home, !/proc*, !/tmp. Wildcards and ! (not) operators are supported. All mountpoints are included if this list is empty.
	Mountpoints []string `json:"mountpoints,omitempty"`
	// Filesystem types to include/exclude. Examples: ext4, !*tmpfs, !squashfs. Wildcards and ! (not) operators are supported. All types are included if this list is empty.
	Fstypes []string `json:"fstypes,omitempty"`
	// Generate separate metrics for each device
	PerDevice *bool `default:"false" json:"perDevice"`
	// Generate full disk metrics
	Detail *bool `default:"false" json:"detail"`
}

func (d Disk) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(d, "", false)
}

func (d *Disk) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &d, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *Disk) GetMode() *InputSystemMetricsInputHostCustomDiskMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *Disk) GetDevices() []string {
	if o == nil {
		return nil
	}
	return o.Devices
}

func (o *Disk) GetMountpoints() []string {
	if o == nil {
		return nil
	}
	return o.Mountpoints
}

func (o *Disk) GetFstypes() []string {
	if o == nil {
		return nil
	}
	return o.Fstypes
}

func (o *Disk) GetPerDevice() *bool {
	if o == nil {
		return nil
	}
	return o.PerDevice
}

func (o *Disk) GetDetail() *bool {
	if o == nil {
		return nil
	}
	return o.Detail
}

type Custom struct {
	System  *InputSystemMetricsSystem `json:"system,omitempty"`
	CPU     *CPU                      `json:"cpu,omitempty"`
	Memory  *InputSystemMetricsMemory `json:"memory,omitempty"`
	Network *Network                  `json:"network,omitempty"`
	Disk    *Disk                     `json:"disk,omitempty"`
}

func (o *Custom) GetSystem() *InputSystemMetricsSystem {
	if o == nil {
		return nil
	}
	return o.System
}

func (o *Custom) GetCPU() *CPU {
	if o == nil {
		return nil
	}
	return o.CPU
}

func (o *Custom) GetMemory() *InputSystemMetricsMemory {
	if o == nil {
		return nil
	}
	return o.Memory
}

func (o *Custom) GetNetwork() *Network {
	if o == nil {
		return nil
	}
	return o.Network
}

func (o *Custom) GetDisk() *Disk {
	if o == nil {
		return nil
	}
	return o.Disk
}

type Host struct {
	// Select level of detail for host metrics
	Mode   *InputSystemMetricsMode `default:"basic" json:"mode"`
	Custom *Custom                 `json:"custom,omitempty"`
}

func (h Host) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(h, "", false)
}

func (h *Host) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &h, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *Host) GetMode() *InputSystemMetricsMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *Host) GetCustom() *Custom {
	if o == nil {
		return nil
	}
	return o.Custom
}

type Sets struct {
	Name            string `json:"name"`
	Filter          string `json:"filter"`
	IncludeChildren *bool  `default:"false" json:"includeChildren"`
}

func (s Sets) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *Sets) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *Sets) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *Sets) GetFilter() string {
	if o == nil {
		return ""
	}
	return o.Filter
}

func (o *Sets) GetIncludeChildren() *bool {
	if o == nil {
		return nil
	}
	return o.IncludeChildren
}

type InputSystemMetricsProcess struct {
	// Configure sets to collect process metrics
	Sets []Sets `json:"sets,omitempty"`
}

func (o *InputSystemMetricsProcess) GetSets() []Sets {
	if o == nil {
		return nil
	}
	return o.Sets
}

// InputSystemMetricsInputMode - Select the level of detail for container metrics
type InputSystemMetricsInputMode string

const (
	InputSystemMetricsInputModeBasic    InputSystemMetricsInputMode = "basic"
	InputSystemMetricsInputModeAll      InputSystemMetricsInputMode = "all"
	InputSystemMetricsInputModeCustom   InputSystemMetricsInputMode = "custom"
	InputSystemMetricsInputModeDisabled InputSystemMetricsInputMode = "disabled"
)

func (e InputSystemMetricsInputMode) ToPointer() *InputSystemMetricsInputMode {
	return &e
}
func (e *InputSystemMetricsInputMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "basic":
		fallthrough
	case "all":
		fallthrough
	case "custom":
		fallthrough
	case "disabled":
		*e = InputSystemMetricsInputMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSystemMetricsInputMode: %v", v)
	}
}

type Filters struct {
	Expr string `json:"expr"`
}

func (o *Filters) GetExpr() string {
	if o == nil {
		return ""
	}
	return o.Expr
}

type InputSystemMetricsContainer struct {
	// Select the level of detail for container metrics
	Mode *InputSystemMetricsInputMode `default:"basic" json:"mode"`
	// Full paths for Docker's UNIX-domain socket
	DockerSocket []string `json:"dockerSocket,omitempty"`
	// Timeout, in seconds, for the Docker API
	DockerTimeout *float64 `default:"5" json:"dockerTimeout"`
	// Containers matching any of these will be included. All are included if no filters are added.
	Filters []Filters `json:"filters,omitempty"`
	// Include stopped and paused containers
	AllContainers *bool `default:"false" json:"allContainers"`
	// Generate separate metrics for each device
	PerDevice *bool `default:"false" json:"perDevice"`
	// Generate full container metrics
	Detail *bool `default:"false" json:"detail"`
}

func (i InputSystemMetricsContainer) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSystemMetricsContainer) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputSystemMetricsContainer) GetMode() *InputSystemMetricsInputMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputSystemMetricsContainer) GetDockerSocket() []string {
	if o == nil {
		return nil
	}
	return o.DockerSocket
}

func (o *InputSystemMetricsContainer) GetDockerTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.DockerTimeout
}

func (o *InputSystemMetricsContainer) GetFilters() []Filters {
	if o == nil {
		return nil
	}
	return o.Filters
}

func (o *InputSystemMetricsContainer) GetAllContainers() *bool {
	if o == nil {
		return nil
	}
	return o.AllContainers
}

func (o *InputSystemMetricsContainer) GetPerDevice() *bool {
	if o == nil {
		return nil
	}
	return o.PerDevice
}

func (o *InputSystemMetricsContainer) GetDetail() *bool {
	if o == nil {
		return nil
	}
	return o.Detail
}

type InputSystemMetricsMetadata struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputSystemMetricsMetadata) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputSystemMetricsMetadata) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputSystemMetricsDataCompressionFormat string

const (
	InputSystemMetricsDataCompressionFormatNone InputSystemMetricsDataCompressionFormat = "none"
	InputSystemMetricsDataCompressionFormatGzip InputSystemMetricsDataCompressionFormat = "gzip"
)

func (e InputSystemMetricsDataCompressionFormat) ToPointer() *InputSystemMetricsDataCompressionFormat {
	return &e
}
func (e *InputSystemMetricsDataCompressionFormat) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputSystemMetricsDataCompressionFormat(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSystemMetricsDataCompressionFormat: %v", v)
	}
}

type InputSystemMetricsPersistence struct {
	// Spool metrics to disk for Cribl Edge and Search
	Enable *bool `default:"false" json:"enable"`
	// Time span for each file bucket
	TimeWindow *string `default:"10m" json:"timeWindow"`
	// Maximum disk space allowed to be consumed (examples: 420MB, 4GB). When limit is reached, older data will be deleted.
	MaxDataSize *string `default:"1GB" json:"maxDataSize"`
	// Maximum amount of time to retain data (examples: 2h, 4d). When limit is reached, older data will be deleted.
	MaxDataTime *string                                  `default:"24h" json:"maxDataTime"`
	Compress    *InputSystemMetricsDataCompressionFormat `default:"gzip" json:"compress"`
	// Path to use to write metrics. Defaults to $CRIBL_HOME/state/system_metrics
	DestPath *string `default:"\\$CRIBL_HOME/state/system_metrics" json:"destPath"`
}

func (i InputSystemMetricsPersistence) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSystemMetricsPersistence) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputSystemMetricsPersistence) GetEnable() *bool {
	if o == nil {
		return nil
	}
	return o.Enable
}

func (o *InputSystemMetricsPersistence) GetTimeWindow() *string {
	if o == nil {
		return nil
	}
	return o.TimeWindow
}

func (o *InputSystemMetricsPersistence) GetMaxDataSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxDataSize
}

func (o *InputSystemMetricsPersistence) GetMaxDataTime() *string {
	if o == nil {
		return nil
	}
	return o.MaxDataTime
}

func (o *InputSystemMetricsPersistence) GetCompress() *InputSystemMetricsDataCompressionFormat {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *InputSystemMetricsPersistence) GetDestPath() *string {
	if o == nil {
		return nil
	}
	return o.DestPath
}

type InputSystemMetrics struct {
	// Unique ID for this input
	ID       string                 `json:"id"`
	Type     InputSystemMetricsType `json:"type"`
	Disabled *bool                  `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputSystemMetricsConnections `json:"connections,omitempty"`
	Pq          *InputSystemMetricsPq           `json:"pq,omitempty"`
	// Time, in seconds, between consecutive metric collections. Default is 10 seconds.
	Interval  *float64                     `default:"10" json:"interval"`
	Host      *Host                        `json:"host,omitempty"`
	Process   *InputSystemMetricsProcess   `json:"process,omitempty"`
	Container *InputSystemMetricsContainer `json:"container,omitempty"`
	// Fields to add to events from this input
	Metadata    []InputSystemMetricsMetadata   `json:"metadata,omitempty"`
	Persistence *InputSystemMetricsPersistence `json:"persistence,omitempty"`
	Description *string                        `json:"description,omitempty"`
	Status      *TFStatus                      `json:"status,omitempty"`
}

func (i InputSystemMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSystemMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputSystemMetrics) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *InputSystemMetrics) GetType() InputSystemMetricsType {
	if o == nil {
		return InputSystemMetricsType("")
	}
	return o.Type
}

func (o *InputSystemMetrics) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputSystemMetrics) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputSystemMetrics) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputSystemMetrics) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputSystemMetrics) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputSystemMetrics) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputSystemMetrics) GetConnections() []InputSystemMetricsConnections {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputSystemMetrics) GetPq() *InputSystemMetricsPq {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputSystemMetrics) GetInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.Interval
}

func (o *InputSystemMetrics) GetHost() *Host {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputSystemMetrics) GetProcess() *InputSystemMetricsProcess {
	if o == nil {
		return nil
	}
	return o.Process
}

func (o *InputSystemMetrics) GetContainer() *InputSystemMetricsContainer {
	if o == nil {
		return nil
	}
	return o.Container
}

func (o *InputSystemMetrics) GetMetadata() []InputSystemMetricsMetadata {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputSystemMetrics) GetPersistence() *InputSystemMetricsPersistence {
	if o == nil {
		return nil
	}
	return o.Persistence
}

func (o *InputSystemMetrics) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputSystemMetrics) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputTcpjsonType string

const (
	InputTcpjsonTypeTcpjson InputTcpjsonType = "tcpjson"
)

func (e InputTcpjsonType) ToPointer() *InputTcpjsonType {
	return &e
}
func (e *InputTcpjsonType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "tcpjson":
		*e = InputTcpjsonType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputTcpjsonType: %v", v)
	}
}

type InputTcpjsonConnections struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *InputTcpjsonConnections) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputTcpjsonConnections) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// InputTcpjsonMode - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputTcpjsonMode string

const (
	InputTcpjsonModeSmart  InputTcpjsonMode = "smart"
	InputTcpjsonModeAlways InputTcpjsonMode = "always"
)

func (e InputTcpjsonMode) ToPointer() *InputTcpjsonMode {
	return &e
}
func (e *InputTcpjsonMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputTcpjsonMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputTcpjsonMode: %v", v)
	}
}

// InputTcpjsonCompression - Codec to use to compress the persisted data
type InputTcpjsonCompression string

const (
	InputTcpjsonCompressionNone InputTcpjsonCompression = "none"
	InputTcpjsonCompressionGzip InputTcpjsonCompression = "gzip"
)

func (e InputTcpjsonCompression) ToPointer() *InputTcpjsonCompression {
	return &e
}
func (e *InputTcpjsonCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputTcpjsonCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputTcpjsonCompression: %v", v)
	}
}

type InputTcpjsonPq struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputTcpjsonMode `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *InputTcpjsonCompression `default:"none" json:"compress"`
}

func (i InputTcpjsonPq) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputTcpjsonPq) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputTcpjsonPq) GetMode() *InputTcpjsonMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputTcpjsonPq) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputTcpjsonPq) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *InputTcpjsonPq) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *InputTcpjsonPq) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *InputTcpjsonPq) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *InputTcpjsonPq) GetCompress() *InputTcpjsonCompression {
	if o == nil {
		return nil
	}
	return o.Compress
}

// InputTcpjsonMinimumTLSVersion - Minimum TLS version to accept from connections
type InputTcpjsonMinimumTLSVersion string

const (
	InputTcpjsonMinimumTLSVersionTlSv1  InputTcpjsonMinimumTLSVersion = "TLSv1"
	InputTcpjsonMinimumTLSVersionTlSv11 InputTcpjsonMinimumTLSVersion = "TLSv1.1"
	InputTcpjsonMinimumTLSVersionTlSv12 InputTcpjsonMinimumTLSVersion = "TLSv1.2"
	InputTcpjsonMinimumTLSVersionTlSv13 InputTcpjsonMinimumTLSVersion = "TLSv1.3"
)

func (e InputTcpjsonMinimumTLSVersion) ToPointer() *InputTcpjsonMinimumTLSVersion {
	return &e
}
func (e *InputTcpjsonMinimumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputTcpjsonMinimumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputTcpjsonMinimumTLSVersion: %v", v)
	}
}

// InputTcpjsonMaximumTLSVersion - Maximum TLS version to accept from connections
type InputTcpjsonMaximumTLSVersion string

const (
	InputTcpjsonMaximumTLSVersionTlSv1  InputTcpjsonMaximumTLSVersion = "TLSv1"
	InputTcpjsonMaximumTLSVersionTlSv11 InputTcpjsonMaximumTLSVersion = "TLSv1.1"
	InputTcpjsonMaximumTLSVersionTlSv12 InputTcpjsonMaximumTLSVersion = "TLSv1.2"
	InputTcpjsonMaximumTLSVersionTlSv13 InputTcpjsonMaximumTLSVersion = "TLSv1.3"
)

func (e InputTcpjsonMaximumTLSVersion) ToPointer() *InputTcpjsonMaximumTLSVersion {
	return &e
}
func (e *InputTcpjsonMaximumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputTcpjsonMaximumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputTcpjsonMaximumTLSVersion: %v", v)
	}
}

type InputTcpjsonTLSSettingsServerSide struct {
	Disabled *bool `default:"true" json:"disabled"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert        *bool `default:"false" json:"requestCert"`
	RejectUnauthorized any   `json:"rejectUnauthorized,omitempty"`
	CommonNameRegex    any   `json:"commonNameRegex,omitempty"`
	// Minimum TLS version to accept from connections
	MinVersion *InputTcpjsonMinimumTLSVersion `json:"minVersion,omitempty"`
	// Maximum TLS version to accept from connections
	MaxVersion *InputTcpjsonMaximumTLSVersion `json:"maxVersion,omitempty"`
}

func (i InputTcpjsonTLSSettingsServerSide) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputTcpjsonTLSSettingsServerSide) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputTcpjsonTLSSettingsServerSide) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputTcpjsonTLSSettingsServerSide) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *InputTcpjsonTLSSettingsServerSide) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *InputTcpjsonTLSSettingsServerSide) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *InputTcpjsonTLSSettingsServerSide) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *InputTcpjsonTLSSettingsServerSide) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *InputTcpjsonTLSSettingsServerSide) GetRequestCert() *bool {
	if o == nil {
		return nil
	}
	return o.RequestCert
}

func (o *InputTcpjsonTLSSettingsServerSide) GetRejectUnauthorized() any {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *InputTcpjsonTLSSettingsServerSide) GetCommonNameRegex() any {
	if o == nil {
		return nil
	}
	return o.CommonNameRegex
}

func (o *InputTcpjsonTLSSettingsServerSide) GetMinVersion() *InputTcpjsonMinimumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *InputTcpjsonTLSSettingsServerSide) GetMaxVersion() *InputTcpjsonMaximumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

type InputTcpjsonMetadata struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputTcpjsonMetadata) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputTcpjsonMetadata) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// InputTcpjsonAuthenticationMethod - Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
type InputTcpjsonAuthenticationMethod string

const (
	InputTcpjsonAuthenticationMethodManual InputTcpjsonAuthenticationMethod = "manual"
	InputTcpjsonAuthenticationMethodSecret InputTcpjsonAuthenticationMethod = "secret"
)

func (e InputTcpjsonAuthenticationMethod) ToPointer() *InputTcpjsonAuthenticationMethod {
	return &e
}
func (e *InputTcpjsonAuthenticationMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "manual":
		fallthrough
	case "secret":
		*e = InputTcpjsonAuthenticationMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputTcpjsonAuthenticationMethod: %v", v)
	}
}

type InputTcpjson struct {
	// Unique ID for this input
	ID       *string           `json:"id,omitempty"`
	Type     *InputTcpjsonType `json:"type,omitempty"`
	Disabled *bool             `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputTcpjsonConnections `json:"connections,omitempty"`
	Pq          *InputTcpjsonPq           `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port float64                            `json:"port"`
	TLS  *InputTcpjsonTLSSettingsServerSide `json:"tls,omitempty"`
	// Regex matching IP addresses that are allowed to establish a connection
	IPWhitelistRegex *string `default:"/.*/" json:"ipWhitelistRegex"`
	// Maximum number of active connections allowed per Worker Process. Use 0 for unlimited.
	MaxActiveCxn *float64 `default:"1000" json:"maxActiveCxn"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. After this time, the connection will be closed. Leave at 0 for no inactive socket monitoring.
	SocketIdleTimeout *float64 `default:"0" json:"socketIdleTimeout"`
	// How long the server will wait after initiating a closure for a client to close its end of the connection. If the client doesn't close the connection within this time, the server will forcefully terminate the socket to prevent resource leaks and ensure efficient connection cleanup and system stability. Leave at 0 for no inactive socket monitoring.
	SocketEndingMaxWait *float64 `default:"30" json:"socketEndingMaxWait"`
	// The maximum duration a socket can remain open, even if active. This helps manage resources and mitigate issues caused by TCP pinning. Set to 0 to disable.
	SocketMaxLifespan *float64 `default:"0" json:"socketMaxLifespan"`
	// Enable if the connection is proxied by a device that supports proxy protocol v1 or v2
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Fields to add to events from this input
	Metadata []InputTcpjsonMetadata `json:"metadata,omitempty"`
	// Load balance traffic across all Worker Processes
	EnableLoadBalancing *bool `default:"false" json:"enableLoadBalancing"`
	// Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
	AuthType    *InputTcpjsonAuthenticationMethod `default:"manual" json:"authType"`
	Description *string                           `json:"description,omitempty"`
	// Shared secret to be provided by any client (in authToken header field). If empty, unauthorized access is permitted.
	AuthToken *string `default:"" json:"authToken"`
	// Select or create a stored text secret
	TextSecret *string   `json:"textSecret,omitempty"`
	Status     *TFStatus `json:"status,omitempty"`
}

func (i InputTcpjson) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputTcpjson) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputTcpjson) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputTcpjson) GetType() *InputTcpjsonType {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputTcpjson) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputTcpjson) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputTcpjson) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputTcpjson) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputTcpjson) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputTcpjson) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputTcpjson) GetConnections() []InputTcpjsonConnections {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputTcpjson) GetPq() *InputTcpjsonPq {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputTcpjson) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputTcpjson) GetPort() float64 {
	if o == nil {
		return 0.0
	}
	return o.Port
}

func (o *InputTcpjson) GetTLS() *InputTcpjsonTLSSettingsServerSide {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputTcpjson) GetIPWhitelistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPWhitelistRegex
}

func (o *InputTcpjson) GetMaxActiveCxn() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxActiveCxn
}

func (o *InputTcpjson) GetSocketIdleTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketIdleTimeout
}

func (o *InputTcpjson) GetSocketEndingMaxWait() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketEndingMaxWait
}

func (o *InputTcpjson) GetSocketMaxLifespan() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketMaxLifespan
}

func (o *InputTcpjson) GetEnableProxyHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableProxyHeader
}

func (o *InputTcpjson) GetMetadata() []InputTcpjsonMetadata {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputTcpjson) GetEnableLoadBalancing() *bool {
	if o == nil {
		return nil
	}
	return o.EnableLoadBalancing
}

func (o *InputTcpjson) GetAuthType() *InputTcpjsonAuthenticationMethod {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *InputTcpjson) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputTcpjson) GetAuthToken() *string {
	if o == nil {
		return nil
	}
	return o.AuthToken
}

func (o *InputTcpjson) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *InputTcpjson) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputCriblHTTPType string

const (
	InputCriblHTTPTypeCriblHTTP InputCriblHTTPType = "cribl_http"
)

func (e InputCriblHTTPType) ToPointer() *InputCriblHTTPType {
	return &e
}
func (e *InputCriblHTTPType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "cribl_http":
		*e = InputCriblHTTPType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputCriblHTTPType: %v", v)
	}
}

type InputCriblHTTPConnections struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *InputCriblHTTPConnections) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputCriblHTTPConnections) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// InputCriblHTTPMode - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputCriblHTTPMode string

const (
	InputCriblHTTPModeSmart  InputCriblHTTPMode = "smart"
	InputCriblHTTPModeAlways InputCriblHTTPMode = "always"
)

func (e InputCriblHTTPMode) ToPointer() *InputCriblHTTPMode {
	return &e
}
func (e *InputCriblHTTPMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputCriblHTTPMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputCriblHTTPMode: %v", v)
	}
}

// InputCriblHTTPCompression - Codec to use to compress the persisted data
type InputCriblHTTPCompression string

const (
	InputCriblHTTPCompressionNone InputCriblHTTPCompression = "none"
	InputCriblHTTPCompressionGzip InputCriblHTTPCompression = "gzip"
)

func (e InputCriblHTTPCompression) ToPointer() *InputCriblHTTPCompression {
	return &e
}
func (e *InputCriblHTTPCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputCriblHTTPCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputCriblHTTPCompression: %v", v)
	}
}

type InputCriblHTTPPq struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputCriblHTTPMode `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *InputCriblHTTPCompression `default:"none" json:"compress"`
}

func (i InputCriblHTTPPq) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputCriblHTTPPq) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputCriblHTTPPq) GetMode() *InputCriblHTTPMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputCriblHTTPPq) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputCriblHTTPPq) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *InputCriblHTTPPq) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *InputCriblHTTPPq) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *InputCriblHTTPPq) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *InputCriblHTTPPq) GetCompress() *InputCriblHTTPCompression {
	if o == nil {
		return nil
	}
	return o.Compress
}

// InputCriblHTTPMinimumTLSVersion - Minimum TLS version to accept from connections
type InputCriblHTTPMinimumTLSVersion string

const (
	InputCriblHTTPMinimumTLSVersionTlSv1  InputCriblHTTPMinimumTLSVersion = "TLSv1"
	InputCriblHTTPMinimumTLSVersionTlSv11 InputCriblHTTPMinimumTLSVersion = "TLSv1.1"
	InputCriblHTTPMinimumTLSVersionTlSv12 InputCriblHTTPMinimumTLSVersion = "TLSv1.2"
	InputCriblHTTPMinimumTLSVersionTlSv13 InputCriblHTTPMinimumTLSVersion = "TLSv1.3"
)

func (e InputCriblHTTPMinimumTLSVersion) ToPointer() *InputCriblHTTPMinimumTLSVersion {
	return &e
}
func (e *InputCriblHTTPMinimumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputCriblHTTPMinimumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputCriblHTTPMinimumTLSVersion: %v", v)
	}
}

// InputCriblHTTPMaximumTLSVersion - Maximum TLS version to accept from connections
type InputCriblHTTPMaximumTLSVersion string

const (
	InputCriblHTTPMaximumTLSVersionTlSv1  InputCriblHTTPMaximumTLSVersion = "TLSv1"
	InputCriblHTTPMaximumTLSVersionTlSv11 InputCriblHTTPMaximumTLSVersion = "TLSv1.1"
	InputCriblHTTPMaximumTLSVersionTlSv12 InputCriblHTTPMaximumTLSVersion = "TLSv1.2"
	InputCriblHTTPMaximumTLSVersionTlSv13 InputCriblHTTPMaximumTLSVersion = "TLSv1.3"
)

func (e InputCriblHTTPMaximumTLSVersion) ToPointer() *InputCriblHTTPMaximumTLSVersion {
	return &e
}
func (e *InputCriblHTTPMaximumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputCriblHTTPMaximumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputCriblHTTPMaximumTLSVersion: %v", v)
	}
}

type InputCriblHTTPTLSSettingsServerSide struct {
	Disabled *bool `default:"true" json:"disabled"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert        *bool `default:"false" json:"requestCert"`
	RejectUnauthorized any   `json:"rejectUnauthorized,omitempty"`
	CommonNameRegex    any   `json:"commonNameRegex,omitempty"`
	// Minimum TLS version to accept from connections
	MinVersion *InputCriblHTTPMinimumTLSVersion `json:"minVersion,omitempty"`
	// Maximum TLS version to accept from connections
	MaxVersion *InputCriblHTTPMaximumTLSVersion `json:"maxVersion,omitempty"`
}

func (i InputCriblHTTPTLSSettingsServerSide) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputCriblHTTPTLSSettingsServerSide) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputCriblHTTPTLSSettingsServerSide) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputCriblHTTPTLSSettingsServerSide) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *InputCriblHTTPTLSSettingsServerSide) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *InputCriblHTTPTLSSettingsServerSide) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *InputCriblHTTPTLSSettingsServerSide) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *InputCriblHTTPTLSSettingsServerSide) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *InputCriblHTTPTLSSettingsServerSide) GetRequestCert() *bool {
	if o == nil {
		return nil
	}
	return o.RequestCert
}

func (o *InputCriblHTTPTLSSettingsServerSide) GetRejectUnauthorized() any {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *InputCriblHTTPTLSSettingsServerSide) GetCommonNameRegex() any {
	if o == nil {
		return nil
	}
	return o.CommonNameRegex
}

func (o *InputCriblHTTPTLSSettingsServerSide) GetMinVersion() *InputCriblHTTPMinimumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *InputCriblHTTPTLSSettingsServerSide) GetMaxVersion() *InputCriblHTTPMaximumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

type InputCriblHTTPMetadata struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputCriblHTTPMetadata) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputCriblHTTPMetadata) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputCriblHTTP struct {
	// Unique ID for this input
	ID       *string             `json:"id,omitempty"`
	Type     *InputCriblHTTPType `json:"type,omitempty"`
	Disabled *bool               `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputCriblHTTPConnections `json:"connections,omitempty"`
	Pq          *InputCriblHTTPPq           `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port float64 `json:"port"`
	// Shared secrets to be provided by any client (Authorization: <token>). If empty, unauthorized access is permitted.
	AuthTokens []string                             `json:"authTokens,omitempty"`
	TLS        *InputCriblHTTPTLSSettingsServerSide `json:"tls,omitempty"`
	// Maximum number of active requests per Worker Process. Use 0 for unlimited.
	MaxActiveReq *float64 `default:"256" json:"maxActiveReq"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket *int64 `default:"0" json:"maxRequestsPerSocket"`
	// Enable when clients are connecting through a proxy that supports the x-forwarded-for header to keep the client's original IP address on the event instead of the proxy's IP address
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Add request headers to events, in the __headers field
	CaptureHeaders *bool `default:"false" json:"captureHeaders"`
	// How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
	ActivityLogSampleRate *float64 `default:"100" json:"activityLogSampleRate"`
	// How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
	RequestTimeout *float64 `default:"0" json:"requestTimeout"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `default:"0" json:"socketTimeout"`
	// After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 sec.; maximum 600 sec. (10 min.).
	KeepAliveTimeout *float64 `default:"5" json:"keepAliveTimeout"`
	// Enable to expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
	EnableHealthCheck *bool `default:"false" json:"enableHealthCheck"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist
	IPAllowlistRegex *string `default:"/.*/" json:"ipAllowlistRegex"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `default:"/^\\$/" json:"ipDenylistRegex"`
	// Fields to add to events from this input
	Metadata    []InputCriblHTTPMetadata `json:"metadata,omitempty"`
	Description *string                  `json:"description,omitempty"`
	Status      *TFStatus                `json:"status,omitempty"`
}

func (i InputCriblHTTP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputCriblHTTP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputCriblHTTP) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputCriblHTTP) GetType() *InputCriblHTTPType {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputCriblHTTP) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputCriblHTTP) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputCriblHTTP) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputCriblHTTP) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputCriblHTTP) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputCriblHTTP) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputCriblHTTP) GetConnections() []InputCriblHTTPConnections {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputCriblHTTP) GetPq() *InputCriblHTTPPq {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputCriblHTTP) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputCriblHTTP) GetPort() float64 {
	if o == nil {
		return 0.0
	}
	return o.Port
}

func (o *InputCriblHTTP) GetAuthTokens() []string {
	if o == nil {
		return nil
	}
	return o.AuthTokens
}

func (o *InputCriblHTTP) GetTLS() *InputCriblHTTPTLSSettingsServerSide {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputCriblHTTP) GetMaxActiveReq() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxActiveReq
}

func (o *InputCriblHTTP) GetMaxRequestsPerSocket() *int64 {
	if o == nil {
		return nil
	}
	return o.MaxRequestsPerSocket
}

func (o *InputCriblHTTP) GetEnableProxyHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableProxyHeader
}

func (o *InputCriblHTTP) GetCaptureHeaders() *bool {
	if o == nil {
		return nil
	}
	return o.CaptureHeaders
}

func (o *InputCriblHTTP) GetActivityLogSampleRate() *float64 {
	if o == nil {
		return nil
	}
	return o.ActivityLogSampleRate
}

func (o *InputCriblHTTP) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *InputCriblHTTP) GetSocketTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketTimeout
}

func (o *InputCriblHTTP) GetKeepAliveTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.KeepAliveTimeout
}

func (o *InputCriblHTTP) GetEnableHealthCheck() *bool {
	if o == nil {
		return nil
	}
	return o.EnableHealthCheck
}

func (o *InputCriblHTTP) GetIPAllowlistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPAllowlistRegex
}

func (o *InputCriblHTTP) GetIPDenylistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPDenylistRegex
}

func (o *InputCriblHTTP) GetMetadata() []InputCriblHTTPMetadata {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputCriblHTTP) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputCriblHTTP) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputCriblTCPType string

const (
	InputCriblTCPTypeCriblTCP InputCriblTCPType = "cribl_tcp"
)

func (e InputCriblTCPType) ToPointer() *InputCriblTCPType {
	return &e
}
func (e *InputCriblTCPType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "cribl_tcp":
		*e = InputCriblTCPType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputCriblTCPType: %v", v)
	}
}

type InputCriblTCPConnections struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *InputCriblTCPConnections) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputCriblTCPConnections) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// InputCriblTCPMode - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputCriblTCPMode string

const (
	InputCriblTCPModeSmart  InputCriblTCPMode = "smart"
	InputCriblTCPModeAlways InputCriblTCPMode = "always"
)

func (e InputCriblTCPMode) ToPointer() *InputCriblTCPMode {
	return &e
}
func (e *InputCriblTCPMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputCriblTCPMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputCriblTCPMode: %v", v)
	}
}

// InputCriblTCPCompression - Codec to use to compress the persisted data
type InputCriblTCPCompression string

const (
	InputCriblTCPCompressionNone InputCriblTCPCompression = "none"
	InputCriblTCPCompressionGzip InputCriblTCPCompression = "gzip"
)

func (e InputCriblTCPCompression) ToPointer() *InputCriblTCPCompression {
	return &e
}
func (e *InputCriblTCPCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputCriblTCPCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputCriblTCPCompression: %v", v)
	}
}

type InputCriblTCPPq struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputCriblTCPMode `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *InputCriblTCPCompression `default:"none" json:"compress"`
}

func (i InputCriblTCPPq) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputCriblTCPPq) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputCriblTCPPq) GetMode() *InputCriblTCPMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputCriblTCPPq) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputCriblTCPPq) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *InputCriblTCPPq) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *InputCriblTCPPq) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *InputCriblTCPPq) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *InputCriblTCPPq) GetCompress() *InputCriblTCPCompression {
	if o == nil {
		return nil
	}
	return o.Compress
}

// InputCriblTCPMinimumTLSVersion - Minimum TLS version to accept from connections
type InputCriblTCPMinimumTLSVersion string

const (
	InputCriblTCPMinimumTLSVersionTlSv1  InputCriblTCPMinimumTLSVersion = "TLSv1"
	InputCriblTCPMinimumTLSVersionTlSv11 InputCriblTCPMinimumTLSVersion = "TLSv1.1"
	InputCriblTCPMinimumTLSVersionTlSv12 InputCriblTCPMinimumTLSVersion = "TLSv1.2"
	InputCriblTCPMinimumTLSVersionTlSv13 InputCriblTCPMinimumTLSVersion = "TLSv1.3"
)

func (e InputCriblTCPMinimumTLSVersion) ToPointer() *InputCriblTCPMinimumTLSVersion {
	return &e
}
func (e *InputCriblTCPMinimumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputCriblTCPMinimumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputCriblTCPMinimumTLSVersion: %v", v)
	}
}

// InputCriblTCPMaximumTLSVersion - Maximum TLS version to accept from connections
type InputCriblTCPMaximumTLSVersion string

const (
	InputCriblTCPMaximumTLSVersionTlSv1  InputCriblTCPMaximumTLSVersion = "TLSv1"
	InputCriblTCPMaximumTLSVersionTlSv11 InputCriblTCPMaximumTLSVersion = "TLSv1.1"
	InputCriblTCPMaximumTLSVersionTlSv12 InputCriblTCPMaximumTLSVersion = "TLSv1.2"
	InputCriblTCPMaximumTLSVersionTlSv13 InputCriblTCPMaximumTLSVersion = "TLSv1.3"
)

func (e InputCriblTCPMaximumTLSVersion) ToPointer() *InputCriblTCPMaximumTLSVersion {
	return &e
}
func (e *InputCriblTCPMaximumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputCriblTCPMaximumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputCriblTCPMaximumTLSVersion: %v", v)
	}
}

type InputCriblTCPTLSSettingsServerSide struct {
	Disabled *bool `default:"true" json:"disabled"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert        *bool `default:"false" json:"requestCert"`
	RejectUnauthorized any   `json:"rejectUnauthorized,omitempty"`
	CommonNameRegex    any   `json:"commonNameRegex,omitempty"`
	// Minimum TLS version to accept from connections
	MinVersion *InputCriblTCPMinimumTLSVersion `json:"minVersion,omitempty"`
	// Maximum TLS version to accept from connections
	MaxVersion *InputCriblTCPMaximumTLSVersion `json:"maxVersion,omitempty"`
}

func (i InputCriblTCPTLSSettingsServerSide) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputCriblTCPTLSSettingsServerSide) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputCriblTCPTLSSettingsServerSide) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputCriblTCPTLSSettingsServerSide) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *InputCriblTCPTLSSettingsServerSide) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *InputCriblTCPTLSSettingsServerSide) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *InputCriblTCPTLSSettingsServerSide) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *InputCriblTCPTLSSettingsServerSide) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *InputCriblTCPTLSSettingsServerSide) GetRequestCert() *bool {
	if o == nil {
		return nil
	}
	return o.RequestCert
}

func (o *InputCriblTCPTLSSettingsServerSide) GetRejectUnauthorized() any {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *InputCriblTCPTLSSettingsServerSide) GetCommonNameRegex() any {
	if o == nil {
		return nil
	}
	return o.CommonNameRegex
}

func (o *InputCriblTCPTLSSettingsServerSide) GetMinVersion() *InputCriblTCPMinimumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *InputCriblTCPTLSSettingsServerSide) GetMaxVersion() *InputCriblTCPMaximumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

type InputCriblTCPMetadata struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputCriblTCPMetadata) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputCriblTCPMetadata) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputCriblTCP struct {
	// Unique ID for this input
	ID       *string            `json:"id,omitempty"`
	Type     *InputCriblTCPType `json:"type,omitempty"`
	Disabled *bool              `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputCriblTCPConnections `json:"connections,omitempty"`
	Pq          *InputCriblTCPPq           `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port float64                             `json:"port"`
	TLS  *InputCriblTCPTLSSettingsServerSide `json:"tls,omitempty"`
	// Maximum number of active connections allowed per Worker Process. Use 0 for unlimited.
	MaxActiveCxn *float64 `default:"1000" json:"maxActiveCxn"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. After this time, the connection will be closed. Leave at 0 for no inactive socket monitoring.
	SocketIdleTimeout *float64 `default:"0" json:"socketIdleTimeout"`
	// How long the server will wait after initiating a closure for a client to close its end of the connection. If the client doesn't close the connection within this time, the server will forcefully terminate the socket to prevent resource leaks and ensure efficient connection cleanup and system stability. Leave at 0 for no inactive socket monitoring.
	SocketEndingMaxWait *float64 `default:"30" json:"socketEndingMaxWait"`
	// The maximum duration a socket can remain open, even if active. This helps manage resources and mitigate issues caused by TCP pinning. Set to 0 to disable.
	SocketMaxLifespan *float64 `default:"0" json:"socketMaxLifespan"`
	// Enable if the connection is proxied by a device that supports proxy protocol v1 or v2
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Fields to add to events from this input
	Metadata []InputCriblTCPMetadata `json:"metadata,omitempty"`
	// Load balance traffic across all Worker Processes
	EnableLoadBalancing *bool     `default:"false" json:"enableLoadBalancing"`
	Description         *string   `json:"description,omitempty"`
	Status              *TFStatus `json:"status,omitempty"`
}

func (i InputCriblTCP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputCriblTCP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputCriblTCP) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputCriblTCP) GetType() *InputCriblTCPType {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputCriblTCP) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputCriblTCP) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputCriblTCP) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputCriblTCP) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputCriblTCP) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputCriblTCP) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputCriblTCP) GetConnections() []InputCriblTCPConnections {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputCriblTCP) GetPq() *InputCriblTCPPq {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputCriblTCP) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputCriblTCP) GetPort() float64 {
	if o == nil {
		return 0.0
	}
	return o.Port
}

func (o *InputCriblTCP) GetTLS() *InputCriblTCPTLSSettingsServerSide {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputCriblTCP) GetMaxActiveCxn() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxActiveCxn
}

func (o *InputCriblTCP) GetSocketIdleTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketIdleTimeout
}

func (o *InputCriblTCP) GetSocketEndingMaxWait() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketEndingMaxWait
}

func (o *InputCriblTCP) GetSocketMaxLifespan() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketMaxLifespan
}

func (o *InputCriblTCP) GetEnableProxyHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableProxyHeader
}

func (o *InputCriblTCP) GetMetadata() []InputCriblTCPMetadata {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputCriblTCP) GetEnableLoadBalancing() *bool {
	if o == nil {
		return nil
	}
	return o.EnableLoadBalancing
}

func (o *InputCriblTCP) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputCriblTCP) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputCriblType string

const (
	InputCriblTypeCribl InputCriblType = "cribl"
)

func (e InputCriblType) ToPointer() *InputCriblType {
	return &e
}
func (e *InputCriblType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "cribl":
		*e = InputCriblType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputCriblType: %v", v)
	}
}

type InputCriblConnections struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *InputCriblConnections) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputCriblConnections) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// InputCriblMode - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputCriblMode string

const (
	InputCriblModeSmart  InputCriblMode = "smart"
	InputCriblModeAlways InputCriblMode = "always"
)

func (e InputCriblMode) ToPointer() *InputCriblMode {
	return &e
}
func (e *InputCriblMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputCriblMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputCriblMode: %v", v)
	}
}

// InputCriblCompression - Codec to use to compress the persisted data
type InputCriblCompression string

const (
	InputCriblCompressionNone InputCriblCompression = "none"
	InputCriblCompressionGzip InputCriblCompression = "gzip"
)

func (e InputCriblCompression) ToPointer() *InputCriblCompression {
	return &e
}
func (e *InputCriblCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputCriblCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputCriblCompression: %v", v)
	}
}

type InputCriblPq struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputCriblMode `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *InputCriblCompression `default:"none" json:"compress"`
}

func (i InputCriblPq) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputCriblPq) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputCriblPq) GetMode() *InputCriblMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputCriblPq) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputCriblPq) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *InputCriblPq) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *InputCriblPq) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *InputCriblPq) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *InputCriblPq) GetCompress() *InputCriblCompression {
	if o == nil {
		return nil
	}
	return o.Compress
}

type InputCriblMetadata struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputCriblMetadata) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputCriblMetadata) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputCribl struct {
	// Unique ID for this input
	ID       string         `json:"id"`
	Type     InputCriblType `json:"type"`
	Disabled *bool          `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputCriblConnections `json:"connections,omitempty"`
	Pq          *InputCriblPq           `json:"pq,omitempty"`
	Filter      *string                 `json:"filter,omitempty"`
	// Fields to add to events from this input
	Metadata    []InputCriblMetadata `json:"metadata,omitempty"`
	Description *string              `json:"description,omitempty"`
	Status      *TFStatus            `json:"status,omitempty"`
}

func (i InputCribl) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputCribl) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputCribl) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *InputCribl) GetType() InputCriblType {
	if o == nil {
		return InputCriblType("")
	}
	return o.Type
}

func (o *InputCribl) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputCribl) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputCribl) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputCribl) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputCribl) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputCribl) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputCribl) GetConnections() []InputCriblConnections {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputCribl) GetPq() *InputCriblPq {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputCribl) GetFilter() *string {
	if o == nil {
		return nil
	}
	return o.Filter
}

func (o *InputCribl) GetMetadata() []InputCriblMetadata {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputCribl) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputCribl) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputGooglePubsubType string

const (
	InputGooglePubsubTypeGooglePubsub InputGooglePubsubType = "google_pubsub"
)

func (e InputGooglePubsubType) ToPointer() *InputGooglePubsubType {
	return &e
}
func (e *InputGooglePubsubType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "google_pubsub":
		*e = InputGooglePubsubType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputGooglePubsubType: %v", v)
	}
}

type InputGooglePubsubConnections struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *InputGooglePubsubConnections) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputGooglePubsubConnections) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// InputGooglePubsubMode - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputGooglePubsubMode string

const (
	InputGooglePubsubModeSmart  InputGooglePubsubMode = "smart"
	InputGooglePubsubModeAlways InputGooglePubsubMode = "always"
)

func (e InputGooglePubsubMode) ToPointer() *InputGooglePubsubMode {
	return &e
}
func (e *InputGooglePubsubMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputGooglePubsubMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputGooglePubsubMode: %v", v)
	}
}

// InputGooglePubsubCompression - Codec to use to compress the persisted data
type InputGooglePubsubCompression string

const (
	InputGooglePubsubCompressionNone InputGooglePubsubCompression = "none"
	InputGooglePubsubCompressionGzip InputGooglePubsubCompression = "gzip"
)

func (e InputGooglePubsubCompression) ToPointer() *InputGooglePubsubCompression {
	return &e
}
func (e *InputGooglePubsubCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputGooglePubsubCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputGooglePubsubCompression: %v", v)
	}
}

type InputGooglePubsubPq struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputGooglePubsubMode `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *InputGooglePubsubCompression `default:"none" json:"compress"`
}

func (i InputGooglePubsubPq) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputGooglePubsubPq) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputGooglePubsubPq) GetMode() *InputGooglePubsubMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputGooglePubsubPq) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputGooglePubsubPq) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *InputGooglePubsubPq) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *InputGooglePubsubPq) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *InputGooglePubsubPq) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *InputGooglePubsubPq) GetCompress() *InputGooglePubsubCompression {
	if o == nil {
		return nil
	}
	return o.Compress
}

// InputGooglePubsubAuthenticationMethod - Google authentication method. Choose Auto to use Google Application Default Credentials.
type InputGooglePubsubAuthenticationMethod string

const (
	InputGooglePubsubAuthenticationMethodAuto   InputGooglePubsubAuthenticationMethod = "auto"
	InputGooglePubsubAuthenticationMethodManual InputGooglePubsubAuthenticationMethod = "manual"
	InputGooglePubsubAuthenticationMethodSecret InputGooglePubsubAuthenticationMethod = "secret"
)

func (e InputGooglePubsubAuthenticationMethod) ToPointer() *InputGooglePubsubAuthenticationMethod {
	return &e
}
func (e *InputGooglePubsubAuthenticationMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "auto":
		fallthrough
	case "manual":
		fallthrough
	case "secret":
		*e = InputGooglePubsubAuthenticationMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputGooglePubsubAuthenticationMethod: %v", v)
	}
}

type InputGooglePubsubMetadata struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputGooglePubsubMetadata) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputGooglePubsubMetadata) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputGooglePubsub struct {
	// Unique ID for this input
	ID       *string                `json:"id,omitempty"`
	Type     *InputGooglePubsubType `json:"type,omitempty"`
	Disabled *bool                  `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputGooglePubsubConnections `json:"connections,omitempty"`
	Pq          *InputGooglePubsubPq           `json:"pq,omitempty"`
	// ID of the topic to receive events from.
	TopicName string `json:"topicName"`
	// ID of the subscription to use when receiving events.
	SubscriptionName string `json:"subscriptionName"`
	// If enabled, create topic if it does not exist
	CreateTopic *bool `default:"false" json:"createTopic"`
	// If enabled, create subscription if it does not exist
	CreateSubscription *bool `default:"true" json:"createSubscription"`
	// Region to retrieve messages from. Select 'default' to allow Google to auto-select the nearest region. When using ordered delivery, the selected region must be allowed by message storage policy.
	Region *string `json:"region,omitempty"`
	// Google authentication method. Choose Auto to use Google Application Default Credentials.
	GoogleAuthMethod *InputGooglePubsubAuthenticationMethod `default:"manual" json:"googleAuthMethod"`
	// Contents of service account credentials (JSON keys) file downloaded from Google Cloud. To upload a file, click the upload button at this field's upper right.
	ServiceAccountCredentials *string `json:"serviceAccountCredentials,omitempty"`
	// Select or create a stored text secret
	Secret *string `json:"secret,omitempty"`
	// If Destination exerts backpressure, this setting limits how many inbound events Stream will queue for processing before it stops retrieving events.
	MaxBacklog *float64 `default:"1000" json:"maxBacklog"`
	// How many streams to pull messages from at one time. Doubling the value doubles the number of messages this Source pulls from the topic (if available), while consuming more CPU and memory. Defaults to 5.
	Concurrency *float64 `default:"5" json:"concurrency"`
	// Pull request timeout, in milliseconds.
	RequestTimeout *float64 `default:"60000" json:"requestTimeout"`
	// Fields to add to events from this input
	Metadata    []InputGooglePubsubMetadata `json:"metadata,omitempty"`
	Description *string                     `json:"description,omitempty"`
	// If enabled, receive events in the order they were added to the queue. For this to work correctly, the process sending events must have ordering enabled.
	OrderedDelivery *bool     `default:"false" json:"orderedDelivery"`
	Status          *TFStatus `json:"status,omitempty"`
}

func (i InputGooglePubsub) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputGooglePubsub) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputGooglePubsub) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputGooglePubsub) GetType() *InputGooglePubsubType {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputGooglePubsub) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputGooglePubsub) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputGooglePubsub) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputGooglePubsub) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputGooglePubsub) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputGooglePubsub) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputGooglePubsub) GetConnections() []InputGooglePubsubConnections {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputGooglePubsub) GetPq() *InputGooglePubsubPq {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputGooglePubsub) GetTopicName() string {
	if o == nil {
		return ""
	}
	return o.TopicName
}

func (o *InputGooglePubsub) GetSubscriptionName() string {
	if o == nil {
		return ""
	}
	return o.SubscriptionName
}

func (o *InputGooglePubsub) GetCreateTopic() *bool {
	if o == nil {
		return nil
	}
	return o.CreateTopic
}

func (o *InputGooglePubsub) GetCreateSubscription() *bool {
	if o == nil {
		return nil
	}
	return o.CreateSubscription
}

func (o *InputGooglePubsub) GetRegion() *string {
	if o == nil {
		return nil
	}
	return o.Region
}

func (o *InputGooglePubsub) GetGoogleAuthMethod() *InputGooglePubsubAuthenticationMethod {
	if o == nil {
		return nil
	}
	return o.GoogleAuthMethod
}

func (o *InputGooglePubsub) GetServiceAccountCredentials() *string {
	if o == nil {
		return nil
	}
	return o.ServiceAccountCredentials
}

func (o *InputGooglePubsub) GetSecret() *string {
	if o == nil {
		return nil
	}
	return o.Secret
}

func (o *InputGooglePubsub) GetMaxBacklog() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBacklog
}

func (o *InputGooglePubsub) GetConcurrency() *float64 {
	if o == nil {
		return nil
	}
	return o.Concurrency
}

func (o *InputGooglePubsub) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *InputGooglePubsub) GetMetadata() []InputGooglePubsubMetadata {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputGooglePubsub) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputGooglePubsub) GetOrderedDelivery() *bool {
	if o == nil {
		return nil
	}
	return o.OrderedDelivery
}

func (o *InputGooglePubsub) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputFirehoseType string

const (
	InputFirehoseTypeFirehose InputFirehoseType = "firehose"
)

func (e InputFirehoseType) ToPointer() *InputFirehoseType {
	return &e
}
func (e *InputFirehoseType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "firehose":
		*e = InputFirehoseType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputFirehoseType: %v", v)
	}
}

type InputFirehoseConnections struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *InputFirehoseConnections) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputFirehoseConnections) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// InputFirehoseMode - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputFirehoseMode string

const (
	InputFirehoseModeSmart  InputFirehoseMode = "smart"
	InputFirehoseModeAlways InputFirehoseMode = "always"
)

func (e InputFirehoseMode) ToPointer() *InputFirehoseMode {
	return &e
}
func (e *InputFirehoseMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputFirehoseMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputFirehoseMode: %v", v)
	}
}

// InputFirehoseCompression - Codec to use to compress the persisted data
type InputFirehoseCompression string

const (
	InputFirehoseCompressionNone InputFirehoseCompression = "none"
	InputFirehoseCompressionGzip InputFirehoseCompression = "gzip"
)

func (e InputFirehoseCompression) ToPointer() *InputFirehoseCompression {
	return &e
}
func (e *InputFirehoseCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputFirehoseCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputFirehoseCompression: %v", v)
	}
}

type InputFirehosePq struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputFirehoseMode `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *InputFirehoseCompression `default:"none" json:"compress"`
}

func (i InputFirehosePq) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputFirehosePq) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputFirehosePq) GetMode() *InputFirehoseMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputFirehosePq) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputFirehosePq) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *InputFirehosePq) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *InputFirehosePq) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *InputFirehosePq) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *InputFirehosePq) GetCompress() *InputFirehoseCompression {
	if o == nil {
		return nil
	}
	return o.Compress
}

// InputFirehoseMinimumTLSVersion - Minimum TLS version to accept from connections
type InputFirehoseMinimumTLSVersion string

const (
	InputFirehoseMinimumTLSVersionTlSv1  InputFirehoseMinimumTLSVersion = "TLSv1"
	InputFirehoseMinimumTLSVersionTlSv11 InputFirehoseMinimumTLSVersion = "TLSv1.1"
	InputFirehoseMinimumTLSVersionTlSv12 InputFirehoseMinimumTLSVersion = "TLSv1.2"
	InputFirehoseMinimumTLSVersionTlSv13 InputFirehoseMinimumTLSVersion = "TLSv1.3"
)

func (e InputFirehoseMinimumTLSVersion) ToPointer() *InputFirehoseMinimumTLSVersion {
	return &e
}
func (e *InputFirehoseMinimumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputFirehoseMinimumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputFirehoseMinimumTLSVersion: %v", v)
	}
}

// InputFirehoseMaximumTLSVersion - Maximum TLS version to accept from connections
type InputFirehoseMaximumTLSVersion string

const (
	InputFirehoseMaximumTLSVersionTlSv1  InputFirehoseMaximumTLSVersion = "TLSv1"
	InputFirehoseMaximumTLSVersionTlSv11 InputFirehoseMaximumTLSVersion = "TLSv1.1"
	InputFirehoseMaximumTLSVersionTlSv12 InputFirehoseMaximumTLSVersion = "TLSv1.2"
	InputFirehoseMaximumTLSVersionTlSv13 InputFirehoseMaximumTLSVersion = "TLSv1.3"
)

func (e InputFirehoseMaximumTLSVersion) ToPointer() *InputFirehoseMaximumTLSVersion {
	return &e
}
func (e *InputFirehoseMaximumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputFirehoseMaximumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputFirehoseMaximumTLSVersion: %v", v)
	}
}

type InputFirehoseTLSSettingsServerSide struct {
	Disabled *bool `default:"true" json:"disabled"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert        *bool `default:"false" json:"requestCert"`
	RejectUnauthorized any   `json:"rejectUnauthorized,omitempty"`
	CommonNameRegex    any   `json:"commonNameRegex,omitempty"`
	// Minimum TLS version to accept from connections
	MinVersion *InputFirehoseMinimumTLSVersion `json:"minVersion,omitempty"`
	// Maximum TLS version to accept from connections
	MaxVersion *InputFirehoseMaximumTLSVersion `json:"maxVersion,omitempty"`
}

func (i InputFirehoseTLSSettingsServerSide) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputFirehoseTLSSettingsServerSide) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputFirehoseTLSSettingsServerSide) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputFirehoseTLSSettingsServerSide) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *InputFirehoseTLSSettingsServerSide) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *InputFirehoseTLSSettingsServerSide) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *InputFirehoseTLSSettingsServerSide) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *InputFirehoseTLSSettingsServerSide) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *InputFirehoseTLSSettingsServerSide) GetRequestCert() *bool {
	if o == nil {
		return nil
	}
	return o.RequestCert
}

func (o *InputFirehoseTLSSettingsServerSide) GetRejectUnauthorized() any {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *InputFirehoseTLSSettingsServerSide) GetCommonNameRegex() any {
	if o == nil {
		return nil
	}
	return o.CommonNameRegex
}

func (o *InputFirehoseTLSSettingsServerSide) GetMinVersion() *InputFirehoseMinimumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *InputFirehoseTLSSettingsServerSide) GetMaxVersion() *InputFirehoseMaximumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

type InputFirehoseMetadata struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputFirehoseMetadata) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputFirehoseMetadata) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputFirehose struct {
	// Unique ID for this input
	ID       *string            `json:"id,omitempty"`
	Type     *InputFirehoseType `json:"type,omitempty"`
	Disabled *bool              `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputFirehoseConnections `json:"connections,omitempty"`
	Pq          *InputFirehosePq           `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port float64 `json:"port"`
	// Shared secrets to be provided by any client (Authorization: <token>). If empty, unauthorized access is permitted.
	AuthTokens []string                            `json:"authTokens,omitempty"`
	TLS        *InputFirehoseTLSSettingsServerSide `json:"tls,omitempty"`
	// Maximum number of active requests per Worker Process. Use 0 for unlimited.
	MaxActiveReq *float64 `default:"256" json:"maxActiveReq"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket *int64 `default:"0" json:"maxRequestsPerSocket"`
	// Enable when clients are connecting through a proxy that supports the x-forwarded-for header to keep the client's original IP address on the event instead of the proxy's IP address
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Add request headers to events, in the __headers field
	CaptureHeaders *bool `default:"false" json:"captureHeaders"`
	// How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
	ActivityLogSampleRate *float64 `default:"100" json:"activityLogSampleRate"`
	// How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
	RequestTimeout *float64 `default:"0" json:"requestTimeout"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `default:"0" json:"socketTimeout"`
	// After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 sec.; maximum 600 sec. (10 min.).
	KeepAliveTimeout *float64 `default:"5" json:"keepAliveTimeout"`
	// Enable to expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
	EnableHealthCheck *bool `default:"false" json:"enableHealthCheck"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist
	IPAllowlistRegex *string `default:"/.*/" json:"ipAllowlistRegex"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `default:"/^\\$/" json:"ipDenylistRegex"`
	// Fields to add to events from this input
	Metadata    []InputFirehoseMetadata `json:"metadata,omitempty"`
	Description *string                 `json:"description,omitempty"`
	Status      *TFStatus               `json:"status,omitempty"`
}

func (i InputFirehose) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputFirehose) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputFirehose) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputFirehose) GetType() *InputFirehoseType {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputFirehose) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputFirehose) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputFirehose) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputFirehose) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputFirehose) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputFirehose) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputFirehose) GetConnections() []InputFirehoseConnections {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputFirehose) GetPq() *InputFirehosePq {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputFirehose) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputFirehose) GetPort() float64 {
	if o == nil {
		return 0.0
	}
	return o.Port
}

func (o *InputFirehose) GetAuthTokens() []string {
	if o == nil {
		return nil
	}
	return o.AuthTokens
}

func (o *InputFirehose) GetTLS() *InputFirehoseTLSSettingsServerSide {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputFirehose) GetMaxActiveReq() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxActiveReq
}

func (o *InputFirehose) GetMaxRequestsPerSocket() *int64 {
	if o == nil {
		return nil
	}
	return o.MaxRequestsPerSocket
}

func (o *InputFirehose) GetEnableProxyHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableProxyHeader
}

func (o *InputFirehose) GetCaptureHeaders() *bool {
	if o == nil {
		return nil
	}
	return o.CaptureHeaders
}

func (o *InputFirehose) GetActivityLogSampleRate() *float64 {
	if o == nil {
		return nil
	}
	return o.ActivityLogSampleRate
}

func (o *InputFirehose) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *InputFirehose) GetSocketTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketTimeout
}

func (o *InputFirehose) GetKeepAliveTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.KeepAliveTimeout
}

func (o *InputFirehose) GetEnableHealthCheck() *bool {
	if o == nil {
		return nil
	}
	return o.EnableHealthCheck
}

func (o *InputFirehose) GetIPAllowlistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPAllowlistRegex
}

func (o *InputFirehose) GetIPDenylistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPDenylistRegex
}

func (o *InputFirehose) GetMetadata() []InputFirehoseMetadata {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputFirehose) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputFirehose) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputExecType string

const (
	InputExecTypeExec InputExecType = "exec"
)

func (e InputExecType) ToPointer() *InputExecType {
	return &e
}
func (e *InputExecType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "exec":
		*e = InputExecType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputExecType: %v", v)
	}
}

type InputExecConnections struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *InputExecConnections) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputExecConnections) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// InputExecMode - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputExecMode string

const (
	InputExecModeSmart  InputExecMode = "smart"
	InputExecModeAlways InputExecMode = "always"
)

func (e InputExecMode) ToPointer() *InputExecMode {
	return &e
}
func (e *InputExecMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputExecMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputExecMode: %v", v)
	}
}

// InputExecCompression - Codec to use to compress the persisted data
type InputExecCompression string

const (
	InputExecCompressionNone InputExecCompression = "none"
	InputExecCompressionGzip InputExecCompression = "gzip"
)

func (e InputExecCompression) ToPointer() *InputExecCompression {
	return &e
}
func (e *InputExecCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputExecCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputExecCompression: %v", v)
	}
}

type InputExecPq struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputExecMode `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *InputExecCompression `default:"none" json:"compress"`
}

func (i InputExecPq) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputExecPq) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputExecPq) GetMode() *InputExecMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputExecPq) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputExecPq) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *InputExecPq) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *InputExecPq) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *InputExecPq) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *InputExecPq) GetCompress() *InputExecCompression {
	if o == nil {
		return nil
	}
	return o.Compress
}

// ScheduleType - Select a schedule type; either an interval (in seconds) or a cron-style schedule.
type ScheduleType string

const (
	ScheduleTypeInterval     ScheduleType = "interval"
	ScheduleTypeCronSchedule ScheduleType = "cronSchedule"
)

func (e ScheduleType) ToPointer() *ScheduleType {
	return &e
}
func (e *ScheduleType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "interval":
		fallthrough
	case "cronSchedule":
		*e = ScheduleType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ScheduleType: %v", v)
	}
}

type InputExecMetadata struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputExecMetadata) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputExecMetadata) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputExec struct {
	// Unique ID for this input
	ID       *string       `json:"id,omitempty"`
	Type     InputExecType `json:"type"`
	Disabled *bool         `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputExecConnections `json:"connections,omitempty"`
	Pq          *InputExecPq           `json:"pq,omitempty"`
	// Command to execute; supports Bourne shell (or CMD on Windows) syntax
	Command string `json:"command"`
	// Maximum number of retry attempts in the event that the command fails
	Retries *float64 `default:"10" json:"retries"`
	// Select a schedule type; either an interval (in seconds) or a cron-style schedule.
	ScheduleType *ScheduleType `default:"interval" json:"scheduleType"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitempty"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `default:"10000" json:"staleChannelFlushMs"`
	// Fields to add to events from this input
	Metadata    []InputExecMetadata `json:"metadata,omitempty"`
	Description *string             `json:"description,omitempty"`
	// Interval between command executions in seconds.
	Interval *float64 `default:"60" json:"interval"`
	// Cron schedule to execute the command on.
	CronSchedule *string   `default:"* * * * *" json:"cronSchedule"`
	Status       *TFStatus `json:"status,omitempty"`
}

func (i InputExec) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputExec) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputExec) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputExec) GetType() InputExecType {
	if o == nil {
		return InputExecType("")
	}
	return o.Type
}

func (o *InputExec) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputExec) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputExec) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputExec) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputExec) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputExec) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputExec) GetConnections() []InputExecConnections {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputExec) GetPq() *InputExecPq {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputExec) GetCommand() string {
	if o == nil {
		return ""
	}
	return o.Command
}

func (o *InputExec) GetRetries() *float64 {
	if o == nil {
		return nil
	}
	return o.Retries
}

func (o *InputExec) GetScheduleType() *ScheduleType {
	if o == nil {
		return nil
	}
	return o.ScheduleType
}

func (o *InputExec) GetBreakerRulesets() []string {
	if o == nil {
		return nil
	}
	return o.BreakerRulesets
}

func (o *InputExec) GetStaleChannelFlushMs() *float64 {
	if o == nil {
		return nil
	}
	return o.StaleChannelFlushMs
}

func (o *InputExec) GetMetadata() []InputExecMetadata {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputExec) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputExec) GetInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.Interval
}

func (o *InputExec) GetCronSchedule() *string {
	if o == nil {
		return nil
	}
	return o.CronSchedule
}

func (o *InputExec) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputEventhubType string

const (
	InputEventhubTypeEventhub InputEventhubType = "eventhub"
)

func (e InputEventhubType) ToPointer() *InputEventhubType {
	return &e
}
func (e *InputEventhubType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "eventhub":
		*e = InputEventhubType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputEventhubType: %v", v)
	}
}

type InputEventhubConnections struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *InputEventhubConnections) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputEventhubConnections) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// InputEventhubMode - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputEventhubMode string

const (
	InputEventhubModeSmart  InputEventhubMode = "smart"
	InputEventhubModeAlways InputEventhubMode = "always"
)

func (e InputEventhubMode) ToPointer() *InputEventhubMode {
	return &e
}
func (e *InputEventhubMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputEventhubMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputEventhubMode: %v", v)
	}
}

// InputEventhubCompression - Codec to use to compress the persisted data
type InputEventhubCompression string

const (
	InputEventhubCompressionNone InputEventhubCompression = "none"
	InputEventhubCompressionGzip InputEventhubCompression = "gzip"
)

func (e InputEventhubCompression) ToPointer() *InputEventhubCompression {
	return &e
}
func (e *InputEventhubCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputEventhubCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputEventhubCompression: %v", v)
	}
}

type InputEventhubPq struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputEventhubMode `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *InputEventhubCompression `default:"none" json:"compress"`
}

func (i InputEventhubPq) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputEventhubPq) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputEventhubPq) GetMode() *InputEventhubMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputEventhubPq) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputEventhubPq) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *InputEventhubPq) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *InputEventhubPq) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *InputEventhubPq) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *InputEventhubPq) GetCompress() *InputEventhubCompression {
	if o == nil {
		return nil
	}
	return o.Compress
}

// InputEventhubSASLMechanism - SASL authentication mechanism to use
type InputEventhubSASLMechanism string

const (
	InputEventhubSASLMechanismPlain       InputEventhubSASLMechanism = "plain"
	InputEventhubSASLMechanismOauthbearer InputEventhubSASLMechanism = "oauthbearer"
)

func (e InputEventhubSASLMechanism) ToPointer() *InputEventhubSASLMechanism {
	return &e
}
func (e *InputEventhubSASLMechanism) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "plain":
		fallthrough
	case "oauthbearer":
		*e = InputEventhubSASLMechanism(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputEventhubSASLMechanism: %v", v)
	}
}

// InputEventhubAuthentication - Authentication parameters to use when connecting to brokers. Using TLS is highly recommended.
type InputEventhubAuthentication struct {
	// Enable authentication.
	Disabled *bool `default:"false" json:"disabled"`
	// SASL authentication mechanism to use
	Mechanism *InputEventhubSASLMechanism `default:"plain" json:"mechanism"`
}

func (i InputEventhubAuthentication) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputEventhubAuthentication) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputEventhubAuthentication) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputEventhubAuthentication) GetMechanism() *InputEventhubSASLMechanism {
	if o == nil {
		return nil
	}
	return o.Mechanism
}

type InputEventhubTLSSettingsClientSide struct {
	Disabled *bool `default:"false" json:"disabled"`
	// Reject certs that are not authorized by a CA in the CA certificate path, or by another trusted CA (e.g., the system's CA).
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
}

func (i InputEventhubTLSSettingsClientSide) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputEventhubTLSSettingsClientSide) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputEventhubTLSSettingsClientSide) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputEventhubTLSSettingsClientSide) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

type InputEventhubMetadata struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputEventhubMetadata) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputEventhubMetadata) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputEventhub struct {
	// Unique ID for this input
	ID       *string            `json:"id,omitempty"`
	Type     *InputEventhubType `json:"type,omitempty"`
	Disabled *bool              `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputEventhubConnections `json:"connections,omitempty"`
	Pq          *InputEventhubPq           `json:"pq,omitempty"`
	// List of Event Hubs Kafka brokers to connect to, e.g., yourdomain.servicebus.windows.net:9093. The hostname can be found in the host portion of the primary or secondary connection string in Shared Access Policies.
	Brokers []string `json:"brokers"`
	// The name of the Event Hub (a.k.a. Kafka topic) to subscribe to. Warning: To optimize performance, Cribl suggests subscribing each Event Hubs Source to only a single topic.
	Topics []string `json:"topics,omitempty"`
	// Specifies the consumer group this instance belongs to, default is 'Cribl'.
	GroupID *string `default:"Cribl" json:"groupId"`
	// Whether to start reading from earliest available data, relevant only during initial subscription.
	FromBeginning *bool `default:"true" json:"fromBeginning"`
	// Maximum time to wait for a connection to complete successfully
	ConnectionTimeout *float64 `default:"10000" json:"connectionTimeout"`
	// Maximum time to wait for Kafka to respond to a request
	RequestTimeout *float64 `default:"60000" json:"requestTimeout"`
	// If messages are failing, you can set the maximum number of retries as high as 100 to prevent loss of data
	MaxRetries *float64 `default:"5" json:"maxRetries"`
	// The maximum wait time for a retry, in milliseconds. Default (and minimum) is 30,000 ms (30 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackOff *float64 `default:"30000" json:"maxBackOff"`
	// Initial value used to calculate the retry, in milliseconds. Maximum is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"300" json:"initialBackoff"`
	// Set the backoff multiplier (2-20) to control the retry frequency for failed messages. For faster retries, use a lower multiplier. For slower retries with more delay between attempts, use a higher multiplier. The multiplier is used in an exponential backoff formula; see the Kafka [documentation](https://kafka.js.org/docs/retry-detailed) for details.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// Maximum time to wait for Kafka to respond to an authentication request
	AuthenticationTimeout *float64 `default:"10000" json:"authenticationTimeout"`
	// Specifies a time window during which @{product} can reauthenticate if needed. Creates the window measuring backwards from the moment when credentials are set to expire.
	ReauthenticationThreshold *float64 `default:"10000" json:"reauthenticationThreshold"`
	// Authentication parameters to use when connecting to brokers. Using TLS is highly recommended.
	Sasl *InputEventhubAuthentication        `json:"sasl,omitempty"`
	TLS  *InputEventhubTLSSettingsClientSide `json:"tls,omitempty"`
	//       Timeout (a.k.a session.timeout.ms in Kafka domain) used to detect client failures when using Kafka's group management facilities.
	//       If the client sends the broker no heartbeats before this timeout expires, the broker will remove this client from the group, and will initiate a rebalance.
	//       Value must be lower than rebalanceTimeout.
	//       See details [here](https://github.com/Azure/azure-event-hubs-for-kafka/blob/master/CONFIGURATION.md).
	SessionTimeout *float64 `default:"30000" json:"sessionTimeout"`
	//       Maximum allowed time (a.k.a rebalance.timeout.ms in Kafka domain) for each worker to join the group after a rebalance has begun.
	//       If the timeout is exceeded, the coordinator broker will remove the worker from the group.
	//       See details [here](https://github.com/Azure/azure-event-hubs-for-kafka/blob/master/CONFIGURATION.md).
	RebalanceTimeout *float64 `default:"60000" json:"rebalanceTimeout"`
	//       Expected time (a.k.a heartbeat.interval.ms in Kafka domain) between heartbeats to the consumer coordinator when using Kafka's group management facilities.
	//       Value must be lower than sessionTimeout, and typically should not exceed 1/3 of the sessionTimeout value.
	//       See details [here](https://github.com/Azure/azure-event-hubs-for-kafka/blob/master/CONFIGURATION.md).
	HeartbeatInterval *float64 `default:"3000" json:"heartbeatInterval"`
	// How often to commit offsets. If both this and Offset commit threshold are set, @{product} commits offsets when either condition is met. If both are empty, @{product} commits offsets after each batch.
	AutoCommitInterval *float64 `json:"autoCommitInterval,omitempty"`
	// How many events are needed to trigger an offset commit. If both this and Offset commit interval are set, @{product} commits offsets when either condition is met. If both are empty, @{product} commits offsets after each batch.
	AutoCommitThreshold *float64 `json:"autoCommitThreshold,omitempty"`
	// Maximum amount of data that Kafka will return per partition, per fetch request. Must equal or exceed the maximum message size (maxBytesPerPartition) that Kafka is configured to allow. Otherwise, @{product} can get stuck trying to retrieve messages. Defaults to 1048576 (1 MB).
	MaxBytesPerPartition *float64 `default:"1048576" json:"maxBytesPerPartition"`
	// Maximum number of bytes that Kafka will return per fetch request. Defaults to 10485760 (10 MB).
	MaxBytes *float64 `default:"10485760" json:"maxBytes"`
	// Maximum number of network errors before the consumer recreates a socket.
	MaxSocketErrors *float64 `default:"0" json:"maxSocketErrors"`
	// Enable feature to minimize duplicate events by only starting one consumer for each topic partition.
	MinimizeDuplicates *bool `default:"false" json:"minimizeDuplicates"`
	// Fields to add to events from this input
	Metadata    []InputEventhubMetadata `json:"metadata,omitempty"`
	Description *string                 `json:"description,omitempty"`
	Status      *TFStatus               `json:"status,omitempty"`
}

func (i InputEventhub) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputEventhub) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputEventhub) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputEventhub) GetType() *InputEventhubType {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputEventhub) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputEventhub) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputEventhub) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputEventhub) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputEventhub) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputEventhub) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputEventhub) GetConnections() []InputEventhubConnections {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputEventhub) GetPq() *InputEventhubPq {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputEventhub) GetBrokers() []string {
	if o == nil {
		return []string{}
	}
	return o.Brokers
}

func (o *InputEventhub) GetTopics() []string {
	if o == nil {
		return nil
	}
	return o.Topics
}

func (o *InputEventhub) GetGroupID() *string {
	if o == nil {
		return nil
	}
	return o.GroupID
}

func (o *InputEventhub) GetFromBeginning() *bool {
	if o == nil {
		return nil
	}
	return o.FromBeginning
}

func (o *InputEventhub) GetConnectionTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.ConnectionTimeout
}

func (o *InputEventhub) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *InputEventhub) GetMaxRetries() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxRetries
}

func (o *InputEventhub) GetMaxBackOff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackOff
}

func (o *InputEventhub) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *InputEventhub) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *InputEventhub) GetAuthenticationTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.AuthenticationTimeout
}

func (o *InputEventhub) GetReauthenticationThreshold() *float64 {
	if o == nil {
		return nil
	}
	return o.ReauthenticationThreshold
}

func (o *InputEventhub) GetSasl() *InputEventhubAuthentication {
	if o == nil {
		return nil
	}
	return o.Sasl
}

func (o *InputEventhub) GetTLS() *InputEventhubTLSSettingsClientSide {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputEventhub) GetSessionTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SessionTimeout
}

func (o *InputEventhub) GetRebalanceTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RebalanceTimeout
}

func (o *InputEventhub) GetHeartbeatInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.HeartbeatInterval
}

func (o *InputEventhub) GetAutoCommitInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.AutoCommitInterval
}

func (o *InputEventhub) GetAutoCommitThreshold() *float64 {
	if o == nil {
		return nil
	}
	return o.AutoCommitThreshold
}

func (o *InputEventhub) GetMaxBytesPerPartition() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBytesPerPartition
}

func (o *InputEventhub) GetMaxBytes() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBytes
}

func (o *InputEventhub) GetMaxSocketErrors() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxSocketErrors
}

func (o *InputEventhub) GetMinimizeDuplicates() *bool {
	if o == nil {
		return nil
	}
	return o.MinimizeDuplicates
}

func (o *InputEventhub) GetMetadata() []InputEventhubMetadata {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputEventhub) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputEventhub) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputOffice365MsgTraceType string

const (
	InputOffice365MsgTraceTypeOffice365MsgTrace InputOffice365MsgTraceType = "office365_msg_trace"
)

func (e InputOffice365MsgTraceType) ToPointer() *InputOffice365MsgTraceType {
	return &e
}
func (e *InputOffice365MsgTraceType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "office365_msg_trace":
		*e = InputOffice365MsgTraceType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputOffice365MsgTraceType: %v", v)
	}
}

type InputOffice365MsgTraceConnections struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *InputOffice365MsgTraceConnections) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputOffice365MsgTraceConnections) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// InputOffice365MsgTraceMode - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputOffice365MsgTraceMode string

const (
	InputOffice365MsgTraceModeSmart  InputOffice365MsgTraceMode = "smart"
	InputOffice365MsgTraceModeAlways InputOffice365MsgTraceMode = "always"
)

func (e InputOffice365MsgTraceMode) ToPointer() *InputOffice365MsgTraceMode {
	return &e
}
func (e *InputOffice365MsgTraceMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputOffice365MsgTraceMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputOffice365MsgTraceMode: %v", v)
	}
}

// InputOffice365MsgTraceCompression - Codec to use to compress the persisted data
type InputOffice365MsgTraceCompression string

const (
	InputOffice365MsgTraceCompressionNone InputOffice365MsgTraceCompression = "none"
	InputOffice365MsgTraceCompressionGzip InputOffice365MsgTraceCompression = "gzip"
)

func (e InputOffice365MsgTraceCompression) ToPointer() *InputOffice365MsgTraceCompression {
	return &e
}
func (e *InputOffice365MsgTraceCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputOffice365MsgTraceCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputOffice365MsgTraceCompression: %v", v)
	}
}

type InputOffice365MsgTracePq struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputOffice365MsgTraceMode `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *InputOffice365MsgTraceCompression `default:"none" json:"compress"`
}

func (i InputOffice365MsgTracePq) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputOffice365MsgTracePq) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputOffice365MsgTracePq) GetMode() *InputOffice365MsgTraceMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputOffice365MsgTracePq) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputOffice365MsgTracePq) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *InputOffice365MsgTracePq) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *InputOffice365MsgTracePq) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *InputOffice365MsgTracePq) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *InputOffice365MsgTracePq) GetCompress() *InputOffice365MsgTraceCompression {
	if o == nil {
		return nil
	}
	return o.Compress
}

// InputOffice365MsgTraceAuthenticationMethod - Select authentication method.
type InputOffice365MsgTraceAuthenticationMethod string

const (
	InputOffice365MsgTraceAuthenticationMethodManual      InputOffice365MsgTraceAuthenticationMethod = "manual"
	InputOffice365MsgTraceAuthenticationMethodSecret      InputOffice365MsgTraceAuthenticationMethod = "secret"
	InputOffice365MsgTraceAuthenticationMethodOauth       InputOffice365MsgTraceAuthenticationMethod = "oauth"
	InputOffice365MsgTraceAuthenticationMethodOauthSecret InputOffice365MsgTraceAuthenticationMethod = "oauthSecret"
	InputOffice365MsgTraceAuthenticationMethodOauthCert   InputOffice365MsgTraceAuthenticationMethod = "oauthCert"
)

func (e InputOffice365MsgTraceAuthenticationMethod) ToPointer() *InputOffice365MsgTraceAuthenticationMethod {
	return &e
}
func (e *InputOffice365MsgTraceAuthenticationMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "manual":
		fallthrough
	case "secret":
		fallthrough
	case "oauth":
		fallthrough
	case "oauthSecret":
		fallthrough
	case "oauthCert":
		*e = InputOffice365MsgTraceAuthenticationMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputOffice365MsgTraceAuthenticationMethod: %v", v)
	}
}

// InputOffice365MsgTraceLogLevel - Log Level (verbosity) for collection runtime behavior.
type InputOffice365MsgTraceLogLevel string

const (
	InputOffice365MsgTraceLogLevelError InputOffice365MsgTraceLogLevel = "error"
	InputOffice365MsgTraceLogLevelWarn  InputOffice365MsgTraceLogLevel = "warn"
	InputOffice365MsgTraceLogLevelInfo  InputOffice365MsgTraceLogLevel = "info"
	InputOffice365MsgTraceLogLevelDebug InputOffice365MsgTraceLogLevel = "debug"
	InputOffice365MsgTraceLogLevelSilly InputOffice365MsgTraceLogLevel = "silly"
)

func (e InputOffice365MsgTraceLogLevel) ToPointer() *InputOffice365MsgTraceLogLevel {
	return &e
}
func (e *InputOffice365MsgTraceLogLevel) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "error":
		fallthrough
	case "warn":
		fallthrough
	case "info":
		fallthrough
	case "debug":
		fallthrough
	case "silly":
		*e = InputOffice365MsgTraceLogLevel(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputOffice365MsgTraceLogLevel: %v", v)
	}
}

type InputOffice365MsgTraceMetadata struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputOffice365MsgTraceMetadata) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputOffice365MsgTraceMetadata) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// InputOffice365MsgTraceRetryType - The algorithm to use when performing HTTP retries
type InputOffice365MsgTraceRetryType string

const (
	InputOffice365MsgTraceRetryTypeNone    InputOffice365MsgTraceRetryType = "none"
	InputOffice365MsgTraceRetryTypeBackoff InputOffice365MsgTraceRetryType = "backoff"
	InputOffice365MsgTraceRetryTypeStatic  InputOffice365MsgTraceRetryType = "static"
)

func (e InputOffice365MsgTraceRetryType) ToPointer() *InputOffice365MsgTraceRetryType {
	return &e
}
func (e *InputOffice365MsgTraceRetryType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "backoff":
		fallthrough
	case "static":
		*e = InputOffice365MsgTraceRetryType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputOffice365MsgTraceRetryType: %v", v)
	}
}

type InputOffice365MsgTraceRetryRules struct {
	// The algorithm to use when performing HTTP retries
	Type *InputOffice365MsgTraceRetryType `default:"backoff" json:"type"`
	// Time interval between failed request and first retry (kickoff). Maximum allowed value is 20,000 ms (1/3 minute).
	Interval *float64 `default:"1000" json:"interval"`
	// The maximum number of times to retry a failed HTTP request
	Limit *float64 `default:"5" json:"limit"`
	// Base for exponential backoff, e.g., base 2 means that retries will occur after 2, then 4, then 8 seconds, and so on
	Multiplier *float64 `default:"2" json:"multiplier"`
	// List of http codes that trigger a retry. Leave empty to use the default list of 429, 500, and 503.
	Codes []float64 `json:"codes,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) or a timestamp after which to retry the request. The delay is limited to 20 seconds, even if the Retry-After header specifies a longer delay. When disabled, all Retry-After headers are ignored.
	EnableHeader *bool `default:"true" json:"enableHeader"`
	// Make a single retry attempt when a connection timeout (ETIMEDOUT) error occurs
	RetryConnectTimeout *bool `default:"false" json:"retryConnectTimeout"`
	// Retry request when a connection reset (ECONNRESET) error occurs
	RetryConnectReset *bool `default:"false" json:"retryConnectReset"`
}

func (i InputOffice365MsgTraceRetryRules) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputOffice365MsgTraceRetryRules) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputOffice365MsgTraceRetryRules) GetType() *InputOffice365MsgTraceRetryType {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputOffice365MsgTraceRetryRules) GetInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.Interval
}

func (o *InputOffice365MsgTraceRetryRules) GetLimit() *float64 {
	if o == nil {
		return nil
	}
	return o.Limit
}

func (o *InputOffice365MsgTraceRetryRules) GetMultiplier() *float64 {
	if o == nil {
		return nil
	}
	return o.Multiplier
}

func (o *InputOffice365MsgTraceRetryRules) GetCodes() []float64 {
	if o == nil {
		return nil
	}
	return o.Codes
}

func (o *InputOffice365MsgTraceRetryRules) GetEnableHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableHeader
}

func (o *InputOffice365MsgTraceRetryRules) GetRetryConnectTimeout() *bool {
	if o == nil {
		return nil
	}
	return o.RetryConnectTimeout
}

func (o *InputOffice365MsgTraceRetryRules) GetRetryConnectReset() *bool {
	if o == nil {
		return nil
	}
	return o.RetryConnectReset
}

// InputOffice365MsgTraceSubscriptionPlan - Office 365 subscription plan for your organization, typically Office 365 Enterprise
type InputOffice365MsgTraceSubscriptionPlan string

const (
	InputOffice365MsgTraceSubscriptionPlanEnterpriseGcc InputOffice365MsgTraceSubscriptionPlan = "enterprise_gcc"
	InputOffice365MsgTraceSubscriptionPlanGcc           InputOffice365MsgTraceSubscriptionPlan = "gcc"
	InputOffice365MsgTraceSubscriptionPlanGccHigh       InputOffice365MsgTraceSubscriptionPlan = "gcc_high"
	InputOffice365MsgTraceSubscriptionPlanDod           InputOffice365MsgTraceSubscriptionPlan = "dod"
)

func (e InputOffice365MsgTraceSubscriptionPlan) ToPointer() *InputOffice365MsgTraceSubscriptionPlan {
	return &e
}
func (e *InputOffice365MsgTraceSubscriptionPlan) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "enterprise_gcc":
		fallthrough
	case "gcc":
		fallthrough
	case "gcc_high":
		fallthrough
	case "dod":
		*e = InputOffice365MsgTraceSubscriptionPlan(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputOffice365MsgTraceSubscriptionPlan: %v", v)
	}
}

type CertOptions struct {
	// The name of the predefined certificate.
	CertificateName *string `json:"certificateName,omitempty"`
	// Path to the private key to use. Key should be in PEM format. Can reference $ENV_VARS.
	PrivKeyPath string `json:"privKeyPath"`
	// Passphrase to use to decrypt the private key.
	Passphrase *string `json:"passphrase,omitempty"`
	// Path to the certificate to use. Certificate should be in PEM format. Can reference $ENV_VARS.
	CertPath string `json:"certPath"`
}

func (o *CertOptions) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *CertOptions) GetPrivKeyPath() string {
	if o == nil {
		return ""
	}
	return o.PrivKeyPath
}

func (o *CertOptions) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *CertOptions) GetCertPath() string {
	if o == nil {
		return ""
	}
	return o.CertPath
}

type InputOffice365MsgTrace struct {
	// Unique ID for this input
	ID       *string                     `json:"id,omitempty"`
	Type     *InputOffice365MsgTraceType `json:"type,omitempty"`
	Disabled *bool                       `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputOffice365MsgTraceConnections `json:"connections,omitempty"`
	Pq          *InputOffice365MsgTracePq           `json:"pq,omitempty"`
	// URL to use when retrieving report data.
	URL *string `default:"https://reports.office365.com/ecp/reportingwebservice/reporting.svc/MessageTrace" json:"url"`
	// How often (in minutes) to run the report. Must divide evenly into 60 minutes to create a predictable schedule, or Save will fail.
	Interval *float64 `default:"60" json:"interval"`
	// Backward offset for the search range's head. (E.g.: -3h@h) Message Trace data is delayed; this parameter (with Date range end) compensates for delay and gaps.
	StartDate *string `json:"startDate,omitempty"`
	// Backward offset for the search range's tail. (E.g.: -2h@h) Message Trace data is delayed; this parameter (with Date range start) compensates for delay and gaps.
	EndDate *string `json:"endDate,omitempty"`
	// HTTP request inactivity timeout. Maximum is 2400 (40 minutes); enter 0 to wait indefinitely.
	Timeout *float64 `default:"300" json:"timeout"`
	// Disables time filtering of events when a date range is specified.
	DisableTimeFilter *bool `default:"true" json:"disableTimeFilter"`
	// Select authentication method.
	AuthType *InputOffice365MsgTraceAuthenticationMethod `default:"oauth" json:"authType"`
	// Reschedule tasks that failed with non-fatal errors
	RescheduleDroppedTasks *bool `default:"true" json:"rescheduleDroppedTasks"`
	// Maximum number of times a task can be rescheduled
	MaxTaskReschedule *float64 `default:"1" json:"maxTaskReschedule"`
	// Log Level (verbosity) for collection runtime behavior.
	LogLevel *InputOffice365MsgTraceLogLevel `default:"info" json:"logLevel"`
	// Maximum time the job is allowed to run (e.g., 30, 45s or 15m). Units are seconds, if not specified. Enter 0 for unlimited time.
	JobTimeout *string `default:"0" json:"jobTimeout"`
	// How often workers should check in with the scheduler to keep job subscription alive
	KeepAliveTime *float64 `default:"30" json:"keepAliveTime"`
	// The number of Keep Alive Time periods before an inactive worker will have its job subscription revoked.
	MaxMissedKeepAlives *float64 `default:"3" json:"maxMissedKeepAlives"`
	// Time to keep the job's artifacts on disk after job completion. This also affects how long a job is listed in the Job Inspector.
	TTL *string `default:"4h" json:"ttl"`
	// Fields to add to events from this input
	Metadata    []InputOffice365MsgTraceMetadata  `json:"metadata,omitempty"`
	RetryRules  *InputOffice365MsgTraceRetryRules `json:"retryRules,omitempty"`
	Description *string                           `json:"description,omitempty"`
	// Username to run Message Trace API call.
	Username *string `json:"username,omitempty"`
	// Password to run Message Trace API call.
	Password *string `json:"password,omitempty"`
	// Select or create a secret that references your credentials.
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
	// client_secret to pass in the OAuth request parameter.
	ClientSecret *string `json:"clientSecret,omitempty"`
	// Directory ID (tenant identifier) in Azure Active Directory.
	TenantID *string `json:"tenantId,omitempty"`
	// client_id to pass in the OAuth request parameter.
	ClientID *string `json:"clientId,omitempty"`
	// Resource to pass in the OAuth request parameter.
	Resource *string `default:"https://outlook.office365.com" json:"resource"`
	// Office 365 subscription plan for your organization, typically Office 365 Enterprise
	PlanType *InputOffice365MsgTraceSubscriptionPlan `default:"enterprise_gcc" json:"planType"`
	// Select or create a secret that references your client_secret to pass in the OAuth request parameter.
	TextSecret  *string      `json:"textSecret,omitempty"`
	CertOptions *CertOptions `json:"certOptions,omitempty"`
	Status      *TFStatus    `json:"status,omitempty"`
}

func (i InputOffice365MsgTrace) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputOffice365MsgTrace) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputOffice365MsgTrace) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputOffice365MsgTrace) GetType() *InputOffice365MsgTraceType {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputOffice365MsgTrace) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputOffice365MsgTrace) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputOffice365MsgTrace) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputOffice365MsgTrace) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputOffice365MsgTrace) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputOffice365MsgTrace) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputOffice365MsgTrace) GetConnections() []InputOffice365MsgTraceConnections {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputOffice365MsgTrace) GetPq() *InputOffice365MsgTracePq {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputOffice365MsgTrace) GetURL() *string {
	if o == nil {
		return nil
	}
	return o.URL
}

func (o *InputOffice365MsgTrace) GetInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.Interval
}

func (o *InputOffice365MsgTrace) GetStartDate() *string {
	if o == nil {
		return nil
	}
	return o.StartDate
}

func (o *InputOffice365MsgTrace) GetEndDate() *string {
	if o == nil {
		return nil
	}
	return o.EndDate
}

func (o *InputOffice365MsgTrace) GetTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.Timeout
}

func (o *InputOffice365MsgTrace) GetDisableTimeFilter() *bool {
	if o == nil {
		return nil
	}
	return o.DisableTimeFilter
}

func (o *InputOffice365MsgTrace) GetAuthType() *InputOffice365MsgTraceAuthenticationMethod {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *InputOffice365MsgTrace) GetRescheduleDroppedTasks() *bool {
	if o == nil {
		return nil
	}
	return o.RescheduleDroppedTasks
}

func (o *InputOffice365MsgTrace) GetMaxTaskReschedule() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxTaskReschedule
}

func (o *InputOffice365MsgTrace) GetLogLevel() *InputOffice365MsgTraceLogLevel {
	if o == nil {
		return nil
	}
	return o.LogLevel
}

func (o *InputOffice365MsgTrace) GetJobTimeout() *string {
	if o == nil {
		return nil
	}
	return o.JobTimeout
}

func (o *InputOffice365MsgTrace) GetKeepAliveTime() *float64 {
	if o == nil {
		return nil
	}
	return o.KeepAliveTime
}

func (o *InputOffice365MsgTrace) GetMaxMissedKeepAlives() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxMissedKeepAlives
}

func (o *InputOffice365MsgTrace) GetTTL() *string {
	if o == nil {
		return nil
	}
	return o.TTL
}

func (o *InputOffice365MsgTrace) GetMetadata() []InputOffice365MsgTraceMetadata {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputOffice365MsgTrace) GetRetryRules() *InputOffice365MsgTraceRetryRules {
	if o == nil {
		return nil
	}
	return o.RetryRules
}

func (o *InputOffice365MsgTrace) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputOffice365MsgTrace) GetUsername() *string {
	if o == nil {
		return nil
	}
	return o.Username
}

func (o *InputOffice365MsgTrace) GetPassword() *string {
	if o == nil {
		return nil
	}
	return o.Password
}

func (o *InputOffice365MsgTrace) GetCredentialsSecret() *string {
	if o == nil {
		return nil
	}
	return o.CredentialsSecret
}

func (o *InputOffice365MsgTrace) GetClientSecret() *string {
	if o == nil {
		return nil
	}
	return o.ClientSecret
}

func (o *InputOffice365MsgTrace) GetTenantID() *string {
	if o == nil {
		return nil
	}
	return o.TenantID
}

func (o *InputOffice365MsgTrace) GetClientID() *string {
	if o == nil {
		return nil
	}
	return o.ClientID
}

func (o *InputOffice365MsgTrace) GetResource() *string {
	if o == nil {
		return nil
	}
	return o.Resource
}

func (o *InputOffice365MsgTrace) GetPlanType() *InputOffice365MsgTraceSubscriptionPlan {
	if o == nil {
		return nil
	}
	return o.PlanType
}

func (o *InputOffice365MsgTrace) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *InputOffice365MsgTrace) GetCertOptions() *CertOptions {
	if o == nil {
		return nil
	}
	return o.CertOptions
}

func (o *InputOffice365MsgTrace) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputOffice365ServiceType string

const (
	InputOffice365ServiceTypeOffice365Service InputOffice365ServiceType = "office365_service"
)

func (e InputOffice365ServiceType) ToPointer() *InputOffice365ServiceType {
	return &e
}
func (e *InputOffice365ServiceType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "office365_service":
		*e = InputOffice365ServiceType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputOffice365ServiceType: %v", v)
	}
}

type InputOffice365ServiceConnections struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *InputOffice365ServiceConnections) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputOffice365ServiceConnections) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// InputOffice365ServiceMode - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputOffice365ServiceMode string

const (
	InputOffice365ServiceModeSmart  InputOffice365ServiceMode = "smart"
	InputOffice365ServiceModeAlways InputOffice365ServiceMode = "always"
)

func (e InputOffice365ServiceMode) ToPointer() *InputOffice365ServiceMode {
	return &e
}
func (e *InputOffice365ServiceMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputOffice365ServiceMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputOffice365ServiceMode: %v", v)
	}
}

// InputOffice365ServiceCompression - Codec to use to compress the persisted data
type InputOffice365ServiceCompression string

const (
	InputOffice365ServiceCompressionNone InputOffice365ServiceCompression = "none"
	InputOffice365ServiceCompressionGzip InputOffice365ServiceCompression = "gzip"
)

func (e InputOffice365ServiceCompression) ToPointer() *InputOffice365ServiceCompression {
	return &e
}
func (e *InputOffice365ServiceCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputOffice365ServiceCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputOffice365ServiceCompression: %v", v)
	}
}

type InputOffice365ServicePq struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputOffice365ServiceMode `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *InputOffice365ServiceCompression `default:"none" json:"compress"`
}

func (i InputOffice365ServicePq) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputOffice365ServicePq) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputOffice365ServicePq) GetMode() *InputOffice365ServiceMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputOffice365ServicePq) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputOffice365ServicePq) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *InputOffice365ServicePq) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *InputOffice365ServicePq) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *InputOffice365ServicePq) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *InputOffice365ServicePq) GetCompress() *InputOffice365ServiceCompression {
	if o == nil {
		return nil
	}
	return o.Compress
}

// InputOffice365ServiceSubscriptionPlan - Office 365 subscription plan for your organization, typically Office 365 Enterprise
type InputOffice365ServiceSubscriptionPlan string

const (
	InputOffice365ServiceSubscriptionPlanEnterpriseGcc InputOffice365ServiceSubscriptionPlan = "enterprise_gcc"
	InputOffice365ServiceSubscriptionPlanGcc           InputOffice365ServiceSubscriptionPlan = "gcc"
	InputOffice365ServiceSubscriptionPlanGccHigh       InputOffice365ServiceSubscriptionPlan = "gcc_high"
	InputOffice365ServiceSubscriptionPlanDod           InputOffice365ServiceSubscriptionPlan = "dod"
)

func (e InputOffice365ServiceSubscriptionPlan) ToPointer() *InputOffice365ServiceSubscriptionPlan {
	return &e
}
func (e *InputOffice365ServiceSubscriptionPlan) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "enterprise_gcc":
		fallthrough
	case "gcc":
		fallthrough
	case "gcc_high":
		fallthrough
	case "dod":
		*e = InputOffice365ServiceSubscriptionPlan(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputOffice365ServiceSubscriptionPlan: %v", v)
	}
}

type InputOffice365ServiceMetadata struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputOffice365ServiceMetadata) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputOffice365ServiceMetadata) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// InputOffice365ServiceLogLevel - Collector runtime Log Level
type InputOffice365ServiceLogLevel string

const (
	InputOffice365ServiceLogLevelError InputOffice365ServiceLogLevel = "error"
	InputOffice365ServiceLogLevelWarn  InputOffice365ServiceLogLevel = "warn"
	InputOffice365ServiceLogLevelInfo  InputOffice365ServiceLogLevel = "info"
	InputOffice365ServiceLogLevelDebug InputOffice365ServiceLogLevel = "debug"
)

func (e InputOffice365ServiceLogLevel) ToPointer() *InputOffice365ServiceLogLevel {
	return &e
}
func (e *InputOffice365ServiceLogLevel) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "error":
		fallthrough
	case "warn":
		fallthrough
	case "info":
		fallthrough
	case "debug":
		*e = InputOffice365ServiceLogLevel(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputOffice365ServiceLogLevel: %v", v)
	}
}

type InputOffice365ServiceContentConfig struct {
	// Office 365 Services API Content Type
	ContentType *string `json:"contentType,omitempty"`
	// If interval type is minutes the value entered must evenly divisible by 60 or save will fail
	Description *string  `json:"description,omitempty"`
	Interval    *float64 `json:"interval,omitempty"`
	// Collector runtime Log Level
	LogLevel *InputOffice365ServiceLogLevel `json:"logLevel,omitempty"`
	Enabled  *bool                          `json:"enabled,omitempty"`
}

func (o *InputOffice365ServiceContentConfig) GetContentType() *string {
	if o == nil {
		return nil
	}
	return o.ContentType
}

func (o *InputOffice365ServiceContentConfig) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputOffice365ServiceContentConfig) GetInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.Interval
}

func (o *InputOffice365ServiceContentConfig) GetLogLevel() *InputOffice365ServiceLogLevel {
	if o == nil {
		return nil
	}
	return o.LogLevel
}

func (o *InputOffice365ServiceContentConfig) GetEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.Enabled
}

// InputOffice365ServiceRetryType - The algorithm to use when performing HTTP retries
type InputOffice365ServiceRetryType string

const (
	InputOffice365ServiceRetryTypeNone    InputOffice365ServiceRetryType = "none"
	InputOffice365ServiceRetryTypeBackoff InputOffice365ServiceRetryType = "backoff"
	InputOffice365ServiceRetryTypeStatic  InputOffice365ServiceRetryType = "static"
)

func (e InputOffice365ServiceRetryType) ToPointer() *InputOffice365ServiceRetryType {
	return &e
}
func (e *InputOffice365ServiceRetryType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "backoff":
		fallthrough
	case "static":
		*e = InputOffice365ServiceRetryType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputOffice365ServiceRetryType: %v", v)
	}
}

type InputOffice365ServiceRetryRules struct {
	// The algorithm to use when performing HTTP retries
	Type *InputOffice365ServiceRetryType `default:"backoff" json:"type"`
	// Time interval between failed request and first retry (kickoff). Maximum allowed value is 20,000 ms (1/3 minute).
	Interval *float64 `default:"1000" json:"interval"`
	// The maximum number of times to retry a failed HTTP request
	Limit *float64 `default:"5" json:"limit"`
	// Base for exponential backoff, e.g., base 2 means that retries will occur after 2, then 4, then 8 seconds, and so on
	Multiplier *float64 `default:"2" json:"multiplier"`
	// List of http codes that trigger a retry. Leave empty to use the default list of 429, 500, and 503.
	Codes []float64 `json:"codes,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) or a timestamp after which to retry the request. The delay is limited to 20 seconds, even if the Retry-After header specifies a longer delay. When disabled, all Retry-After headers are ignored.
	EnableHeader *bool `default:"true" json:"enableHeader"`
	// Make a single retry attempt when a connection timeout (ETIMEDOUT) error occurs
	RetryConnectTimeout *bool `default:"false" json:"retryConnectTimeout"`
	// Retry request when a connection reset (ECONNRESET) error occurs
	RetryConnectReset *bool `default:"false" json:"retryConnectReset"`
}

func (i InputOffice365ServiceRetryRules) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputOffice365ServiceRetryRules) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputOffice365ServiceRetryRules) GetType() *InputOffice365ServiceRetryType {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputOffice365ServiceRetryRules) GetInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.Interval
}

func (o *InputOffice365ServiceRetryRules) GetLimit() *float64 {
	if o == nil {
		return nil
	}
	return o.Limit
}

func (o *InputOffice365ServiceRetryRules) GetMultiplier() *float64 {
	if o == nil {
		return nil
	}
	return o.Multiplier
}

func (o *InputOffice365ServiceRetryRules) GetCodes() []float64 {
	if o == nil {
		return nil
	}
	return o.Codes
}

func (o *InputOffice365ServiceRetryRules) GetEnableHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableHeader
}

func (o *InputOffice365ServiceRetryRules) GetRetryConnectTimeout() *bool {
	if o == nil {
		return nil
	}
	return o.RetryConnectTimeout
}

func (o *InputOffice365ServiceRetryRules) GetRetryConnectReset() *bool {
	if o == nil {
		return nil
	}
	return o.RetryConnectReset
}

// InputOffice365ServiceAuthenticationMethod - Enter client secret directly, or select a stored secret
type InputOffice365ServiceAuthenticationMethod string

const (
	InputOffice365ServiceAuthenticationMethodManual InputOffice365ServiceAuthenticationMethod = "manual"
	InputOffice365ServiceAuthenticationMethodSecret InputOffice365ServiceAuthenticationMethod = "secret"
)

func (e InputOffice365ServiceAuthenticationMethod) ToPointer() *InputOffice365ServiceAuthenticationMethod {
	return &e
}
func (e *InputOffice365ServiceAuthenticationMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "manual":
		fallthrough
	case "secret":
		*e = InputOffice365ServiceAuthenticationMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputOffice365ServiceAuthenticationMethod: %v", v)
	}
}

type InputOffice365Service struct {
	// Unique ID for this input
	ID       *string                    `json:"id,omitempty"`
	Type     *InputOffice365ServiceType `json:"type,omitempty"`
	Disabled *bool                      `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputOffice365ServiceConnections `json:"connections,omitempty"`
	Pq          *InputOffice365ServicePq           `json:"pq,omitempty"`
	// Office 365 subscription plan for your organization, typically Office 365 Enterprise
	PlanType *InputOffice365ServiceSubscriptionPlan `default:"enterprise_gcc" json:"planType"`
	// Office 365 Azure Tenant ID
	TenantID string `json:"tenantId"`
	// Office 365 Azure Application ID
	AppID string `json:"appId"`
	// HTTP request inactivity timeout, use 0 to disable
	Timeout *float64 `default:"300" json:"timeout"`
	// How often workers should check in with the scheduler to keep job subscription alive
	KeepAliveTime *float64 `default:"30" json:"keepAliveTime"`
	// Maximum time the job is allowed to run (e.g., 30, 45s or 15m). Units are seconds, if not specified. Enter 0 for unlimited time.
	JobTimeout *string `default:"0" json:"jobTimeout"`
	// The number of Keep Alive Time periods before an inactive worker will have its job subscription revoked.
	MaxMissedKeepAlives *float64 `default:"3" json:"maxMissedKeepAlives"`
	// Time to keep the job's artifacts on disk after job completion. This also affects how long a job is listed in the Job Inspector.
	TTL *string `default:"4h" json:"ttl"`
	// Fields to add to events from this input
	Metadata []InputOffice365ServiceMetadata `json:"metadata,omitempty"`
	// Enable Office 365 Service Communication API content types and polling intervals. Polling intervals are used to set up search date range and cron schedule, e.g.: */${interval} * * * *. Because of this, intervals entered for current and historical status must be evenly divisible by 60 to give a predictable schedule.
	ContentConfig []InputOffice365ServiceContentConfig `json:"contentConfig,omitempty"`
	RetryRules    *InputOffice365ServiceRetryRules     `json:"retryRules,omitempty"`
	// Enter client secret directly, or select a stored secret
	AuthType    *InputOffice365ServiceAuthenticationMethod `default:"manual" json:"authType"`
	Description *string                                    `json:"description,omitempty"`
	// Office 365 Azure client secret
	ClientSecret *string `json:"clientSecret,omitempty"`
	// Select or create a stored text secret
	TextSecret *string   `json:"textSecret,omitempty"`
	Status     *TFStatus `json:"status,omitempty"`
}

func (i InputOffice365Service) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputOffice365Service) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputOffice365Service) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputOffice365Service) GetType() *InputOffice365ServiceType {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputOffice365Service) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputOffice365Service) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputOffice365Service) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputOffice365Service) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputOffice365Service) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputOffice365Service) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputOffice365Service) GetConnections() []InputOffice365ServiceConnections {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputOffice365Service) GetPq() *InputOffice365ServicePq {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputOffice365Service) GetPlanType() *InputOffice365ServiceSubscriptionPlan {
	if o == nil {
		return nil
	}
	return o.PlanType
}

func (o *InputOffice365Service) GetTenantID() string {
	if o == nil {
		return ""
	}
	return o.TenantID
}

func (o *InputOffice365Service) GetAppID() string {
	if o == nil {
		return ""
	}
	return o.AppID
}

func (o *InputOffice365Service) GetTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.Timeout
}

func (o *InputOffice365Service) GetKeepAliveTime() *float64 {
	if o == nil {
		return nil
	}
	return o.KeepAliveTime
}

func (o *InputOffice365Service) GetJobTimeout() *string {
	if o == nil {
		return nil
	}
	return o.JobTimeout
}

func (o *InputOffice365Service) GetMaxMissedKeepAlives() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxMissedKeepAlives
}

func (o *InputOffice365Service) GetTTL() *string {
	if o == nil {
		return nil
	}
	return o.TTL
}

func (o *InputOffice365Service) GetMetadata() []InputOffice365ServiceMetadata {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputOffice365Service) GetContentConfig() []InputOffice365ServiceContentConfig {
	if o == nil {
		return nil
	}
	return o.ContentConfig
}

func (o *InputOffice365Service) GetRetryRules() *InputOffice365ServiceRetryRules {
	if o == nil {
		return nil
	}
	return o.RetryRules
}

func (o *InputOffice365Service) GetAuthType() *InputOffice365ServiceAuthenticationMethod {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *InputOffice365Service) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputOffice365Service) GetClientSecret() *string {
	if o == nil {
		return nil
	}
	return o.ClientSecret
}

func (o *InputOffice365Service) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *InputOffice365Service) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputOffice365MgmtType string

const (
	InputOffice365MgmtTypeOffice365Mgmt InputOffice365MgmtType = "office365_mgmt"
)

func (e InputOffice365MgmtType) ToPointer() *InputOffice365MgmtType {
	return &e
}
func (e *InputOffice365MgmtType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "office365_mgmt":
		*e = InputOffice365MgmtType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputOffice365MgmtType: %v", v)
	}
}

type InputOffice365MgmtConnections struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *InputOffice365MgmtConnections) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputOffice365MgmtConnections) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// InputOffice365MgmtMode - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputOffice365MgmtMode string

const (
	InputOffice365MgmtModeSmart  InputOffice365MgmtMode = "smart"
	InputOffice365MgmtModeAlways InputOffice365MgmtMode = "always"
)

func (e InputOffice365MgmtMode) ToPointer() *InputOffice365MgmtMode {
	return &e
}
func (e *InputOffice365MgmtMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputOffice365MgmtMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputOffice365MgmtMode: %v", v)
	}
}

// InputOffice365MgmtCompression - Codec to use to compress the persisted data
type InputOffice365MgmtCompression string

const (
	InputOffice365MgmtCompressionNone InputOffice365MgmtCompression = "none"
	InputOffice365MgmtCompressionGzip InputOffice365MgmtCompression = "gzip"
)

func (e InputOffice365MgmtCompression) ToPointer() *InputOffice365MgmtCompression {
	return &e
}
func (e *InputOffice365MgmtCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputOffice365MgmtCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputOffice365MgmtCompression: %v", v)
	}
}

type InputOffice365MgmtPq struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputOffice365MgmtMode `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *InputOffice365MgmtCompression `default:"none" json:"compress"`
}

func (i InputOffice365MgmtPq) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputOffice365MgmtPq) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputOffice365MgmtPq) GetMode() *InputOffice365MgmtMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputOffice365MgmtPq) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputOffice365MgmtPq) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *InputOffice365MgmtPq) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *InputOffice365MgmtPq) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *InputOffice365MgmtPq) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *InputOffice365MgmtPq) GetCompress() *InputOffice365MgmtCompression {
	if o == nil {
		return nil
	}
	return o.Compress
}

// SubscriptionPlan - Office 365 subscription plan for your organization, typically Office 365 Enterprise
type SubscriptionPlan string

const (
	SubscriptionPlanEnterpriseGcc SubscriptionPlan = "enterprise_gcc"
	SubscriptionPlanGcc           SubscriptionPlan = "gcc"
	SubscriptionPlanGccHigh       SubscriptionPlan = "gcc_high"
	SubscriptionPlanDod           SubscriptionPlan = "dod"
)

func (e SubscriptionPlan) ToPointer() *SubscriptionPlan {
	return &e
}
func (e *SubscriptionPlan) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "enterprise_gcc":
		fallthrough
	case "gcc":
		fallthrough
	case "gcc_high":
		fallthrough
	case "dod":
		*e = SubscriptionPlan(v)
		return nil
	default:
		return fmt.Errorf("invalid value for SubscriptionPlan: %v", v)
	}
}

type InputOffice365MgmtMetadata struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputOffice365MgmtMetadata) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputOffice365MgmtMetadata) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// InputOffice365MgmtLogLevel - Collector runtime Log Level
type InputOffice365MgmtLogLevel string

const (
	InputOffice365MgmtLogLevelError InputOffice365MgmtLogLevel = "error"
	InputOffice365MgmtLogLevelWarn  InputOffice365MgmtLogLevel = "warn"
	InputOffice365MgmtLogLevelInfo  InputOffice365MgmtLogLevel = "info"
	InputOffice365MgmtLogLevelDebug InputOffice365MgmtLogLevel = "debug"
)

func (e InputOffice365MgmtLogLevel) ToPointer() *InputOffice365MgmtLogLevel {
	return &e
}
func (e *InputOffice365MgmtLogLevel) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "error":
		fallthrough
	case "warn":
		fallthrough
	case "info":
		fallthrough
	case "debug":
		*e = InputOffice365MgmtLogLevel(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputOffice365MgmtLogLevel: %v", v)
	}
}

type ContentConfig struct {
	// Office 365 Management Activity API Content Type
	ContentType *string `json:"contentType,omitempty"`
	// If interval type is minutes the value entered must evenly divisible by 60 or save will fail
	Description *string  `json:"description,omitempty"`
	Interval    *float64 `json:"interval,omitempty"`
	// Collector runtime Log Level
	LogLevel *InputOffice365MgmtLogLevel `json:"logLevel,omitempty"`
	Enabled  *bool                       `json:"enabled,omitempty"`
}

func (o *ContentConfig) GetContentType() *string {
	if o == nil {
		return nil
	}
	return o.ContentType
}

func (o *ContentConfig) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *ContentConfig) GetInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.Interval
}

func (o *ContentConfig) GetLogLevel() *InputOffice365MgmtLogLevel {
	if o == nil {
		return nil
	}
	return o.LogLevel
}

func (o *ContentConfig) GetEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.Enabled
}

// InputOffice365MgmtRetryType - The algorithm to use when performing HTTP retries
type InputOffice365MgmtRetryType string

const (
	InputOffice365MgmtRetryTypeNone    InputOffice365MgmtRetryType = "none"
	InputOffice365MgmtRetryTypeBackoff InputOffice365MgmtRetryType = "backoff"
	InputOffice365MgmtRetryTypeStatic  InputOffice365MgmtRetryType = "static"
)

func (e InputOffice365MgmtRetryType) ToPointer() *InputOffice365MgmtRetryType {
	return &e
}
func (e *InputOffice365MgmtRetryType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "backoff":
		fallthrough
	case "static":
		*e = InputOffice365MgmtRetryType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputOffice365MgmtRetryType: %v", v)
	}
}

type InputOffice365MgmtRetryRules struct {
	// The algorithm to use when performing HTTP retries
	Type *InputOffice365MgmtRetryType `default:"backoff" json:"type"`
	// Time interval between failed request and first retry (kickoff). Maximum allowed value is 20,000 ms (1/3 minute).
	Interval *float64 `default:"1000" json:"interval"`
	// The maximum number of times to retry a failed HTTP request
	Limit *float64 `default:"5" json:"limit"`
	// Base for exponential backoff, e.g., base 2 means that retries will occur after 2, then 4, then 8 seconds, and so on
	Multiplier *float64 `default:"2" json:"multiplier"`
	// List of http codes that trigger a retry. Leave empty to use the default list of 429, 500, and 503.
	Codes []float64 `json:"codes,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) or a timestamp after which to retry the request. The delay is limited to 20 seconds, even if the Retry-After header specifies a longer delay. When disabled, all Retry-After headers are ignored.
	EnableHeader *bool `default:"true" json:"enableHeader"`
	// Make a single retry attempt when a connection timeout (ETIMEDOUT) error occurs
	RetryConnectTimeout *bool `default:"false" json:"retryConnectTimeout"`
	// Retry request when a connection reset (ECONNRESET) error occurs
	RetryConnectReset *bool `default:"false" json:"retryConnectReset"`
}

func (i InputOffice365MgmtRetryRules) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputOffice365MgmtRetryRules) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputOffice365MgmtRetryRules) GetType() *InputOffice365MgmtRetryType {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputOffice365MgmtRetryRules) GetInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.Interval
}

func (o *InputOffice365MgmtRetryRules) GetLimit() *float64 {
	if o == nil {
		return nil
	}
	return o.Limit
}

func (o *InputOffice365MgmtRetryRules) GetMultiplier() *float64 {
	if o == nil {
		return nil
	}
	return o.Multiplier
}

func (o *InputOffice365MgmtRetryRules) GetCodes() []float64 {
	if o == nil {
		return nil
	}
	return o.Codes
}

func (o *InputOffice365MgmtRetryRules) GetEnableHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableHeader
}

func (o *InputOffice365MgmtRetryRules) GetRetryConnectTimeout() *bool {
	if o == nil {
		return nil
	}
	return o.RetryConnectTimeout
}

func (o *InputOffice365MgmtRetryRules) GetRetryConnectReset() *bool {
	if o == nil {
		return nil
	}
	return o.RetryConnectReset
}

// InputOffice365MgmtAuthenticationMethod - Enter client secret directly, or select a stored secret
type InputOffice365MgmtAuthenticationMethod string

const (
	InputOffice365MgmtAuthenticationMethodManual InputOffice365MgmtAuthenticationMethod = "manual"
	InputOffice365MgmtAuthenticationMethodSecret InputOffice365MgmtAuthenticationMethod = "secret"
)

func (e InputOffice365MgmtAuthenticationMethod) ToPointer() *InputOffice365MgmtAuthenticationMethod {
	return &e
}
func (e *InputOffice365MgmtAuthenticationMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "manual":
		fallthrough
	case "secret":
		*e = InputOffice365MgmtAuthenticationMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputOffice365MgmtAuthenticationMethod: %v", v)
	}
}

type InputOffice365Mgmt struct {
	// Unique ID for this input
	ID       *string                 `json:"id,omitempty"`
	Type     *InputOffice365MgmtType `json:"type,omitempty"`
	Disabled *bool                   `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputOffice365MgmtConnections `json:"connections,omitempty"`
	Pq          *InputOffice365MgmtPq           `json:"pq,omitempty"`
	// Office 365 subscription plan for your organization, typically Office 365 Enterprise
	PlanType *SubscriptionPlan `default:"enterprise_gcc" json:"planType"`
	// Office 365 Azure Tenant ID
	TenantID string `json:"tenantId"`
	// Office 365 Azure Application ID
	AppID string `json:"appId"`
	// HTTP request inactivity timeout, use 0 to disable
	Timeout *float64 `default:"300" json:"timeout"`
	// How often workers should check in with the scheduler to keep job subscription alive
	KeepAliveTime *float64 `default:"30" json:"keepAliveTime"`
	// Maximum time the job is allowed to run (e.g., 30, 45s or 15m). Units are seconds, if not specified. Enter 0 for unlimited time.
	JobTimeout *string `default:"0" json:"jobTimeout"`
	// The number of Keep Alive Time periods before an inactive worker will have its job subscription revoked.
	MaxMissedKeepAlives *float64 `default:"3" json:"maxMissedKeepAlives"`
	// Time to keep the job's artifacts on disk after job completion. This also affects how long a job is listed in the Job Inspector.
	TTL *string `default:"4h" json:"ttl"`
	// Fields to add to events from this input
	Metadata []InputOffice365MgmtMetadata `json:"metadata,omitempty"`
	// Optional Publisher Identifier to use in API requests, defaults to tenant id if not defined. For more information see [here](https://docs.microsoft.com/en-us/office/office-365-management-api/office-365-management-activity-api-reference#start-a-subscription)
	PublisherIdentifier *string `json:"publisherIdentifier,omitempty"`
	// Enable Office 365 Management Activity API content types and polling intervals. Polling intervals are used to set up search date range and cron schedule, e.g.: */${interval} * * * *. Because of this, intervals entered must be evenly divisible by 60 to give a predictable schedule.
	ContentConfig []ContentConfig `json:"contentConfig,omitempty"`
	// Use this setting to account for ingestion lag. This is necessary because there can be a lag of 60 - 90 minutes (or longer) before Office 365 events are available for retrieval.
	IngestionLag *float64                      `default:"0" json:"ingestionLag"`
	RetryRules   *InputOffice365MgmtRetryRules `json:"retryRules,omitempty"`
	// Enter client secret directly, or select a stored secret
	AuthType    *InputOffice365MgmtAuthenticationMethod `default:"manual" json:"authType"`
	Description *string                                 `json:"description,omitempty"`
	// Office 365 Azure client secret
	ClientSecret *string `json:"clientSecret,omitempty"`
	// Select or create a stored text secret
	TextSecret *string   `json:"textSecret,omitempty"`
	Status     *TFStatus `json:"status,omitempty"`
}

func (i InputOffice365Mgmt) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputOffice365Mgmt) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputOffice365Mgmt) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputOffice365Mgmt) GetType() *InputOffice365MgmtType {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputOffice365Mgmt) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputOffice365Mgmt) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputOffice365Mgmt) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputOffice365Mgmt) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputOffice365Mgmt) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputOffice365Mgmt) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputOffice365Mgmt) GetConnections() []InputOffice365MgmtConnections {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputOffice365Mgmt) GetPq() *InputOffice365MgmtPq {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputOffice365Mgmt) GetPlanType() *SubscriptionPlan {
	if o == nil {
		return nil
	}
	return o.PlanType
}

func (o *InputOffice365Mgmt) GetTenantID() string {
	if o == nil {
		return ""
	}
	return o.TenantID
}

func (o *InputOffice365Mgmt) GetAppID() string {
	if o == nil {
		return ""
	}
	return o.AppID
}

func (o *InputOffice365Mgmt) GetTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.Timeout
}

func (o *InputOffice365Mgmt) GetKeepAliveTime() *float64 {
	if o == nil {
		return nil
	}
	return o.KeepAliveTime
}

func (o *InputOffice365Mgmt) GetJobTimeout() *string {
	if o == nil {
		return nil
	}
	return o.JobTimeout
}

func (o *InputOffice365Mgmt) GetMaxMissedKeepAlives() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxMissedKeepAlives
}

func (o *InputOffice365Mgmt) GetTTL() *string {
	if o == nil {
		return nil
	}
	return o.TTL
}

func (o *InputOffice365Mgmt) GetMetadata() []InputOffice365MgmtMetadata {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputOffice365Mgmt) GetPublisherIdentifier() *string {
	if o == nil {
		return nil
	}
	return o.PublisherIdentifier
}

func (o *InputOffice365Mgmt) GetContentConfig() []ContentConfig {
	if o == nil {
		return nil
	}
	return o.ContentConfig
}

func (o *InputOffice365Mgmt) GetIngestionLag() *float64 {
	if o == nil {
		return nil
	}
	return o.IngestionLag
}

func (o *InputOffice365Mgmt) GetRetryRules() *InputOffice365MgmtRetryRules {
	if o == nil {
		return nil
	}
	return o.RetryRules
}

func (o *InputOffice365Mgmt) GetAuthType() *InputOffice365MgmtAuthenticationMethod {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *InputOffice365Mgmt) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputOffice365Mgmt) GetClientSecret() *string {
	if o == nil {
		return nil
	}
	return o.ClientSecret
}

func (o *InputOffice365Mgmt) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *InputOffice365Mgmt) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputEdgePrometheusType string

const (
	InputEdgePrometheusTypeEdgePrometheus InputEdgePrometheusType = "edge_prometheus"
)

func (e InputEdgePrometheusType) ToPointer() *InputEdgePrometheusType {
	return &e
}
func (e *InputEdgePrometheusType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "edge_prometheus":
		*e = InputEdgePrometheusType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputEdgePrometheusType: %v", v)
	}
}

type InputEdgePrometheusConnections struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *InputEdgePrometheusConnections) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputEdgePrometheusConnections) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// InputEdgePrometheusMode - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputEdgePrometheusMode string

const (
	InputEdgePrometheusModeSmart  InputEdgePrometheusMode = "smart"
	InputEdgePrometheusModeAlways InputEdgePrometheusMode = "always"
)

func (e InputEdgePrometheusMode) ToPointer() *InputEdgePrometheusMode {
	return &e
}
func (e *InputEdgePrometheusMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputEdgePrometheusMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputEdgePrometheusMode: %v", v)
	}
}

// InputEdgePrometheusCompression - Codec to use to compress the persisted data
type InputEdgePrometheusCompression string

const (
	InputEdgePrometheusCompressionNone InputEdgePrometheusCompression = "none"
	InputEdgePrometheusCompressionGzip InputEdgePrometheusCompression = "gzip"
)

func (e InputEdgePrometheusCompression) ToPointer() *InputEdgePrometheusCompression {
	return &e
}
func (e *InputEdgePrometheusCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputEdgePrometheusCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputEdgePrometheusCompression: %v", v)
	}
}

type InputEdgePrometheusPq struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputEdgePrometheusMode `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *InputEdgePrometheusCompression `default:"none" json:"compress"`
}

func (i InputEdgePrometheusPq) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputEdgePrometheusPq) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputEdgePrometheusPq) GetMode() *InputEdgePrometheusMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputEdgePrometheusPq) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputEdgePrometheusPq) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *InputEdgePrometheusPq) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *InputEdgePrometheusPq) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *InputEdgePrometheusPq) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *InputEdgePrometheusPq) GetCompress() *InputEdgePrometheusCompression {
	if o == nil {
		return nil
	}
	return o.Compress
}

// InputEdgePrometheusDiscoveryType - Target discovery mechanism. Use static to manually enter a list of targets.
type InputEdgePrometheusDiscoveryType string

const (
	InputEdgePrometheusDiscoveryTypeStatic  InputEdgePrometheusDiscoveryType = "static"
	InputEdgePrometheusDiscoveryTypeDNS     InputEdgePrometheusDiscoveryType = "dns"
	InputEdgePrometheusDiscoveryTypeEc2     InputEdgePrometheusDiscoveryType = "ec2"
	InputEdgePrometheusDiscoveryTypeK8sNode InputEdgePrometheusDiscoveryType = "k8s-node"
	InputEdgePrometheusDiscoveryTypeK8sPods InputEdgePrometheusDiscoveryType = "k8s-pods"
)

func (e InputEdgePrometheusDiscoveryType) ToPointer() *InputEdgePrometheusDiscoveryType {
	return &e
}
func (e *InputEdgePrometheusDiscoveryType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "static":
		fallthrough
	case "dns":
		fallthrough
	case "ec2":
		fallthrough
	case "k8s-node":
		fallthrough
	case "k8s-pods":
		*e = InputEdgePrometheusDiscoveryType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputEdgePrometheusDiscoveryType: %v", v)
	}
}

// InputEdgePrometheusInputCompression - Data compression format. Default is gzip.
type InputEdgePrometheusInputCompression string

const (
	InputEdgePrometheusInputCompressionNone InputEdgePrometheusInputCompression = "none"
	InputEdgePrometheusInputCompressionGzip InputEdgePrometheusInputCompression = "gzip"
)

func (e InputEdgePrometheusInputCompression) ToPointer() *InputEdgePrometheusInputCompression {
	return &e
}
func (e *InputEdgePrometheusInputCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputEdgePrometheusInputCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputEdgePrometheusInputCompression: %v", v)
	}
}

type DiskSpooling struct {
	// Spool events on disk for Cribl Edge and Search. Default is disabled.
	Enable *bool `default:"false" json:"enable"`
	// Time period for grouping spooled events. Default is 10m.
	TimeWindow *string `default:"10m" json:"timeWindow"`
	// Maximum disk space that can be consumed before older buckets are deleted. Examples: 420MB, 4GB. Default is 1GB.
	MaxDataSize *string `default:"1GB" json:"maxDataSize"`
	// Maximum amount of time to retain data before older buckets are deleted. Examples: 2h, 4d. Default is 24h.
	MaxDataTime *string `default:"24h" json:"maxDataTime"`
	// Data compression format. Default is gzip.
	Compress *InputEdgePrometheusInputCompression `default:"gzip" json:"compress"`
}

func (d DiskSpooling) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(d, "", false)
}

func (d *DiskSpooling) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &d, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *DiskSpooling) GetEnable() *bool {
	if o == nil {
		return nil
	}
	return o.Enable
}

func (o *DiskSpooling) GetTimeWindow() *string {
	if o == nil {
		return nil
	}
	return o.TimeWindow
}

func (o *DiskSpooling) GetMaxDataSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxDataSize
}

func (o *DiskSpooling) GetMaxDataTime() *string {
	if o == nil {
		return nil
	}
	return o.MaxDataTime
}

func (o *DiskSpooling) GetCompress() *InputEdgePrometheusInputCompression {
	if o == nil {
		return nil
	}
	return o.Compress
}

type InputEdgePrometheusMetadata struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputEdgePrometheusMetadata) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputEdgePrometheusMetadata) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// InputEdgePrometheusAuthenticationMethod - Enter credentials directly, or select a stored secret
type InputEdgePrometheusAuthenticationMethod string

const (
	InputEdgePrometheusAuthenticationMethodManual     InputEdgePrometheusAuthenticationMethod = "manual"
	InputEdgePrometheusAuthenticationMethodSecret     InputEdgePrometheusAuthenticationMethod = "secret"
	InputEdgePrometheusAuthenticationMethodKubernetes InputEdgePrometheusAuthenticationMethod = "kubernetes"
)

func (e InputEdgePrometheusAuthenticationMethod) ToPointer() *InputEdgePrometheusAuthenticationMethod {
	return &e
}
func (e *InputEdgePrometheusAuthenticationMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "manual":
		fallthrough
	case "secret":
		fallthrough
	case "kubernetes":
		*e = InputEdgePrometheusAuthenticationMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputEdgePrometheusAuthenticationMethod: %v", v)
	}
}

// InputEdgePrometheusInputProtocol - Protocol to use when collecting metrics
type InputEdgePrometheusInputProtocol string

const (
	InputEdgePrometheusInputProtocolHTTP  InputEdgePrometheusInputProtocol = "http"
	InputEdgePrometheusInputProtocolHTTPS InputEdgePrometheusInputProtocol = "https"
)

func (e InputEdgePrometheusInputProtocol) ToPointer() *InputEdgePrometheusInputProtocol {
	return &e
}
func (e *InputEdgePrometheusInputProtocol) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "http":
		fallthrough
	case "https":
		*e = InputEdgePrometheusInputProtocol(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputEdgePrometheusInputProtocol: %v", v)
	}
}

type Targets struct {
	// Protocol to use when collecting metrics
	Protocol *InputEdgePrometheusInputProtocol `default:"http" json:"protocol"`
	// Name of host from which to pull metrics.
	Host string `json:"host"`
	// The port number in the metrics URL for discovered targets.
	Port *float64 `default:"9090" json:"port"`
	// Path to use when collecting metrics from discovered targets
	Path *string `default:"/metrics" json:"path"`
}

func (t Targets) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(t, "", false)
}

func (t *Targets) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &t, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *Targets) GetProtocol() *InputEdgePrometheusInputProtocol {
	if o == nil {
		return nil
	}
	return o.Protocol
}

func (o *Targets) GetHost() string {
	if o == nil {
		return ""
	}
	return o.Host
}

func (o *Targets) GetPort() *float64 {
	if o == nil {
		return nil
	}
	return o.Port
}

func (o *Targets) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

// InputEdgePrometheusRecordType - DNS Record type to resolve
type InputEdgePrometheusRecordType string

const (
	InputEdgePrometheusRecordTypeSrv  InputEdgePrometheusRecordType = "SRV"
	InputEdgePrometheusRecordTypeA    InputEdgePrometheusRecordType = "A"
	InputEdgePrometheusRecordTypeAaaa InputEdgePrometheusRecordType = "AAAA"
)

func (e InputEdgePrometheusRecordType) ToPointer() *InputEdgePrometheusRecordType {
	return &e
}
func (e *InputEdgePrometheusRecordType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "SRV":
		fallthrough
	case "A":
		fallthrough
	case "AAAA":
		*e = InputEdgePrometheusRecordType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputEdgePrometheusRecordType: %v", v)
	}
}

// InputEdgePrometheusProtocol - Protocol to use when collecting metrics
type InputEdgePrometheusProtocol string

const (
	InputEdgePrometheusProtocolHTTP  InputEdgePrometheusProtocol = "http"
	InputEdgePrometheusProtocolHTTPS InputEdgePrometheusProtocol = "https"
)

func (e InputEdgePrometheusProtocol) ToPointer() *InputEdgePrometheusProtocol {
	return &e
}
func (e *InputEdgePrometheusProtocol) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "http":
		fallthrough
	case "https":
		*e = InputEdgePrometheusProtocol(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputEdgePrometheusProtocol: %v", v)
	}
}

type InputEdgePrometheusSearchFilter struct {
	// Search filter attribute name, see: https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_DescribeInstances.html for more information. Attributes can be manually entered if not present in the drop down list
	Name string `json:"Name"`
	// Search Filter Values, if empty only "running" EC2 instances will be returned
	Values []string `json:"Values,omitempty"`
}

func (o *InputEdgePrometheusSearchFilter) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputEdgePrometheusSearchFilter) GetValues() []string {
	if o == nil {
		return nil
	}
	return o.Values
}

// InputEdgePrometheusInputAuthenticationMethod - AWS authentication method. Choose Auto to use IAM roles.
type InputEdgePrometheusInputAuthenticationMethod string

const (
	InputEdgePrometheusInputAuthenticationMethodAuto   InputEdgePrometheusInputAuthenticationMethod = "auto"
	InputEdgePrometheusInputAuthenticationMethodManual InputEdgePrometheusInputAuthenticationMethod = "manual"
	InputEdgePrometheusInputAuthenticationMethodSecret InputEdgePrometheusInputAuthenticationMethod = "secret"
)

func (e InputEdgePrometheusInputAuthenticationMethod) ToPointer() *InputEdgePrometheusInputAuthenticationMethod {
	return &e
}
func (e *InputEdgePrometheusInputAuthenticationMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "auto":
		fallthrough
	case "manual":
		fallthrough
	case "secret":
		*e = InputEdgePrometheusInputAuthenticationMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputEdgePrometheusInputAuthenticationMethod: %v", v)
	}
}

// InputEdgePrometheusSignatureVersion - Signature version to use for signing EC2 requests
type InputEdgePrometheusSignatureVersion string

const (
	InputEdgePrometheusSignatureVersionV2 InputEdgePrometheusSignatureVersion = "v2"
	InputEdgePrometheusSignatureVersionV4 InputEdgePrometheusSignatureVersion = "v4"
)

func (e InputEdgePrometheusSignatureVersion) ToPointer() *InputEdgePrometheusSignatureVersion {
	return &e
}
func (e *InputEdgePrometheusSignatureVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "v2":
		fallthrough
	case "v4":
		*e = InputEdgePrometheusSignatureVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputEdgePrometheusSignatureVersion: %v", v)
	}
}

type PodFilter struct {
	// JavaScript expression applied to pods objects. Return 'true' to include it.
	Filter string `json:"filter"`
	// Optional description of this rule's purpose
	Description *string `json:"description,omitempty"`
}

func (o *PodFilter) GetFilter() string {
	if o == nil {
		return ""
	}
	return o.Filter
}

func (o *PodFilter) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

type InputEdgePrometheus struct {
	// Unique ID for this input
	ID       *string                  `json:"id,omitempty"`
	Type     *InputEdgePrometheusType `json:"type,omitempty"`
	Disabled *bool                    `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputEdgePrometheusConnections `json:"connections,omitempty"`
	Pq          *InputEdgePrometheusPq           `json:"pq,omitempty"`
	// Other dimensions to include in events
	DimensionList []string `json:"dimensionList,omitempty"`
	// Target discovery mechanism. Use static to manually enter a list of targets.
	DiscoveryType *InputEdgePrometheusDiscoveryType `default:"static" json:"discoveryType"`
	// How often in seconds to scrape targets for metrics.
	Interval *float64 `default:"15" json:"interval"`
	// Timeout, in milliseconds, before aborting HTTP connection attempts; 1-60000 or 0 to disable
	Timeout     *float64      `default:"5000" json:"timeout"`
	Persistence *DiskSpooling `json:"persistence,omitempty"`
	// Fields to add to events from this input
	Metadata []InputEdgePrometheusMetadata `json:"metadata,omitempty"`
	// Enter credentials directly, or select a stored secret
	AuthType    *InputEdgePrometheusAuthenticationMethod `default:"manual" json:"authType"`
	Description *string                                  `json:"description,omitempty"`
	Targets     []Targets                                `json:"targets,omitempty"`
	// List of DNS names to resolve
	NameList []string `json:"nameList,omitempty"`
	// DNS Record type to resolve
	RecordType *InputEdgePrometheusRecordType `default:"SRV" json:"recordType"`
	// Protocol to use when collecting metrics
	ScrapeProtocol *InputEdgePrometheusProtocol `default:"http" json:"scrapeProtocol"`
	// Path to use when collecting metrics from discovered targets
	ScrapePath *string `default:"/metrics" json:"scrapePath"`
	// Use public IP address for discovered targets. Set to false if the private IP address should be used.
	UsePublicIP *bool `default:"true" json:"usePublicIp"`
	// The port number in the metrics URL for discovered targets.
	ScrapePort *float64 `default:"9090" json:"scrapePort"`
	// EC2 Instance Search Filter
	SearchFilter []InputEdgePrometheusSearchFilter `json:"searchFilter,omitempty"`
	// AWS authentication method. Choose Auto to use IAM roles.
	AwsAuthenticationMethod *InputEdgePrometheusInputAuthenticationMethod `default:"auto" json:"awsAuthenticationMethod"`
	AwsSecretKey            *string                                       `json:"awsSecretKey,omitempty"`
	// Region where the EC2 is located
	Region *string `json:"region,omitempty"`
	// EC2 service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to EC2-compatible endpoint.
	Endpoint *string `json:"endpoint,omitempty"`
	// Signature version to use for signing EC2 requests
	SignatureVersion *InputEdgePrometheusSignatureVersion `default:"v4" json:"signatureVersion"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `default:"true" json:"reuseConnections"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Use Assume Role credentials to access EC2
	EnableAssumeRole *bool `default:"false" json:"enableAssumeRole"`
	// Amazon Resource Name (ARN) of the role to assume
	AssumeRoleArn *string `json:"assumeRoleArn,omitempty"`
	// External ID to use when assuming role
	AssumeRoleExternalID *string `json:"assumeRoleExternalId,omitempty"`
	// Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
	DurationSeconds *float64 `default:"3600" json:"durationSeconds"`
	// Protocol to use when collecting metrics
	ScrapeProtocolExpr *string `default:"metadata.annotations['prometheus.io/scheme'] || 'http'" json:"scrapeProtocolExpr"`
	// The port number in the metrics URL for discovered targets.
	ScrapePortExpr *string `default:"metadata.annotations['prometheus.io/port'] || 9090" json:"scrapePortExpr"`
	// Path to use when collecting metrics from discovered targets
	ScrapePathExpr *string `default:"metadata.annotations['prometheus.io/path'] || '/metrics'" json:"scrapePathExpr"`
	//   Add rules to decide which pods to discover for metrics.
	//   Pods are searched if no rules are given or of all the rules'
	//   expressions evaluate to true.
	//
	PodFilter []PodFilter `json:"podFilter,omitempty"`
	// Username for Prometheus Basic authentication
	Username *string `json:"username,omitempty"`
	// Password for Prometheus Basic authentication
	Password *string `json:"password,omitempty"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string   `json:"credentialsSecret,omitempty"`
	Status            *TFStatus `json:"status,omitempty"`
}

func (i InputEdgePrometheus) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputEdgePrometheus) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputEdgePrometheus) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputEdgePrometheus) GetType() *InputEdgePrometheusType {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputEdgePrometheus) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputEdgePrometheus) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputEdgePrometheus) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputEdgePrometheus) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputEdgePrometheus) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputEdgePrometheus) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputEdgePrometheus) GetConnections() []InputEdgePrometheusConnections {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputEdgePrometheus) GetPq() *InputEdgePrometheusPq {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputEdgePrometheus) GetDimensionList() []string {
	if o == nil {
		return nil
	}
	return o.DimensionList
}

func (o *InputEdgePrometheus) GetDiscoveryType() *InputEdgePrometheusDiscoveryType {
	if o == nil {
		return nil
	}
	return o.DiscoveryType
}

func (o *InputEdgePrometheus) GetInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.Interval
}

func (o *InputEdgePrometheus) GetTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.Timeout
}

func (o *InputEdgePrometheus) GetPersistence() *DiskSpooling {
	if o == nil {
		return nil
	}
	return o.Persistence
}

func (o *InputEdgePrometheus) GetMetadata() []InputEdgePrometheusMetadata {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputEdgePrometheus) GetAuthType() *InputEdgePrometheusAuthenticationMethod {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *InputEdgePrometheus) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputEdgePrometheus) GetTargets() []Targets {
	if o == nil {
		return nil
	}
	return o.Targets
}

func (o *InputEdgePrometheus) GetNameList() []string {
	if o == nil {
		return nil
	}
	return o.NameList
}

func (o *InputEdgePrometheus) GetRecordType() *InputEdgePrometheusRecordType {
	if o == nil {
		return nil
	}
	return o.RecordType
}

func (o *InputEdgePrometheus) GetScrapeProtocol() *InputEdgePrometheusProtocol {
	if o == nil {
		return nil
	}
	return o.ScrapeProtocol
}

func (o *InputEdgePrometheus) GetScrapePath() *string {
	if o == nil {
		return nil
	}
	return o.ScrapePath
}

func (o *InputEdgePrometheus) GetUsePublicIP() *bool {
	if o == nil {
		return nil
	}
	return o.UsePublicIP
}

func (o *InputEdgePrometheus) GetScrapePort() *float64 {
	if o == nil {
		return nil
	}
	return o.ScrapePort
}

func (o *InputEdgePrometheus) GetSearchFilter() []InputEdgePrometheusSearchFilter {
	if o == nil {
		return nil
	}
	return o.SearchFilter
}

func (o *InputEdgePrometheus) GetAwsAuthenticationMethod() *InputEdgePrometheusInputAuthenticationMethod {
	if o == nil {
		return nil
	}
	return o.AwsAuthenticationMethod
}

func (o *InputEdgePrometheus) GetAwsSecretKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecretKey
}

func (o *InputEdgePrometheus) GetRegion() *string {
	if o == nil {
		return nil
	}
	return o.Region
}

func (o *InputEdgePrometheus) GetEndpoint() *string {
	if o == nil {
		return nil
	}
	return o.Endpoint
}

func (o *InputEdgePrometheus) GetSignatureVersion() *InputEdgePrometheusSignatureVersion {
	if o == nil {
		return nil
	}
	return o.SignatureVersion
}

func (o *InputEdgePrometheus) GetReuseConnections() *bool {
	if o == nil {
		return nil
	}
	return o.ReuseConnections
}

func (o *InputEdgePrometheus) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *InputEdgePrometheus) GetEnableAssumeRole() *bool {
	if o == nil {
		return nil
	}
	return o.EnableAssumeRole
}

func (o *InputEdgePrometheus) GetAssumeRoleArn() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleArn
}

func (o *InputEdgePrometheus) GetAssumeRoleExternalID() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleExternalID
}

func (o *InputEdgePrometheus) GetDurationSeconds() *float64 {
	if o == nil {
		return nil
	}
	return o.DurationSeconds
}

func (o *InputEdgePrometheus) GetScrapeProtocolExpr() *string {
	if o == nil {
		return nil
	}
	return o.ScrapeProtocolExpr
}

func (o *InputEdgePrometheus) GetScrapePortExpr() *string {
	if o == nil {
		return nil
	}
	return o.ScrapePortExpr
}

func (o *InputEdgePrometheus) GetScrapePathExpr() *string {
	if o == nil {
		return nil
	}
	return o.ScrapePathExpr
}

func (o *InputEdgePrometheus) GetPodFilter() []PodFilter {
	if o == nil {
		return nil
	}
	return o.PodFilter
}

func (o *InputEdgePrometheus) GetUsername() *string {
	if o == nil {
		return nil
	}
	return o.Username
}

func (o *InputEdgePrometheus) GetPassword() *string {
	if o == nil {
		return nil
	}
	return o.Password
}

func (o *InputEdgePrometheus) GetCredentialsSecret() *string {
	if o == nil {
		return nil
	}
	return o.CredentialsSecret
}

func (o *InputEdgePrometheus) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputPrometheusType string

const (
	InputPrometheusTypePrometheus InputPrometheusType = "prometheus"
)

func (e InputPrometheusType) ToPointer() *InputPrometheusType {
	return &e
}
func (e *InputPrometheusType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "prometheus":
		*e = InputPrometheusType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputPrometheusType: %v", v)
	}
}

type InputPrometheusConnections struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *InputPrometheusConnections) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputPrometheusConnections) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// InputPrometheusMode - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputPrometheusMode string

const (
	InputPrometheusModeSmart  InputPrometheusMode = "smart"
	InputPrometheusModeAlways InputPrometheusMode = "always"
)

func (e InputPrometheusMode) ToPointer() *InputPrometheusMode {
	return &e
}
func (e *InputPrometheusMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputPrometheusMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputPrometheusMode: %v", v)
	}
}

// InputPrometheusCompression - Codec to use to compress the persisted data
type InputPrometheusCompression string

const (
	InputPrometheusCompressionNone InputPrometheusCompression = "none"
	InputPrometheusCompressionGzip InputPrometheusCompression = "gzip"
)

func (e InputPrometheusCompression) ToPointer() *InputPrometheusCompression {
	return &e
}
func (e *InputPrometheusCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputPrometheusCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputPrometheusCompression: %v", v)
	}
}

type InputPrometheusPq struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputPrometheusMode `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *InputPrometheusCompression `default:"none" json:"compress"`
}

func (i InputPrometheusPq) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputPrometheusPq) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputPrometheusPq) GetMode() *InputPrometheusMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputPrometheusPq) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputPrometheusPq) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *InputPrometheusPq) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *InputPrometheusPq) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *InputPrometheusPq) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *InputPrometheusPq) GetCompress() *InputPrometheusCompression {
	if o == nil {
		return nil
	}
	return o.Compress
}

// DiscoveryType - Target discovery mechanism. Use static to manually enter a list of targets.
type DiscoveryType string

const (
	DiscoveryTypeStatic DiscoveryType = "static"
	DiscoveryTypeDNS    DiscoveryType = "dns"
	DiscoveryTypeEc2    DiscoveryType = "ec2"
)

func (e DiscoveryType) ToPointer() *DiscoveryType {
	return &e
}
func (e *DiscoveryType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "static":
		fallthrough
	case "dns":
		fallthrough
	case "ec2":
		*e = DiscoveryType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DiscoveryType: %v", v)
	}
}

// InputPrometheusLogLevel - Collector runtime Log Level
type InputPrometheusLogLevel string

const (
	InputPrometheusLogLevelError InputPrometheusLogLevel = "error"
	InputPrometheusLogLevelWarn  InputPrometheusLogLevel = "warn"
	InputPrometheusLogLevelInfo  InputPrometheusLogLevel = "info"
	InputPrometheusLogLevelDebug InputPrometheusLogLevel = "debug"
)

func (e InputPrometheusLogLevel) ToPointer() *InputPrometheusLogLevel {
	return &e
}
func (e *InputPrometheusLogLevel) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "error":
		fallthrough
	case "warn":
		fallthrough
	case "info":
		fallthrough
	case "debug":
		*e = InputPrometheusLogLevel(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputPrometheusLogLevel: %v", v)
	}
}

type InputPrometheusMetadata struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputPrometheusMetadata) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputPrometheusMetadata) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// InputPrometheusAuthenticationMethod - Enter credentials directly, or select a stored secret
type InputPrometheusAuthenticationMethod string

const (
	InputPrometheusAuthenticationMethodManual InputPrometheusAuthenticationMethod = "manual"
	InputPrometheusAuthenticationMethodSecret InputPrometheusAuthenticationMethod = "secret"
)

func (e InputPrometheusAuthenticationMethod) ToPointer() *InputPrometheusAuthenticationMethod {
	return &e
}
func (e *InputPrometheusAuthenticationMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "manual":
		fallthrough
	case "secret":
		*e = InputPrometheusAuthenticationMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputPrometheusAuthenticationMethod: %v", v)
	}
}

// RecordType - DNS Record type to resolve
type RecordType string

const (
	RecordTypeSrv  RecordType = "SRV"
	RecordTypeA    RecordType = "A"
	RecordTypeAaaa RecordType = "AAAA"
)

func (e RecordType) ToPointer() *RecordType {
	return &e
}
func (e *RecordType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "SRV":
		fallthrough
	case "A":
		fallthrough
	case "AAAA":
		*e = RecordType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for RecordType: %v", v)
	}
}

// MetricsProtocol - Protocol to use when collecting metrics
type MetricsProtocol string

const (
	MetricsProtocolHTTP  MetricsProtocol = "http"
	MetricsProtocolHTTPS MetricsProtocol = "https"
)

func (e MetricsProtocol) ToPointer() *MetricsProtocol {
	return &e
}
func (e *MetricsProtocol) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "http":
		fallthrough
	case "https":
		*e = MetricsProtocol(v)
		return nil
	default:
		return fmt.Errorf("invalid value for MetricsProtocol: %v", v)
	}
}

type SearchFilter struct {
	// Search filter attribute name, see: https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_DescribeInstances.html for more information. Attributes can be manually entered if not present in the drop down list
	Name string `json:"Name"`
	// Search Filter Values, if empty only "running" EC2 instances will be returned
	Values []string `json:"Values,omitempty"`
}

func (o *SearchFilter) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *SearchFilter) GetValues() []string {
	if o == nil {
		return nil
	}
	return o.Values
}

// InputPrometheusInputAuthenticationMethod - AWS authentication method. Choose Auto to use IAM roles.
type InputPrometheusInputAuthenticationMethod string

const (
	InputPrometheusInputAuthenticationMethodAuto   InputPrometheusInputAuthenticationMethod = "auto"
	InputPrometheusInputAuthenticationMethodManual InputPrometheusInputAuthenticationMethod = "manual"
	InputPrometheusInputAuthenticationMethodSecret InputPrometheusInputAuthenticationMethod = "secret"
)

func (e InputPrometheusInputAuthenticationMethod) ToPointer() *InputPrometheusInputAuthenticationMethod {
	return &e
}
func (e *InputPrometheusInputAuthenticationMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "auto":
		fallthrough
	case "manual":
		fallthrough
	case "secret":
		*e = InputPrometheusInputAuthenticationMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputPrometheusInputAuthenticationMethod: %v", v)
	}
}

// InputPrometheusSignatureVersion - Signature version to use for signing EC2 requests
type InputPrometheusSignatureVersion string

const (
	InputPrometheusSignatureVersionV2 InputPrometheusSignatureVersion = "v2"
	InputPrometheusSignatureVersionV4 InputPrometheusSignatureVersion = "v4"
)

func (e InputPrometheusSignatureVersion) ToPointer() *InputPrometheusSignatureVersion {
	return &e
}
func (e *InputPrometheusSignatureVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "v2":
		fallthrough
	case "v4":
		*e = InputPrometheusSignatureVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputPrometheusSignatureVersion: %v", v)
	}
}

type InputPrometheus struct {
	// Unique ID for this input
	ID       *string              `json:"id,omitempty"`
	Type     *InputPrometheusType `json:"type,omitempty"`
	Disabled *bool                `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputPrometheusConnections `json:"connections,omitempty"`
	Pq          *InputPrometheusPq           `json:"pq,omitempty"`
	// Other dimensions to include in events
	DimensionList []string `json:"dimensionList,omitempty"`
	// Target discovery mechanism. Use static to manually enter a list of targets.
	DiscoveryType *DiscoveryType `default:"static" json:"discoveryType"`
	// How often in minutes to scrape targets for metrics, 60 must be evenly divisible by the value or save will fail.
	Interval *float64 `default:"15" json:"interval"`
	// Collector runtime Log Level
	LogLevel *InputPrometheusLogLevel `default:"info" json:"logLevel"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// How often workers should check in with the scheduler to keep job subscription alive
	KeepAliveTime *float64 `default:"30" json:"keepAliveTime"`
	// Maximum time the job is allowed to run (e.g., 30, 45s or 15m). Units are seconds, if not specified. Enter 0 for unlimited time.
	JobTimeout *string `default:"0" json:"jobTimeout"`
	// The number of Keep Alive Time periods before an inactive worker will have its job subscription revoked.
	MaxMissedKeepAlives *float64 `default:"3" json:"maxMissedKeepAlives"`
	// Time to keep the job's artifacts on disk after job completion. This also affects how long a job is listed in the Job Inspector.
	TTL *string `default:"4h" json:"ttl"`
	// Fields to add to events from this input
	Metadata []InputPrometheusMetadata `json:"metadata,omitempty"`
	// Enter credentials directly, or select a stored secret
	AuthType    *InputPrometheusAuthenticationMethod `default:"manual" json:"authType"`
	Description *string                              `json:"description,omitempty"`
	// List of Prometheus targets to pull metrics from. Values can be in URL or host[:port] format. For example: http://localhost:9090/metrics, localhost:9090, or localhost. In cases where just host[:port] is specified, the endpoint will resolve to 'http://host[:port]/metrics'.
	TargetList []string `json:"targetList,omitempty"`
	// List of DNS names to resolve
	NameList []string `json:"nameList,omitempty"`
	// DNS Record type to resolve
	RecordType *RecordType `default:"SRV" json:"recordType"`
	// Protocol to use when collecting metrics
	ScrapeProtocol *MetricsProtocol `default:"http" json:"scrapeProtocol"`
	// Path to use when collecting metrics from discovered targets
	ScrapePath *string `default:"/metrics" json:"scrapePath"`
	// Use public IP address for discovered targets. Set to false if the private IP address should be used.
	UsePublicIP *bool `default:"true" json:"usePublicIp"`
	// The port number in the metrics URL for discovered targets.
	ScrapePort *float64 `default:"9090" json:"scrapePort"`
	// EC2 Instance Search Filter
	SearchFilter []SearchFilter `json:"searchFilter,omitempty"`
	// AWS authentication method. Choose Auto to use IAM roles.
	AwsAuthenticationMethod *InputPrometheusInputAuthenticationMethod `default:"auto" json:"awsAuthenticationMethod"`
	AwsSecretKey            *string                                   `json:"awsSecretKey,omitempty"`
	// Region where the EC2 is located
	Region *string `json:"region,omitempty"`
	// EC2 service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to EC2-compatible endpoint.
	Endpoint *string `json:"endpoint,omitempty"`
	// Signature version to use for signing EC2 requests
	SignatureVersion *InputPrometheusSignatureVersion `default:"v4" json:"signatureVersion"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `default:"true" json:"reuseConnections"`
	// Use Assume Role credentials to access EC2
	EnableAssumeRole *bool `default:"false" json:"enableAssumeRole"`
	// Amazon Resource Name (ARN) of the role to assume
	AssumeRoleArn *string `json:"assumeRoleArn,omitempty"`
	// External ID to use when assuming role
	AssumeRoleExternalID *string `json:"assumeRoleExternalId,omitempty"`
	// Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
	DurationSeconds *float64 `default:"3600" json:"durationSeconds"`
	// Username for Prometheus Basic authentication
	Username *string `json:"username,omitempty"`
	// Password for Prometheus Basic authentication
	Password *string `json:"password,omitempty"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string   `json:"credentialsSecret,omitempty"`
	Status            *TFStatus `json:"status,omitempty"`
}

func (i InputPrometheus) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputPrometheus) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputPrometheus) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputPrometheus) GetType() *InputPrometheusType {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputPrometheus) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputPrometheus) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputPrometheus) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputPrometheus) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputPrometheus) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputPrometheus) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputPrometheus) GetConnections() []InputPrometheusConnections {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputPrometheus) GetPq() *InputPrometheusPq {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputPrometheus) GetDimensionList() []string {
	if o == nil {
		return nil
	}
	return o.DimensionList
}

func (o *InputPrometheus) GetDiscoveryType() *DiscoveryType {
	if o == nil {
		return nil
	}
	return o.DiscoveryType
}

func (o *InputPrometheus) GetInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.Interval
}

func (o *InputPrometheus) GetLogLevel() *InputPrometheusLogLevel {
	if o == nil {
		return nil
	}
	return o.LogLevel
}

func (o *InputPrometheus) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *InputPrometheus) GetKeepAliveTime() *float64 {
	if o == nil {
		return nil
	}
	return o.KeepAliveTime
}

func (o *InputPrometheus) GetJobTimeout() *string {
	if o == nil {
		return nil
	}
	return o.JobTimeout
}

func (o *InputPrometheus) GetMaxMissedKeepAlives() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxMissedKeepAlives
}

func (o *InputPrometheus) GetTTL() *string {
	if o == nil {
		return nil
	}
	return o.TTL
}

func (o *InputPrometheus) GetMetadata() []InputPrometheusMetadata {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputPrometheus) GetAuthType() *InputPrometheusAuthenticationMethod {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *InputPrometheus) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputPrometheus) GetTargetList() []string {
	if o == nil {
		return nil
	}
	return o.TargetList
}

func (o *InputPrometheus) GetNameList() []string {
	if o == nil {
		return nil
	}
	return o.NameList
}

func (o *InputPrometheus) GetRecordType() *RecordType {
	if o == nil {
		return nil
	}
	return o.RecordType
}

func (o *InputPrometheus) GetScrapeProtocol() *MetricsProtocol {
	if o == nil {
		return nil
	}
	return o.ScrapeProtocol
}

func (o *InputPrometheus) GetScrapePath() *string {
	if o == nil {
		return nil
	}
	return o.ScrapePath
}

func (o *InputPrometheus) GetUsePublicIP() *bool {
	if o == nil {
		return nil
	}
	return o.UsePublicIP
}

func (o *InputPrometheus) GetScrapePort() *float64 {
	if o == nil {
		return nil
	}
	return o.ScrapePort
}

func (o *InputPrometheus) GetSearchFilter() []SearchFilter {
	if o == nil {
		return nil
	}
	return o.SearchFilter
}

func (o *InputPrometheus) GetAwsAuthenticationMethod() *InputPrometheusInputAuthenticationMethod {
	if o == nil {
		return nil
	}
	return o.AwsAuthenticationMethod
}

func (o *InputPrometheus) GetAwsSecretKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecretKey
}

func (o *InputPrometheus) GetRegion() *string {
	if o == nil {
		return nil
	}
	return o.Region
}

func (o *InputPrometheus) GetEndpoint() *string {
	if o == nil {
		return nil
	}
	return o.Endpoint
}

func (o *InputPrometheus) GetSignatureVersion() *InputPrometheusSignatureVersion {
	if o == nil {
		return nil
	}
	return o.SignatureVersion
}

func (o *InputPrometheus) GetReuseConnections() *bool {
	if o == nil {
		return nil
	}
	return o.ReuseConnections
}

func (o *InputPrometheus) GetEnableAssumeRole() *bool {
	if o == nil {
		return nil
	}
	return o.EnableAssumeRole
}

func (o *InputPrometheus) GetAssumeRoleArn() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleArn
}

func (o *InputPrometheus) GetAssumeRoleExternalID() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleExternalID
}

func (o *InputPrometheus) GetDurationSeconds() *float64 {
	if o == nil {
		return nil
	}
	return o.DurationSeconds
}

func (o *InputPrometheus) GetUsername() *string {
	if o == nil {
		return nil
	}
	return o.Username
}

func (o *InputPrometheus) GetPassword() *string {
	if o == nil {
		return nil
	}
	return o.Password
}

func (o *InputPrometheus) GetCredentialsSecret() *string {
	if o == nil {
		return nil
	}
	return o.CredentialsSecret
}

func (o *InputPrometheus) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputPrometheusRwType string

const (
	InputPrometheusRwTypePrometheusRw InputPrometheusRwType = "prometheus_rw"
)

func (e InputPrometheusRwType) ToPointer() *InputPrometheusRwType {
	return &e
}
func (e *InputPrometheusRwType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "prometheus_rw":
		*e = InputPrometheusRwType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputPrometheusRwType: %v", v)
	}
}

type InputPrometheusRwConnections struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *InputPrometheusRwConnections) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputPrometheusRwConnections) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// InputPrometheusRwMode - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputPrometheusRwMode string

const (
	InputPrometheusRwModeSmart  InputPrometheusRwMode = "smart"
	InputPrometheusRwModeAlways InputPrometheusRwMode = "always"
)

func (e InputPrometheusRwMode) ToPointer() *InputPrometheusRwMode {
	return &e
}
func (e *InputPrometheusRwMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputPrometheusRwMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputPrometheusRwMode: %v", v)
	}
}

// InputPrometheusRwCompression - Codec to use to compress the persisted data
type InputPrometheusRwCompression string

const (
	InputPrometheusRwCompressionNone InputPrometheusRwCompression = "none"
	InputPrometheusRwCompressionGzip InputPrometheusRwCompression = "gzip"
)

func (e InputPrometheusRwCompression) ToPointer() *InputPrometheusRwCompression {
	return &e
}
func (e *InputPrometheusRwCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputPrometheusRwCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputPrometheusRwCompression: %v", v)
	}
}

type InputPrometheusRwPq struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputPrometheusRwMode `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *InputPrometheusRwCompression `default:"none" json:"compress"`
}

func (i InputPrometheusRwPq) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputPrometheusRwPq) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputPrometheusRwPq) GetMode() *InputPrometheusRwMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputPrometheusRwPq) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputPrometheusRwPq) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *InputPrometheusRwPq) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *InputPrometheusRwPq) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *InputPrometheusRwPq) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *InputPrometheusRwPq) GetCompress() *InputPrometheusRwCompression {
	if o == nil {
		return nil
	}
	return o.Compress
}

// InputPrometheusRwMinimumTLSVersion - Minimum TLS version to accept from connections
type InputPrometheusRwMinimumTLSVersion string

const (
	InputPrometheusRwMinimumTLSVersionTlSv1  InputPrometheusRwMinimumTLSVersion = "TLSv1"
	InputPrometheusRwMinimumTLSVersionTlSv11 InputPrometheusRwMinimumTLSVersion = "TLSv1.1"
	InputPrometheusRwMinimumTLSVersionTlSv12 InputPrometheusRwMinimumTLSVersion = "TLSv1.2"
	InputPrometheusRwMinimumTLSVersionTlSv13 InputPrometheusRwMinimumTLSVersion = "TLSv1.3"
)

func (e InputPrometheusRwMinimumTLSVersion) ToPointer() *InputPrometheusRwMinimumTLSVersion {
	return &e
}
func (e *InputPrometheusRwMinimumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputPrometheusRwMinimumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputPrometheusRwMinimumTLSVersion: %v", v)
	}
}

// InputPrometheusRwMaximumTLSVersion - Maximum TLS version to accept from connections
type InputPrometheusRwMaximumTLSVersion string

const (
	InputPrometheusRwMaximumTLSVersionTlSv1  InputPrometheusRwMaximumTLSVersion = "TLSv1"
	InputPrometheusRwMaximumTLSVersionTlSv11 InputPrometheusRwMaximumTLSVersion = "TLSv1.1"
	InputPrometheusRwMaximumTLSVersionTlSv12 InputPrometheusRwMaximumTLSVersion = "TLSv1.2"
	InputPrometheusRwMaximumTLSVersionTlSv13 InputPrometheusRwMaximumTLSVersion = "TLSv1.3"
)

func (e InputPrometheusRwMaximumTLSVersion) ToPointer() *InputPrometheusRwMaximumTLSVersion {
	return &e
}
func (e *InputPrometheusRwMaximumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputPrometheusRwMaximumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputPrometheusRwMaximumTLSVersion: %v", v)
	}
}

type InputPrometheusRwTLSSettingsServerSide struct {
	Disabled *bool `default:"true" json:"disabled"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert        *bool `default:"false" json:"requestCert"`
	RejectUnauthorized any   `json:"rejectUnauthorized,omitempty"`
	CommonNameRegex    any   `json:"commonNameRegex,omitempty"`
	// Minimum TLS version to accept from connections
	MinVersion *InputPrometheusRwMinimumTLSVersion `json:"minVersion,omitempty"`
	// Maximum TLS version to accept from connections
	MaxVersion *InputPrometheusRwMaximumTLSVersion `json:"maxVersion,omitempty"`
}

func (i InputPrometheusRwTLSSettingsServerSide) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputPrometheusRwTLSSettingsServerSide) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputPrometheusRwTLSSettingsServerSide) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputPrometheusRwTLSSettingsServerSide) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *InputPrometheusRwTLSSettingsServerSide) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *InputPrometheusRwTLSSettingsServerSide) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *InputPrometheusRwTLSSettingsServerSide) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *InputPrometheusRwTLSSettingsServerSide) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *InputPrometheusRwTLSSettingsServerSide) GetRequestCert() *bool {
	if o == nil {
		return nil
	}
	return o.RequestCert
}

func (o *InputPrometheusRwTLSSettingsServerSide) GetRejectUnauthorized() any {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *InputPrometheusRwTLSSettingsServerSide) GetCommonNameRegex() any {
	if o == nil {
		return nil
	}
	return o.CommonNameRegex
}

func (o *InputPrometheusRwTLSSettingsServerSide) GetMinVersion() *InputPrometheusRwMinimumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *InputPrometheusRwTLSSettingsServerSide) GetMaxVersion() *InputPrometheusRwMaximumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

// InputPrometheusRwAuthenticationType - Remote Write authentication type
type InputPrometheusRwAuthenticationType string

const (
	InputPrometheusRwAuthenticationTypeNone              InputPrometheusRwAuthenticationType = "none"
	InputPrometheusRwAuthenticationTypeBasic             InputPrometheusRwAuthenticationType = "basic"
	InputPrometheusRwAuthenticationTypeCredentialsSecret InputPrometheusRwAuthenticationType = "credentialsSecret"
	InputPrometheusRwAuthenticationTypeToken             InputPrometheusRwAuthenticationType = "token"
	InputPrometheusRwAuthenticationTypeTextSecret        InputPrometheusRwAuthenticationType = "textSecret"
	InputPrometheusRwAuthenticationTypeOauth             InputPrometheusRwAuthenticationType = "oauth"
)

func (e InputPrometheusRwAuthenticationType) ToPointer() *InputPrometheusRwAuthenticationType {
	return &e
}
func (e *InputPrometheusRwAuthenticationType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "basic":
		fallthrough
	case "credentialsSecret":
		fallthrough
	case "token":
		fallthrough
	case "textSecret":
		fallthrough
	case "oauth":
		*e = InputPrometheusRwAuthenticationType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputPrometheusRwAuthenticationType: %v", v)
	}
}

type InputPrometheusRwMetadata struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputPrometheusRwMetadata) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputPrometheusRwMetadata) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputPrometheusRwOauthParams struct {
	// OAuth parameter name
	Name string `json:"name"`
	// OAuth parameter value
	Value string `json:"value"`
}

func (o *InputPrometheusRwOauthParams) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputPrometheusRwOauthParams) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputPrometheusRwOauthHeaders struct {
	// OAuth header name
	Name string `json:"name"`
	// OAuth header value
	Value string `json:"value"`
}

func (o *InputPrometheusRwOauthHeaders) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputPrometheusRwOauthHeaders) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputPrometheusRw struct {
	// Unique ID for this input
	ID       *string                `json:"id,omitempty"`
	Type     *InputPrometheusRwType `json:"type,omitempty"`
	Disabled *bool                  `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputPrometheusRwConnections `json:"connections,omitempty"`
	Pq          *InputPrometheusRwPq           `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port float64                                 `json:"port"`
	TLS  *InputPrometheusRwTLSSettingsServerSide `json:"tls,omitempty"`
	// Maximum number of active requests per Worker Process. Use 0 for unlimited.
	MaxActiveReq *float64 `default:"256" json:"maxActiveReq"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket *int64 `default:"0" json:"maxRequestsPerSocket"`
	// Enable when clients are connecting through a proxy that supports the x-forwarded-for header to keep the client's original IP address on the event instead of the proxy's IP address
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Add request headers to events, in the __headers field
	CaptureHeaders *bool `default:"false" json:"captureHeaders"`
	// How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
	ActivityLogSampleRate *float64 `default:"100" json:"activityLogSampleRate"`
	// How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
	RequestTimeout *float64 `default:"0" json:"requestTimeout"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `default:"0" json:"socketTimeout"`
	// After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 sec.; maximum 600 sec. (10 min.).
	KeepAliveTimeout *float64 `default:"5" json:"keepAliveTimeout"`
	// Enable to expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
	EnableHealthCheck *bool `default:"false" json:"enableHealthCheck"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist
	IPAllowlistRegex *string `default:"/.*/" json:"ipAllowlistRegex"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `default:"/^\\$/" json:"ipDenylistRegex"`
	// Absolute path on which to listen for Prometheus requests. Defaults to /write, which will expand as: http://<yourupstreamURL>:<yourport>/write.
	PrometheusAPI *string `default:"/write" json:"prometheusAPI"`
	// Remote Write authentication type
	AuthType *InputPrometheusRwAuthenticationType `default:"none" json:"authType"`
	// Fields to add to events from this input
	Metadata    []InputPrometheusRwMetadata `json:"metadata,omitempty"`
	Description *string                     `json:"description,omitempty"`
	Username    *string                     `json:"username,omitempty"`
	Password    *string                     `json:"password,omitempty"`
	// Bearer token to include in the authorization header
	Token *string `json:"token,omitempty"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// URL for OAuth
	LoginURL *string `json:"loginUrl,omitempty"`
	// Secret parameter name to pass in request body
	SecretParamName *string `json:"secretParamName,omitempty"`
	// Secret parameter value to pass in request body
	Secret *string `json:"secret,omitempty"`
	// Name of the auth token attribute in the OAuth response. Can be top-level (e.g., 'token'); or nested, using a period (e.g., 'data.token').
	TokenAttributeName *string `json:"tokenAttributeName,omitempty"`
	// JavaScript expression to compute the Authorization header value to pass in requests. The value `${token}` is used to reference the token obtained from authentication, e.g.: `Bearer ${token}`.
	AuthHeaderExpr *string `default:"Bearer \\${token}" json:"authHeaderExpr"`
	// How often the OAuth token should be refreshed.
	TokenTimeoutSecs *float64 `default:"3600" json:"tokenTimeoutSecs"`
	// Additional parameters to send in the OAuth login request. @{product} will combine the secret with these parameters, and will send the URL-encoded result in a POST request to the endpoint specified in the 'Login URL'. We'll automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthParams []InputPrometheusRwOauthParams `json:"oauthParams,omitempty"`
	// Additional headers to send in the OAuth login request. @{product} will automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthHeaders []InputPrometheusRwOauthHeaders `json:"oauthHeaders,omitempty"`
	Status       *TFStatus                       `json:"status,omitempty"`
}

func (i InputPrometheusRw) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputPrometheusRw) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputPrometheusRw) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputPrometheusRw) GetType() *InputPrometheusRwType {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputPrometheusRw) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputPrometheusRw) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputPrometheusRw) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputPrometheusRw) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputPrometheusRw) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputPrometheusRw) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputPrometheusRw) GetConnections() []InputPrometheusRwConnections {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputPrometheusRw) GetPq() *InputPrometheusRwPq {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputPrometheusRw) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputPrometheusRw) GetPort() float64 {
	if o == nil {
		return 0.0
	}
	return o.Port
}

func (o *InputPrometheusRw) GetTLS() *InputPrometheusRwTLSSettingsServerSide {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputPrometheusRw) GetMaxActiveReq() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxActiveReq
}

func (o *InputPrometheusRw) GetMaxRequestsPerSocket() *int64 {
	if o == nil {
		return nil
	}
	return o.MaxRequestsPerSocket
}

func (o *InputPrometheusRw) GetEnableProxyHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableProxyHeader
}

func (o *InputPrometheusRw) GetCaptureHeaders() *bool {
	if o == nil {
		return nil
	}
	return o.CaptureHeaders
}

func (o *InputPrometheusRw) GetActivityLogSampleRate() *float64 {
	if o == nil {
		return nil
	}
	return o.ActivityLogSampleRate
}

func (o *InputPrometheusRw) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *InputPrometheusRw) GetSocketTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketTimeout
}

func (o *InputPrometheusRw) GetKeepAliveTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.KeepAliveTimeout
}

func (o *InputPrometheusRw) GetEnableHealthCheck() *bool {
	if o == nil {
		return nil
	}
	return o.EnableHealthCheck
}

func (o *InputPrometheusRw) GetIPAllowlistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPAllowlistRegex
}

func (o *InputPrometheusRw) GetIPDenylistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPDenylistRegex
}

func (o *InputPrometheusRw) GetPrometheusAPI() *string {
	if o == nil {
		return nil
	}
	return o.PrometheusAPI
}

func (o *InputPrometheusRw) GetAuthType() *InputPrometheusRwAuthenticationType {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *InputPrometheusRw) GetMetadata() []InputPrometheusRwMetadata {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputPrometheusRw) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputPrometheusRw) GetUsername() *string {
	if o == nil {
		return nil
	}
	return o.Username
}

func (o *InputPrometheusRw) GetPassword() *string {
	if o == nil {
		return nil
	}
	return o.Password
}

func (o *InputPrometheusRw) GetToken() *string {
	if o == nil {
		return nil
	}
	return o.Token
}

func (o *InputPrometheusRw) GetCredentialsSecret() *string {
	if o == nil {
		return nil
	}
	return o.CredentialsSecret
}

func (o *InputPrometheusRw) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *InputPrometheusRw) GetLoginURL() *string {
	if o == nil {
		return nil
	}
	return o.LoginURL
}

func (o *InputPrometheusRw) GetSecretParamName() *string {
	if o == nil {
		return nil
	}
	return o.SecretParamName
}

func (o *InputPrometheusRw) GetSecret() *string {
	if o == nil {
		return nil
	}
	return o.Secret
}

func (o *InputPrometheusRw) GetTokenAttributeName() *string {
	if o == nil {
		return nil
	}
	return o.TokenAttributeName
}

func (o *InputPrometheusRw) GetAuthHeaderExpr() *string {
	if o == nil {
		return nil
	}
	return o.AuthHeaderExpr
}

func (o *InputPrometheusRw) GetTokenTimeoutSecs() *float64 {
	if o == nil {
		return nil
	}
	return o.TokenTimeoutSecs
}

func (o *InputPrometheusRw) GetOauthParams() []InputPrometheusRwOauthParams {
	if o == nil {
		return nil
	}
	return o.OauthParams
}

func (o *InputPrometheusRw) GetOauthHeaders() []InputPrometheusRwOauthHeaders {
	if o == nil {
		return nil
	}
	return o.OauthHeaders
}

func (o *InputPrometheusRw) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputLokiType string

const (
	InputLokiTypeLoki InputLokiType = "loki"
)

func (e InputLokiType) ToPointer() *InputLokiType {
	return &e
}
func (e *InputLokiType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "loki":
		*e = InputLokiType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputLokiType: %v", v)
	}
}

type InputLokiConnections struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *InputLokiConnections) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputLokiConnections) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// InputLokiMode - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputLokiMode string

const (
	InputLokiModeSmart  InputLokiMode = "smart"
	InputLokiModeAlways InputLokiMode = "always"
)

func (e InputLokiMode) ToPointer() *InputLokiMode {
	return &e
}
func (e *InputLokiMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputLokiMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputLokiMode: %v", v)
	}
}

// InputLokiCompression - Codec to use to compress the persisted data
type InputLokiCompression string

const (
	InputLokiCompressionNone InputLokiCompression = "none"
	InputLokiCompressionGzip InputLokiCompression = "gzip"
)

func (e InputLokiCompression) ToPointer() *InputLokiCompression {
	return &e
}
func (e *InputLokiCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputLokiCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputLokiCompression: %v", v)
	}
}

type InputLokiPq struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputLokiMode `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *InputLokiCompression `default:"none" json:"compress"`
}

func (i InputLokiPq) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputLokiPq) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputLokiPq) GetMode() *InputLokiMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputLokiPq) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputLokiPq) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *InputLokiPq) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *InputLokiPq) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *InputLokiPq) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *InputLokiPq) GetCompress() *InputLokiCompression {
	if o == nil {
		return nil
	}
	return o.Compress
}

// InputLokiMinimumTLSVersion - Minimum TLS version to accept from connections
type InputLokiMinimumTLSVersion string

const (
	InputLokiMinimumTLSVersionTlSv1  InputLokiMinimumTLSVersion = "TLSv1"
	InputLokiMinimumTLSVersionTlSv11 InputLokiMinimumTLSVersion = "TLSv1.1"
	InputLokiMinimumTLSVersionTlSv12 InputLokiMinimumTLSVersion = "TLSv1.2"
	InputLokiMinimumTLSVersionTlSv13 InputLokiMinimumTLSVersion = "TLSv1.3"
)

func (e InputLokiMinimumTLSVersion) ToPointer() *InputLokiMinimumTLSVersion {
	return &e
}
func (e *InputLokiMinimumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputLokiMinimumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputLokiMinimumTLSVersion: %v", v)
	}
}

// InputLokiMaximumTLSVersion - Maximum TLS version to accept from connections
type InputLokiMaximumTLSVersion string

const (
	InputLokiMaximumTLSVersionTlSv1  InputLokiMaximumTLSVersion = "TLSv1"
	InputLokiMaximumTLSVersionTlSv11 InputLokiMaximumTLSVersion = "TLSv1.1"
	InputLokiMaximumTLSVersionTlSv12 InputLokiMaximumTLSVersion = "TLSv1.2"
	InputLokiMaximumTLSVersionTlSv13 InputLokiMaximumTLSVersion = "TLSv1.3"
)

func (e InputLokiMaximumTLSVersion) ToPointer() *InputLokiMaximumTLSVersion {
	return &e
}
func (e *InputLokiMaximumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputLokiMaximumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputLokiMaximumTLSVersion: %v", v)
	}
}

type InputLokiTLSSettingsServerSide struct {
	Disabled *bool `default:"true" json:"disabled"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert        *bool `default:"false" json:"requestCert"`
	RejectUnauthorized any   `json:"rejectUnauthorized,omitempty"`
	CommonNameRegex    any   `json:"commonNameRegex,omitempty"`
	// Minimum TLS version to accept from connections
	MinVersion *InputLokiMinimumTLSVersion `json:"minVersion,omitempty"`
	// Maximum TLS version to accept from connections
	MaxVersion *InputLokiMaximumTLSVersion `json:"maxVersion,omitempty"`
}

func (i InputLokiTLSSettingsServerSide) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputLokiTLSSettingsServerSide) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputLokiTLSSettingsServerSide) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputLokiTLSSettingsServerSide) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *InputLokiTLSSettingsServerSide) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *InputLokiTLSSettingsServerSide) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *InputLokiTLSSettingsServerSide) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *InputLokiTLSSettingsServerSide) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *InputLokiTLSSettingsServerSide) GetRequestCert() *bool {
	if o == nil {
		return nil
	}
	return o.RequestCert
}

func (o *InputLokiTLSSettingsServerSide) GetRejectUnauthorized() any {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *InputLokiTLSSettingsServerSide) GetCommonNameRegex() any {
	if o == nil {
		return nil
	}
	return o.CommonNameRegex
}

func (o *InputLokiTLSSettingsServerSide) GetMinVersion() *InputLokiMinimumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *InputLokiTLSSettingsServerSide) GetMaxVersion() *InputLokiMaximumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

// InputLokiAuthenticationType - Loki logs authentication type
type InputLokiAuthenticationType string

const (
	InputLokiAuthenticationTypeNone              InputLokiAuthenticationType = "none"
	InputLokiAuthenticationTypeBasic             InputLokiAuthenticationType = "basic"
	InputLokiAuthenticationTypeCredentialsSecret InputLokiAuthenticationType = "credentialsSecret"
	InputLokiAuthenticationTypeToken             InputLokiAuthenticationType = "token"
	InputLokiAuthenticationTypeTextSecret        InputLokiAuthenticationType = "textSecret"
	InputLokiAuthenticationTypeOauth             InputLokiAuthenticationType = "oauth"
)

func (e InputLokiAuthenticationType) ToPointer() *InputLokiAuthenticationType {
	return &e
}
func (e *InputLokiAuthenticationType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "basic":
		fallthrough
	case "credentialsSecret":
		fallthrough
	case "token":
		fallthrough
	case "textSecret":
		fallthrough
	case "oauth":
		*e = InputLokiAuthenticationType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputLokiAuthenticationType: %v", v)
	}
}

type InputLokiMetadata struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputLokiMetadata) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputLokiMetadata) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputLokiOauthParams struct {
	// OAuth parameter name
	Name string `json:"name"`
	// OAuth parameter value
	Value string `json:"value"`
}

func (o *InputLokiOauthParams) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputLokiOauthParams) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputLokiOauthHeaders struct {
	// OAuth header name
	Name string `json:"name"`
	// OAuth header value
	Value string `json:"value"`
}

func (o *InputLokiOauthHeaders) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputLokiOauthHeaders) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputLoki struct {
	// Unique ID for this input
	ID       *string        `json:"id,omitempty"`
	Type     *InputLokiType `json:"type,omitempty"`
	Disabled *bool          `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputLokiConnections `json:"connections,omitempty"`
	Pq          *InputLokiPq           `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port float64                         `json:"port"`
	TLS  *InputLokiTLSSettingsServerSide `json:"tls,omitempty"`
	// Maximum number of active requests per Worker Process. Use 0 for unlimited.
	MaxActiveReq *float64 `default:"256" json:"maxActiveReq"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket *int64 `default:"0" json:"maxRequestsPerSocket"`
	// Enable when clients are connecting through a proxy that supports the x-forwarded-for header to keep the client's original IP address on the event instead of the proxy's IP address
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Add request headers to events, in the __headers field
	CaptureHeaders *bool `default:"false" json:"captureHeaders"`
	// How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
	ActivityLogSampleRate *float64 `default:"100" json:"activityLogSampleRate"`
	// How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
	RequestTimeout *float64 `default:"0" json:"requestTimeout"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `default:"0" json:"socketTimeout"`
	// After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 sec.; maximum 600 sec. (10 min.).
	KeepAliveTimeout *float64 `default:"5" json:"keepAliveTimeout"`
	// Enable to expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
	EnableHealthCheck *bool `default:"false" json:"enableHealthCheck"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist
	IPAllowlistRegex *string `default:"/.*/" json:"ipAllowlistRegex"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `default:"/^\\$/" json:"ipDenylistRegex"`
	// Absolute path on which to listen for Loki logs requests. Defaults to /loki/api/v1/push, which will (in this example) expand as: 'http://<yourupstreamURL>:<yourport>/loki/api/v1/push'.
	LokiAPI *string `default:"/loki/api/v1/push" json:"lokiAPI"`
	// Loki logs authentication type
	AuthType *InputLokiAuthenticationType `default:"none" json:"authType"`
	// Fields to add to events from this input
	Metadata    []InputLokiMetadata `json:"metadata,omitempty"`
	Description *string             `json:"description,omitempty"`
	Username    *string             `json:"username,omitempty"`
	Password    *string             `json:"password,omitempty"`
	// Bearer token to include in the authorization header
	Token *string `json:"token,omitempty"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// URL for OAuth
	LoginURL *string `json:"loginUrl,omitempty"`
	// Secret parameter name to pass in request body
	SecretParamName *string `json:"secretParamName,omitempty"`
	// Secret parameter value to pass in request body
	Secret *string `json:"secret,omitempty"`
	// Name of the auth token attribute in the OAuth response. Can be top-level (e.g., 'token'); or nested, using a period (e.g., 'data.token').
	TokenAttributeName *string `json:"tokenAttributeName,omitempty"`
	// JavaScript expression to compute the Authorization header value to pass in requests. The value `${token}` is used to reference the token obtained from authentication, e.g.: `Bearer ${token}`.
	AuthHeaderExpr *string `default:"Bearer \\${token}" json:"authHeaderExpr"`
	// How often the OAuth token should be refreshed.
	TokenTimeoutSecs *float64 `default:"3600" json:"tokenTimeoutSecs"`
	// Additional parameters to send in the OAuth login request. @{product} will combine the secret with these parameters, and will send the URL-encoded result in a POST request to the endpoint specified in the 'Login URL'. We'll automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthParams []InputLokiOauthParams `json:"oauthParams,omitempty"`
	// Additional headers to send in the OAuth login request. @{product} will automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthHeaders []InputLokiOauthHeaders `json:"oauthHeaders,omitempty"`
	Status       *TFStatus               `json:"status,omitempty"`
}

func (i InputLoki) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputLoki) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputLoki) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputLoki) GetType() *InputLokiType {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputLoki) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputLoki) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputLoki) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputLoki) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputLoki) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputLoki) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputLoki) GetConnections() []InputLokiConnections {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputLoki) GetPq() *InputLokiPq {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputLoki) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputLoki) GetPort() float64 {
	if o == nil {
		return 0.0
	}
	return o.Port
}

func (o *InputLoki) GetTLS() *InputLokiTLSSettingsServerSide {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputLoki) GetMaxActiveReq() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxActiveReq
}

func (o *InputLoki) GetMaxRequestsPerSocket() *int64 {
	if o == nil {
		return nil
	}
	return o.MaxRequestsPerSocket
}

func (o *InputLoki) GetEnableProxyHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableProxyHeader
}

func (o *InputLoki) GetCaptureHeaders() *bool {
	if o == nil {
		return nil
	}
	return o.CaptureHeaders
}

func (o *InputLoki) GetActivityLogSampleRate() *float64 {
	if o == nil {
		return nil
	}
	return o.ActivityLogSampleRate
}

func (o *InputLoki) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *InputLoki) GetSocketTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketTimeout
}

func (o *InputLoki) GetKeepAliveTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.KeepAliveTimeout
}

func (o *InputLoki) GetEnableHealthCheck() *bool {
	if o == nil {
		return nil
	}
	return o.EnableHealthCheck
}

func (o *InputLoki) GetIPAllowlistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPAllowlistRegex
}

func (o *InputLoki) GetIPDenylistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPDenylistRegex
}

func (o *InputLoki) GetLokiAPI() *string {
	if o == nil {
		return nil
	}
	return o.LokiAPI
}

func (o *InputLoki) GetAuthType() *InputLokiAuthenticationType {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *InputLoki) GetMetadata() []InputLokiMetadata {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputLoki) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputLoki) GetUsername() *string {
	if o == nil {
		return nil
	}
	return o.Username
}

func (o *InputLoki) GetPassword() *string {
	if o == nil {
		return nil
	}
	return o.Password
}

func (o *InputLoki) GetToken() *string {
	if o == nil {
		return nil
	}
	return o.Token
}

func (o *InputLoki) GetCredentialsSecret() *string {
	if o == nil {
		return nil
	}
	return o.CredentialsSecret
}

func (o *InputLoki) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *InputLoki) GetLoginURL() *string {
	if o == nil {
		return nil
	}
	return o.LoginURL
}

func (o *InputLoki) GetSecretParamName() *string {
	if o == nil {
		return nil
	}
	return o.SecretParamName
}

func (o *InputLoki) GetSecret() *string {
	if o == nil {
		return nil
	}
	return o.Secret
}

func (o *InputLoki) GetTokenAttributeName() *string {
	if o == nil {
		return nil
	}
	return o.TokenAttributeName
}

func (o *InputLoki) GetAuthHeaderExpr() *string {
	if o == nil {
		return nil
	}
	return o.AuthHeaderExpr
}

func (o *InputLoki) GetTokenTimeoutSecs() *float64 {
	if o == nil {
		return nil
	}
	return o.TokenTimeoutSecs
}

func (o *InputLoki) GetOauthParams() []InputLokiOauthParams {
	if o == nil {
		return nil
	}
	return o.OauthParams
}

func (o *InputLoki) GetOauthHeaders() []InputLokiOauthHeaders {
	if o == nil {
		return nil
	}
	return o.OauthHeaders
}

func (o *InputLoki) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputInputGrafanaType string

const (
	InputInputGrafanaTypeGrafana InputInputGrafanaType = "grafana"
)

func (e InputInputGrafanaType) ToPointer() *InputInputGrafanaType {
	return &e
}
func (e *InputInputGrafanaType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "grafana":
		*e = InputInputGrafanaType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputInputGrafanaType: %v", v)
	}
}

type InputInputGrafanaConnections struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *InputInputGrafanaConnections) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputInputGrafanaConnections) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// InputInputGrafanaMode - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputInputGrafanaMode string

const (
	InputInputGrafanaModeSmart  InputInputGrafanaMode = "smart"
	InputInputGrafanaModeAlways InputInputGrafanaMode = "always"
)

func (e InputInputGrafanaMode) ToPointer() *InputInputGrafanaMode {
	return &e
}
func (e *InputInputGrafanaMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputInputGrafanaMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputInputGrafanaMode: %v", v)
	}
}

// InputInputGrafanaCompression - Codec to use to compress the persisted data
type InputInputGrafanaCompression string

const (
	InputInputGrafanaCompressionNone InputInputGrafanaCompression = "none"
	InputInputGrafanaCompressionGzip InputInputGrafanaCompression = "gzip"
)

func (e InputInputGrafanaCompression) ToPointer() *InputInputGrafanaCompression {
	return &e
}
func (e *InputInputGrafanaCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputInputGrafanaCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputInputGrafanaCompression: %v", v)
	}
}

type InputInputGrafanaPq struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputInputGrafanaMode `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *InputInputGrafanaCompression `default:"none" json:"compress"`
}

func (i InputInputGrafanaPq) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputInputGrafanaPq) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputInputGrafanaPq) GetMode() *InputInputGrafanaMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputInputGrafanaPq) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputInputGrafanaPq) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *InputInputGrafanaPq) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *InputInputGrafanaPq) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *InputInputGrafanaPq) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *InputInputGrafanaPq) GetCompress() *InputInputGrafanaCompression {
	if o == nil {
		return nil
	}
	return o.Compress
}

// InputInputGrafanaMinimumTLSVersion - Minimum TLS version to accept from connections
type InputInputGrafanaMinimumTLSVersion string

const (
	InputInputGrafanaMinimumTLSVersionTlSv1  InputInputGrafanaMinimumTLSVersion = "TLSv1"
	InputInputGrafanaMinimumTLSVersionTlSv11 InputInputGrafanaMinimumTLSVersion = "TLSv1.1"
	InputInputGrafanaMinimumTLSVersionTlSv12 InputInputGrafanaMinimumTLSVersion = "TLSv1.2"
	InputInputGrafanaMinimumTLSVersionTlSv13 InputInputGrafanaMinimumTLSVersion = "TLSv1.3"
)

func (e InputInputGrafanaMinimumTLSVersion) ToPointer() *InputInputGrafanaMinimumTLSVersion {
	return &e
}
func (e *InputInputGrafanaMinimumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputInputGrafanaMinimumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputInputGrafanaMinimumTLSVersion: %v", v)
	}
}

// InputInputGrafanaMaximumTLSVersion - Maximum TLS version to accept from connections
type InputInputGrafanaMaximumTLSVersion string

const (
	InputInputGrafanaMaximumTLSVersionTlSv1  InputInputGrafanaMaximumTLSVersion = "TLSv1"
	InputInputGrafanaMaximumTLSVersionTlSv11 InputInputGrafanaMaximumTLSVersion = "TLSv1.1"
	InputInputGrafanaMaximumTLSVersionTlSv12 InputInputGrafanaMaximumTLSVersion = "TLSv1.2"
	InputInputGrafanaMaximumTLSVersionTlSv13 InputInputGrafanaMaximumTLSVersion = "TLSv1.3"
)

func (e InputInputGrafanaMaximumTLSVersion) ToPointer() *InputInputGrafanaMaximumTLSVersion {
	return &e
}
func (e *InputInputGrafanaMaximumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputInputGrafanaMaximumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputInputGrafanaMaximumTLSVersion: %v", v)
	}
}

type InputInputGrafanaTLSSettingsServerSide struct {
	Disabled *bool `default:"true" json:"disabled"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert        *bool `default:"false" json:"requestCert"`
	RejectUnauthorized any   `json:"rejectUnauthorized,omitempty"`
	CommonNameRegex    any   `json:"commonNameRegex,omitempty"`
	// Minimum TLS version to accept from connections
	MinVersion *InputInputGrafanaMinimumTLSVersion `json:"minVersion,omitempty"`
	// Maximum TLS version to accept from connections
	MaxVersion *InputInputGrafanaMaximumTLSVersion `json:"maxVersion,omitempty"`
}

func (i InputInputGrafanaTLSSettingsServerSide) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputInputGrafanaTLSSettingsServerSide) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputInputGrafanaTLSSettingsServerSide) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputInputGrafanaTLSSettingsServerSide) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *InputInputGrafanaTLSSettingsServerSide) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *InputInputGrafanaTLSSettingsServerSide) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *InputInputGrafanaTLSSettingsServerSide) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *InputInputGrafanaTLSSettingsServerSide) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *InputInputGrafanaTLSSettingsServerSide) GetRequestCert() *bool {
	if o == nil {
		return nil
	}
	return o.RequestCert
}

func (o *InputInputGrafanaTLSSettingsServerSide) GetRejectUnauthorized() any {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *InputInputGrafanaTLSSettingsServerSide) GetCommonNameRegex() any {
	if o == nil {
		return nil
	}
	return o.CommonNameRegex
}

func (o *InputInputGrafanaTLSSettingsServerSide) GetMinVersion() *InputInputGrafanaMinimumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *InputInputGrafanaTLSSettingsServerSide) GetMaxVersion() *InputInputGrafanaMaximumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

// InputInputGrafana2AuthenticationType - Remote Write authentication type
type InputInputGrafana2AuthenticationType string

const (
	InputInputGrafana2AuthenticationTypeNone              InputInputGrafana2AuthenticationType = "none"
	InputInputGrafana2AuthenticationTypeBasic             InputInputGrafana2AuthenticationType = "basic"
	InputInputGrafana2AuthenticationTypeCredentialsSecret InputInputGrafana2AuthenticationType = "credentialsSecret"
	InputInputGrafana2AuthenticationTypeToken             InputInputGrafana2AuthenticationType = "token"
	InputInputGrafana2AuthenticationTypeTextSecret        InputInputGrafana2AuthenticationType = "textSecret"
	InputInputGrafana2AuthenticationTypeOauth             InputInputGrafana2AuthenticationType = "oauth"
)

func (e InputInputGrafana2AuthenticationType) ToPointer() *InputInputGrafana2AuthenticationType {
	return &e
}
func (e *InputInputGrafana2AuthenticationType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "basic":
		fallthrough
	case "credentialsSecret":
		fallthrough
	case "token":
		fallthrough
	case "textSecret":
		fallthrough
	case "oauth":
		*e = InputInputGrafana2AuthenticationType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputInputGrafana2AuthenticationType: %v", v)
	}
}

type InputInputGrafana2OauthParams struct {
	// OAuth parameter name
	Name string `json:"name"`
	// OAuth parameter value
	Value string `json:"value"`
}

func (o *InputInputGrafana2OauthParams) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputInputGrafana2OauthParams) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputInputGrafana2OauthHeaders struct {
	// OAuth header name
	Name string `json:"name"`
	// OAuth header value
	Value string `json:"value"`
}

func (o *InputInputGrafana2OauthHeaders) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputInputGrafana2OauthHeaders) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputGrafanaPrometheusAuth struct {
	// Remote Write authentication type
	AuthType *InputInputGrafana2AuthenticationType `default:"none" json:"authType"`
	Username *string                               `json:"username,omitempty"`
	Password *string                               `json:"password,omitempty"`
	// Bearer token to include in the authorization header
	Token *string `json:"token,omitempty"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// URL for OAuth
	LoginURL *string `json:"loginUrl,omitempty"`
	// Secret parameter name to pass in request body
	SecretParamName *string `json:"secretParamName,omitempty"`
	// Secret parameter value to pass in request body
	Secret *string `json:"secret,omitempty"`
	// Name of the auth token attribute in the OAuth response. Can be top-level (e.g., 'token'); or nested, using a period (e.g., 'data.token').
	TokenAttributeName *string `json:"tokenAttributeName,omitempty"`
	// JavaScript expression to compute the Authorization header value to pass in requests. The value `${token}` is used to reference the token obtained from authentication, e.g.: `Bearer ${token}`.
	AuthHeaderExpr *string `default:"Bearer \\${token}" json:"authHeaderExpr"`
	// How often the OAuth token should be refreshed.
	TokenTimeoutSecs *float64 `default:"3600" json:"tokenTimeoutSecs"`
	// Additional parameters to send in the OAuth login request. @{product} will combine the secret with these parameters, and will send the URL-encoded result in a POST request to the endpoint specified in the 'Login URL'. We'll automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthParams []InputInputGrafana2OauthParams `json:"oauthParams,omitempty"`
	// Additional headers to send in the OAuth login request. @{product} will automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthHeaders []InputInputGrafana2OauthHeaders `json:"oauthHeaders,omitempty"`
}

func (i InputGrafanaPrometheusAuth) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputGrafanaPrometheusAuth) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputGrafanaPrometheusAuth) GetAuthType() *InputInputGrafana2AuthenticationType {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *InputGrafanaPrometheusAuth) GetUsername() *string {
	if o == nil {
		return nil
	}
	return o.Username
}

func (o *InputGrafanaPrometheusAuth) GetPassword() *string {
	if o == nil {
		return nil
	}
	return o.Password
}

func (o *InputGrafanaPrometheusAuth) GetToken() *string {
	if o == nil {
		return nil
	}
	return o.Token
}

func (o *InputGrafanaPrometheusAuth) GetCredentialsSecret() *string {
	if o == nil {
		return nil
	}
	return o.CredentialsSecret
}

func (o *InputGrafanaPrometheusAuth) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *InputGrafanaPrometheusAuth) GetLoginURL() *string {
	if o == nil {
		return nil
	}
	return o.LoginURL
}

func (o *InputGrafanaPrometheusAuth) GetSecretParamName() *string {
	if o == nil {
		return nil
	}
	return o.SecretParamName
}

func (o *InputGrafanaPrometheusAuth) GetSecret() *string {
	if o == nil {
		return nil
	}
	return o.Secret
}

func (o *InputGrafanaPrometheusAuth) GetTokenAttributeName() *string {
	if o == nil {
		return nil
	}
	return o.TokenAttributeName
}

func (o *InputGrafanaPrometheusAuth) GetAuthHeaderExpr() *string {
	if o == nil {
		return nil
	}
	return o.AuthHeaderExpr
}

func (o *InputGrafanaPrometheusAuth) GetTokenTimeoutSecs() *float64 {
	if o == nil {
		return nil
	}
	return o.TokenTimeoutSecs
}

func (o *InputGrafanaPrometheusAuth) GetOauthParams() []InputInputGrafana2OauthParams {
	if o == nil {
		return nil
	}
	return o.OauthParams
}

func (o *InputGrafanaPrometheusAuth) GetOauthHeaders() []InputInputGrafana2OauthHeaders {
	if o == nil {
		return nil
	}
	return o.OauthHeaders
}

// InputInputGrafana2LokiAuthAuthenticationType - Loki logs authentication type
type InputInputGrafana2LokiAuthAuthenticationType string

const (
	InputInputGrafana2LokiAuthAuthenticationTypeNone              InputInputGrafana2LokiAuthAuthenticationType = "none"
	InputInputGrafana2LokiAuthAuthenticationTypeBasic             InputInputGrafana2LokiAuthAuthenticationType = "basic"
	InputInputGrafana2LokiAuthAuthenticationTypeCredentialsSecret InputInputGrafana2LokiAuthAuthenticationType = "credentialsSecret"
	InputInputGrafana2LokiAuthAuthenticationTypeToken             InputInputGrafana2LokiAuthAuthenticationType = "token"
	InputInputGrafana2LokiAuthAuthenticationTypeTextSecret        InputInputGrafana2LokiAuthAuthenticationType = "textSecret"
	InputInputGrafana2LokiAuthAuthenticationTypeOauth             InputInputGrafana2LokiAuthAuthenticationType = "oauth"
)

func (e InputInputGrafana2LokiAuthAuthenticationType) ToPointer() *InputInputGrafana2LokiAuthAuthenticationType {
	return &e
}
func (e *InputInputGrafana2LokiAuthAuthenticationType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "basic":
		fallthrough
	case "credentialsSecret":
		fallthrough
	case "token":
		fallthrough
	case "textSecret":
		fallthrough
	case "oauth":
		*e = InputInputGrafana2LokiAuthAuthenticationType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputInputGrafana2LokiAuthAuthenticationType: %v", v)
	}
}

type InputInputGrafana2LokiAuthOauthParams struct {
	// OAuth parameter name
	Name string `json:"name"`
	// OAuth parameter value
	Value string `json:"value"`
}

func (o *InputInputGrafana2LokiAuthOauthParams) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputInputGrafana2LokiAuthOauthParams) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputInputGrafana2LokiAuthOauthHeaders struct {
	// OAuth header name
	Name string `json:"name"`
	// OAuth header value
	Value string `json:"value"`
}

func (o *InputInputGrafana2LokiAuthOauthHeaders) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputInputGrafana2LokiAuthOauthHeaders) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputGrafanaLokiAuth struct {
	// Loki logs authentication type
	AuthType *InputInputGrafana2LokiAuthAuthenticationType `default:"none" json:"authType"`
	Username *string                                       `json:"username,omitempty"`
	Password *string                                       `json:"password,omitempty"`
	// Bearer token to include in the authorization header
	Token *string `json:"token,omitempty"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// URL for OAuth
	LoginURL *string `json:"loginUrl,omitempty"`
	// Secret parameter name to pass in request body
	SecretParamName *string `json:"secretParamName,omitempty"`
	// Secret parameter value to pass in request body
	Secret *string `json:"secret,omitempty"`
	// Name of the auth token attribute in the OAuth response. Can be top-level (e.g., 'token'); or nested, using a period (e.g., 'data.token').
	TokenAttributeName *string `json:"tokenAttributeName,omitempty"`
	// JavaScript expression to compute the Authorization header value to pass in requests. The value `${token}` is used to reference the token obtained from authentication, e.g.: `Bearer ${token}`.
	AuthHeaderExpr *string `default:"Bearer \\${token}" json:"authHeaderExpr"`
	// How often the OAuth token should be refreshed.
	TokenTimeoutSecs *float64 `default:"3600" json:"tokenTimeoutSecs"`
	// Additional parameters to send in the OAuth login request. @{product} will combine the secret with these parameters, and will send the URL-encoded result in a POST request to the endpoint specified in the 'Login URL'. We'll automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthParams []InputInputGrafana2LokiAuthOauthParams `json:"oauthParams,omitempty"`
	// Additional headers to send in the OAuth login request. @{product} will automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthHeaders []InputInputGrafana2LokiAuthOauthHeaders `json:"oauthHeaders,omitempty"`
}

func (i InputGrafanaLokiAuth) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputGrafanaLokiAuth) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputGrafanaLokiAuth) GetAuthType() *InputInputGrafana2LokiAuthAuthenticationType {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *InputGrafanaLokiAuth) GetUsername() *string {
	if o == nil {
		return nil
	}
	return o.Username
}

func (o *InputGrafanaLokiAuth) GetPassword() *string {
	if o == nil {
		return nil
	}
	return o.Password
}

func (o *InputGrafanaLokiAuth) GetToken() *string {
	if o == nil {
		return nil
	}
	return o.Token
}

func (o *InputGrafanaLokiAuth) GetCredentialsSecret() *string {
	if o == nil {
		return nil
	}
	return o.CredentialsSecret
}

func (o *InputGrafanaLokiAuth) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *InputGrafanaLokiAuth) GetLoginURL() *string {
	if o == nil {
		return nil
	}
	return o.LoginURL
}

func (o *InputGrafanaLokiAuth) GetSecretParamName() *string {
	if o == nil {
		return nil
	}
	return o.SecretParamName
}

func (o *InputGrafanaLokiAuth) GetSecret() *string {
	if o == nil {
		return nil
	}
	return o.Secret
}

func (o *InputGrafanaLokiAuth) GetTokenAttributeName() *string {
	if o == nil {
		return nil
	}
	return o.TokenAttributeName
}

func (o *InputGrafanaLokiAuth) GetAuthHeaderExpr() *string {
	if o == nil {
		return nil
	}
	return o.AuthHeaderExpr
}

func (o *InputGrafanaLokiAuth) GetTokenTimeoutSecs() *float64 {
	if o == nil {
		return nil
	}
	return o.TokenTimeoutSecs
}

func (o *InputGrafanaLokiAuth) GetOauthParams() []InputInputGrafana2LokiAuthOauthParams {
	if o == nil {
		return nil
	}
	return o.OauthParams
}

func (o *InputGrafanaLokiAuth) GetOauthHeaders() []InputInputGrafana2LokiAuthOauthHeaders {
	if o == nil {
		return nil
	}
	return o.OauthHeaders
}

type InputInputGrafanaMetadata struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputInputGrafanaMetadata) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputInputGrafanaMetadata) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputGrafana2 struct {
	// Unique ID for this input
	ID       *string                `json:"id,omitempty"`
	Type     *InputInputGrafanaType `json:"type,omitempty"`
	Disabled *bool                  `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputInputGrafanaConnections `json:"connections,omitempty"`
	Pq          *InputInputGrafanaPq           `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port float64                                 `json:"port"`
	TLS  *InputInputGrafanaTLSSettingsServerSide `json:"tls,omitempty"`
	// Maximum number of active requests per Worker Process. Use 0 for unlimited.
	MaxActiveReq *float64 `default:"256" json:"maxActiveReq"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket *int64 `default:"0" json:"maxRequestsPerSocket"`
	// Enable when clients are connecting through a proxy that supports the x-forwarded-for header to keep the client's original IP address on the event instead of the proxy's IP address
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Add request headers to events, in the __headers field
	CaptureHeaders *bool `default:"false" json:"captureHeaders"`
	// How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
	ActivityLogSampleRate *float64 `default:"100" json:"activityLogSampleRate"`
	// How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
	RequestTimeout *float64 `default:"0" json:"requestTimeout"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `default:"0" json:"socketTimeout"`
	// Maximum time to wait for additional data, after the last response was sent, before closing a socket connection. This can be very useful when Grafana Agent remote write's request frequency is high so, reusing connections, would help mitigating the cost of creating a new connection per request. Note that Grafana Agent's embedded Prometheus would attempt to keep connections open for up to 5 minutes.
	KeepAliveTimeout *float64 `default:"5" json:"keepAliveTimeout"`
	// Enable to expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
	EnableHealthCheck *bool `default:"false" json:"enableHealthCheck"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist
	IPAllowlistRegex *string `default:"/.*/" json:"ipAllowlistRegex"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `default:"/^\\$/" json:"ipDenylistRegex"`
	// Absolute path on which to listen for Grafana Agent's Remote Write requests. Defaults to /api/prom/push, which will expand as: 'http://<yourupstreamURL>:<yourport>/api/prom/push'. Either this field or 'Logs API endpoint' must be configured.
	PrometheusAPI *string `default:"/api/prom/push" json:"prometheusAPI"`
	// Absolute path on which to listen for Loki logs requests. Defaults to /loki/api/v1/push, which will (in this example) expand as: 'http://<yourupstreamURL>:<yourport>/loki/api/v1/push'. Either this field or 'Remote Write API endpoint' must be configured.
	LokiAPI        *string                     `default:"/loki/api/v1/push" json:"lokiAPI"`
	PrometheusAuth *InputGrafanaPrometheusAuth `json:"prometheusAuth,omitempty"`
	LokiAuth       *InputGrafanaLokiAuth       `json:"lokiAuth,omitempty"`
	// Fields to add to events from this input
	Metadata    []InputInputGrafanaMetadata `json:"metadata,omitempty"`
	Description *string                     `json:"description,omitempty"`
	Status      *TFStatus                   `json:"status,omitempty"`
}

func (i InputGrafana2) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputGrafana2) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputGrafana2) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputGrafana2) GetType() *InputInputGrafanaType {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputGrafana2) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputGrafana2) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputGrafana2) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputGrafana2) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputGrafana2) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputGrafana2) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputGrafana2) GetConnections() []InputInputGrafanaConnections {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputGrafana2) GetPq() *InputInputGrafanaPq {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputGrafana2) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputGrafana2) GetPort() float64 {
	if o == nil {
		return 0.0
	}
	return o.Port
}

func (o *InputGrafana2) GetTLS() *InputInputGrafanaTLSSettingsServerSide {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputGrafana2) GetMaxActiveReq() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxActiveReq
}

func (o *InputGrafana2) GetMaxRequestsPerSocket() *int64 {
	if o == nil {
		return nil
	}
	return o.MaxRequestsPerSocket
}

func (o *InputGrafana2) GetEnableProxyHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableProxyHeader
}

func (o *InputGrafana2) GetCaptureHeaders() *bool {
	if o == nil {
		return nil
	}
	return o.CaptureHeaders
}

func (o *InputGrafana2) GetActivityLogSampleRate() *float64 {
	if o == nil {
		return nil
	}
	return o.ActivityLogSampleRate
}

func (o *InputGrafana2) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *InputGrafana2) GetSocketTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketTimeout
}

func (o *InputGrafana2) GetKeepAliveTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.KeepAliveTimeout
}

func (o *InputGrafana2) GetEnableHealthCheck() *bool {
	if o == nil {
		return nil
	}
	return o.EnableHealthCheck
}

func (o *InputGrafana2) GetIPAllowlistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPAllowlistRegex
}

func (o *InputGrafana2) GetIPDenylistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPDenylistRegex
}

func (o *InputGrafana2) GetPrometheusAPI() *string {
	if o == nil {
		return nil
	}
	return o.PrometheusAPI
}

func (o *InputGrafana2) GetLokiAPI() *string {
	if o == nil {
		return nil
	}
	return o.LokiAPI
}

func (o *InputGrafana2) GetPrometheusAuth() *InputGrafanaPrometheusAuth {
	if o == nil {
		return nil
	}
	return o.PrometheusAuth
}

func (o *InputGrafana2) GetLokiAuth() *InputGrafanaLokiAuth {
	if o == nil {
		return nil
	}
	return o.LokiAuth
}

func (o *InputGrafana2) GetMetadata() []InputInputGrafanaMetadata {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputGrafana2) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputGrafana2) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputGrafanaType string

const (
	InputGrafanaTypeGrafana InputGrafanaType = "grafana"
)

func (e InputGrafanaType) ToPointer() *InputGrafanaType {
	return &e
}
func (e *InputGrafanaType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "grafana":
		*e = InputGrafanaType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputGrafanaType: %v", v)
	}
}

type InputGrafanaConnections struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *InputGrafanaConnections) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputGrafanaConnections) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// InputGrafanaMode - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputGrafanaMode string

const (
	InputGrafanaModeSmart  InputGrafanaMode = "smart"
	InputGrafanaModeAlways InputGrafanaMode = "always"
)

func (e InputGrafanaMode) ToPointer() *InputGrafanaMode {
	return &e
}
func (e *InputGrafanaMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputGrafanaMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputGrafanaMode: %v", v)
	}
}

// InputGrafanaCompression - Codec to use to compress the persisted data
type InputGrafanaCompression string

const (
	InputGrafanaCompressionNone InputGrafanaCompression = "none"
	InputGrafanaCompressionGzip InputGrafanaCompression = "gzip"
)

func (e InputGrafanaCompression) ToPointer() *InputGrafanaCompression {
	return &e
}
func (e *InputGrafanaCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputGrafanaCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputGrafanaCompression: %v", v)
	}
}

type InputGrafanaPq struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputGrafanaMode `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *InputGrafanaCompression `default:"none" json:"compress"`
}

func (i InputGrafanaPq) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputGrafanaPq) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputGrafanaPq) GetMode() *InputGrafanaMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputGrafanaPq) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputGrafanaPq) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *InputGrafanaPq) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *InputGrafanaPq) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *InputGrafanaPq) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *InputGrafanaPq) GetCompress() *InputGrafanaCompression {
	if o == nil {
		return nil
	}
	return o.Compress
}

// InputGrafanaMinimumTLSVersion - Minimum TLS version to accept from connections
type InputGrafanaMinimumTLSVersion string

const (
	InputGrafanaMinimumTLSVersionTlSv1  InputGrafanaMinimumTLSVersion = "TLSv1"
	InputGrafanaMinimumTLSVersionTlSv11 InputGrafanaMinimumTLSVersion = "TLSv1.1"
	InputGrafanaMinimumTLSVersionTlSv12 InputGrafanaMinimumTLSVersion = "TLSv1.2"
	InputGrafanaMinimumTLSVersionTlSv13 InputGrafanaMinimumTLSVersion = "TLSv1.3"
)

func (e InputGrafanaMinimumTLSVersion) ToPointer() *InputGrafanaMinimumTLSVersion {
	return &e
}
func (e *InputGrafanaMinimumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputGrafanaMinimumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputGrafanaMinimumTLSVersion: %v", v)
	}
}

// InputGrafanaMaximumTLSVersion - Maximum TLS version to accept from connections
type InputGrafanaMaximumTLSVersion string

const (
	InputGrafanaMaximumTLSVersionTlSv1  InputGrafanaMaximumTLSVersion = "TLSv1"
	InputGrafanaMaximumTLSVersionTlSv11 InputGrafanaMaximumTLSVersion = "TLSv1.1"
	InputGrafanaMaximumTLSVersionTlSv12 InputGrafanaMaximumTLSVersion = "TLSv1.2"
	InputGrafanaMaximumTLSVersionTlSv13 InputGrafanaMaximumTLSVersion = "TLSv1.3"
)

func (e InputGrafanaMaximumTLSVersion) ToPointer() *InputGrafanaMaximumTLSVersion {
	return &e
}
func (e *InputGrafanaMaximumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputGrafanaMaximumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputGrafanaMaximumTLSVersion: %v", v)
	}
}

type InputGrafanaTLSSettingsServerSide struct {
	Disabled *bool `default:"true" json:"disabled"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert        *bool `default:"false" json:"requestCert"`
	RejectUnauthorized any   `json:"rejectUnauthorized,omitempty"`
	CommonNameRegex    any   `json:"commonNameRegex,omitempty"`
	// Minimum TLS version to accept from connections
	MinVersion *InputGrafanaMinimumTLSVersion `json:"minVersion,omitempty"`
	// Maximum TLS version to accept from connections
	MaxVersion *InputGrafanaMaximumTLSVersion `json:"maxVersion,omitempty"`
}

func (i InputGrafanaTLSSettingsServerSide) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputGrafanaTLSSettingsServerSide) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputGrafanaTLSSettingsServerSide) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputGrafanaTLSSettingsServerSide) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *InputGrafanaTLSSettingsServerSide) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *InputGrafanaTLSSettingsServerSide) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *InputGrafanaTLSSettingsServerSide) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *InputGrafanaTLSSettingsServerSide) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *InputGrafanaTLSSettingsServerSide) GetRequestCert() *bool {
	if o == nil {
		return nil
	}
	return o.RequestCert
}

func (o *InputGrafanaTLSSettingsServerSide) GetRejectUnauthorized() any {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *InputGrafanaTLSSettingsServerSide) GetCommonNameRegex() any {
	if o == nil {
		return nil
	}
	return o.CommonNameRegex
}

func (o *InputGrafanaTLSSettingsServerSide) GetMinVersion() *InputGrafanaMinimumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *InputGrafanaTLSSettingsServerSide) GetMaxVersion() *InputGrafanaMaximumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

// InputGrafanaAuthenticationType - Remote Write authentication type
type InputGrafanaAuthenticationType string

const (
	InputGrafanaAuthenticationTypeNone              InputGrafanaAuthenticationType = "none"
	InputGrafanaAuthenticationTypeBasic             InputGrafanaAuthenticationType = "basic"
	InputGrafanaAuthenticationTypeCredentialsSecret InputGrafanaAuthenticationType = "credentialsSecret"
	InputGrafanaAuthenticationTypeToken             InputGrafanaAuthenticationType = "token"
	InputGrafanaAuthenticationTypeTextSecret        InputGrafanaAuthenticationType = "textSecret"
	InputGrafanaAuthenticationTypeOauth             InputGrafanaAuthenticationType = "oauth"
)

func (e InputGrafanaAuthenticationType) ToPointer() *InputGrafanaAuthenticationType {
	return &e
}
func (e *InputGrafanaAuthenticationType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "basic":
		fallthrough
	case "credentialsSecret":
		fallthrough
	case "token":
		fallthrough
	case "textSecret":
		fallthrough
	case "oauth":
		*e = InputGrafanaAuthenticationType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputGrafanaAuthenticationType: %v", v)
	}
}

type InputGrafanaOauthParams struct {
	// OAuth parameter name
	Name string `json:"name"`
	// OAuth parameter value
	Value string `json:"value"`
}

func (o *InputGrafanaOauthParams) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputGrafanaOauthParams) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputGrafanaOauthHeaders struct {
	// OAuth header name
	Name string `json:"name"`
	// OAuth header value
	Value string `json:"value"`
}

func (o *InputGrafanaOauthHeaders) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputGrafanaOauthHeaders) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type PrometheusAuth struct {
	// Remote Write authentication type
	AuthType *InputGrafanaAuthenticationType `default:"none" json:"authType"`
	Username *string                         `json:"username,omitempty"`
	Password *string                         `json:"password,omitempty"`
	// Bearer token to include in the authorization header
	Token *string `json:"token,omitempty"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// URL for OAuth
	LoginURL *string `json:"loginUrl,omitempty"`
	// Secret parameter name to pass in request body
	SecretParamName *string `json:"secretParamName,omitempty"`
	// Secret parameter value to pass in request body
	Secret *string `json:"secret,omitempty"`
	// Name of the auth token attribute in the OAuth response. Can be top-level (e.g., 'token'); or nested, using a period (e.g., 'data.token').
	TokenAttributeName *string `json:"tokenAttributeName,omitempty"`
	// JavaScript expression to compute the Authorization header value to pass in requests. The value `${token}` is used to reference the token obtained from authentication, e.g.: `Bearer ${token}`.
	AuthHeaderExpr *string `default:"Bearer \\${token}" json:"authHeaderExpr"`
	// How often the OAuth token should be refreshed.
	TokenTimeoutSecs *float64 `default:"3600" json:"tokenTimeoutSecs"`
	// Additional parameters to send in the OAuth login request. @{product} will combine the secret with these parameters, and will send the URL-encoded result in a POST request to the endpoint specified in the 'Login URL'. We'll automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthParams []InputGrafanaOauthParams `json:"oauthParams,omitempty"`
	// Additional headers to send in the OAuth login request. @{product} will automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthHeaders []InputGrafanaOauthHeaders `json:"oauthHeaders,omitempty"`
}

func (p PrometheusAuth) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PrometheusAuth) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PrometheusAuth) GetAuthType() *InputGrafanaAuthenticationType {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *PrometheusAuth) GetUsername() *string {
	if o == nil {
		return nil
	}
	return o.Username
}

func (o *PrometheusAuth) GetPassword() *string {
	if o == nil {
		return nil
	}
	return o.Password
}

func (o *PrometheusAuth) GetToken() *string {
	if o == nil {
		return nil
	}
	return o.Token
}

func (o *PrometheusAuth) GetCredentialsSecret() *string {
	if o == nil {
		return nil
	}
	return o.CredentialsSecret
}

func (o *PrometheusAuth) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *PrometheusAuth) GetLoginURL() *string {
	if o == nil {
		return nil
	}
	return o.LoginURL
}

func (o *PrometheusAuth) GetSecretParamName() *string {
	if o == nil {
		return nil
	}
	return o.SecretParamName
}

func (o *PrometheusAuth) GetSecret() *string {
	if o == nil {
		return nil
	}
	return o.Secret
}

func (o *PrometheusAuth) GetTokenAttributeName() *string {
	if o == nil {
		return nil
	}
	return o.TokenAttributeName
}

func (o *PrometheusAuth) GetAuthHeaderExpr() *string {
	if o == nil {
		return nil
	}
	return o.AuthHeaderExpr
}

func (o *PrometheusAuth) GetTokenTimeoutSecs() *float64 {
	if o == nil {
		return nil
	}
	return o.TokenTimeoutSecs
}

func (o *PrometheusAuth) GetOauthParams() []InputGrafanaOauthParams {
	if o == nil {
		return nil
	}
	return o.OauthParams
}

func (o *PrometheusAuth) GetOauthHeaders() []InputGrafanaOauthHeaders {
	if o == nil {
		return nil
	}
	return o.OauthHeaders
}

// InputInputGrafanaAuthenticationType - Loki logs authentication type
type InputInputGrafanaAuthenticationType string

const (
	InputInputGrafanaAuthenticationTypeNone              InputInputGrafanaAuthenticationType = "none"
	InputInputGrafanaAuthenticationTypeBasic             InputInputGrafanaAuthenticationType = "basic"
	InputInputGrafanaAuthenticationTypeCredentialsSecret InputInputGrafanaAuthenticationType = "credentialsSecret"
	InputInputGrafanaAuthenticationTypeToken             InputInputGrafanaAuthenticationType = "token"
	InputInputGrafanaAuthenticationTypeTextSecret        InputInputGrafanaAuthenticationType = "textSecret"
	InputInputGrafanaAuthenticationTypeOauth             InputInputGrafanaAuthenticationType = "oauth"
)

func (e InputInputGrafanaAuthenticationType) ToPointer() *InputInputGrafanaAuthenticationType {
	return &e
}
func (e *InputInputGrafanaAuthenticationType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "basic":
		fallthrough
	case "credentialsSecret":
		fallthrough
	case "token":
		fallthrough
	case "textSecret":
		fallthrough
	case "oauth":
		*e = InputInputGrafanaAuthenticationType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputInputGrafanaAuthenticationType: %v", v)
	}
}

type InputInputGrafanaOauthParams struct {
	// OAuth parameter name
	Name string `json:"name"`
	// OAuth parameter value
	Value string `json:"value"`
}

func (o *InputInputGrafanaOauthParams) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputInputGrafanaOauthParams) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputInputGrafanaOauthHeaders struct {
	// OAuth header name
	Name string `json:"name"`
	// OAuth header value
	Value string `json:"value"`
}

func (o *InputInputGrafanaOauthHeaders) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputInputGrafanaOauthHeaders) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type LokiAuth struct {
	// Loki logs authentication type
	AuthType *InputInputGrafanaAuthenticationType `default:"none" json:"authType"`
	Username *string                              `json:"username,omitempty"`
	Password *string                              `json:"password,omitempty"`
	// Bearer token to include in the authorization header
	Token *string `json:"token,omitempty"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// URL for OAuth
	LoginURL *string `json:"loginUrl,omitempty"`
	// Secret parameter name to pass in request body
	SecretParamName *string `json:"secretParamName,omitempty"`
	// Secret parameter value to pass in request body
	Secret *string `json:"secret,omitempty"`
	// Name of the auth token attribute in the OAuth response. Can be top-level (e.g., 'token'); or nested, using a period (e.g., 'data.token').
	TokenAttributeName *string `json:"tokenAttributeName,omitempty"`
	// JavaScript expression to compute the Authorization header value to pass in requests. The value `${token}` is used to reference the token obtained from authentication, e.g.: `Bearer ${token}`.
	AuthHeaderExpr *string `default:"Bearer \\${token}" json:"authHeaderExpr"`
	// How often the OAuth token should be refreshed.
	TokenTimeoutSecs *float64 `default:"3600" json:"tokenTimeoutSecs"`
	// Additional parameters to send in the OAuth login request. @{product} will combine the secret with these parameters, and will send the URL-encoded result in a POST request to the endpoint specified in the 'Login URL'. We'll automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthParams []InputInputGrafanaOauthParams `json:"oauthParams,omitempty"`
	// Additional headers to send in the OAuth login request. @{product} will automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthHeaders []InputInputGrafanaOauthHeaders `json:"oauthHeaders,omitempty"`
}

func (l LokiAuth) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(l, "", false)
}

func (l *LokiAuth) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &l, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *LokiAuth) GetAuthType() *InputInputGrafanaAuthenticationType {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *LokiAuth) GetUsername() *string {
	if o == nil {
		return nil
	}
	return o.Username
}

func (o *LokiAuth) GetPassword() *string {
	if o == nil {
		return nil
	}
	return o.Password
}

func (o *LokiAuth) GetToken() *string {
	if o == nil {
		return nil
	}
	return o.Token
}

func (o *LokiAuth) GetCredentialsSecret() *string {
	if o == nil {
		return nil
	}
	return o.CredentialsSecret
}

func (o *LokiAuth) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *LokiAuth) GetLoginURL() *string {
	if o == nil {
		return nil
	}
	return o.LoginURL
}

func (o *LokiAuth) GetSecretParamName() *string {
	if o == nil {
		return nil
	}
	return o.SecretParamName
}

func (o *LokiAuth) GetSecret() *string {
	if o == nil {
		return nil
	}
	return o.Secret
}

func (o *LokiAuth) GetTokenAttributeName() *string {
	if o == nil {
		return nil
	}
	return o.TokenAttributeName
}

func (o *LokiAuth) GetAuthHeaderExpr() *string {
	if o == nil {
		return nil
	}
	return o.AuthHeaderExpr
}

func (o *LokiAuth) GetTokenTimeoutSecs() *float64 {
	if o == nil {
		return nil
	}
	return o.TokenTimeoutSecs
}

func (o *LokiAuth) GetOauthParams() []InputInputGrafanaOauthParams {
	if o == nil {
		return nil
	}
	return o.OauthParams
}

func (o *LokiAuth) GetOauthHeaders() []InputInputGrafanaOauthHeaders {
	if o == nil {
		return nil
	}
	return o.OauthHeaders
}

type InputGrafanaMetadata struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputGrafanaMetadata) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputGrafanaMetadata) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputGrafana1 struct {
	// Unique ID for this input
	ID       *string           `json:"id,omitempty"`
	Type     *InputGrafanaType `json:"type,omitempty"`
	Disabled *bool             `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputGrafanaConnections `json:"connections,omitempty"`
	Pq          *InputGrafanaPq           `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port float64                            `json:"port"`
	TLS  *InputGrafanaTLSSettingsServerSide `json:"tls,omitempty"`
	// Maximum number of active requests per Worker Process. Use 0 for unlimited.
	MaxActiveReq *float64 `default:"256" json:"maxActiveReq"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket *int64 `default:"0" json:"maxRequestsPerSocket"`
	// Enable when clients are connecting through a proxy that supports the x-forwarded-for header to keep the client's original IP address on the event instead of the proxy's IP address
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Add request headers to events, in the __headers field
	CaptureHeaders *bool `default:"false" json:"captureHeaders"`
	// How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
	ActivityLogSampleRate *float64 `default:"100" json:"activityLogSampleRate"`
	// How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
	RequestTimeout *float64 `default:"0" json:"requestTimeout"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `default:"0" json:"socketTimeout"`
	// Maximum time to wait for additional data, after the last response was sent, before closing a socket connection. This can be very useful when Grafana Agent remote write's request frequency is high so, reusing connections, would help mitigating the cost of creating a new connection per request. Note that Grafana Agent's embedded Prometheus would attempt to keep connections open for up to 5 minutes.
	KeepAliveTimeout *float64 `default:"5" json:"keepAliveTimeout"`
	// Enable to expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
	EnableHealthCheck *bool `default:"false" json:"enableHealthCheck"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist
	IPAllowlistRegex *string `default:"/.*/" json:"ipAllowlistRegex"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `default:"/^\\$/" json:"ipDenylistRegex"`
	// Absolute path on which to listen for Grafana Agent's Remote Write requests. Defaults to /api/prom/push, which will expand as: 'http://<yourupstreamURL>:<yourport>/api/prom/push'. Either this field or 'Logs API endpoint' must be configured.
	PrometheusAPI *string `default:"/api/prom/push" json:"prometheusAPI"`
	// Absolute path on which to listen for Loki logs requests. Defaults to /loki/api/v1/push, which will (in this example) expand as: 'http://<yourupstreamURL>:<yourport>/loki/api/v1/push'. Either this field or 'Remote Write API endpoint' must be configured.
	LokiAPI        *string         `default:"/loki/api/v1/push" json:"lokiAPI"`
	PrometheusAuth *PrometheusAuth `json:"prometheusAuth,omitempty"`
	LokiAuth       *LokiAuth       `json:"lokiAuth,omitempty"`
	// Fields to add to events from this input
	Metadata    []InputGrafanaMetadata `json:"metadata,omitempty"`
	Description *string                `json:"description,omitempty"`
	Status      *TFStatus              `json:"status,omitempty"`
}

func (i InputGrafana1) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputGrafana1) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputGrafana1) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputGrafana1) GetType() *InputGrafanaType {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputGrafana1) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputGrafana1) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputGrafana1) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputGrafana1) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputGrafana1) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputGrafana1) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputGrafana1) GetConnections() []InputGrafanaConnections {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputGrafana1) GetPq() *InputGrafanaPq {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputGrafana1) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputGrafana1) GetPort() float64 {
	if o == nil {
		return 0.0
	}
	return o.Port
}

func (o *InputGrafana1) GetTLS() *InputGrafanaTLSSettingsServerSide {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputGrafana1) GetMaxActiveReq() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxActiveReq
}

func (o *InputGrafana1) GetMaxRequestsPerSocket() *int64 {
	if o == nil {
		return nil
	}
	return o.MaxRequestsPerSocket
}

func (o *InputGrafana1) GetEnableProxyHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableProxyHeader
}

func (o *InputGrafana1) GetCaptureHeaders() *bool {
	if o == nil {
		return nil
	}
	return o.CaptureHeaders
}

func (o *InputGrafana1) GetActivityLogSampleRate() *float64 {
	if o == nil {
		return nil
	}
	return o.ActivityLogSampleRate
}

func (o *InputGrafana1) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *InputGrafana1) GetSocketTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketTimeout
}

func (o *InputGrafana1) GetKeepAliveTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.KeepAliveTimeout
}

func (o *InputGrafana1) GetEnableHealthCheck() *bool {
	if o == nil {
		return nil
	}
	return o.EnableHealthCheck
}

func (o *InputGrafana1) GetIPAllowlistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPAllowlistRegex
}

func (o *InputGrafana1) GetIPDenylistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPDenylistRegex
}

func (o *InputGrafana1) GetPrometheusAPI() *string {
	if o == nil {
		return nil
	}
	return o.PrometheusAPI
}

func (o *InputGrafana1) GetLokiAPI() *string {
	if o == nil {
		return nil
	}
	return o.LokiAPI
}

func (o *InputGrafana1) GetPrometheusAuth() *PrometheusAuth {
	if o == nil {
		return nil
	}
	return o.PrometheusAuth
}

func (o *InputGrafana1) GetLokiAuth() *LokiAuth {
	if o == nil {
		return nil
	}
	return o.LokiAuth
}

func (o *InputGrafana1) GetMetadata() []InputGrafanaMetadata {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputGrafana1) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputGrafana1) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputGrafanaUnionType string

const (
	InputGrafanaUnionTypeInputGrafana1 InputGrafanaUnionType = "InputGrafana_1"
	InputGrafanaUnionTypeInputGrafana2 InputGrafanaUnionType = "InputGrafana_2"
)

type InputGrafana struct {
	InputGrafana1 *InputGrafana1 `queryParam:"inline"`
	InputGrafana2 *InputGrafana2 `queryParam:"inline"`

	Type InputGrafanaUnionType
}

func CreateInputGrafanaInputGrafana1(inputGrafana1 InputGrafana1) InputGrafana {
	typ := InputGrafanaUnionTypeInputGrafana1

	return InputGrafana{
		InputGrafana1: &inputGrafana1,
		Type:          typ,
	}
}

func CreateInputGrafanaInputGrafana2(inputGrafana2 InputGrafana2) InputGrafana {
	typ := InputGrafanaUnionTypeInputGrafana2

	return InputGrafana{
		InputGrafana2: &inputGrafana2,
		Type:          typ,
	}
}

func (u *InputGrafana) UnmarshalJSON(data []byte) error {

	var inputGrafana1 InputGrafana1 = InputGrafana1{}
	if err := utils.UnmarshalJSON(data, &inputGrafana1, "", true, true); err == nil {
		u.InputGrafana1 = &inputGrafana1
		u.Type = InputGrafanaUnionTypeInputGrafana1
		return nil
	}

	var inputGrafana2 InputGrafana2 = InputGrafana2{}
	if err := utils.UnmarshalJSON(data, &inputGrafana2, "", true, true); err == nil {
		u.InputGrafana2 = &inputGrafana2
		u.Type = InputGrafanaUnionTypeInputGrafana2
		return nil
	}

	return fmt.Errorf("could not unmarshal `%s` into any supported union types for InputGrafana", string(data))
}

func (u InputGrafana) MarshalJSON() ([]byte, error) {
	if u.InputGrafana1 != nil {
		return utils.MarshalJSON(u.InputGrafana1, "", true)
	}

	if u.InputGrafana2 != nil {
		return utils.MarshalJSON(u.InputGrafana2, "", true)
	}

	return nil, errors.New("could not marshal union type InputGrafana: all fields are null")
}

type InputConfluentCloudType string

const (
	InputConfluentCloudTypeConfluentCloud InputConfluentCloudType = "confluent_cloud"
)

func (e InputConfluentCloudType) ToPointer() *InputConfluentCloudType {
	return &e
}
func (e *InputConfluentCloudType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "confluent_cloud":
		*e = InputConfluentCloudType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputConfluentCloudType: %v", v)
	}
}

type InputConfluentCloudConnections struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *InputConfluentCloudConnections) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputConfluentCloudConnections) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// InputConfluentCloudMode - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputConfluentCloudMode string

const (
	InputConfluentCloudModeSmart  InputConfluentCloudMode = "smart"
	InputConfluentCloudModeAlways InputConfluentCloudMode = "always"
)

func (e InputConfluentCloudMode) ToPointer() *InputConfluentCloudMode {
	return &e
}
func (e *InputConfluentCloudMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputConfluentCloudMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputConfluentCloudMode: %v", v)
	}
}

// InputConfluentCloudCompression - Codec to use to compress the persisted data
type InputConfluentCloudCompression string

const (
	InputConfluentCloudCompressionNone InputConfluentCloudCompression = "none"
	InputConfluentCloudCompressionGzip InputConfluentCloudCompression = "gzip"
)

func (e InputConfluentCloudCompression) ToPointer() *InputConfluentCloudCompression {
	return &e
}
func (e *InputConfluentCloudCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputConfluentCloudCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputConfluentCloudCompression: %v", v)
	}
}

type InputConfluentCloudPq struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputConfluentCloudMode `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *InputConfluentCloudCompression `default:"none" json:"compress"`
}

func (i InputConfluentCloudPq) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputConfluentCloudPq) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputConfluentCloudPq) GetMode() *InputConfluentCloudMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputConfluentCloudPq) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputConfluentCloudPq) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *InputConfluentCloudPq) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *InputConfluentCloudPq) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *InputConfluentCloudPq) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *InputConfluentCloudPq) GetCompress() *InputConfluentCloudCompression {
	if o == nil {
		return nil
	}
	return o.Compress
}

// InputConfluentCloudMinimumTLSVersion - Minimum TLS version to use when connecting
type InputConfluentCloudMinimumTLSVersion string

const (
	InputConfluentCloudMinimumTLSVersionTlSv1  InputConfluentCloudMinimumTLSVersion = "TLSv1"
	InputConfluentCloudMinimumTLSVersionTlSv11 InputConfluentCloudMinimumTLSVersion = "TLSv1.1"
	InputConfluentCloudMinimumTLSVersionTlSv12 InputConfluentCloudMinimumTLSVersion = "TLSv1.2"
	InputConfluentCloudMinimumTLSVersionTlSv13 InputConfluentCloudMinimumTLSVersion = "TLSv1.3"
)

func (e InputConfluentCloudMinimumTLSVersion) ToPointer() *InputConfluentCloudMinimumTLSVersion {
	return &e
}
func (e *InputConfluentCloudMinimumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputConfluentCloudMinimumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputConfluentCloudMinimumTLSVersion: %v", v)
	}
}

// InputConfluentCloudMaximumTLSVersion - Maximum TLS version to use when connecting
type InputConfluentCloudMaximumTLSVersion string

const (
	InputConfluentCloudMaximumTLSVersionTlSv1  InputConfluentCloudMaximumTLSVersion = "TLSv1"
	InputConfluentCloudMaximumTLSVersionTlSv11 InputConfluentCloudMaximumTLSVersion = "TLSv1.1"
	InputConfluentCloudMaximumTLSVersionTlSv12 InputConfluentCloudMaximumTLSVersion = "TLSv1.2"
	InputConfluentCloudMaximumTLSVersionTlSv13 InputConfluentCloudMaximumTLSVersion = "TLSv1.3"
)

func (e InputConfluentCloudMaximumTLSVersion) ToPointer() *InputConfluentCloudMaximumTLSVersion {
	return &e
}
func (e *InputConfluentCloudMaximumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputConfluentCloudMaximumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputConfluentCloudMaximumTLSVersion: %v", v)
	}
}

type InputConfluentCloudTLSSettingsClientSide struct {
	Disabled *bool `default:"false" json:"disabled"`
	// Reject certs that are not authorized by a CA in the CA certificate path, or by another
	//                     trusted CA (e.g., the system's CA). Defaults to Yes. Overrides the toggle from Advanced Settings, when also present.
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.
	Servername *string `json:"servername,omitempty"`
	// The name of the predefined certificate.
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Passphrase to use to decrypt private key.
	Passphrase *string `json:"passphrase,omitempty"`
	// Minimum TLS version to use when connecting
	MinVersion *InputConfluentCloudMinimumTLSVersion `json:"minVersion,omitempty"`
	// Maximum TLS version to use when connecting
	MaxVersion *InputConfluentCloudMaximumTLSVersion `json:"maxVersion,omitempty"`
}

func (i InputConfluentCloudTLSSettingsClientSide) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputConfluentCloudTLSSettingsClientSide) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputConfluentCloudTLSSettingsClientSide) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputConfluentCloudTLSSettingsClientSide) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *InputConfluentCloudTLSSettingsClientSide) GetServername() *string {
	if o == nil {
		return nil
	}
	return o.Servername
}

func (o *InputConfluentCloudTLSSettingsClientSide) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *InputConfluentCloudTLSSettingsClientSide) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *InputConfluentCloudTLSSettingsClientSide) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *InputConfluentCloudTLSSettingsClientSide) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *InputConfluentCloudTLSSettingsClientSide) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *InputConfluentCloudTLSSettingsClientSide) GetMinVersion() *InputConfluentCloudMinimumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *InputConfluentCloudTLSSettingsClientSide) GetMaxVersion() *InputConfluentCloudMaximumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

// InputConfluentCloudAuth - Credentials to use when authenticating with the schema registry using basic HTTP authentication
type InputConfluentCloudAuth struct {
	// Enable authentication
	Disabled *bool `default:"true" json:"disabled"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
}

func (i InputConfluentCloudAuth) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputConfluentCloudAuth) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputConfluentCloudAuth) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputConfluentCloudAuth) GetCredentialsSecret() *string {
	if o == nil {
		return nil
	}
	return o.CredentialsSecret
}

// InputConfluentCloudInputMinimumTLSVersion - Minimum TLS version to use when connecting
type InputConfluentCloudInputMinimumTLSVersion string

const (
	InputConfluentCloudInputMinimumTLSVersionTlSv1  InputConfluentCloudInputMinimumTLSVersion = "TLSv1"
	InputConfluentCloudInputMinimumTLSVersionTlSv11 InputConfluentCloudInputMinimumTLSVersion = "TLSv1.1"
	InputConfluentCloudInputMinimumTLSVersionTlSv12 InputConfluentCloudInputMinimumTLSVersion = "TLSv1.2"
	InputConfluentCloudInputMinimumTLSVersionTlSv13 InputConfluentCloudInputMinimumTLSVersion = "TLSv1.3"
)

func (e InputConfluentCloudInputMinimumTLSVersion) ToPointer() *InputConfluentCloudInputMinimumTLSVersion {
	return &e
}
func (e *InputConfluentCloudInputMinimumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputConfluentCloudInputMinimumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputConfluentCloudInputMinimumTLSVersion: %v", v)
	}
}

// InputConfluentCloudInputMaximumTLSVersion - Maximum TLS version to use when connecting
type InputConfluentCloudInputMaximumTLSVersion string

const (
	InputConfluentCloudInputMaximumTLSVersionTlSv1  InputConfluentCloudInputMaximumTLSVersion = "TLSv1"
	InputConfluentCloudInputMaximumTLSVersionTlSv11 InputConfluentCloudInputMaximumTLSVersion = "TLSv1.1"
	InputConfluentCloudInputMaximumTLSVersionTlSv12 InputConfluentCloudInputMaximumTLSVersion = "TLSv1.2"
	InputConfluentCloudInputMaximumTLSVersionTlSv13 InputConfluentCloudInputMaximumTLSVersion = "TLSv1.3"
)

func (e InputConfluentCloudInputMaximumTLSVersion) ToPointer() *InputConfluentCloudInputMaximumTLSVersion {
	return &e
}
func (e *InputConfluentCloudInputMaximumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputConfluentCloudInputMaximumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputConfluentCloudInputMaximumTLSVersion: %v", v)
	}
}

type InputConfluentCloudInputTLSSettingsClientSide struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Reject certs that are not authorized by a CA in the CA certificate path, or by another
	//                     trusted CA (e.g., the system's CA). Defaults to Yes. Overrides the toggle from Advanced Settings, when also present.
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.
	Servername *string `json:"servername,omitempty"`
	// The name of the predefined certificate.
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Passphrase to use to decrypt private key.
	Passphrase *string `json:"passphrase,omitempty"`
	// Minimum TLS version to use when connecting
	MinVersion *InputConfluentCloudInputMinimumTLSVersion `json:"minVersion,omitempty"`
	// Maximum TLS version to use when connecting
	MaxVersion *InputConfluentCloudInputMaximumTLSVersion `json:"maxVersion,omitempty"`
}

func (i InputConfluentCloudInputTLSSettingsClientSide) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputConfluentCloudInputTLSSettingsClientSide) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputConfluentCloudInputTLSSettingsClientSide) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputConfluentCloudInputTLSSettingsClientSide) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *InputConfluentCloudInputTLSSettingsClientSide) GetServername() *string {
	if o == nil {
		return nil
	}
	return o.Servername
}

func (o *InputConfluentCloudInputTLSSettingsClientSide) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *InputConfluentCloudInputTLSSettingsClientSide) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *InputConfluentCloudInputTLSSettingsClientSide) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *InputConfluentCloudInputTLSSettingsClientSide) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *InputConfluentCloudInputTLSSettingsClientSide) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *InputConfluentCloudInputTLSSettingsClientSide) GetMinVersion() *InputConfluentCloudInputMinimumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *InputConfluentCloudInputTLSSettingsClientSide) GetMaxVersion() *InputConfluentCloudInputMaximumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

type InputConfluentCloudKafkaSchemaRegistryAuthentication struct {
	// Enable Schema Registry
	Disabled *bool `default:"true" json:"disabled"`
	// URL for accessing the Confluent Schema Registry. Example: http://localhost:8081. To connect over TLS, use https instead of http.
	SchemaRegistryURL *string `default:"http://localhost:8081" json:"schemaRegistryURL"`
	// Maximum time to wait for a Schema Registry connection to complete successfully
	ConnectionTimeout *float64 `default:"30000" json:"connectionTimeout"`
	// Maximum time to wait for the Schema Registry to respond to a request
	RequestTimeout *float64 `default:"30000" json:"requestTimeout"`
	// Maximum number of times to try fetching schemas from the Schema Registry
	MaxRetries *float64 `default:"1" json:"maxRetries"`
	// Credentials to use when authenticating with the schema registry using basic HTTP authentication
	Auth *InputConfluentCloudAuth                       `json:"auth,omitempty"`
	TLS  *InputConfluentCloudInputTLSSettingsClientSide `json:"tls,omitempty"`
}

func (i InputConfluentCloudKafkaSchemaRegistryAuthentication) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputConfluentCloudKafkaSchemaRegistryAuthentication) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputConfluentCloudKafkaSchemaRegistryAuthentication) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputConfluentCloudKafkaSchemaRegistryAuthentication) GetSchemaRegistryURL() *string {
	if o == nil {
		return nil
	}
	return o.SchemaRegistryURL
}

func (o *InputConfluentCloudKafkaSchemaRegistryAuthentication) GetConnectionTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.ConnectionTimeout
}

func (o *InputConfluentCloudKafkaSchemaRegistryAuthentication) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *InputConfluentCloudKafkaSchemaRegistryAuthentication) GetMaxRetries() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxRetries
}

func (o *InputConfluentCloudKafkaSchemaRegistryAuthentication) GetAuth() *InputConfluentCloudAuth {
	if o == nil {
		return nil
	}
	return o.Auth
}

func (o *InputConfluentCloudKafkaSchemaRegistryAuthentication) GetTLS() *InputConfluentCloudInputTLSSettingsClientSide {
	if o == nil {
		return nil
	}
	return o.TLS
}

// InputConfluentCloudSASLMechanism - SASL authentication mechanism to use.
type InputConfluentCloudSASLMechanism string

const (
	InputConfluentCloudSASLMechanismPlain       InputConfluentCloudSASLMechanism = "plain"
	InputConfluentCloudSASLMechanismScramSha256 InputConfluentCloudSASLMechanism = "scram-sha-256"
	InputConfluentCloudSASLMechanismScramSha512 InputConfluentCloudSASLMechanism = "scram-sha-512"
	InputConfluentCloudSASLMechanismKerberos    InputConfluentCloudSASLMechanism = "kerberos"
)

func (e InputConfluentCloudSASLMechanism) ToPointer() *InputConfluentCloudSASLMechanism {
	return &e
}
func (e *InputConfluentCloudSASLMechanism) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "plain":
		fallthrough
	case "scram-sha-256":
		fallthrough
	case "scram-sha-512":
		fallthrough
	case "kerberos":
		*e = InputConfluentCloudSASLMechanism(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputConfluentCloudSASLMechanism: %v", v)
	}
}

// InputConfluentCloudAuthentication - Authentication parameters to use when connecting to brokers. Using TLS is highly recommended.
type InputConfluentCloudAuthentication struct {
	// Enable Authentication
	Disabled *bool `default:"true" json:"disabled"`
	// SASL authentication mechanism to use.
	Mechanism *InputConfluentCloudSASLMechanism `default:"plain" json:"mechanism"`
}

func (i InputConfluentCloudAuthentication) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputConfluentCloudAuthentication) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputConfluentCloudAuthentication) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputConfluentCloudAuthentication) GetMechanism() *InputConfluentCloudSASLMechanism {
	if o == nil {
		return nil
	}
	return o.Mechanism
}

type InputConfluentCloudMetadata struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputConfluentCloudMetadata) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputConfluentCloudMetadata) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputConfluentCloud struct {
	// Unique ID for this input
	ID       *string                  `json:"id,omitempty"`
	Type     *InputConfluentCloudType `json:"type,omitempty"`
	Disabled *bool                    `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputConfluentCloudConnections `json:"connections,omitempty"`
	Pq          *InputConfluentCloudPq           `json:"pq,omitempty"`
	// List of Confluent Cloud bootstrap servers to use, such as yourAccount.confluent.cloud:9092
	Brokers []string                                  `json:"brokers"`
	TLS     *InputConfluentCloudTLSSettingsClientSide `json:"tls,omitempty"`
	// Topic to subscribe to. Warning: To optimize performance, Cribl suggests subscribing each Kafka Source to only a single topic.
	Topics []string `json:"topics,omitempty"`
	// Specifies the consumer group to which this instance belongs. Defaults to 'Cribl'.
	GroupID *string `default:"Cribl" json:"groupId"`
	// Leave toggled to 'Yes' if you want the Source, upon first subscribing to a topic, to read starting with the earliest available message
	FromBeginning       *bool                                                 `default:"true" json:"fromBeginning"`
	KafkaSchemaRegistry *InputConfluentCloudKafkaSchemaRegistryAuthentication `json:"kafkaSchemaRegistry,omitempty"`
	// Maximum time to wait for a connection to complete successfully
	ConnectionTimeout *float64 `default:"10000" json:"connectionTimeout"`
	// Maximum time to wait for Kafka to respond to a request
	RequestTimeout *float64 `default:"60000" json:"requestTimeout"`
	// If messages are failing, you can set the maximum number of retries as high as 100 to prevent loss of data
	MaxRetries *float64 `default:"5" json:"maxRetries"`
	// The maximum wait time for a retry, in milliseconds. Default (and minimum) is 30,000 ms (30 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackOff *float64 `default:"30000" json:"maxBackOff"`
	// Initial value used to calculate the retry, in milliseconds. Maximum is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"300" json:"initialBackoff"`
	// Set the backoff multiplier (2-20) to control the retry frequency for failed messages. For faster retries, use a lower multiplier. For slower retries with more delay between attempts, use a higher multiplier. The multiplier is used in an exponential backoff formula; see the Kafka [documentation](https://kafka.js.org/docs/retry-detailed) for details.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// Maximum time to wait for Kafka to respond to an authentication request
	AuthenticationTimeout *float64 `default:"10000" json:"authenticationTimeout"`
	// Specifies a time window during which @{product} can reauthenticate if needed. Creates the window measuring backwards from the moment when credentials are set to expire.
	ReauthenticationThreshold *float64 `default:"10000" json:"reauthenticationThreshold"`
	// Authentication parameters to use when connecting to brokers. Using TLS is highly recommended.
	Sasl *InputConfluentCloudAuthentication `json:"sasl,omitempty"`
	//       Timeout used to detect client failures when using Kafka's group management facilities.
	//       If the client sends the broker no heartbeats before this timeout expires,
	//       the broker will remove this client from the group, and will initiate a rebalance.
	//       Value must be between the broker's configured group.min.session.timeout.ms and group.max.session.timeout.ms.
	//       See details [here](https://kafka.apache.org/documentation/#consumerconfigs_session.timeout.ms).
	SessionTimeout *float64 `default:"30000" json:"sessionTimeout"`
	//       Maximum allowed time for each worker to join the group after a rebalance has begun.
	//       If the timeout is exceeded, the coordinator broker will remove the worker from the group.
	//       See details [here](https://kafka.apache.org/documentation/#connectconfigs_rebalance.timeout.ms).
	RebalanceTimeout *float64 `default:"60000" json:"rebalanceTimeout"`
	//       Expected time between heartbeats to the consumer coordinator when using Kafka's group management facilities.
	//       Value must be lower than sessionTimeout, and typically should not exceed 1/3 of the sessionTimeout value.
	//       See details [here](https://kafka.apache.org/documentation/#consumerconfigs_heartbeat.interval.ms).
	HeartbeatInterval *float64 `default:"3000" json:"heartbeatInterval"`
	// How often to commit offsets. If both this and Offset commit threshold are set, @{product} commits offsets when either condition is met. If both are empty, @{product} commits offsets after each batch.
	AutoCommitInterval *float64 `json:"autoCommitInterval,omitempty"`
	// How many events are needed to trigger an offset commit. If both this and Offset commit interval are set, @{product} commits offsets when either condition is met. If both are empty, @{product} commits offsets after each batch.
	AutoCommitThreshold *float64 `json:"autoCommitThreshold,omitempty"`
	// Maximum amount of data that Kafka will return per partition, per fetch request. Must equal or exceed the maximum message size (maxBytesPerPartition) that Kafka is configured to allow. Otherwise, @{product} can get stuck trying to retrieve messages. Defaults to 1048576 (1 MB).
	MaxBytesPerPartition *float64 `default:"1048576" json:"maxBytesPerPartition"`
	// Maximum number of bytes that Kafka will return per fetch request. Defaults to 10485760 (10 MB).
	MaxBytes *float64 `default:"10485760" json:"maxBytes"`
	// Maximum number of network errors before the consumer recreates a socket.
	MaxSocketErrors *float64 `default:"0" json:"maxSocketErrors"`
	// Fields to add to events from this input
	Metadata    []InputConfluentCloudMetadata `json:"metadata,omitempty"`
	Description *string                       `json:"description,omitempty"`
	Status      *TFStatus                     `json:"status,omitempty"`
}

func (i InputConfluentCloud) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputConfluentCloud) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputConfluentCloud) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputConfluentCloud) GetType() *InputConfluentCloudType {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputConfluentCloud) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputConfluentCloud) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputConfluentCloud) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputConfluentCloud) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputConfluentCloud) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputConfluentCloud) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputConfluentCloud) GetConnections() []InputConfluentCloudConnections {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputConfluentCloud) GetPq() *InputConfluentCloudPq {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputConfluentCloud) GetBrokers() []string {
	if o == nil {
		return []string{}
	}
	return o.Brokers
}

func (o *InputConfluentCloud) GetTLS() *InputConfluentCloudTLSSettingsClientSide {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputConfluentCloud) GetTopics() []string {
	if o == nil {
		return nil
	}
	return o.Topics
}

func (o *InputConfluentCloud) GetGroupID() *string {
	if o == nil {
		return nil
	}
	return o.GroupID
}

func (o *InputConfluentCloud) GetFromBeginning() *bool {
	if o == nil {
		return nil
	}
	return o.FromBeginning
}

func (o *InputConfluentCloud) GetKafkaSchemaRegistry() *InputConfluentCloudKafkaSchemaRegistryAuthentication {
	if o == nil {
		return nil
	}
	return o.KafkaSchemaRegistry
}

func (o *InputConfluentCloud) GetConnectionTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.ConnectionTimeout
}

func (o *InputConfluentCloud) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *InputConfluentCloud) GetMaxRetries() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxRetries
}

func (o *InputConfluentCloud) GetMaxBackOff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackOff
}

func (o *InputConfluentCloud) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *InputConfluentCloud) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *InputConfluentCloud) GetAuthenticationTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.AuthenticationTimeout
}

func (o *InputConfluentCloud) GetReauthenticationThreshold() *float64 {
	if o == nil {
		return nil
	}
	return o.ReauthenticationThreshold
}

func (o *InputConfluentCloud) GetSasl() *InputConfluentCloudAuthentication {
	if o == nil {
		return nil
	}
	return o.Sasl
}

func (o *InputConfluentCloud) GetSessionTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SessionTimeout
}

func (o *InputConfluentCloud) GetRebalanceTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RebalanceTimeout
}

func (o *InputConfluentCloud) GetHeartbeatInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.HeartbeatInterval
}

func (o *InputConfluentCloud) GetAutoCommitInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.AutoCommitInterval
}

func (o *InputConfluentCloud) GetAutoCommitThreshold() *float64 {
	if o == nil {
		return nil
	}
	return o.AutoCommitThreshold
}

func (o *InputConfluentCloud) GetMaxBytesPerPartition() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBytesPerPartition
}

func (o *InputConfluentCloud) GetMaxBytes() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBytes
}

func (o *InputConfluentCloud) GetMaxSocketErrors() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxSocketErrors
}

func (o *InputConfluentCloud) GetMetadata() []InputConfluentCloudMetadata {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputConfluentCloud) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputConfluentCloud) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputElasticType string

const (
	InputElasticTypeElastic InputElasticType = "elastic"
)

func (e InputElasticType) ToPointer() *InputElasticType {
	return &e
}
func (e *InputElasticType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "elastic":
		*e = InputElasticType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputElasticType: %v", v)
	}
}

type InputElasticConnections struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *InputElasticConnections) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputElasticConnections) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// InputElasticMode - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputElasticMode string

const (
	InputElasticModeSmart  InputElasticMode = "smart"
	InputElasticModeAlways InputElasticMode = "always"
)

func (e InputElasticMode) ToPointer() *InputElasticMode {
	return &e
}
func (e *InputElasticMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputElasticMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputElasticMode: %v", v)
	}
}

// InputElasticCompression - Codec to use to compress the persisted data
type InputElasticCompression string

const (
	InputElasticCompressionNone InputElasticCompression = "none"
	InputElasticCompressionGzip InputElasticCompression = "gzip"
)

func (e InputElasticCompression) ToPointer() *InputElasticCompression {
	return &e
}
func (e *InputElasticCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputElasticCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputElasticCompression: %v", v)
	}
}

type InputElasticPq struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputElasticMode `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *InputElasticCompression `default:"none" json:"compress"`
}

func (i InputElasticPq) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputElasticPq) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputElasticPq) GetMode() *InputElasticMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputElasticPq) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputElasticPq) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *InputElasticPq) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *InputElasticPq) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *InputElasticPq) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *InputElasticPq) GetCompress() *InputElasticCompression {
	if o == nil {
		return nil
	}
	return o.Compress
}

// InputElasticMinimumTLSVersion - Minimum TLS version to accept from connections
type InputElasticMinimumTLSVersion string

const (
	InputElasticMinimumTLSVersionTlSv1  InputElasticMinimumTLSVersion = "TLSv1"
	InputElasticMinimumTLSVersionTlSv11 InputElasticMinimumTLSVersion = "TLSv1.1"
	InputElasticMinimumTLSVersionTlSv12 InputElasticMinimumTLSVersion = "TLSv1.2"
	InputElasticMinimumTLSVersionTlSv13 InputElasticMinimumTLSVersion = "TLSv1.3"
)

func (e InputElasticMinimumTLSVersion) ToPointer() *InputElasticMinimumTLSVersion {
	return &e
}
func (e *InputElasticMinimumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputElasticMinimumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputElasticMinimumTLSVersion: %v", v)
	}
}

// InputElasticMaximumTLSVersion - Maximum TLS version to accept from connections
type InputElasticMaximumTLSVersion string

const (
	InputElasticMaximumTLSVersionTlSv1  InputElasticMaximumTLSVersion = "TLSv1"
	InputElasticMaximumTLSVersionTlSv11 InputElasticMaximumTLSVersion = "TLSv1.1"
	InputElasticMaximumTLSVersionTlSv12 InputElasticMaximumTLSVersion = "TLSv1.2"
	InputElasticMaximumTLSVersionTlSv13 InputElasticMaximumTLSVersion = "TLSv1.3"
)

func (e InputElasticMaximumTLSVersion) ToPointer() *InputElasticMaximumTLSVersion {
	return &e
}
func (e *InputElasticMaximumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputElasticMaximumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputElasticMaximumTLSVersion: %v", v)
	}
}

type InputElasticTLSSettingsServerSide struct {
	Disabled *bool `default:"true" json:"disabled"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert        *bool `default:"false" json:"requestCert"`
	RejectUnauthorized any   `json:"rejectUnauthorized,omitempty"`
	CommonNameRegex    any   `json:"commonNameRegex,omitempty"`
	// Minimum TLS version to accept from connections
	MinVersion *InputElasticMinimumTLSVersion `json:"minVersion,omitempty"`
	// Maximum TLS version to accept from connections
	MaxVersion *InputElasticMaximumTLSVersion `json:"maxVersion,omitempty"`
}

func (i InputElasticTLSSettingsServerSide) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputElasticTLSSettingsServerSide) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputElasticTLSSettingsServerSide) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputElasticTLSSettingsServerSide) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *InputElasticTLSSettingsServerSide) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *InputElasticTLSSettingsServerSide) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *InputElasticTLSSettingsServerSide) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *InputElasticTLSSettingsServerSide) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *InputElasticTLSSettingsServerSide) GetRequestCert() *bool {
	if o == nil {
		return nil
	}
	return o.RequestCert
}

func (o *InputElasticTLSSettingsServerSide) GetRejectUnauthorized() any {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *InputElasticTLSSettingsServerSide) GetCommonNameRegex() any {
	if o == nil {
		return nil
	}
	return o.CommonNameRegex
}

func (o *InputElasticTLSSettingsServerSide) GetMinVersion() *InputElasticMinimumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *InputElasticTLSSettingsServerSide) GetMaxVersion() *InputElasticMaximumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

// InputElasticAuthenticationType - Elastic authentication type
type InputElasticAuthenticationType string

const (
	InputElasticAuthenticationTypeNone              InputElasticAuthenticationType = "none"
	InputElasticAuthenticationTypeBasic             InputElasticAuthenticationType = "basic"
	InputElasticAuthenticationTypeCredentialsSecret InputElasticAuthenticationType = "credentialsSecret"
	InputElasticAuthenticationTypeAuthTokens        InputElasticAuthenticationType = "authTokens"
)

func (e InputElasticAuthenticationType) ToPointer() *InputElasticAuthenticationType {
	return &e
}
func (e *InputElasticAuthenticationType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "basic":
		fallthrough
	case "credentialsSecret":
		fallthrough
	case "authTokens":
		*e = InputElasticAuthenticationType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputElasticAuthenticationType: %v", v)
	}
}

// APIVersion - The API version to use for communicating with the server.
type APIVersion string

const (
	APIVersionSixDot8Dot4   APIVersion = "6.8.4"
	APIVersionEightDot3Dot2 APIVersion = "8.3.2"
	APIVersionCustom        APIVersion = "custom"
)

func (e APIVersion) ToPointer() *APIVersion {
	return &e
}
func (e *APIVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "6.8.4":
		fallthrough
	case "8.3.2":
		fallthrough
	case "custom":
		*e = APIVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for APIVersion: %v", v)
	}
}

type ExtraHTTPHeaders struct {
	// Field name
	Name *string `json:"name,omitempty"`
	// Field value
	Value string `json:"value"`
}

func (o *ExtraHTTPHeaders) GetName() *string {
	if o == nil {
		return nil
	}
	return o.Name
}

func (o *ExtraHTTPHeaders) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputElasticMetadata struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputElasticMetadata) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputElasticMetadata) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// InputElasticAuthenticationMethod - Enter credentials directly, or select a stored secret
type InputElasticAuthenticationMethod string

const (
	InputElasticAuthenticationMethodNone   InputElasticAuthenticationMethod = "none"
	InputElasticAuthenticationMethodManual InputElasticAuthenticationMethod = "manual"
	InputElasticAuthenticationMethodSecret InputElasticAuthenticationMethod = "secret"
)

func (e InputElasticAuthenticationMethod) ToPointer() *InputElasticAuthenticationMethod {
	return &e
}
func (e *InputElasticAuthenticationMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "manual":
		fallthrough
	case "secret":
		*e = InputElasticAuthenticationMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputElasticAuthenticationMethod: %v", v)
	}
}

type ProxyMode struct {
	// Enable proxying of non-bulk API requests to an external Elastic server. Enable this only if you understand the implications; see docs for more details.
	Enabled *bool `default:"false" json:"enabled"`
	// URL of the Elastic server to proxy non-bulk requests to, e.g., http://elastic:9200
	URL *string `json:"url,omitempty"`
	// Whether to reject certificates that cannot be verified against a valid CA (e.g., self-signed certificates).
	RejectUnauthorized *bool `default:"false" json:"rejectUnauthorized"`
	// List of headers to remove from the request to proxy
	RemoveHeaders []string `json:"removeHeaders,omitempty"`
	// Amount of time, in seconds, to wait for a proxy request to complete before canceling it.
	TimeoutSec *float64 `default:"60" json:"timeoutSec"`
	// Enter credentials directly, or select a stored secret
	AuthType *InputElasticAuthenticationMethod `default:"none" json:"authType"`
}

func (p ProxyMode) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *ProxyMode) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *ProxyMode) GetEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.Enabled
}

func (o *ProxyMode) GetURL() *string {
	if o == nil {
		return nil
	}
	return o.URL
}

func (o *ProxyMode) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *ProxyMode) GetRemoveHeaders() []string {
	if o == nil {
		return nil
	}
	return o.RemoveHeaders
}

func (o *ProxyMode) GetTimeoutSec() *float64 {
	if o == nil {
		return nil
	}
	return o.TimeoutSec
}

func (o *ProxyMode) GetAuthType() *InputElasticAuthenticationMethod {
	if o == nil {
		return nil
	}
	return o.AuthType
}

type InputElastic struct {
	// Unique ID for this input
	ID       *string           `json:"id,omitempty"`
	Type     *InputElasticType `json:"type,omitempty"`
	Disabled *bool             `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputElasticConnections `json:"connections,omitempty"`
	Pq          *InputElasticPq           `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port float64                            `json:"port"`
	TLS  *InputElasticTLSSettingsServerSide `json:"tls,omitempty"`
	// Maximum number of active requests per Worker Process. Use 0 for unlimited.
	MaxActiveReq *float64 `default:"256" json:"maxActiveReq"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket *int64 `default:"0" json:"maxRequestsPerSocket"`
	// Enable when clients are connecting through a proxy that supports the x-forwarded-for header to keep the client's original IP address on the event instead of the proxy's IP address
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Add request headers to events, in the __headers field
	CaptureHeaders *bool `default:"false" json:"captureHeaders"`
	// How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
	ActivityLogSampleRate *float64 `default:"100" json:"activityLogSampleRate"`
	// How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
	RequestTimeout *float64 `default:"0" json:"requestTimeout"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `default:"0" json:"socketTimeout"`
	// After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 sec.; maximum 600 sec. (10 min.).
	KeepAliveTimeout *float64 `default:"5" json:"keepAliveTimeout"`
	// Enable to expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
	EnableHealthCheck *bool `default:"false" json:"enableHealthCheck"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist
	IPAllowlistRegex *string `default:"/.*/" json:"ipAllowlistRegex"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `default:"/^\\$/" json:"ipDenylistRegex"`
	// Absolute path on which to listen for Elasticsearch API requests. Defaults to /. _bulk will be appended automatically, e.g., /myPath becomes /myPath/_bulk. Requests can then be made to either /myPath/_bulk or /myPath/<myIndexName>/_bulk. Other entries are faked as success.
	ElasticAPI *string `default:"/" json:"elasticAPI"`
	// Elastic authentication type
	AuthType *InputElasticAuthenticationType `default:"none" json:"authType"`
	// The API version to use for communicating with the server.
	APIVersion *APIVersion `default:"8.3.2" json:"apiVersion"`
	// Headers to add to all events.
	ExtraHTTPHeaders []ExtraHTTPHeaders `json:"extraHttpHeaders,omitempty"`
	// Fields to add to events from this input
	Metadata []InputElasticMetadata `json:"metadata,omitempty"`
	// Whether to ignore extra HTTP headers that don't start with X- or x-
	IgnoreStandardHeaders *bool      `default:"false" json:"ignoreStandardHeaders"`
	ProxyMode             *ProxyMode `json:"proxyMode,omitempty"`
	Description           *string    `json:"description,omitempty"`
	// Username for Basic authentication
	Username *string `json:"username,omitempty"`
	// Password for Basic authentication
	Password *string `json:"password,omitempty"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
	// Bearer tokens to include in the authorization header
	AuthTokens []string `json:"authTokens,omitempty"`
	// Custom version information to respond to requests
	CustomAPIVersion *string   `default:"{\n    \"name\": \"AzU84iL\",\n    \"cluster_name\": \"cribl\",\n    \"cluster_uuid\": \"Js6_Z2VKS3KbfRSxPmPbaw\",\n    \"version\": {\n        \"number\": \"8.3.2\",\n        \"build_type\": \"tar\",\n        \"build_hash\": \"bca0c8d\",\n        \"build_date\": \"2019-10-16T06:19:49.319352Z\",\n        \"build_snapshot\": false,\n        \"lucene_version\": \"9.7.2\",\n        \"minimum_wire_compatibility_version\": \"7.17.0\",\n        \"minimum_index_compatibility_version\": \"7.0.0\"\n    },\n    \"tagline\": \"You Know, for Search\"\n}" json:"customAPIVersion"`
	Status           *TFStatus `json:"status,omitempty"`
}

func (i InputElastic) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputElastic) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputElastic) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputElastic) GetType() *InputElasticType {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputElastic) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputElastic) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputElastic) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputElastic) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputElastic) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputElastic) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputElastic) GetConnections() []InputElasticConnections {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputElastic) GetPq() *InputElasticPq {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputElastic) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputElastic) GetPort() float64 {
	if o == nil {
		return 0.0
	}
	return o.Port
}

func (o *InputElastic) GetTLS() *InputElasticTLSSettingsServerSide {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputElastic) GetMaxActiveReq() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxActiveReq
}

func (o *InputElastic) GetMaxRequestsPerSocket() *int64 {
	if o == nil {
		return nil
	}
	return o.MaxRequestsPerSocket
}

func (o *InputElastic) GetEnableProxyHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableProxyHeader
}

func (o *InputElastic) GetCaptureHeaders() *bool {
	if o == nil {
		return nil
	}
	return o.CaptureHeaders
}

func (o *InputElastic) GetActivityLogSampleRate() *float64 {
	if o == nil {
		return nil
	}
	return o.ActivityLogSampleRate
}

func (o *InputElastic) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *InputElastic) GetSocketTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketTimeout
}

func (o *InputElastic) GetKeepAliveTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.KeepAliveTimeout
}

func (o *InputElastic) GetEnableHealthCheck() *bool {
	if o == nil {
		return nil
	}
	return o.EnableHealthCheck
}

func (o *InputElastic) GetIPAllowlistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPAllowlistRegex
}

func (o *InputElastic) GetIPDenylistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPDenylistRegex
}

func (o *InputElastic) GetElasticAPI() *string {
	if o == nil {
		return nil
	}
	return o.ElasticAPI
}

func (o *InputElastic) GetAuthType() *InputElasticAuthenticationType {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *InputElastic) GetAPIVersion() *APIVersion {
	if o == nil {
		return nil
	}
	return o.APIVersion
}

func (o *InputElastic) GetExtraHTTPHeaders() []ExtraHTTPHeaders {
	if o == nil {
		return nil
	}
	return o.ExtraHTTPHeaders
}

func (o *InputElastic) GetMetadata() []InputElasticMetadata {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputElastic) GetIgnoreStandardHeaders() *bool {
	if o == nil {
		return nil
	}
	return o.IgnoreStandardHeaders
}

func (o *InputElastic) GetProxyMode() *ProxyMode {
	if o == nil {
		return nil
	}
	return o.ProxyMode
}

func (o *InputElastic) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputElastic) GetUsername() *string {
	if o == nil {
		return nil
	}
	return o.Username
}

func (o *InputElastic) GetPassword() *string {
	if o == nil {
		return nil
	}
	return o.Password
}

func (o *InputElastic) GetCredentialsSecret() *string {
	if o == nil {
		return nil
	}
	return o.CredentialsSecret
}

func (o *InputElastic) GetAuthTokens() []string {
	if o == nil {
		return nil
	}
	return o.AuthTokens
}

func (o *InputElastic) GetCustomAPIVersion() *string {
	if o == nil {
		return nil
	}
	return o.CustomAPIVersion
}

func (o *InputElastic) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputAzureBlobType string

const (
	InputAzureBlobTypeAzureBlob InputAzureBlobType = "azure_blob"
)

func (e InputAzureBlobType) ToPointer() *InputAzureBlobType {
	return &e
}
func (e *InputAzureBlobType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "azure_blob":
		*e = InputAzureBlobType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputAzureBlobType: %v", v)
	}
}

type InputAzureBlobConnections struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *InputAzureBlobConnections) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputAzureBlobConnections) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// InputAzureBlobMode - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputAzureBlobMode string

const (
	InputAzureBlobModeSmart  InputAzureBlobMode = "smart"
	InputAzureBlobModeAlways InputAzureBlobMode = "always"
)

func (e InputAzureBlobMode) ToPointer() *InputAzureBlobMode {
	return &e
}
func (e *InputAzureBlobMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputAzureBlobMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputAzureBlobMode: %v", v)
	}
}

// InputAzureBlobCompression - Codec to use to compress the persisted data
type InputAzureBlobCompression string

const (
	InputAzureBlobCompressionNone InputAzureBlobCompression = "none"
	InputAzureBlobCompressionGzip InputAzureBlobCompression = "gzip"
)

func (e InputAzureBlobCompression) ToPointer() *InputAzureBlobCompression {
	return &e
}
func (e *InputAzureBlobCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputAzureBlobCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputAzureBlobCompression: %v", v)
	}
}

type InputAzureBlobPq struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputAzureBlobMode `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *InputAzureBlobCompression `default:"none" json:"compress"`
}

func (i InputAzureBlobPq) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputAzureBlobPq) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputAzureBlobPq) GetMode() *InputAzureBlobMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputAzureBlobPq) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputAzureBlobPq) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *InputAzureBlobPq) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *InputAzureBlobPq) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *InputAzureBlobPq) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *InputAzureBlobPq) GetCompress() *InputAzureBlobCompression {
	if o == nil {
		return nil
	}
	return o.Compress
}

type InputAzureBlobMetadata struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputAzureBlobMetadata) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputAzureBlobMetadata) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// InputAzureBlobAuthenticationMethod - Enter connection string directly, or select a stored secret
type InputAzureBlobAuthenticationMethod string

const (
	InputAzureBlobAuthenticationMethodManual       InputAzureBlobAuthenticationMethod = "manual"
	InputAzureBlobAuthenticationMethodSecret       InputAzureBlobAuthenticationMethod = "secret"
	InputAzureBlobAuthenticationMethodClientSecret InputAzureBlobAuthenticationMethod = "clientSecret"
	InputAzureBlobAuthenticationMethodClientCert   InputAzureBlobAuthenticationMethod = "clientCert"
)

func (e InputAzureBlobAuthenticationMethod) ToPointer() *InputAzureBlobAuthenticationMethod {
	return &e
}
func (e *InputAzureBlobAuthenticationMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "manual":
		fallthrough
	case "secret":
		fallthrough
	case "clientSecret":
		fallthrough
	case "clientCert":
		*e = InputAzureBlobAuthenticationMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputAzureBlobAuthenticationMethod: %v", v)
	}
}

type InputAzureBlobCertificate struct {
	// The certificate you registered as credentials for your app in the Azure portal
	CertificateName string `json:"certificateName"`
}

func (o *InputAzureBlobCertificate) GetCertificateName() string {
	if o == nil {
		return ""
	}
	return o.CertificateName
}

type InputAzureBlob struct {
	// Unique ID for this input
	ID       *string            `json:"id,omitempty"`
	Type     InputAzureBlobType `json:"type"`
	Disabled *bool              `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputAzureBlobConnections `json:"connections,omitempty"`
	Pq          *InputAzureBlobPq           `json:"pq,omitempty"`
	// The storage account queue name blob notifications will be read from. Value must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at init time. E.g., referencing a Global Variable: `myQueue-${C.vars.myVar}`
	QueueName string `json:"queueName"`
	// Regex matching file names to download and process. Defaults to: .*
	FileFilter *string `default:"/.*/" json:"fileFilter"`
	// The duration (in seconds) that the received messages are hidden from subsequent retrieve requests after being retrieved by a ReceiveMessage request.
	VisibilityTimeout *float64 `default:"600" json:"visibilityTimeout"`
	// How many receiver processes to run. The higher the number, the better the throughput - at the expense of CPU overhead.
	NumReceivers *float64 `default:"1" json:"numReceivers"`
	// The maximum number of messages to return in a poll request. Azure storage queues never returns more messages than this value (however, fewer messages might be returned). Valid values: 1 to 32.
	MaxMessages *float64 `default:"1" json:"maxMessages"`
	// The duration (in seconds) which pollers should be validated and restarted if exited
	ServicePeriodSecs *float64 `default:"5" json:"servicePeriodSecs"`
	// Skip files that trigger a processing error. Disabled by default, which allows retries after processing errors.
	SkipOnError *bool `default:"false" json:"skipOnError"`
	// Fields to add to events from this input
	Metadata []InputAzureBlobMetadata `json:"metadata,omitempty"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitempty"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `default:"10000" json:"staleChannelFlushMs"`
	// Maximum file size for each Parquet chunk
	ParquetChunkSizeMB *float64 `default:"5" json:"parquetChunkSizeMB"`
	// The maximum time allowed for downloading a Parquet chunk. Processing will stop if a chunk cannot be downloaded within the time specified.
	ParquetChunkDownloadTimeout *float64 `default:"600" json:"parquetChunkDownloadTimeout"`
	// Enter connection string directly, or select a stored secret
	AuthType    *InputAzureBlobAuthenticationMethod `default:"manual" json:"authType"`
	Description *string                             `json:"description,omitempty"`
	// Enter your Azure Storage account connection string. If left blank, Stream will fall back to env.AZURE_STORAGE_CONNECTION_STRING.
	ConnectionString *string `json:"connectionString,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// The name of your Azure storage account
	StorageAccountName *string `json:"storageAccountName,omitempty"`
	// The service principal's tenant ID
	TenantID *string `json:"tenantId,omitempty"`
	// The service principal's client ID
	ClientID *string `json:"clientId,omitempty"`
	// Endpoint suffix for the service URL. Defaults to core.windows.net.
	EndpointSuffix *string `json:"endpointSuffix,omitempty"`
	// Select or create a stored text secret
	ClientTextSecret *string                    `json:"clientTextSecret,omitempty"`
	Certificate      *InputAzureBlobCertificate `json:"certificate,omitempty"`
	Status           *TFStatus                  `json:"status,omitempty"`
}

func (i InputAzureBlob) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputAzureBlob) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputAzureBlob) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputAzureBlob) GetType() InputAzureBlobType {
	if o == nil {
		return InputAzureBlobType("")
	}
	return o.Type
}

func (o *InputAzureBlob) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputAzureBlob) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputAzureBlob) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputAzureBlob) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputAzureBlob) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputAzureBlob) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputAzureBlob) GetConnections() []InputAzureBlobConnections {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputAzureBlob) GetPq() *InputAzureBlobPq {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputAzureBlob) GetQueueName() string {
	if o == nil {
		return ""
	}
	return o.QueueName
}

func (o *InputAzureBlob) GetFileFilter() *string {
	if o == nil {
		return nil
	}
	return o.FileFilter
}

func (o *InputAzureBlob) GetVisibilityTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.VisibilityTimeout
}

func (o *InputAzureBlob) GetNumReceivers() *float64 {
	if o == nil {
		return nil
	}
	return o.NumReceivers
}

func (o *InputAzureBlob) GetMaxMessages() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxMessages
}

func (o *InputAzureBlob) GetServicePeriodSecs() *float64 {
	if o == nil {
		return nil
	}
	return o.ServicePeriodSecs
}

func (o *InputAzureBlob) GetSkipOnError() *bool {
	if o == nil {
		return nil
	}
	return o.SkipOnError
}

func (o *InputAzureBlob) GetMetadata() []InputAzureBlobMetadata {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputAzureBlob) GetBreakerRulesets() []string {
	if o == nil {
		return nil
	}
	return o.BreakerRulesets
}

func (o *InputAzureBlob) GetStaleChannelFlushMs() *float64 {
	if o == nil {
		return nil
	}
	return o.StaleChannelFlushMs
}

func (o *InputAzureBlob) GetParquetChunkSizeMB() *float64 {
	if o == nil {
		return nil
	}
	return o.ParquetChunkSizeMB
}

func (o *InputAzureBlob) GetParquetChunkDownloadTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.ParquetChunkDownloadTimeout
}

func (o *InputAzureBlob) GetAuthType() *InputAzureBlobAuthenticationMethod {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *InputAzureBlob) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputAzureBlob) GetConnectionString() *string {
	if o == nil {
		return nil
	}
	return o.ConnectionString
}

func (o *InputAzureBlob) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *InputAzureBlob) GetStorageAccountName() *string {
	if o == nil {
		return nil
	}
	return o.StorageAccountName
}

func (o *InputAzureBlob) GetTenantID() *string {
	if o == nil {
		return nil
	}
	return o.TenantID
}

func (o *InputAzureBlob) GetClientID() *string {
	if o == nil {
		return nil
	}
	return o.ClientID
}

func (o *InputAzureBlob) GetEndpointSuffix() *string {
	if o == nil {
		return nil
	}
	return o.EndpointSuffix
}

func (o *InputAzureBlob) GetClientTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.ClientTextSecret
}

func (o *InputAzureBlob) GetCertificate() *InputAzureBlobCertificate {
	if o == nil {
		return nil
	}
	return o.Certificate
}

func (o *InputAzureBlob) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputSplunkHecType string

const (
	InputSplunkHecTypeSplunkHec InputSplunkHecType = "splunk_hec"
)

func (e InputSplunkHecType) ToPointer() *InputSplunkHecType {
	return &e
}
func (e *InputSplunkHecType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "splunk_hec":
		*e = InputSplunkHecType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSplunkHecType: %v", v)
	}
}

type InputSplunkHecConnections struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *InputSplunkHecConnections) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputSplunkHecConnections) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// InputSplunkHecMode - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputSplunkHecMode string

const (
	InputSplunkHecModeSmart  InputSplunkHecMode = "smart"
	InputSplunkHecModeAlways InputSplunkHecMode = "always"
)

func (e InputSplunkHecMode) ToPointer() *InputSplunkHecMode {
	return &e
}
func (e *InputSplunkHecMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputSplunkHecMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSplunkHecMode: %v", v)
	}
}

// InputSplunkHecCompression - Codec to use to compress the persisted data
type InputSplunkHecCompression string

const (
	InputSplunkHecCompressionNone InputSplunkHecCompression = "none"
	InputSplunkHecCompressionGzip InputSplunkHecCompression = "gzip"
)

func (e InputSplunkHecCompression) ToPointer() *InputSplunkHecCompression {
	return &e
}
func (e *InputSplunkHecCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputSplunkHecCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSplunkHecCompression: %v", v)
	}
}

type InputSplunkHecPq struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputSplunkHecMode `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *InputSplunkHecCompression `default:"none" json:"compress"`
}

func (i InputSplunkHecPq) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSplunkHecPq) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputSplunkHecPq) GetMode() *InputSplunkHecMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputSplunkHecPq) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputSplunkHecPq) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *InputSplunkHecPq) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *InputSplunkHecPq) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *InputSplunkHecPq) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *InputSplunkHecPq) GetCompress() *InputSplunkHecCompression {
	if o == nil {
		return nil
	}
	return o.Compress
}

// InputSplunkHecAuthenticationMethod - Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
type InputSplunkHecAuthenticationMethod string

const (
	InputSplunkHecAuthenticationMethodManual InputSplunkHecAuthenticationMethod = "manual"
	InputSplunkHecAuthenticationMethodSecret InputSplunkHecAuthenticationMethod = "secret"
)

func (e InputSplunkHecAuthenticationMethod) ToPointer() *InputSplunkHecAuthenticationMethod {
	return &e
}
func (e *InputSplunkHecAuthenticationMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "manual":
		fallthrough
	case "secret":
		*e = InputSplunkHecAuthenticationMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSplunkHecAuthenticationMethod: %v", v)
	}
}

type InputSplunkHecInputMetadata struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputSplunkHecInputMetadata) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputSplunkHecInputMetadata) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputSplunkHecAuthTokens struct {
	// Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
	AuthType    *InputSplunkHecAuthenticationMethod `default:"manual" json:"authType"`
	TokenSecret any                                 `json:"tokenSecret,omitempty"`
	Token       any                                 `json:"token"`
	Enabled     *bool                               `default:"true" json:"enabled"`
	// Optional token description
	Description *string `json:"description,omitempty"`
	// Enter the values you want to allow in the HEC event index field at the token level. Supports wildcards. To skip validation, leave blank.
	AllowedIndexesAtToken []string `json:"allowedIndexesAtToken,omitempty"`
	// Fields to add to events referencing this token
	Metadata []InputSplunkHecInputMetadata `json:"metadata,omitempty"`
}

func (i InputSplunkHecAuthTokens) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSplunkHecAuthTokens) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputSplunkHecAuthTokens) GetAuthType() *InputSplunkHecAuthenticationMethod {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *InputSplunkHecAuthTokens) GetTokenSecret() any {
	if o == nil {
		return nil
	}
	return o.TokenSecret
}

func (o *InputSplunkHecAuthTokens) GetToken() any {
	if o == nil {
		return nil
	}
	return o.Token
}

func (o *InputSplunkHecAuthTokens) GetEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.Enabled
}

func (o *InputSplunkHecAuthTokens) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputSplunkHecAuthTokens) GetAllowedIndexesAtToken() []string {
	if o == nil {
		return nil
	}
	return o.AllowedIndexesAtToken
}

func (o *InputSplunkHecAuthTokens) GetMetadata() []InputSplunkHecInputMetadata {
	if o == nil {
		return nil
	}
	return o.Metadata
}

// InputSplunkHecMinimumTLSVersion - Minimum TLS version to accept from connections
type InputSplunkHecMinimumTLSVersion string

const (
	InputSplunkHecMinimumTLSVersionTlSv1  InputSplunkHecMinimumTLSVersion = "TLSv1"
	InputSplunkHecMinimumTLSVersionTlSv11 InputSplunkHecMinimumTLSVersion = "TLSv1.1"
	InputSplunkHecMinimumTLSVersionTlSv12 InputSplunkHecMinimumTLSVersion = "TLSv1.2"
	InputSplunkHecMinimumTLSVersionTlSv13 InputSplunkHecMinimumTLSVersion = "TLSv1.3"
)

func (e InputSplunkHecMinimumTLSVersion) ToPointer() *InputSplunkHecMinimumTLSVersion {
	return &e
}
func (e *InputSplunkHecMinimumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputSplunkHecMinimumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSplunkHecMinimumTLSVersion: %v", v)
	}
}

// InputSplunkHecMaximumTLSVersion - Maximum TLS version to accept from connections
type InputSplunkHecMaximumTLSVersion string

const (
	InputSplunkHecMaximumTLSVersionTlSv1  InputSplunkHecMaximumTLSVersion = "TLSv1"
	InputSplunkHecMaximumTLSVersionTlSv11 InputSplunkHecMaximumTLSVersion = "TLSv1.1"
	InputSplunkHecMaximumTLSVersionTlSv12 InputSplunkHecMaximumTLSVersion = "TLSv1.2"
	InputSplunkHecMaximumTLSVersionTlSv13 InputSplunkHecMaximumTLSVersion = "TLSv1.3"
)

func (e InputSplunkHecMaximumTLSVersion) ToPointer() *InputSplunkHecMaximumTLSVersion {
	return &e
}
func (e *InputSplunkHecMaximumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputSplunkHecMaximumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSplunkHecMaximumTLSVersion: %v", v)
	}
}

type InputSplunkHecTLSSettingsServerSide struct {
	Disabled *bool `default:"true" json:"disabled"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert        *bool `default:"false" json:"requestCert"`
	RejectUnauthorized any   `json:"rejectUnauthorized,omitempty"`
	CommonNameRegex    any   `json:"commonNameRegex,omitempty"`
	// Minimum TLS version to accept from connections
	MinVersion *InputSplunkHecMinimumTLSVersion `json:"minVersion,omitempty"`
	// Maximum TLS version to accept from connections
	MaxVersion *InputSplunkHecMaximumTLSVersion `json:"maxVersion,omitempty"`
}

func (i InputSplunkHecTLSSettingsServerSide) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSplunkHecTLSSettingsServerSide) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputSplunkHecTLSSettingsServerSide) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputSplunkHecTLSSettingsServerSide) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *InputSplunkHecTLSSettingsServerSide) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *InputSplunkHecTLSSettingsServerSide) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *InputSplunkHecTLSSettingsServerSide) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *InputSplunkHecTLSSettingsServerSide) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *InputSplunkHecTLSSettingsServerSide) GetRequestCert() *bool {
	if o == nil {
		return nil
	}
	return o.RequestCert
}

func (o *InputSplunkHecTLSSettingsServerSide) GetRejectUnauthorized() any {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *InputSplunkHecTLSSettingsServerSide) GetCommonNameRegex() any {
	if o == nil {
		return nil
	}
	return o.CommonNameRegex
}

func (o *InputSplunkHecTLSSettingsServerSide) GetMinVersion() *InputSplunkHecMinimumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *InputSplunkHecTLSSettingsServerSide) GetMaxVersion() *InputSplunkHecMaximumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

type InputSplunkHecMetadata struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputSplunkHecMetadata) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputSplunkHecMetadata) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputSplunkHec struct {
	// Unique ID for this input
	ID       *string             `json:"id,omitempty"`
	Type     *InputSplunkHecType `json:"type,omitempty"`
	Disabled *bool               `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputSplunkHecConnections `json:"connections,omitempty"`
	Pq          *InputSplunkHecPq           `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port float64 `json:"port"`
	// Shared secrets to be provided by any client (Authorization: <token>). If empty, unauthorized access is permitted.
	AuthTokens []InputSplunkHecAuthTokens           `json:"authTokens,omitempty"`
	TLS        *InputSplunkHecTLSSettingsServerSide `json:"tls,omitempty"`
	// Maximum number of active requests per Worker Process. Use 0 for unlimited.
	MaxActiveReq *float64 `default:"256" json:"maxActiveReq"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket *int64 `default:"0" json:"maxRequestsPerSocket"`
	// Enable when clients are connecting through a proxy that supports the x-forwarded-for header to keep the client's original IP address on the event instead of the proxy's IP address
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Add request headers to events, in the __headers field
	CaptureHeaders *bool `default:"false" json:"captureHeaders"`
	// How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
	ActivityLogSampleRate *float64 `default:"100" json:"activityLogSampleRate"`
	// How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
	RequestTimeout *float64 `default:"0" json:"requestTimeout"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `default:"0" json:"socketTimeout"`
	// After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 sec.; maximum 600 sec. (10 min.).
	KeepAliveTimeout  *float64 `default:"5" json:"keepAliveTimeout"`
	EnableHealthCheck any      `json:"enableHealthCheck,omitempty"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist
	IPAllowlistRegex *string `default:"/.*/" json:"ipAllowlistRegex"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `default:"/^\\$/" json:"ipDenylistRegex"`
	// Absolute path on which to listen for the Splunk HTTP Event Collector API requests. This input supports the /event, /raw and /s2s endpoints.
	SplunkHecAPI *string `default:"/services/collector" json:"splunkHecAPI"`
	// Fields to add to every event. Overrides fields added at the token or request level. See [the Source documentation](https://docs.cribl.io/stream/sources-splunk-hec/#fields) for more info.
	Metadata []InputSplunkHecMetadata `json:"metadata,omitempty"`
	// List values allowed in HEC event index field. Leave blank to skip validation. Supports wildcards. The values here can expand index validation at the token level.
	AllowedIndexes []string `json:"allowedIndexes,omitempty"`
	// Enable Splunk HEC acknowledgements
	SplunkHecAcks *bool `default:"false" json:"splunkHecAcks"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitempty"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `default:"10000" json:"staleChannelFlushMs"`
	// Event Breakers will determine events' time zone from UF-provided metadata, when TZ can't be inferred from the raw event
	UseFwdTimezone *bool `default:"true" json:"useFwdTimezone"`
	// Drop Splunk control fields such as `crcSalt` and `_savedPort`. If disabled, control fields are stored in the internal field `__ctrlFields`.
	DropControlFields *bool `default:"true" json:"dropControlFields"`
	// Extract and process Splunk-generated metrics as Cribl metrics
	ExtractMetrics *bool `default:"false" json:"extractMetrics"`
	// Optionally, list HTTP origins to which @{product} should send CORS (cross-origin resource sharing) Access-Control-Allow-* headers. Supports wildcards.
	AccessControlAllowOrigin []string `json:"accessControlAllowOrigin,omitempty"`
	// Optionally, list HTTP headers that @{product} will send to allowed origins as "Access-Control-Allow-Headers" in a CORS preflight response. Use "*" to allow all headers.
	AccessControlAllowHeaders []string `json:"accessControlAllowHeaders,omitempty"`
	// Emit per-token (<prefix>.http.perToken) and summary (<prefix>.http.summary) request metrics
	EmitTokenMetrics *bool     `default:"false" json:"emitTokenMetrics"`
	Description      *string   `json:"description,omitempty"`
	Status           *TFStatus `json:"status,omitempty"`
}

func (i InputSplunkHec) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSplunkHec) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputSplunkHec) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputSplunkHec) GetType() *InputSplunkHecType {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputSplunkHec) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputSplunkHec) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputSplunkHec) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputSplunkHec) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputSplunkHec) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputSplunkHec) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputSplunkHec) GetConnections() []InputSplunkHecConnections {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputSplunkHec) GetPq() *InputSplunkHecPq {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputSplunkHec) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputSplunkHec) GetPort() float64 {
	if o == nil {
		return 0.0
	}
	return o.Port
}

func (o *InputSplunkHec) GetAuthTokens() []InputSplunkHecAuthTokens {
	if o == nil {
		return nil
	}
	return o.AuthTokens
}

func (o *InputSplunkHec) GetTLS() *InputSplunkHecTLSSettingsServerSide {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputSplunkHec) GetMaxActiveReq() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxActiveReq
}

func (o *InputSplunkHec) GetMaxRequestsPerSocket() *int64 {
	if o == nil {
		return nil
	}
	return o.MaxRequestsPerSocket
}

func (o *InputSplunkHec) GetEnableProxyHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableProxyHeader
}

func (o *InputSplunkHec) GetCaptureHeaders() *bool {
	if o == nil {
		return nil
	}
	return o.CaptureHeaders
}

func (o *InputSplunkHec) GetActivityLogSampleRate() *float64 {
	if o == nil {
		return nil
	}
	return o.ActivityLogSampleRate
}

func (o *InputSplunkHec) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *InputSplunkHec) GetSocketTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketTimeout
}

func (o *InputSplunkHec) GetKeepAliveTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.KeepAliveTimeout
}

func (o *InputSplunkHec) GetEnableHealthCheck() any {
	if o == nil {
		return nil
	}
	return o.EnableHealthCheck
}

func (o *InputSplunkHec) GetIPAllowlistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPAllowlistRegex
}

func (o *InputSplunkHec) GetIPDenylistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPDenylistRegex
}

func (o *InputSplunkHec) GetSplunkHecAPI() *string {
	if o == nil {
		return nil
	}
	return o.SplunkHecAPI
}

func (o *InputSplunkHec) GetMetadata() []InputSplunkHecMetadata {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputSplunkHec) GetAllowedIndexes() []string {
	if o == nil {
		return nil
	}
	return o.AllowedIndexes
}

func (o *InputSplunkHec) GetSplunkHecAcks() *bool {
	if o == nil {
		return nil
	}
	return o.SplunkHecAcks
}

func (o *InputSplunkHec) GetBreakerRulesets() []string {
	if o == nil {
		return nil
	}
	return o.BreakerRulesets
}

func (o *InputSplunkHec) GetStaleChannelFlushMs() *float64 {
	if o == nil {
		return nil
	}
	return o.StaleChannelFlushMs
}

func (o *InputSplunkHec) GetUseFwdTimezone() *bool {
	if o == nil {
		return nil
	}
	return o.UseFwdTimezone
}

func (o *InputSplunkHec) GetDropControlFields() *bool {
	if o == nil {
		return nil
	}
	return o.DropControlFields
}

func (o *InputSplunkHec) GetExtractMetrics() *bool {
	if o == nil {
		return nil
	}
	return o.ExtractMetrics
}

func (o *InputSplunkHec) GetAccessControlAllowOrigin() []string {
	if o == nil {
		return nil
	}
	return o.AccessControlAllowOrigin
}

func (o *InputSplunkHec) GetAccessControlAllowHeaders() []string {
	if o == nil {
		return nil
	}
	return o.AccessControlAllowHeaders
}

func (o *InputSplunkHec) GetEmitTokenMetrics() *bool {
	if o == nil {
		return nil
	}
	return o.EmitTokenMetrics
}

func (o *InputSplunkHec) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputSplunkHec) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputSplunkSearchType string

const (
	InputSplunkSearchTypeSplunkSearch InputSplunkSearchType = "splunk_search"
)

func (e InputSplunkSearchType) ToPointer() *InputSplunkSearchType {
	return &e
}
func (e *InputSplunkSearchType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "splunk_search":
		*e = InputSplunkSearchType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSplunkSearchType: %v", v)
	}
}

type InputSplunkSearchConnections struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *InputSplunkSearchConnections) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputSplunkSearchConnections) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// InputSplunkSearchMode - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputSplunkSearchMode string

const (
	InputSplunkSearchModeSmart  InputSplunkSearchMode = "smart"
	InputSplunkSearchModeAlways InputSplunkSearchMode = "always"
)

func (e InputSplunkSearchMode) ToPointer() *InputSplunkSearchMode {
	return &e
}
func (e *InputSplunkSearchMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputSplunkSearchMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSplunkSearchMode: %v", v)
	}
}

// InputSplunkSearchCompression - Codec to use to compress the persisted data
type InputSplunkSearchCompression string

const (
	InputSplunkSearchCompressionNone InputSplunkSearchCompression = "none"
	InputSplunkSearchCompressionGzip InputSplunkSearchCompression = "gzip"
)

func (e InputSplunkSearchCompression) ToPointer() *InputSplunkSearchCompression {
	return &e
}
func (e *InputSplunkSearchCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputSplunkSearchCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSplunkSearchCompression: %v", v)
	}
}

type InputSplunkSearchPq struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputSplunkSearchMode `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *InputSplunkSearchCompression `default:"none" json:"compress"`
}

func (i InputSplunkSearchPq) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSplunkSearchPq) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputSplunkSearchPq) GetMode() *InputSplunkSearchMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputSplunkSearchPq) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputSplunkSearchPq) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *InputSplunkSearchPq) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *InputSplunkSearchPq) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *InputSplunkSearchPq) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *InputSplunkSearchPq) GetCompress() *InputSplunkSearchCompression {
	if o == nil {
		return nil
	}
	return o.Compress
}

// OutputMode - Format of the returned output
type OutputMode string

const (
	OutputModeCsv  OutputMode = "csv"
	OutputModeJSON OutputMode = "json"
)

func (e OutputMode) ToPointer() *OutputMode {
	return &e
}
func (e *OutputMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "csv":
		fallthrough
	case "json":
		*e = OutputMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputMode: %v", v)
	}
}

type EndpointParams struct {
	Name string `json:"name"`
	// JavaScript expression to compute the parameter's value, normally enclosed in backticks (e.g., `${earliest}`). If a constant, use single quotes (e.g., 'earliest'). Values without delimiters (e.g., earliest) are evaluated as strings.
	Value string `json:"value"`
}

func (o *EndpointParams) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *EndpointParams) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type EndpointHeaders struct {
	Name string `json:"name"`
	// JavaScript expression to compute the header's value, normally enclosed in backticks (e.g., `${earliest}`). If a constant, use single quotes (e.g., 'earliest'). Values without delimiters (e.g., earliest) are evaluated as strings.
	Value string `json:"value"`
}

func (o *EndpointHeaders) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *EndpointHeaders) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// InputSplunkSearchLogLevel - Collector runtime log level (verbosity)
type InputSplunkSearchLogLevel string

const (
	InputSplunkSearchLogLevelError InputSplunkSearchLogLevel = "error"
	InputSplunkSearchLogLevelWarn  InputSplunkSearchLogLevel = "warn"
	InputSplunkSearchLogLevelInfo  InputSplunkSearchLogLevel = "info"
	InputSplunkSearchLogLevelDebug InputSplunkSearchLogLevel = "debug"
)

func (e InputSplunkSearchLogLevel) ToPointer() *InputSplunkSearchLogLevel {
	return &e
}
func (e *InputSplunkSearchLogLevel) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "error":
		fallthrough
	case "warn":
		fallthrough
	case "info":
		fallthrough
	case "debug":
		*e = InputSplunkSearchLogLevel(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSplunkSearchLogLevel: %v", v)
	}
}

type InputSplunkSearchMetadata struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputSplunkSearchMetadata) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputSplunkSearchMetadata) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// RetryType - The algorithm to use when performing HTTP retries
type RetryType string

const (
	RetryTypeNone    RetryType = "none"
	RetryTypeBackoff RetryType = "backoff"
	RetryTypeStatic  RetryType = "static"
)

func (e RetryType) ToPointer() *RetryType {
	return &e
}
func (e *RetryType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "backoff":
		fallthrough
	case "static":
		*e = RetryType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for RetryType: %v", v)
	}
}

type RetryRules struct {
	// The algorithm to use when performing HTTP retries
	Type *RetryType `default:"backoff" json:"type"`
	// Time interval between failed request and first retry (kickoff). Maximum allowed value is 20,000 ms (1/3 minute).
	Interval *float64 `default:"1000" json:"interval"`
	// The maximum number of times to retry a failed HTTP request
	Limit *float64 `default:"5" json:"limit"`
	// Base for exponential backoff, e.g., base 2 means that retries will occur after 2, then 4, then 8 seconds, and so on
	Multiplier *float64 `default:"2" json:"multiplier"`
	// List of HTTP codes that trigger a retry. Leave empty to use the default list of 429 and 503.
	Codes []float64 `json:"codes,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) or a timestamp after which to retry the request. The delay is limited to 20 seconds, even if the Retry-After header specifies a longer delay. When disabled, all Retry-After headers are ignored.
	EnableHeader *bool `default:"true" json:"enableHeader"`
	// Make a single retry attempt when a connection timeout (ETIMEDOUT) error occurs
	RetryConnectTimeout *bool `default:"false" json:"retryConnectTimeout"`
	// Retry request when a connection reset (ECONNRESET) error occurs
	RetryConnectReset *bool `default:"false" json:"retryConnectReset"`
}

func (r RetryRules) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(r, "", false)
}

func (r *RetryRules) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &r, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *RetryRules) GetType() *RetryType {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *RetryRules) GetInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.Interval
}

func (o *RetryRules) GetLimit() *float64 {
	if o == nil {
		return nil
	}
	return o.Limit
}

func (o *RetryRules) GetMultiplier() *float64 {
	if o == nil {
		return nil
	}
	return o.Multiplier
}

func (o *RetryRules) GetCodes() []float64 {
	if o == nil {
		return nil
	}
	return o.Codes
}

func (o *RetryRules) GetEnableHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableHeader
}

func (o *RetryRules) GetRetryConnectTimeout() *bool {
	if o == nil {
		return nil
	}
	return o.RetryConnectTimeout
}

func (o *RetryRules) GetRetryConnectReset() *bool {
	if o == nil {
		return nil
	}
	return o.RetryConnectReset
}

// AuthenticationType - Splunk Search authentication type
type AuthenticationType string

const (
	AuthenticationTypeNone              AuthenticationType = "none"
	AuthenticationTypeBasic             AuthenticationType = "basic"
	AuthenticationTypeCredentialsSecret AuthenticationType = "credentialsSecret"
	AuthenticationTypeToken             AuthenticationType = "token"
	AuthenticationTypeTextSecret        AuthenticationType = "textSecret"
	AuthenticationTypeOauth             AuthenticationType = "oauth"
)

func (e AuthenticationType) ToPointer() *AuthenticationType {
	return &e
}
func (e *AuthenticationType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "basic":
		fallthrough
	case "credentialsSecret":
		fallthrough
	case "token":
		fallthrough
	case "textSecret":
		fallthrough
	case "oauth":
		*e = AuthenticationType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for AuthenticationType: %v", v)
	}
}

type OauthParams struct {
	// OAuth parameter name
	Name string `json:"name"`
	// OAuth parameter value
	Value string `json:"value"`
}

func (o *OauthParams) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *OauthParams) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type OauthHeaders struct {
	// OAuth header name
	Name string `json:"name"`
	// OAuth header value
	Value string `json:"value"`
}

func (o *OauthHeaders) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *OauthHeaders) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputSplunkSearch struct {
	// Unique ID for this input
	ID       *string                `json:"id,omitempty"`
	Type     *InputSplunkSearchType `json:"type,omitempty"`
	Disabled *bool                  `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputSplunkSearchConnections `json:"connections,omitempty"`
	Pq          *InputSplunkSearchPq           `json:"pq,omitempty"`
	// Search head base URL. Can be an expression. Default is https://localhost:8089.
	SearchHead *string `default:"https://localhost:8089" json:"searchHead"`
	// Enter Splunk search here. Examples: 'index=myAppLogs level=error channel=myApp' OR '| mstats avg(myStat) as myStat WHERE index=myStatsIndex.'
	Search string `json:"search"`
	// The earliest time boundary for the search. Can be an exact or relative time. Examples: '2022-01-14T12:00:00Z' or '-16m@m'
	Earliest *string `default:"-16m@m" json:"earliest"`
	// The latest time boundary for the search. Can be an exact or relative time. Examples: '2022-01-14T12:00:00Z' or '-1m@m'
	Latest *string `default:"-1m@m" json:"latest"`
	// A cron schedule on which to run this job
	CronSchedule *string `default:"*/15 * * * *" json:"cronSchedule"`
	// REST API used to create a search
	Endpoint *string `default:"/services/search/v2/jobs/export" json:"endpoint"`
	// Format of the returned output
	OutputMode *OutputMode `default:"json" json:"outputMode"`
	// Optional request parameters to send to the endpoint
	EndpointParams []EndpointParams `json:"endpointParams,omitempty"`
	// Optional request headers to send to the endpoint
	EndpointHeaders []EndpointHeaders `json:"endpointHeaders,omitempty"`
	// Collector runtime log level (verbosity)
	LogLevel *InputSplunkSearchLogLevel `json:"logLevel,omitempty"`
	// HTTP request inactivity timeout. Use 0 for no timeout.
	RequestTimeout *float64 `default:"0" json:"requestTimeout"`
	// When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned
	UseRoundRobinDNS *bool `default:"false" json:"useRoundRobinDns"`
	// Reject certificates that cannot be verified against a valid CA (such as self-signed certificates)
	RejectUnauthorized *bool `default:"false" json:"rejectUnauthorized"`
	// Character encoding to use when parsing ingested data. When not set, @{product} will default to UTF-8 but may incorrectly interpret multi-byte characters.
	Encoding *string `json:"encoding,omitempty"`
	// How often workers should check in with the scheduler to keep job subscription alive
	KeepAliveTime *float64 `default:"30" json:"keepAliveTime"`
	// Maximum time the job is allowed to run (e.g., 30, 45s or 15m). Units are seconds, if not specified. Enter 0 for unlimited time.
	JobTimeout *string `default:"0" json:"jobTimeout"`
	// The number of Keep Alive Time periods before an inactive worker will have its job subscription revoked.
	MaxMissedKeepAlives *float64 `default:"3" json:"maxMissedKeepAlives"`
	// Time to keep the job's artifacts on disk after job completion. This also affects how long a job is listed in the Job Inspector.
	TTL *string `default:"4h" json:"ttl"`
	// Fields to add to events from this input
	Metadata   []InputSplunkSearchMetadata `json:"metadata,omitempty"`
	RetryRules *RetryRules                 `json:"retryRules,omitempty"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitempty"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `default:"10000" json:"staleChannelFlushMs"`
	// Splunk Search authentication type
	AuthType    *AuthenticationType `default:"basic" json:"authType"`
	Description *string             `json:"description,omitempty"`
	Username    *string             `json:"username,omitempty"`
	Password    *string             `json:"password,omitempty"`
	// Bearer token to include in the authorization header
	Token *string `json:"token,omitempty"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// URL for OAuth
	LoginURL *string `json:"loginUrl,omitempty"`
	// Secret parameter name to pass in request body
	SecretParamName *string `json:"secretParamName,omitempty"`
	// Secret parameter value to pass in request body
	Secret *string `json:"secret,omitempty"`
	// Name of the auth token attribute in the OAuth response. Can be top-level (e.g., 'token'); or nested, using a period (e.g., 'data.token').
	TokenAttributeName *string `json:"tokenAttributeName,omitempty"`
	// JavaScript expression to compute the Authorization header value to pass in requests. The value `${token}` is used to reference the token obtained from authentication, e.g.: `Bearer ${token}`.
	AuthHeaderExpr *string `default:"Bearer \\${token}" json:"authHeaderExpr"`
	// How often the OAuth token should be refreshed.
	TokenTimeoutSecs *float64 `default:"3600" json:"tokenTimeoutSecs"`
	// Additional parameters to send in the OAuth login request. @{product} will combine the secret with these parameters, and will send the URL-encoded result in a POST request to the endpoint specified in the 'Login URL'. We'll automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthParams []OauthParams `json:"oauthParams,omitempty"`
	// Additional headers to send in the OAuth login request. @{product} will automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthHeaders []OauthHeaders `json:"oauthHeaders,omitempty"`
	Status       *TFStatus      `json:"status,omitempty"`
}

func (i InputSplunkSearch) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSplunkSearch) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputSplunkSearch) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputSplunkSearch) GetType() *InputSplunkSearchType {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputSplunkSearch) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputSplunkSearch) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputSplunkSearch) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputSplunkSearch) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputSplunkSearch) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputSplunkSearch) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputSplunkSearch) GetConnections() []InputSplunkSearchConnections {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputSplunkSearch) GetPq() *InputSplunkSearchPq {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputSplunkSearch) GetSearchHead() *string {
	if o == nil {
		return nil
	}
	return o.SearchHead
}

func (o *InputSplunkSearch) GetSearch() string {
	if o == nil {
		return ""
	}
	return o.Search
}

func (o *InputSplunkSearch) GetEarliest() *string {
	if o == nil {
		return nil
	}
	return o.Earliest
}

func (o *InputSplunkSearch) GetLatest() *string {
	if o == nil {
		return nil
	}
	return o.Latest
}

func (o *InputSplunkSearch) GetCronSchedule() *string {
	if o == nil {
		return nil
	}
	return o.CronSchedule
}

func (o *InputSplunkSearch) GetEndpoint() *string {
	if o == nil {
		return nil
	}
	return o.Endpoint
}

func (o *InputSplunkSearch) GetOutputMode() *OutputMode {
	if o == nil {
		return nil
	}
	return o.OutputMode
}

func (o *InputSplunkSearch) GetEndpointParams() []EndpointParams {
	if o == nil {
		return nil
	}
	return o.EndpointParams
}

func (o *InputSplunkSearch) GetEndpointHeaders() []EndpointHeaders {
	if o == nil {
		return nil
	}
	return o.EndpointHeaders
}

func (o *InputSplunkSearch) GetLogLevel() *InputSplunkSearchLogLevel {
	if o == nil {
		return nil
	}
	return o.LogLevel
}

func (o *InputSplunkSearch) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *InputSplunkSearch) GetUseRoundRobinDNS() *bool {
	if o == nil {
		return nil
	}
	return o.UseRoundRobinDNS
}

func (o *InputSplunkSearch) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *InputSplunkSearch) GetEncoding() *string {
	if o == nil {
		return nil
	}
	return o.Encoding
}

func (o *InputSplunkSearch) GetKeepAliveTime() *float64 {
	if o == nil {
		return nil
	}
	return o.KeepAliveTime
}

func (o *InputSplunkSearch) GetJobTimeout() *string {
	if o == nil {
		return nil
	}
	return o.JobTimeout
}

func (o *InputSplunkSearch) GetMaxMissedKeepAlives() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxMissedKeepAlives
}

func (o *InputSplunkSearch) GetTTL() *string {
	if o == nil {
		return nil
	}
	return o.TTL
}

func (o *InputSplunkSearch) GetMetadata() []InputSplunkSearchMetadata {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputSplunkSearch) GetRetryRules() *RetryRules {
	if o == nil {
		return nil
	}
	return o.RetryRules
}

func (o *InputSplunkSearch) GetBreakerRulesets() []string {
	if o == nil {
		return nil
	}
	return o.BreakerRulesets
}

func (o *InputSplunkSearch) GetStaleChannelFlushMs() *float64 {
	if o == nil {
		return nil
	}
	return o.StaleChannelFlushMs
}

func (o *InputSplunkSearch) GetAuthType() *AuthenticationType {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *InputSplunkSearch) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputSplunkSearch) GetUsername() *string {
	if o == nil {
		return nil
	}
	return o.Username
}

func (o *InputSplunkSearch) GetPassword() *string {
	if o == nil {
		return nil
	}
	return o.Password
}

func (o *InputSplunkSearch) GetToken() *string {
	if o == nil {
		return nil
	}
	return o.Token
}

func (o *InputSplunkSearch) GetCredentialsSecret() *string {
	if o == nil {
		return nil
	}
	return o.CredentialsSecret
}

func (o *InputSplunkSearch) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *InputSplunkSearch) GetLoginURL() *string {
	if o == nil {
		return nil
	}
	return o.LoginURL
}

func (o *InputSplunkSearch) GetSecretParamName() *string {
	if o == nil {
		return nil
	}
	return o.SecretParamName
}

func (o *InputSplunkSearch) GetSecret() *string {
	if o == nil {
		return nil
	}
	return o.Secret
}

func (o *InputSplunkSearch) GetTokenAttributeName() *string {
	if o == nil {
		return nil
	}
	return o.TokenAttributeName
}

func (o *InputSplunkSearch) GetAuthHeaderExpr() *string {
	if o == nil {
		return nil
	}
	return o.AuthHeaderExpr
}

func (o *InputSplunkSearch) GetTokenTimeoutSecs() *float64 {
	if o == nil {
		return nil
	}
	return o.TokenTimeoutSecs
}

func (o *InputSplunkSearch) GetOauthParams() []OauthParams {
	if o == nil {
		return nil
	}
	return o.OauthParams
}

func (o *InputSplunkSearch) GetOauthHeaders() []OauthHeaders {
	if o == nil {
		return nil
	}
	return o.OauthHeaders
}

func (o *InputSplunkSearch) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputSplunkType string

const (
	InputSplunkTypeSplunk InputSplunkType = "splunk"
)

func (e InputSplunkType) ToPointer() *InputSplunkType {
	return &e
}
func (e *InputSplunkType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "splunk":
		*e = InputSplunkType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSplunkType: %v", v)
	}
}

type InputSplunkConnections struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *InputSplunkConnections) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputSplunkConnections) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// InputSplunkMode - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputSplunkMode string

const (
	InputSplunkModeSmart  InputSplunkMode = "smart"
	InputSplunkModeAlways InputSplunkMode = "always"
)

func (e InputSplunkMode) ToPointer() *InputSplunkMode {
	return &e
}
func (e *InputSplunkMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputSplunkMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSplunkMode: %v", v)
	}
}

// InputSplunkCompression - Codec to use to compress the persisted data
type InputSplunkCompression string

const (
	InputSplunkCompressionNone InputSplunkCompression = "none"
	InputSplunkCompressionGzip InputSplunkCompression = "gzip"
)

func (e InputSplunkCompression) ToPointer() *InputSplunkCompression {
	return &e
}
func (e *InputSplunkCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputSplunkCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSplunkCompression: %v", v)
	}
}

type InputSplunkPq struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputSplunkMode `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *InputSplunkCompression `default:"none" json:"compress"`
}

func (i InputSplunkPq) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSplunkPq) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputSplunkPq) GetMode() *InputSplunkMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputSplunkPq) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputSplunkPq) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *InputSplunkPq) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *InputSplunkPq) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *InputSplunkPq) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *InputSplunkPq) GetCompress() *InputSplunkCompression {
	if o == nil {
		return nil
	}
	return o.Compress
}

// InputSplunkMinimumTLSVersion - Minimum TLS version to accept from connections
type InputSplunkMinimumTLSVersion string

const (
	InputSplunkMinimumTLSVersionTlSv1  InputSplunkMinimumTLSVersion = "TLSv1"
	InputSplunkMinimumTLSVersionTlSv11 InputSplunkMinimumTLSVersion = "TLSv1.1"
	InputSplunkMinimumTLSVersionTlSv12 InputSplunkMinimumTLSVersion = "TLSv1.2"
	InputSplunkMinimumTLSVersionTlSv13 InputSplunkMinimumTLSVersion = "TLSv1.3"
)

func (e InputSplunkMinimumTLSVersion) ToPointer() *InputSplunkMinimumTLSVersion {
	return &e
}
func (e *InputSplunkMinimumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputSplunkMinimumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSplunkMinimumTLSVersion: %v", v)
	}
}

// InputSplunkMaximumTLSVersion - Maximum TLS version to accept from connections
type InputSplunkMaximumTLSVersion string

const (
	InputSplunkMaximumTLSVersionTlSv1  InputSplunkMaximumTLSVersion = "TLSv1"
	InputSplunkMaximumTLSVersionTlSv11 InputSplunkMaximumTLSVersion = "TLSv1.1"
	InputSplunkMaximumTLSVersionTlSv12 InputSplunkMaximumTLSVersion = "TLSv1.2"
	InputSplunkMaximumTLSVersionTlSv13 InputSplunkMaximumTLSVersion = "TLSv1.3"
)

func (e InputSplunkMaximumTLSVersion) ToPointer() *InputSplunkMaximumTLSVersion {
	return &e
}
func (e *InputSplunkMaximumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputSplunkMaximumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSplunkMaximumTLSVersion: %v", v)
	}
}

type InputSplunkTLSSettingsServerSide struct {
	Disabled *bool `default:"true" json:"disabled"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert        *bool `default:"false" json:"requestCert"`
	RejectUnauthorized any   `json:"rejectUnauthorized,omitempty"`
	CommonNameRegex    any   `json:"commonNameRegex,omitempty"`
	// Minimum TLS version to accept from connections
	MinVersion *InputSplunkMinimumTLSVersion `json:"minVersion,omitempty"`
	// Maximum TLS version to accept from connections
	MaxVersion *InputSplunkMaximumTLSVersion `json:"maxVersion,omitempty"`
}

func (i InputSplunkTLSSettingsServerSide) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSplunkTLSSettingsServerSide) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputSplunkTLSSettingsServerSide) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputSplunkTLSSettingsServerSide) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *InputSplunkTLSSettingsServerSide) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *InputSplunkTLSSettingsServerSide) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *InputSplunkTLSSettingsServerSide) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *InputSplunkTLSSettingsServerSide) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *InputSplunkTLSSettingsServerSide) GetRequestCert() *bool {
	if o == nil {
		return nil
	}
	return o.RequestCert
}

func (o *InputSplunkTLSSettingsServerSide) GetRejectUnauthorized() any {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *InputSplunkTLSSettingsServerSide) GetCommonNameRegex() any {
	if o == nil {
		return nil
	}
	return o.CommonNameRegex
}

func (o *InputSplunkTLSSettingsServerSide) GetMinVersion() *InputSplunkMinimumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *InputSplunkTLSSettingsServerSide) GetMaxVersion() *InputSplunkMaximumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

type InputSplunkMetadata struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputSplunkMetadata) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputSplunkMetadata) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type AuthTokens struct {
	// Shared secrets to be provided by any Splunk forwarder. If empty, unauthorized access is permitted.
	Token       string  `json:"token"`
	Description *string `json:"description,omitempty"`
}

func (o *AuthTokens) GetToken() string {
	if o == nil {
		return ""
	}
	return o.Token
}

func (o *AuthTokens) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

// MaxS2SVersion - The highest S2S protocol version to advertise during handshake
type MaxS2SVersion string

const (
	MaxS2SVersionV3 MaxS2SVersion = "v3"
	MaxS2SVersionV4 MaxS2SVersion = "v4"
)

func (e MaxS2SVersion) ToPointer() *MaxS2SVersion {
	return &e
}
func (e *MaxS2SVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "v3":
		fallthrough
	case "v4":
		*e = MaxS2SVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for MaxS2SVersion: %v", v)
	}
}

// Compression - Controls whether to support reading compressed data from a forwarder. Select 'Automatic' to match the forwarder's configuration, or 'Disabled' to reject compressed connections.
type Compression string

const (
	CompressionDisabled Compression = "disabled"
	CompressionAuto     Compression = "auto"
	CompressionAlways   Compression = "always"
)

func (e Compression) ToPointer() *Compression {
	return &e
}
func (e *Compression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "disabled":
		fallthrough
	case "auto":
		fallthrough
	case "always":
		*e = Compression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for Compression: %v", v)
	}
}

type InputSplunk struct {
	// Unique ID for this input
	ID       *string          `json:"id,omitempty"`
	Type     *InputSplunkType `json:"type,omitempty"`
	Disabled *bool            `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputSplunkConnections `json:"connections,omitempty"`
	Pq          *InputSplunkPq           `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port float64                           `json:"port"`
	TLS  *InputSplunkTLSSettingsServerSide `json:"tls,omitempty"`
	// Regex matching IP addresses that are allowed to establish a connection
	IPWhitelistRegex *string `default:"/.*/" json:"ipWhitelistRegex"`
	// Maximum number of active connections allowed per Worker Process. Use 0 for unlimited.
	MaxActiveCxn *float64 `default:"1000" json:"maxActiveCxn"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. After this time, the connection will be closed. Leave at 0 for no inactive socket monitoring.
	SocketIdleTimeout *float64 `default:"0" json:"socketIdleTimeout"`
	// How long the server will wait after initiating a closure for a client to close its end of the connection. If the client doesn't close the connection within this time, the server will forcefully terminate the socket to prevent resource leaks and ensure efficient connection cleanup and system stability. Leave at 0 for no inactive socket monitoring.
	SocketEndingMaxWait *float64 `default:"30" json:"socketEndingMaxWait"`
	// The maximum duration a socket can remain open, even if active. This helps manage resources and mitigate issues caused by TCP pinning. Set to 0 to disable.
	SocketMaxLifespan *float64 `default:"0" json:"socketMaxLifespan"`
	// Enable if the connection is proxied by a device that supports proxy protocol v1 or v2
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Fields to add to events from this input
	Metadata []InputSplunkMetadata `json:"metadata,omitempty"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitempty"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `default:"10000" json:"staleChannelFlushMs"`
	// Shared secrets to be provided by any Splunk forwarder. If empty, unauthorized access is permitted.
	AuthTokens []AuthTokens `json:"authTokens,omitempty"`
	// The highest S2S protocol version to advertise during handshake
	MaxS2Sversion *MaxS2SVersion `default:"v3" json:"maxS2Sversion"`
	Description   *string        `json:"description,omitempty"`
	// Event Breakers will determine events' time zone from UF-provided metadata, when TZ can't be inferred from the raw event
	UseFwdTimezone *bool `default:"true" json:"useFwdTimezone"`
	// Drop Splunk control fields such as `crcSalt` and `_savedPort`. If disabled, control fields are stored in the internal field `__ctrlFields`.
	DropControlFields *bool `default:"true" json:"dropControlFields"`
	// Extract and process Splunk-generated metrics as Cribl metrics
	ExtractMetrics *bool `default:"false" json:"extractMetrics"`
	// Controls whether to support reading compressed data from a forwarder. Select 'Automatic' to match the forwarder's configuration, or 'Disabled' to reject compressed connections.
	Compress *Compression `default:"disabled" json:"compress"`
	Status   *TFStatus    `json:"status,omitempty"`
}

func (i InputSplunk) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSplunk) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputSplunk) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputSplunk) GetType() *InputSplunkType {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputSplunk) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputSplunk) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputSplunk) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputSplunk) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputSplunk) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputSplunk) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputSplunk) GetConnections() []InputSplunkConnections {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputSplunk) GetPq() *InputSplunkPq {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputSplunk) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputSplunk) GetPort() float64 {
	if o == nil {
		return 0.0
	}
	return o.Port
}

func (o *InputSplunk) GetTLS() *InputSplunkTLSSettingsServerSide {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputSplunk) GetIPWhitelistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPWhitelistRegex
}

func (o *InputSplunk) GetMaxActiveCxn() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxActiveCxn
}

func (o *InputSplunk) GetSocketIdleTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketIdleTimeout
}

func (o *InputSplunk) GetSocketEndingMaxWait() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketEndingMaxWait
}

func (o *InputSplunk) GetSocketMaxLifespan() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketMaxLifespan
}

func (o *InputSplunk) GetEnableProxyHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableProxyHeader
}

func (o *InputSplunk) GetMetadata() []InputSplunkMetadata {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputSplunk) GetBreakerRulesets() []string {
	if o == nil {
		return nil
	}
	return o.BreakerRulesets
}

func (o *InputSplunk) GetStaleChannelFlushMs() *float64 {
	if o == nil {
		return nil
	}
	return o.StaleChannelFlushMs
}

func (o *InputSplunk) GetAuthTokens() []AuthTokens {
	if o == nil {
		return nil
	}
	return o.AuthTokens
}

func (o *InputSplunk) GetMaxS2Sversion() *MaxS2SVersion {
	if o == nil {
		return nil
	}
	return o.MaxS2Sversion
}

func (o *InputSplunk) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputSplunk) GetUseFwdTimezone() *bool {
	if o == nil {
		return nil
	}
	return o.UseFwdTimezone
}

func (o *InputSplunk) GetDropControlFields() *bool {
	if o == nil {
		return nil
	}
	return o.DropControlFields
}

func (o *InputSplunk) GetExtractMetrics() *bool {
	if o == nil {
		return nil
	}
	return o.ExtractMetrics
}

func (o *InputSplunk) GetCompress() *Compression {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *InputSplunk) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputHTTPType string

const (
	InputHTTPTypeHTTP InputHTTPType = "http"
)

func (e InputHTTPType) ToPointer() *InputHTTPType {
	return &e
}
func (e *InputHTTPType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "http":
		*e = InputHTTPType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputHTTPType: %v", v)
	}
}

type InputHTTPConnections struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *InputHTTPConnections) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputHTTPConnections) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// InputHTTPMode - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputHTTPMode string

const (
	InputHTTPModeSmart  InputHTTPMode = "smart"
	InputHTTPModeAlways InputHTTPMode = "always"
)

func (e InputHTTPMode) ToPointer() *InputHTTPMode {
	return &e
}
func (e *InputHTTPMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputHTTPMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputHTTPMode: %v", v)
	}
}

// InputHTTPCompression - Codec to use to compress the persisted data
type InputHTTPCompression string

const (
	InputHTTPCompressionNone InputHTTPCompression = "none"
	InputHTTPCompressionGzip InputHTTPCompression = "gzip"
)

func (e InputHTTPCompression) ToPointer() *InputHTTPCompression {
	return &e
}
func (e *InputHTTPCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputHTTPCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputHTTPCompression: %v", v)
	}
}

type InputHTTPPq struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputHTTPMode `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *InputHTTPCompression `default:"none" json:"compress"`
}

func (i InputHTTPPq) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputHTTPPq) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputHTTPPq) GetMode() *InputHTTPMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputHTTPPq) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputHTTPPq) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *InputHTTPPq) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *InputHTTPPq) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *InputHTTPPq) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *InputHTTPPq) GetCompress() *InputHTTPCompression {
	if o == nil {
		return nil
	}
	return o.Compress
}

// InputHTTPMinimumTLSVersion - Minimum TLS version to accept from connections
type InputHTTPMinimumTLSVersion string

const (
	InputHTTPMinimumTLSVersionTlSv1  InputHTTPMinimumTLSVersion = "TLSv1"
	InputHTTPMinimumTLSVersionTlSv11 InputHTTPMinimumTLSVersion = "TLSv1.1"
	InputHTTPMinimumTLSVersionTlSv12 InputHTTPMinimumTLSVersion = "TLSv1.2"
	InputHTTPMinimumTLSVersionTlSv13 InputHTTPMinimumTLSVersion = "TLSv1.3"
)

func (e InputHTTPMinimumTLSVersion) ToPointer() *InputHTTPMinimumTLSVersion {
	return &e
}
func (e *InputHTTPMinimumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputHTTPMinimumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputHTTPMinimumTLSVersion: %v", v)
	}
}

// InputHTTPMaximumTLSVersion - Maximum TLS version to accept from connections
type InputHTTPMaximumTLSVersion string

const (
	InputHTTPMaximumTLSVersionTlSv1  InputHTTPMaximumTLSVersion = "TLSv1"
	InputHTTPMaximumTLSVersionTlSv11 InputHTTPMaximumTLSVersion = "TLSv1.1"
	InputHTTPMaximumTLSVersionTlSv12 InputHTTPMaximumTLSVersion = "TLSv1.2"
	InputHTTPMaximumTLSVersionTlSv13 InputHTTPMaximumTLSVersion = "TLSv1.3"
)

func (e InputHTTPMaximumTLSVersion) ToPointer() *InputHTTPMaximumTLSVersion {
	return &e
}
func (e *InputHTTPMaximumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputHTTPMaximumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputHTTPMaximumTLSVersion: %v", v)
	}
}

type TLSSettingsServerSide struct {
	Disabled *bool `default:"true" json:"disabled"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert        *bool `default:"false" json:"requestCert"`
	RejectUnauthorized any   `json:"rejectUnauthorized,omitempty"`
	CommonNameRegex    any   `json:"commonNameRegex,omitempty"`
	// Minimum TLS version to accept from connections
	MinVersion *InputHTTPMinimumTLSVersion `json:"minVersion,omitempty"`
	// Maximum TLS version to accept from connections
	MaxVersion *InputHTTPMaximumTLSVersion `json:"maxVersion,omitempty"`
}

func (t TLSSettingsServerSide) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(t, "", false)
}

func (t *TLSSettingsServerSide) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &t, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *TLSSettingsServerSide) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *TLSSettingsServerSide) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *TLSSettingsServerSide) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *TLSSettingsServerSide) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *TLSSettingsServerSide) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *TLSSettingsServerSide) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *TLSSettingsServerSide) GetRequestCert() *bool {
	if o == nil {
		return nil
	}
	return o.RequestCert
}

func (o *TLSSettingsServerSide) GetRejectUnauthorized() any {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *TLSSettingsServerSide) GetCommonNameRegex() any {
	if o == nil {
		return nil
	}
	return o.CommonNameRegex
}

func (o *TLSSettingsServerSide) GetMinVersion() *InputHTTPMinimumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *TLSSettingsServerSide) GetMaxVersion() *InputHTTPMaximumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

type InputHTTPMetadata struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputHTTPMetadata) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputHTTPMetadata) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputHTTPInputMetadata struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputHTTPInputMetadata) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputHTTPInputMetadata) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type AuthTokensExt struct {
	// Shared secret to be provided by any client (Authorization: <token>).
	Token       string  `json:"token"`
	Description *string `json:"description,omitempty"`
	// Fields to add to events referencing this token
	Metadata []InputHTTPInputMetadata `json:"metadata,omitempty"`
}

func (o *AuthTokensExt) GetToken() string {
	if o == nil {
		return ""
	}
	return o.Token
}

func (o *AuthTokensExt) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *AuthTokensExt) GetMetadata() []InputHTTPInputMetadata {
	if o == nil {
		return nil
	}
	return o.Metadata
}

type InputHTTP struct {
	// Unique ID for this input
	ID       *string        `json:"id,omitempty"`
	Type     *InputHTTPType `json:"type,omitempty"`
	Disabled *bool          `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputHTTPConnections `json:"connections,omitempty"`
	Pq          *InputHTTPPq           `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port float64 `json:"port"`
	// Shared secrets to be provided by any client (Authorization: <token>). If empty, unauthorized access is permitted.
	AuthTokens []string               `json:"authTokens,omitempty"`
	TLS        *TLSSettingsServerSide `json:"tls,omitempty"`
	// Maximum number of active requests per Worker Process. Use 0 for unlimited.
	MaxActiveReq *float64 `default:"256" json:"maxActiveReq"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket *int64 `default:"0" json:"maxRequestsPerSocket"`
	// Enable when clients are connecting through a proxy that supports the x-forwarded-for header to keep the client's original IP address on the event instead of the proxy's IP address
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Add request headers to events, in the __headers field
	CaptureHeaders *bool `default:"false" json:"captureHeaders"`
	// How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
	ActivityLogSampleRate *float64 `default:"100" json:"activityLogSampleRate"`
	// How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
	RequestTimeout *float64 `default:"0" json:"requestTimeout"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `default:"0" json:"socketTimeout"`
	// After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 sec.; maximum 600 sec. (10 min.).
	KeepAliveTimeout *float64 `default:"5" json:"keepAliveTimeout"`
	// Enable to expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
	EnableHealthCheck *bool `default:"false" json:"enableHealthCheck"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist
	IPAllowlistRegex *string `default:"/.*/" json:"ipAllowlistRegex"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `default:"/^\\$/" json:"ipDenylistRegex"`
	// Absolute path on which to listen for the Cribl HTTP API requests. At the moment, only _bulk (default /cribl/_bulk) is available. Use empty string to disable.
	CriblAPI *string `default:"/cribl" json:"criblAPI"`
	// Absolute path on which to listen for the Elasticsearch API requests. Only _bulk (default /elastic/_bulk) is available. Use empty string to disable.
	ElasticAPI *string `default:"/elastic" json:"elasticAPI"`
	// Absolute path on which listen for the Splunk HTTP Event Collector API requests. Use empty string to disable.
	SplunkHecAPI  *string `default:"/services/collector" json:"splunkHecAPI"`
	SplunkHecAcks *bool   `default:"false" json:"splunkHecAcks"`
	// Fields to add to events from this input
	Metadata []InputHTTPMetadata `json:"metadata,omitempty"`
	// Shared secrets to be provided by any client (Authorization: <token>). If empty, unauthorized access is permitted.
	AuthTokensExt []AuthTokensExt `json:"authTokensExt,omitempty"`
	Description   *string         `json:"description,omitempty"`
	Status        *TFStatus       `json:"status,omitempty"`
}

func (i InputHTTP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputHTTP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputHTTP) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputHTTP) GetType() *InputHTTPType {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputHTTP) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputHTTP) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputHTTP) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputHTTP) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputHTTP) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputHTTP) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputHTTP) GetConnections() []InputHTTPConnections {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputHTTP) GetPq() *InputHTTPPq {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputHTTP) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputHTTP) GetPort() float64 {
	if o == nil {
		return 0.0
	}
	return o.Port
}

func (o *InputHTTP) GetAuthTokens() []string {
	if o == nil {
		return nil
	}
	return o.AuthTokens
}

func (o *InputHTTP) GetTLS() *TLSSettingsServerSide {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputHTTP) GetMaxActiveReq() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxActiveReq
}

func (o *InputHTTP) GetMaxRequestsPerSocket() *int64 {
	if o == nil {
		return nil
	}
	return o.MaxRequestsPerSocket
}

func (o *InputHTTP) GetEnableProxyHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableProxyHeader
}

func (o *InputHTTP) GetCaptureHeaders() *bool {
	if o == nil {
		return nil
	}
	return o.CaptureHeaders
}

func (o *InputHTTP) GetActivityLogSampleRate() *float64 {
	if o == nil {
		return nil
	}
	return o.ActivityLogSampleRate
}

func (o *InputHTTP) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *InputHTTP) GetSocketTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketTimeout
}

func (o *InputHTTP) GetKeepAliveTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.KeepAliveTimeout
}

func (o *InputHTTP) GetEnableHealthCheck() *bool {
	if o == nil {
		return nil
	}
	return o.EnableHealthCheck
}

func (o *InputHTTP) GetIPAllowlistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPAllowlistRegex
}

func (o *InputHTTP) GetIPDenylistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPDenylistRegex
}

func (o *InputHTTP) GetCriblAPI() *string {
	if o == nil {
		return nil
	}
	return o.CriblAPI
}

func (o *InputHTTP) GetElasticAPI() *string {
	if o == nil {
		return nil
	}
	return o.ElasticAPI
}

func (o *InputHTTP) GetSplunkHecAPI() *string {
	if o == nil {
		return nil
	}
	return o.SplunkHecAPI
}

func (o *InputHTTP) GetSplunkHecAcks() *bool {
	if o == nil {
		return nil
	}
	return o.SplunkHecAcks
}

func (o *InputHTTP) GetMetadata() []InputHTTPMetadata {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputHTTP) GetAuthTokensExt() []AuthTokensExt {
	if o == nil {
		return nil
	}
	return o.AuthTokensExt
}

func (o *InputHTTP) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputHTTP) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputMskType string

const (
	InputMskTypeMsk InputMskType = "msk"
)

func (e InputMskType) ToPointer() *InputMskType {
	return &e
}
func (e *InputMskType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "msk":
		*e = InputMskType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputMskType: %v", v)
	}
}

type InputMskConnections struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *InputMskConnections) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputMskConnections) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// InputMskMode - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputMskMode string

const (
	InputMskModeSmart  InputMskMode = "smart"
	InputMskModeAlways InputMskMode = "always"
)

func (e InputMskMode) ToPointer() *InputMskMode {
	return &e
}
func (e *InputMskMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputMskMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputMskMode: %v", v)
	}
}

// InputMskCompression - Codec to use to compress the persisted data
type InputMskCompression string

const (
	InputMskCompressionNone InputMskCompression = "none"
	InputMskCompressionGzip InputMskCompression = "gzip"
)

func (e InputMskCompression) ToPointer() *InputMskCompression {
	return &e
}
func (e *InputMskCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputMskCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputMskCompression: %v", v)
	}
}

type InputMskPq struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputMskMode `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *InputMskCompression `default:"none" json:"compress"`
}

func (i InputMskPq) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputMskPq) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputMskPq) GetMode() *InputMskMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputMskPq) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputMskPq) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *InputMskPq) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *InputMskPq) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *InputMskPq) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *InputMskPq) GetCompress() *InputMskCompression {
	if o == nil {
		return nil
	}
	return o.Compress
}

type InputMskMetadata struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputMskMetadata) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputMskMetadata) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// InputMskAuth - Credentials to use when authenticating with the schema registry using basic HTTP authentication
type InputMskAuth struct {
	// Enable authentication
	Disabled *bool `default:"true" json:"disabled"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
}

func (i InputMskAuth) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputMskAuth) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputMskAuth) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputMskAuth) GetCredentialsSecret() *string {
	if o == nil {
		return nil
	}
	return o.CredentialsSecret
}

// InputMskInputMinimumTLSVersion - Minimum TLS version to use when connecting
type InputMskInputMinimumTLSVersion string

const (
	InputMskInputMinimumTLSVersionTlSv1  InputMskInputMinimumTLSVersion = "TLSv1"
	InputMskInputMinimumTLSVersionTlSv11 InputMskInputMinimumTLSVersion = "TLSv1.1"
	InputMskInputMinimumTLSVersionTlSv12 InputMskInputMinimumTLSVersion = "TLSv1.2"
	InputMskInputMinimumTLSVersionTlSv13 InputMskInputMinimumTLSVersion = "TLSv1.3"
)

func (e InputMskInputMinimumTLSVersion) ToPointer() *InputMskInputMinimumTLSVersion {
	return &e
}
func (e *InputMskInputMinimumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputMskInputMinimumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputMskInputMinimumTLSVersion: %v", v)
	}
}

// InputMskInputMaximumTLSVersion - Maximum TLS version to use when connecting
type InputMskInputMaximumTLSVersion string

const (
	InputMskInputMaximumTLSVersionTlSv1  InputMskInputMaximumTLSVersion = "TLSv1"
	InputMskInputMaximumTLSVersionTlSv11 InputMskInputMaximumTLSVersion = "TLSv1.1"
	InputMskInputMaximumTLSVersionTlSv12 InputMskInputMaximumTLSVersion = "TLSv1.2"
	InputMskInputMaximumTLSVersionTlSv13 InputMskInputMaximumTLSVersion = "TLSv1.3"
)

func (e InputMskInputMaximumTLSVersion) ToPointer() *InputMskInputMaximumTLSVersion {
	return &e
}
func (e *InputMskInputMaximumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputMskInputMaximumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputMskInputMaximumTLSVersion: %v", v)
	}
}

type InputMskInputTLSSettingsClientSide struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Reject certs that are not authorized by a CA in the CA certificate path, or by another
	//                     trusted CA (e.g., the system's CA). Defaults to Yes. Overrides the toggle from Advanced Settings, when also present.
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.
	Servername *string `json:"servername,omitempty"`
	// The name of the predefined certificate.
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Passphrase to use to decrypt private key.
	Passphrase *string `json:"passphrase,omitempty"`
	// Minimum TLS version to use when connecting
	MinVersion *InputMskInputMinimumTLSVersion `json:"minVersion,omitempty"`
	// Maximum TLS version to use when connecting
	MaxVersion *InputMskInputMaximumTLSVersion `json:"maxVersion,omitempty"`
}

func (i InputMskInputTLSSettingsClientSide) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputMskInputTLSSettingsClientSide) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputMskInputTLSSettingsClientSide) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputMskInputTLSSettingsClientSide) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *InputMskInputTLSSettingsClientSide) GetServername() *string {
	if o == nil {
		return nil
	}
	return o.Servername
}

func (o *InputMskInputTLSSettingsClientSide) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *InputMskInputTLSSettingsClientSide) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *InputMskInputTLSSettingsClientSide) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *InputMskInputTLSSettingsClientSide) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *InputMskInputTLSSettingsClientSide) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *InputMskInputTLSSettingsClientSide) GetMinVersion() *InputMskInputMinimumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *InputMskInputTLSSettingsClientSide) GetMaxVersion() *InputMskInputMaximumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

type InputMskKafkaSchemaRegistryAuthentication struct {
	// Enable Schema Registry
	Disabled *bool `default:"true" json:"disabled"`
	// URL for accessing the Confluent Schema Registry. Example: http://localhost:8081. To connect over TLS, use https instead of http.
	SchemaRegistryURL *string `default:"http://localhost:8081" json:"schemaRegistryURL"`
	// Maximum time to wait for a Schema Registry connection to complete successfully
	ConnectionTimeout *float64 `default:"30000" json:"connectionTimeout"`
	// Maximum time to wait for the Schema Registry to respond to a request
	RequestTimeout *float64 `default:"30000" json:"requestTimeout"`
	// Maximum number of times to try fetching schemas from the Schema Registry
	MaxRetries *float64 `default:"1" json:"maxRetries"`
	// Credentials to use when authenticating with the schema registry using basic HTTP authentication
	Auth *InputMskAuth                       `json:"auth,omitempty"`
	TLS  *InputMskInputTLSSettingsClientSide `json:"tls,omitempty"`
}

func (i InputMskKafkaSchemaRegistryAuthentication) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputMskKafkaSchemaRegistryAuthentication) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputMskKafkaSchemaRegistryAuthentication) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputMskKafkaSchemaRegistryAuthentication) GetSchemaRegistryURL() *string {
	if o == nil {
		return nil
	}
	return o.SchemaRegistryURL
}

func (o *InputMskKafkaSchemaRegistryAuthentication) GetConnectionTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.ConnectionTimeout
}

func (o *InputMskKafkaSchemaRegistryAuthentication) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *InputMskKafkaSchemaRegistryAuthentication) GetMaxRetries() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxRetries
}

func (o *InputMskKafkaSchemaRegistryAuthentication) GetAuth() *InputMskAuth {
	if o == nil {
		return nil
	}
	return o.Auth
}

func (o *InputMskKafkaSchemaRegistryAuthentication) GetTLS() *InputMskInputTLSSettingsClientSide {
	if o == nil {
		return nil
	}
	return o.TLS
}

// AuthenticationMethod - AWS authentication method. Choose Auto to use IAM roles.
type AuthenticationMethod string

const (
	AuthenticationMethodAuto   AuthenticationMethod = "auto"
	AuthenticationMethodManual AuthenticationMethod = "manual"
	AuthenticationMethodSecret AuthenticationMethod = "secret"
)

func (e AuthenticationMethod) ToPointer() *AuthenticationMethod {
	return &e
}
func (e *AuthenticationMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "auto":
		fallthrough
	case "manual":
		fallthrough
	case "secret":
		*e = AuthenticationMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for AuthenticationMethod: %v", v)
	}
}

// SignatureVersion - Signature version to use for signing MSK cluster requests
type SignatureVersion string

const (
	SignatureVersionV2 SignatureVersion = "v2"
	SignatureVersionV4 SignatureVersion = "v4"
)

func (e SignatureVersion) ToPointer() *SignatureVersion {
	return &e
}
func (e *SignatureVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "v2":
		fallthrough
	case "v4":
		*e = SignatureVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for SignatureVersion: %v", v)
	}
}

// InputMskMinimumTLSVersion - Minimum TLS version to use when connecting
type InputMskMinimumTLSVersion string

const (
	InputMskMinimumTLSVersionTlSv1  InputMskMinimumTLSVersion = "TLSv1"
	InputMskMinimumTLSVersionTlSv11 InputMskMinimumTLSVersion = "TLSv1.1"
	InputMskMinimumTLSVersionTlSv12 InputMskMinimumTLSVersion = "TLSv1.2"
	InputMskMinimumTLSVersionTlSv13 InputMskMinimumTLSVersion = "TLSv1.3"
)

func (e InputMskMinimumTLSVersion) ToPointer() *InputMskMinimumTLSVersion {
	return &e
}
func (e *InputMskMinimumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputMskMinimumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputMskMinimumTLSVersion: %v", v)
	}
}

// InputMskMaximumTLSVersion - Maximum TLS version to use when connecting
type InputMskMaximumTLSVersion string

const (
	InputMskMaximumTLSVersionTlSv1  InputMskMaximumTLSVersion = "TLSv1"
	InputMskMaximumTLSVersionTlSv11 InputMskMaximumTLSVersion = "TLSv1.1"
	InputMskMaximumTLSVersionTlSv12 InputMskMaximumTLSVersion = "TLSv1.2"
	InputMskMaximumTLSVersionTlSv13 InputMskMaximumTLSVersion = "TLSv1.3"
)

func (e InputMskMaximumTLSVersion) ToPointer() *InputMskMaximumTLSVersion {
	return &e
}
func (e *InputMskMaximumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputMskMaximumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputMskMaximumTLSVersion: %v", v)
	}
}

type InputMskTLSSettingsClientSide struct {
	Disabled *bool `default:"false" json:"disabled"`
	// Reject certs that are not authorized by a CA in the CA certificate path, or by another
	//                     trusted CA (e.g., the system's CA). Defaults to Yes. Overrides the toggle from Advanced Settings, when also present.
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.
	Servername *string `json:"servername,omitempty"`
	// The name of the predefined certificate.
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Passphrase to use to decrypt private key.
	Passphrase *string `json:"passphrase,omitempty"`
	// Minimum TLS version to use when connecting
	MinVersion *InputMskMinimumTLSVersion `json:"minVersion,omitempty"`
	// Maximum TLS version to use when connecting
	MaxVersion *InputMskMaximumTLSVersion `json:"maxVersion,omitempty"`
}

func (i InputMskTLSSettingsClientSide) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputMskTLSSettingsClientSide) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputMskTLSSettingsClientSide) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputMskTLSSettingsClientSide) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *InputMskTLSSettingsClientSide) GetServername() *string {
	if o == nil {
		return nil
	}
	return o.Servername
}

func (o *InputMskTLSSettingsClientSide) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *InputMskTLSSettingsClientSide) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *InputMskTLSSettingsClientSide) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *InputMskTLSSettingsClientSide) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *InputMskTLSSettingsClientSide) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *InputMskTLSSettingsClientSide) GetMinVersion() *InputMskMinimumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *InputMskTLSSettingsClientSide) GetMaxVersion() *InputMskMaximumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

type InputMsk struct {
	// Unique ID for this input
	ID       *string       `json:"id,omitempty"`
	Type     *InputMskType `json:"type,omitempty"`
	Disabled *bool         `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputMskConnections `json:"connections,omitempty"`
	Pq          *InputMskPq           `json:"pq,omitempty"`
	// Enter each Kafka bootstrap server you want to use. Specify the hostname and port (such as mykafkabroker:9092) or just the hostname (in which case @{product} will assign port 9092).
	Brokers []string `json:"brokers"`
	// Topic to subscribe to. Warning: To optimize performance, Cribl suggests subscribing each Kafka Source to only a single topic.
	Topics []string `json:"topics,omitempty"`
	// Specifies the consumer group to which this instance belongs. Defaults to 'Cribl'.
	GroupID *string `default:"Cribl" json:"groupId"`
	// Leave toggled to 'Yes' if you want the Source, upon first subscribing to a topic, to read starting with the earliest available message
	FromBeginning *bool `default:"true" json:"fromBeginning"`
	//       Timeout used to detect client failures when using Kafka's group management facilities.
	//       If the client sends the broker no heartbeats before this timeout expires,
	//       the broker will remove this client from the group, and will initiate a rebalance.
	//       Value must be between the broker's configured group.min.session.timeout.ms and group.max.session.timeout.ms.
	//       See details [here](https://kafka.apache.org/documentation/#consumerconfigs_session.timeout.ms).
	SessionTimeout *float64 `default:"30000" json:"sessionTimeout"`
	//       Maximum allowed time for each worker to join the group after a rebalance has begun.
	//       If the timeout is exceeded, the coordinator broker will remove the worker from the group.
	//       See details [here](https://kafka.apache.org/documentation/#connectconfigs_rebalance.timeout.ms).
	RebalanceTimeout *float64 `default:"60000" json:"rebalanceTimeout"`
	//       Expected time between heartbeats to the consumer coordinator when using Kafka's group management facilities.
	//       Value must be lower than sessionTimeout, and typically should not exceed 1/3 of the sessionTimeout value.
	//       See details [here](https://kafka.apache.org/documentation/#consumerconfigs_heartbeat.interval.ms).
	HeartbeatInterval *float64 `default:"3000" json:"heartbeatInterval"`
	// Fields to add to events from this input
	Metadata            []InputMskMetadata                         `json:"metadata,omitempty"`
	KafkaSchemaRegistry *InputMskKafkaSchemaRegistryAuthentication `json:"kafkaSchemaRegistry,omitempty"`
	// Maximum time to wait for a connection to complete successfully
	ConnectionTimeout *float64 `default:"10000" json:"connectionTimeout"`
	// Maximum time to wait for Kafka to respond to a request
	RequestTimeout *float64 `default:"60000" json:"requestTimeout"`
	// If messages are failing, you can set the maximum number of retries as high as 100 to prevent loss of data
	MaxRetries *float64 `default:"5" json:"maxRetries"`
	// The maximum wait time for a retry, in milliseconds. Default (and minimum) is 30,000 ms (30 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackOff *float64 `default:"30000" json:"maxBackOff"`
	// Initial value used to calculate the retry, in milliseconds. Maximum is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"300" json:"initialBackoff"`
	// Set the backoff multiplier (2-20) to control the retry frequency for failed messages. For faster retries, use a lower multiplier. For slower retries with more delay between attempts, use a higher multiplier. The multiplier is used in an exponential backoff formula; see the Kafka [documentation](https://kafka.js.org/docs/retry-detailed) for details.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// Maximum time to wait for Kafka to respond to an authentication request
	AuthenticationTimeout *float64 `default:"10000" json:"authenticationTimeout"`
	// Specifies a time window during which @{product} can reauthenticate if needed. Creates the window measuring backwards from the moment when credentials are set to expire.
	ReauthenticationThreshold *float64 `default:"10000" json:"reauthenticationThreshold"`
	// AWS authentication method. Choose Auto to use IAM roles.
	AwsAuthenticationMethod *AuthenticationMethod `default:"auto" json:"awsAuthenticationMethod"`
	AwsSecretKey            *string               `json:"awsSecretKey,omitempty"`
	// Region where the MSK cluster is located
	Region string `json:"region"`
	// MSK cluster service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to MSK cluster-compatible endpoint.
	Endpoint *string `json:"endpoint,omitempty"`
	// Signature version to use for signing MSK cluster requests
	SignatureVersion *SignatureVersion `default:"v4" json:"signatureVersion"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `default:"true" json:"reuseConnections"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Use Assume Role credentials to access MSK
	EnableAssumeRole *bool `default:"false" json:"enableAssumeRole"`
	// Amazon Resource Name (ARN) of the role to assume
	AssumeRoleArn *string `json:"assumeRoleArn,omitempty"`
	// External ID to use when assuming role
	AssumeRoleExternalID *string `json:"assumeRoleExternalId,omitempty"`
	// Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
	DurationSeconds *float64                       `default:"3600" json:"durationSeconds"`
	TLS             *InputMskTLSSettingsClientSide `json:"tls,omitempty"`
	// How often to commit offsets. If both this and Offset commit threshold are set, @{product} commits offsets when either condition is met. If both are empty, @{product} commits offsets after each batch.
	AutoCommitInterval *float64 `json:"autoCommitInterval,omitempty"`
	// How many events are needed to trigger an offset commit. If both this and Offset commit interval are set, @{product} commits offsets when either condition is met. If both are empty, @{product} commits offsets after each batch.
	AutoCommitThreshold *float64 `json:"autoCommitThreshold,omitempty"`
	// Maximum amount of data that Kafka will return per partition, per fetch request. Must equal or exceed the maximum message size (maxBytesPerPartition) that Kafka is configured to allow. Otherwise, @{product} can get stuck trying to retrieve messages. Defaults to 1048576 (1 MB).
	MaxBytesPerPartition *float64 `default:"1048576" json:"maxBytesPerPartition"`
	// Maximum number of bytes that Kafka will return per fetch request. Defaults to 10485760 (10 MB).
	MaxBytes *float64 `default:"10485760" json:"maxBytes"`
	// Maximum number of network errors before the consumer recreates a socket.
	MaxSocketErrors *float64 `default:"0" json:"maxSocketErrors"`
	Description     *string  `json:"description,omitempty"`
	AwsAPIKey       *string  `json:"awsApiKey,omitempty"`
	// Select or create a stored secret that references your access key and secret key
	AwsSecret *string   `json:"awsSecret,omitempty"`
	Status    *TFStatus `json:"status,omitempty"`
}

func (i InputMsk) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputMsk) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputMsk) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputMsk) GetType() *InputMskType {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputMsk) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputMsk) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputMsk) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputMsk) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputMsk) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputMsk) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputMsk) GetConnections() []InputMskConnections {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputMsk) GetPq() *InputMskPq {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputMsk) GetBrokers() []string {
	if o == nil {
		return []string{}
	}
	return o.Brokers
}

func (o *InputMsk) GetTopics() []string {
	if o == nil {
		return nil
	}
	return o.Topics
}

func (o *InputMsk) GetGroupID() *string {
	if o == nil {
		return nil
	}
	return o.GroupID
}

func (o *InputMsk) GetFromBeginning() *bool {
	if o == nil {
		return nil
	}
	return o.FromBeginning
}

func (o *InputMsk) GetSessionTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SessionTimeout
}

func (o *InputMsk) GetRebalanceTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RebalanceTimeout
}

func (o *InputMsk) GetHeartbeatInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.HeartbeatInterval
}

func (o *InputMsk) GetMetadata() []InputMskMetadata {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputMsk) GetKafkaSchemaRegistry() *InputMskKafkaSchemaRegistryAuthentication {
	if o == nil {
		return nil
	}
	return o.KafkaSchemaRegistry
}

func (o *InputMsk) GetConnectionTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.ConnectionTimeout
}

func (o *InputMsk) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *InputMsk) GetMaxRetries() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxRetries
}

func (o *InputMsk) GetMaxBackOff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackOff
}

func (o *InputMsk) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *InputMsk) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *InputMsk) GetAuthenticationTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.AuthenticationTimeout
}

func (o *InputMsk) GetReauthenticationThreshold() *float64 {
	if o == nil {
		return nil
	}
	return o.ReauthenticationThreshold
}

func (o *InputMsk) GetAwsAuthenticationMethod() *AuthenticationMethod {
	if o == nil {
		return nil
	}
	return o.AwsAuthenticationMethod
}

func (o *InputMsk) GetAwsSecretKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecretKey
}

func (o *InputMsk) GetRegion() string {
	if o == nil {
		return ""
	}
	return o.Region
}

func (o *InputMsk) GetEndpoint() *string {
	if o == nil {
		return nil
	}
	return o.Endpoint
}

func (o *InputMsk) GetSignatureVersion() *SignatureVersion {
	if o == nil {
		return nil
	}
	return o.SignatureVersion
}

func (o *InputMsk) GetReuseConnections() *bool {
	if o == nil {
		return nil
	}
	return o.ReuseConnections
}

func (o *InputMsk) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *InputMsk) GetEnableAssumeRole() *bool {
	if o == nil {
		return nil
	}
	return o.EnableAssumeRole
}

func (o *InputMsk) GetAssumeRoleArn() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleArn
}

func (o *InputMsk) GetAssumeRoleExternalID() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleExternalID
}

func (o *InputMsk) GetDurationSeconds() *float64 {
	if o == nil {
		return nil
	}
	return o.DurationSeconds
}

func (o *InputMsk) GetTLS() *InputMskTLSSettingsClientSide {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputMsk) GetAutoCommitInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.AutoCommitInterval
}

func (o *InputMsk) GetAutoCommitThreshold() *float64 {
	if o == nil {
		return nil
	}
	return o.AutoCommitThreshold
}

func (o *InputMsk) GetMaxBytesPerPartition() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBytesPerPartition
}

func (o *InputMsk) GetMaxBytes() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBytes
}

func (o *InputMsk) GetMaxSocketErrors() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxSocketErrors
}

func (o *InputMsk) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputMsk) GetAwsAPIKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsAPIKey
}

func (o *InputMsk) GetAwsSecret() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecret
}

func (o *InputMsk) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputKafkaType string

const (
	InputKafkaTypeKafka InputKafkaType = "kafka"
)

func (e InputKafkaType) ToPointer() *InputKafkaType {
	return &e
}
func (e *InputKafkaType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "kafka":
		*e = InputKafkaType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputKafkaType: %v", v)
	}
}

type InputKafkaConnections struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *InputKafkaConnections) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputKafkaConnections) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// InputKafkaMode - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputKafkaMode string

const (
	InputKafkaModeSmart  InputKafkaMode = "smart"
	InputKafkaModeAlways InputKafkaMode = "always"
)

func (e InputKafkaMode) ToPointer() *InputKafkaMode {
	return &e
}
func (e *InputKafkaMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputKafkaMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputKafkaMode: %v", v)
	}
}

// InputKafkaCompression - Codec to use to compress the persisted data
type InputKafkaCompression string

const (
	InputKafkaCompressionNone InputKafkaCompression = "none"
	InputKafkaCompressionGzip InputKafkaCompression = "gzip"
)

func (e InputKafkaCompression) ToPointer() *InputKafkaCompression {
	return &e
}
func (e *InputKafkaCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputKafkaCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputKafkaCompression: %v", v)
	}
}

type InputKafkaPq struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputKafkaMode `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *InputKafkaCompression `default:"none" json:"compress"`
}

func (i InputKafkaPq) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputKafkaPq) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputKafkaPq) GetMode() *InputKafkaMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputKafkaPq) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputKafkaPq) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *InputKafkaPq) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *InputKafkaPq) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *InputKafkaPq) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *InputKafkaPq) GetCompress() *InputKafkaCompression {
	if o == nil {
		return nil
	}
	return o.Compress
}

// InputKafkaAuth - Credentials to use when authenticating with the schema registry using basic HTTP authentication
type InputKafkaAuth struct {
	// Enable authentication
	Disabled *bool `default:"true" json:"disabled"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
}

func (i InputKafkaAuth) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputKafkaAuth) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputKafkaAuth) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputKafkaAuth) GetCredentialsSecret() *string {
	if o == nil {
		return nil
	}
	return o.CredentialsSecret
}

// InputKafkaMinimumTLSVersion - Minimum TLS version to use when connecting
type InputKafkaMinimumTLSVersion string

const (
	InputKafkaMinimumTLSVersionTlSv1  InputKafkaMinimumTLSVersion = "TLSv1"
	InputKafkaMinimumTLSVersionTlSv11 InputKafkaMinimumTLSVersion = "TLSv1.1"
	InputKafkaMinimumTLSVersionTlSv12 InputKafkaMinimumTLSVersion = "TLSv1.2"
	InputKafkaMinimumTLSVersionTlSv13 InputKafkaMinimumTLSVersion = "TLSv1.3"
)

func (e InputKafkaMinimumTLSVersion) ToPointer() *InputKafkaMinimumTLSVersion {
	return &e
}
func (e *InputKafkaMinimumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputKafkaMinimumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputKafkaMinimumTLSVersion: %v", v)
	}
}

// InputKafkaMaximumTLSVersion - Maximum TLS version to use when connecting
type InputKafkaMaximumTLSVersion string

const (
	InputKafkaMaximumTLSVersionTlSv1  InputKafkaMaximumTLSVersion = "TLSv1"
	InputKafkaMaximumTLSVersionTlSv11 InputKafkaMaximumTLSVersion = "TLSv1.1"
	InputKafkaMaximumTLSVersionTlSv12 InputKafkaMaximumTLSVersion = "TLSv1.2"
	InputKafkaMaximumTLSVersionTlSv13 InputKafkaMaximumTLSVersion = "TLSv1.3"
)

func (e InputKafkaMaximumTLSVersion) ToPointer() *InputKafkaMaximumTLSVersion {
	return &e
}
func (e *InputKafkaMaximumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputKafkaMaximumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputKafkaMaximumTLSVersion: %v", v)
	}
}

type InputKafkaTLSSettingsClientSide struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Reject certs that are not authorized by a CA in the CA certificate path, or by another
	//                     trusted CA (e.g., the system's CA). Defaults to Yes. Overrides the toggle from Advanced Settings, when also present.
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.
	Servername *string `json:"servername,omitempty"`
	// The name of the predefined certificate.
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Passphrase to use to decrypt private key.
	Passphrase *string `json:"passphrase,omitempty"`
	// Minimum TLS version to use when connecting
	MinVersion *InputKafkaMinimumTLSVersion `json:"minVersion,omitempty"`
	// Maximum TLS version to use when connecting
	MaxVersion *InputKafkaMaximumTLSVersion `json:"maxVersion,omitempty"`
}

func (i InputKafkaTLSSettingsClientSide) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputKafkaTLSSettingsClientSide) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputKafkaTLSSettingsClientSide) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputKafkaTLSSettingsClientSide) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *InputKafkaTLSSettingsClientSide) GetServername() *string {
	if o == nil {
		return nil
	}
	return o.Servername
}

func (o *InputKafkaTLSSettingsClientSide) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *InputKafkaTLSSettingsClientSide) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *InputKafkaTLSSettingsClientSide) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *InputKafkaTLSSettingsClientSide) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *InputKafkaTLSSettingsClientSide) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *InputKafkaTLSSettingsClientSide) GetMinVersion() *InputKafkaMinimumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *InputKafkaTLSSettingsClientSide) GetMaxVersion() *InputKafkaMaximumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

type KafkaSchemaRegistryAuthentication struct {
	// Enable Schema Registry
	Disabled *bool `default:"true" json:"disabled"`
	// URL for accessing the Confluent Schema Registry. Example: http://localhost:8081. To connect over TLS, use https instead of http.
	SchemaRegistryURL *string `default:"http://localhost:8081" json:"schemaRegistryURL"`
	// Maximum time to wait for a Schema Registry connection to complete successfully
	ConnectionTimeout *float64 `default:"30000" json:"connectionTimeout"`
	// Maximum time to wait for the Schema Registry to respond to a request
	RequestTimeout *float64 `default:"30000" json:"requestTimeout"`
	// Maximum number of times to try fetching schemas from the Schema Registry
	MaxRetries *float64 `default:"1" json:"maxRetries"`
	// Credentials to use when authenticating with the schema registry using basic HTTP authentication
	Auth *InputKafkaAuth                  `json:"auth,omitempty"`
	TLS  *InputKafkaTLSSettingsClientSide `json:"tls,omitempty"`
}

func (k KafkaSchemaRegistryAuthentication) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(k, "", false)
}

func (k *KafkaSchemaRegistryAuthentication) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &k, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *KafkaSchemaRegistryAuthentication) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *KafkaSchemaRegistryAuthentication) GetSchemaRegistryURL() *string {
	if o == nil {
		return nil
	}
	return o.SchemaRegistryURL
}

func (o *KafkaSchemaRegistryAuthentication) GetConnectionTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.ConnectionTimeout
}

func (o *KafkaSchemaRegistryAuthentication) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *KafkaSchemaRegistryAuthentication) GetMaxRetries() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxRetries
}

func (o *KafkaSchemaRegistryAuthentication) GetAuth() *InputKafkaAuth {
	if o == nil {
		return nil
	}
	return o.Auth
}

func (o *KafkaSchemaRegistryAuthentication) GetTLS() *InputKafkaTLSSettingsClientSide {
	if o == nil {
		return nil
	}
	return o.TLS
}

// SASLMechanism - SASL authentication mechanism to use.
type SASLMechanism string

const (
	SASLMechanismPlain       SASLMechanism = "plain"
	SASLMechanismScramSha256 SASLMechanism = "scram-sha-256"
	SASLMechanismScramSha512 SASLMechanism = "scram-sha-512"
	SASLMechanismKerberos    SASLMechanism = "kerberos"
)

func (e SASLMechanism) ToPointer() *SASLMechanism {
	return &e
}
func (e *SASLMechanism) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "plain":
		fallthrough
	case "scram-sha-256":
		fallthrough
	case "scram-sha-512":
		fallthrough
	case "kerberos":
		*e = SASLMechanism(v)
		return nil
	default:
		return fmt.Errorf("invalid value for SASLMechanism: %v", v)
	}
}

// Authentication parameters to use when connecting to brokers. Using TLS is highly recommended.
type Authentication struct {
	// Enable Authentication
	Disabled *bool `default:"true" json:"disabled"`
	// SASL authentication mechanism to use.
	Mechanism *SASLMechanism `default:"plain" json:"mechanism"`
}

func (a Authentication) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(a, "", false)
}

func (a *Authentication) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &a, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *Authentication) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *Authentication) GetMechanism() *SASLMechanism {
	if o == nil {
		return nil
	}
	return o.Mechanism
}

// MinimumTLSVersion - Minimum TLS version to use when connecting
type MinimumTLSVersion string

const (
	MinimumTLSVersionTlSv1  MinimumTLSVersion = "TLSv1"
	MinimumTLSVersionTlSv11 MinimumTLSVersion = "TLSv1.1"
	MinimumTLSVersionTlSv12 MinimumTLSVersion = "TLSv1.2"
	MinimumTLSVersionTlSv13 MinimumTLSVersion = "TLSv1.3"
)

func (e MinimumTLSVersion) ToPointer() *MinimumTLSVersion {
	return &e
}
func (e *MinimumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = MinimumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for MinimumTLSVersion: %v", v)
	}
}

// MaximumTLSVersion - Maximum TLS version to use when connecting
type MaximumTLSVersion string

const (
	MaximumTLSVersionTlSv1  MaximumTLSVersion = "TLSv1"
	MaximumTLSVersionTlSv11 MaximumTLSVersion = "TLSv1.1"
	MaximumTLSVersionTlSv12 MaximumTLSVersion = "TLSv1.2"
	MaximumTLSVersionTlSv13 MaximumTLSVersion = "TLSv1.3"
)

func (e MaximumTLSVersion) ToPointer() *MaximumTLSVersion {
	return &e
}
func (e *MaximumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = MaximumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for MaximumTLSVersion: %v", v)
	}
}

type TLSSettingsClientSide struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Reject certs that are not authorized by a CA in the CA certificate path, or by another
	//                     trusted CA (e.g., the system's CA). Defaults to Yes. Overrides the toggle from Advanced Settings, when also present.
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.
	Servername *string `json:"servername,omitempty"`
	// The name of the predefined certificate.
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Passphrase to use to decrypt private key.
	Passphrase *string `json:"passphrase,omitempty"`
	// Minimum TLS version to use when connecting
	MinVersion *MinimumTLSVersion `json:"minVersion,omitempty"`
	// Maximum TLS version to use when connecting
	MaxVersion *MaximumTLSVersion `json:"maxVersion,omitempty"`
}

func (t TLSSettingsClientSide) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(t, "", false)
}

func (t *TLSSettingsClientSide) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &t, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *TLSSettingsClientSide) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *TLSSettingsClientSide) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *TLSSettingsClientSide) GetServername() *string {
	if o == nil {
		return nil
	}
	return o.Servername
}

func (o *TLSSettingsClientSide) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *TLSSettingsClientSide) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *TLSSettingsClientSide) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *TLSSettingsClientSide) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *TLSSettingsClientSide) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *TLSSettingsClientSide) GetMinVersion() *MinimumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *TLSSettingsClientSide) GetMaxVersion() *MaximumTLSVersion {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

type InputKafkaMetadata struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputKafkaMetadata) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputKafkaMetadata) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputKafka struct {
	// Unique ID for this input
	ID       *string         `json:"id,omitempty"`
	Type     *InputKafkaType `json:"type,omitempty"`
	Disabled *bool           `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputKafkaConnections `json:"connections,omitempty"`
	Pq          *InputKafkaPq           `json:"pq,omitempty"`
	// Enter each Kafka bootstrap server you want to use. Specify the hostname and port (such as mykafkabroker:9092) or just the hostname (in which case @{product} will assign port 9092).
	Brokers []string `json:"brokers"`
	// Topic to subscribe to. Warning: To optimize performance, Cribl suggests subscribing each Kafka Source to only a single topic.
	Topics []string `json:"topics,omitempty"`
	// Specifies the consumer group to which this instance belongs. Defaults to 'Cribl'.
	GroupID *string `default:"Cribl" json:"groupId"`
	// Leave toggled to 'Yes' if you want the Source, upon first subscribing to a topic, to read starting with the earliest available message
	FromBeginning       *bool                              `default:"true" json:"fromBeginning"`
	KafkaSchemaRegistry *KafkaSchemaRegistryAuthentication `json:"kafkaSchemaRegistry,omitempty"`
	// Maximum time to wait for a connection to complete successfully
	ConnectionTimeout *float64 `default:"10000" json:"connectionTimeout"`
	// Maximum time to wait for Kafka to respond to a request
	RequestTimeout *float64 `default:"60000" json:"requestTimeout"`
	// If messages are failing, you can set the maximum number of retries as high as 100 to prevent loss of data
	MaxRetries *float64 `default:"5" json:"maxRetries"`
	// The maximum wait time for a retry, in milliseconds. Default (and minimum) is 30,000 ms (30 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackOff *float64 `default:"30000" json:"maxBackOff"`
	// Initial value used to calculate the retry, in milliseconds. Maximum is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"300" json:"initialBackoff"`
	// Set the backoff multiplier (2-20) to control the retry frequency for failed messages. For faster retries, use a lower multiplier. For slower retries with more delay between attempts, use a higher multiplier. The multiplier is used in an exponential backoff formula; see the Kafka [documentation](https://kafka.js.org/docs/retry-detailed) for details.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// Maximum time to wait for Kafka to respond to an authentication request
	AuthenticationTimeout *float64 `default:"10000" json:"authenticationTimeout"`
	// Specifies a time window during which @{product} can reauthenticate if needed. Creates the window measuring backwards from the moment when credentials are set to expire.
	ReauthenticationThreshold *float64 `default:"10000" json:"reauthenticationThreshold"`
	// Authentication parameters to use when connecting to brokers. Using TLS is highly recommended.
	Sasl *Authentication        `json:"sasl,omitempty"`
	TLS  *TLSSettingsClientSide `json:"tls,omitempty"`
	//       Timeout used to detect client failures when using Kafka's group management facilities.
	//       If the client sends the broker no heartbeats before this timeout expires,
	//       the broker will remove this client from the group, and will initiate a rebalance.
	//       Value must be between the broker's configured group.min.session.timeout.ms and group.max.session.timeout.ms.
	//       See details [here](https://kafka.apache.org/documentation/#consumerconfigs_session.timeout.ms).
	SessionTimeout *float64 `default:"30000" json:"sessionTimeout"`
	//       Maximum allowed time for each worker to join the group after a rebalance has begun.
	//       If the timeout is exceeded, the coordinator broker will remove the worker from the group.
	//       See details [here](https://kafka.apache.org/documentation/#connectconfigs_rebalance.timeout.ms).
	RebalanceTimeout *float64 `default:"60000" json:"rebalanceTimeout"`
	//       Expected time between heartbeats to the consumer coordinator when using Kafka's group management facilities.
	//       Value must be lower than sessionTimeout, and typically should not exceed 1/3 of the sessionTimeout value.
	//       See details [here](https://kafka.apache.org/documentation/#consumerconfigs_heartbeat.interval.ms).
	HeartbeatInterval *float64 `default:"3000" json:"heartbeatInterval"`
	// How often to commit offsets. If both this and Offset commit threshold are set, @{product} commits offsets when either condition is met. If both are empty, @{product} commits offsets after each batch.
	AutoCommitInterval *float64 `json:"autoCommitInterval,omitempty"`
	// How many events are needed to trigger an offset commit. If both this and Offset commit interval are set, @{product} commits offsets when either condition is met. If both are empty, @{product} commits offsets after each batch.
	AutoCommitThreshold *float64 `json:"autoCommitThreshold,omitempty"`
	// Maximum amount of data that Kafka will return per partition, per fetch request. Must equal or exceed the maximum message size (maxBytesPerPartition) that Kafka is configured to allow. Otherwise, @{product} can get stuck trying to retrieve messages. Defaults to 1048576 (1 MB).
	MaxBytesPerPartition *float64 `default:"1048576" json:"maxBytesPerPartition"`
	// Maximum number of bytes that Kafka will return per fetch request. Defaults to 10485760 (10 MB).
	MaxBytes *float64 `default:"10485760" json:"maxBytes"`
	// Maximum number of network errors before the consumer recreates a socket.
	MaxSocketErrors *float64 `default:"0" json:"maxSocketErrors"`
	// Fields to add to events from this input
	Metadata    []InputKafkaMetadata `json:"metadata,omitempty"`
	Description *string              `json:"description,omitempty"`
	Status      *TFStatus            `json:"status,omitempty"`
}

func (i InputKafka) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputKafka) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputKafka) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputKafka) GetType() *InputKafkaType {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputKafka) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputKafka) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputKafka) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputKafka) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputKafka) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputKafka) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputKafka) GetConnections() []InputKafkaConnections {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputKafka) GetPq() *InputKafkaPq {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputKafka) GetBrokers() []string {
	if o == nil {
		return []string{}
	}
	return o.Brokers
}

func (o *InputKafka) GetTopics() []string {
	if o == nil {
		return nil
	}
	return o.Topics
}

func (o *InputKafka) GetGroupID() *string {
	if o == nil {
		return nil
	}
	return o.GroupID
}

func (o *InputKafka) GetFromBeginning() *bool {
	if o == nil {
		return nil
	}
	return o.FromBeginning
}

func (o *InputKafka) GetKafkaSchemaRegistry() *KafkaSchemaRegistryAuthentication {
	if o == nil {
		return nil
	}
	return o.KafkaSchemaRegistry
}

func (o *InputKafka) GetConnectionTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.ConnectionTimeout
}

func (o *InputKafka) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *InputKafka) GetMaxRetries() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxRetries
}

func (o *InputKafka) GetMaxBackOff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackOff
}

func (o *InputKafka) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *InputKafka) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *InputKafka) GetAuthenticationTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.AuthenticationTimeout
}

func (o *InputKafka) GetReauthenticationThreshold() *float64 {
	if o == nil {
		return nil
	}
	return o.ReauthenticationThreshold
}

func (o *InputKafka) GetSasl() *Authentication {
	if o == nil {
		return nil
	}
	return o.Sasl
}

func (o *InputKafka) GetTLS() *TLSSettingsClientSide {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputKafka) GetSessionTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SessionTimeout
}

func (o *InputKafka) GetRebalanceTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RebalanceTimeout
}

func (o *InputKafka) GetHeartbeatInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.HeartbeatInterval
}

func (o *InputKafka) GetAutoCommitInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.AutoCommitInterval
}

func (o *InputKafka) GetAutoCommitThreshold() *float64 {
	if o == nil {
		return nil
	}
	return o.AutoCommitThreshold
}

func (o *InputKafka) GetMaxBytesPerPartition() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBytesPerPartition
}

func (o *InputKafka) GetMaxBytes() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBytes
}

func (o *InputKafka) GetMaxSocketErrors() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxSocketErrors
}

func (o *InputKafka) GetMetadata() []InputKafkaMetadata {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputKafka) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputKafka) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputCollectionType string

const (
	InputCollectionTypeCollection InputCollectionType = "collection"
)

func (e InputCollectionType) ToPointer() *InputCollectionType {
	return &e
}
func (e *InputCollectionType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "collection":
		*e = InputCollectionType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputCollectionType: %v", v)
	}
}

type Connections struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *Connections) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *Connections) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// InputCollectionMode - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputCollectionMode string

const (
	InputCollectionModeSmart  InputCollectionMode = "smart"
	InputCollectionModeAlways InputCollectionMode = "always"
)

func (e InputCollectionMode) ToPointer() *InputCollectionMode {
	return &e
}
func (e *InputCollectionMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputCollectionMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputCollectionMode: %v", v)
	}
}

// InputCollectionCompression - Codec to use to compress the persisted data
type InputCollectionCompression string

const (
	InputCollectionCompressionNone InputCollectionCompression = "none"
	InputCollectionCompressionGzip InputCollectionCompression = "gzip"
)

func (e InputCollectionCompression) ToPointer() *InputCollectionCompression {
	return &e
}
func (e *InputCollectionCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputCollectionCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputCollectionCompression: %v", v)
	}
}

type Pq struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputCollectionMode `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *InputCollectionCompression `default:"none" json:"compress"`
}

func (p Pq) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *Pq) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *Pq) GetMode() *InputCollectionMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *Pq) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *Pq) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *Pq) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *Pq) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *Pq) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *Pq) GetCompress() *InputCollectionCompression {
	if o == nil {
		return nil
	}
	return o.Compress
}

type InputCollectionPreprocess struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Command to feed the data through (via stdin) and process its output (stdout)
	Command *string `json:"command,omitempty"`
	// Arguments to be added to the custom command
	Args []string `json:"args,omitempty"`
}

func (i InputCollectionPreprocess) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputCollectionPreprocess) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputCollectionPreprocess) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputCollectionPreprocess) GetCommand() *string {
	if o == nil {
		return nil
	}
	return o.Command
}

func (o *InputCollectionPreprocess) GetArgs() []string {
	if o == nil {
		return nil
	}
	return o.Args
}

type InputCollectionMetadata struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputCollectionMetadata) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputCollectionMetadata) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputCollection struct {
	// Unique ID for this input
	ID       string               `json:"id"`
	Type     *InputCollectionType `default:"collection" json:"type"`
	Disabled *bool                `default:"false" json:"disabled"`
	// Pipeline to process results
	Pipeline *string `json:"pipeline,omitempty"`
	// Send events to normal routing and event processing. Disable to select a specific Pipeline/Destination combination.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []Connections `json:"connections,omitempty"`
	Pq          *Pq           `json:"pq,omitempty"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitempty"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64                   `default:"10000" json:"staleChannelFlushMs"`
	Preprocess          *InputCollectionPreprocess `json:"preprocess,omitempty"`
	// Rate (in bytes per second) to throttle while writing to an output. Accepts values with multiple-byte units, such as KB, MB, and GB. (Example: 42 MB) Default value of 0 specifies no throttling.
	ThrottleRatePerSec *string `default:"0" json:"throttleRatePerSec"`
	// Fields to add to events from this input
	Metadata []InputCollectionMetadata `json:"metadata,omitempty"`
	// Destination to send results to
	Output *string   `json:"output,omitempty"`
	Status *TFStatus `json:"status,omitempty"`
}

func (i InputCollection) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputCollection) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputCollection) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *InputCollection) GetType() *InputCollectionType {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputCollection) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputCollection) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputCollection) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputCollection) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputCollection) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputCollection) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputCollection) GetConnections() []Connections {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputCollection) GetPq() *Pq {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputCollection) GetBreakerRulesets() []string {
	if o == nil {
		return nil
	}
	return o.BreakerRulesets
}

func (o *InputCollection) GetStaleChannelFlushMs() *float64 {
	if o == nil {
		return nil
	}
	return o.StaleChannelFlushMs
}

func (o *InputCollection) GetPreprocess() *InputCollectionPreprocess {
	if o == nil {
		return nil
	}
	return o.Preprocess
}

func (o *InputCollection) GetThrottleRatePerSec() *string {
	if o == nil {
		return nil
	}
	return o.ThrottleRatePerSec
}

func (o *InputCollection) GetMetadata() []InputCollectionMetadata {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputCollection) GetOutput() *string {
	if o == nil {
		return nil
	}
	return o.Output
}

func (o *InputCollection) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputType string

const (
	InputTypeInputCollection           InputType = "InputCollection"
	InputTypeInputKafka                InputType = "InputKafka"
	InputTypeInputMsk                  InputType = "InputMsk"
	InputTypeInputHTTP                 InputType = "InputHttp"
	InputTypeInputSplunk               InputType = "InputSplunk"
	InputTypeInputSplunkSearch         InputType = "InputSplunkSearch"
	InputTypeInputSplunkHec            InputType = "InputSplunkHec"
	InputTypeInputAzureBlob            InputType = "InputAzureBlob"
	InputTypeInputElastic              InputType = "InputElastic"
	InputTypeInputConfluentCloud       InputType = "InputConfluentCloud"
	InputTypeInputGrafana              InputType = "InputGrafana"
	InputTypeInputLoki                 InputType = "InputLoki"
	InputTypeInputPrometheusRw         InputType = "InputPrometheusRw"
	InputTypeInputPrometheus           InputType = "InputPrometheus"
	InputTypeInputEdgePrometheus       InputType = "InputEdgePrometheus"
	InputTypeInputOffice365Mgmt        InputType = "InputOffice365Mgmt"
	InputTypeInputOffice365Service     InputType = "InputOffice365Service"
	InputTypeInputOffice365MsgTrace    InputType = "InputOffice365MsgTrace"
	InputTypeInputEventhub             InputType = "InputEventhub"
	InputTypeInputExec                 InputType = "InputExec"
	InputTypeInputFirehose             InputType = "InputFirehose"
	InputTypeInputGooglePubsub         InputType = "InputGooglePubsub"
	InputTypeInputCribl                InputType = "InputCribl"
	InputTypeInputCriblTCP             InputType = "InputCriblTcp"
	InputTypeInputCriblHTTP            InputType = "InputCriblHttp"
	InputTypeInputTcpjson              InputType = "InputTcpjson"
	InputTypeInputSystemMetrics        InputType = "InputSystemMetrics"
	InputTypeInputSystemState          InputType = "InputSystemState"
	InputTypeInputKubeMetrics          InputType = "InputKubeMetrics"
	InputTypeInputKubeLogs             InputType = "InputKubeLogs"
	InputTypeInputKubeEvents           InputType = "InputKubeEvents"
	InputTypeInputWindowsMetrics       InputType = "InputWindowsMetrics"
	InputTypeInputCrowdstrike          InputType = "InputCrowdstrike"
	InputTypeInputDatadogAgent         InputType = "InputDatadogAgent"
	InputTypeInputDatagen              InputType = "InputDatagen"
	InputTypeInputHTTPRaw              InputType = "InputHttpRaw"
	InputTypeInputKinesis              InputType = "InputKinesis"
	InputTypeInputCriblmetrics         InputType = "InputCriblmetrics"
	InputTypeInputMetrics              InputType = "InputMetrics"
	InputTypeInputS3                   InputType = "InputS3"
	InputTypeInputS3Inventory          InputType = "InputS3Inventory"
	InputTypeInputSnmp                 InputType = "InputSnmp"
	InputTypeInputOpenTelemetry        InputType = "InputOpenTelemetry"
	InputTypeInputModelDrivenTelemetry InputType = "InputModelDrivenTelemetry"
	InputTypeInputSqs                  InputType = "InputSqs"
	InputTypeInputSyslog               InputType = "InputSyslog"
	InputTypeInputFile                 InputType = "InputFile"
	InputTypeInputTCP                  InputType = "InputTcp"
	InputTypeInputAppscope             InputType = "InputAppscope"
	InputTypeInputWef                  InputType = "InputWef"
	InputTypeInputWinEventLogs         InputType = "InputWinEventLogs"
	InputTypeInputRawUDP               InputType = "InputRawUdp"
	InputTypeInputJournalFiles         InputType = "InputJournalFiles"
	InputTypeInputWiz                  InputType = "InputWiz"
	InputTypeInputNetflow              InputType = "InputNetflow"
	InputTypeInputSecurityLake         InputType = "InputSecurityLake"
	InputTypeInputZscalerHec           InputType = "InputZscalerHec"
)

type Input struct {
	InputCollection           *InputCollection           `queryParam:"inline"`
	InputKafka                *InputKafka                `queryParam:"inline"`
	InputMsk                  *InputMsk                  `queryParam:"inline"`
	InputHTTP                 *InputHTTP                 `queryParam:"inline"`
	InputSplunk               *InputSplunk               `queryParam:"inline"`
	InputSplunkSearch         *InputSplunkSearch         `queryParam:"inline"`
	InputSplunkHec            *InputSplunkHec            `queryParam:"inline"`
	InputAzureBlob            *InputAzureBlob            `queryParam:"inline"`
	InputElastic              *InputElastic              `queryParam:"inline"`
	InputConfluentCloud       *InputConfluentCloud       `queryParam:"inline"`
	InputGrafana              *InputGrafana              `queryParam:"inline"`
	InputLoki                 *InputLoki                 `queryParam:"inline"`
	InputPrometheusRw         *InputPrometheusRw         `queryParam:"inline"`
	InputPrometheus           *InputPrometheus           `queryParam:"inline"`
	InputEdgePrometheus       *InputEdgePrometheus       `queryParam:"inline"`
	InputOffice365Mgmt        *InputOffice365Mgmt        `queryParam:"inline"`
	InputOffice365Service     *InputOffice365Service     `queryParam:"inline"`
	InputOffice365MsgTrace    *InputOffice365MsgTrace    `queryParam:"inline"`
	InputEventhub             *InputEventhub             `queryParam:"inline"`
	InputExec                 *InputExec                 `queryParam:"inline"`
	InputFirehose             *InputFirehose             `queryParam:"inline"`
	InputGooglePubsub         *InputGooglePubsub         `queryParam:"inline"`
	InputCribl                *InputCribl                `queryParam:"inline"`
	InputCriblTCP             *InputCriblTCP             `queryParam:"inline"`
	InputCriblHTTP            *InputCriblHTTP            `queryParam:"inline"`
	InputTcpjson              *InputTcpjson              `queryParam:"inline"`
	InputSystemMetrics        *InputSystemMetrics        `queryParam:"inline"`
	InputSystemState          *InputSystemState          `queryParam:"inline"`
	InputKubeMetrics          *InputKubeMetrics          `queryParam:"inline"`
	InputKubeLogs             *InputKubeLogs             `queryParam:"inline"`
	InputKubeEvents           *InputKubeEvents           `queryParam:"inline"`
	InputWindowsMetrics       *InputWindowsMetrics       `queryParam:"inline"`
	InputCrowdstrike          *InputCrowdstrike          `queryParam:"inline"`
	InputDatadogAgent         *InputDatadogAgent         `queryParam:"inline"`
	InputDatagen              *InputDatagen              `queryParam:"inline"`
	InputHTTPRaw              *InputHTTPRaw              `queryParam:"inline"`
	InputKinesis              *InputKinesis              `queryParam:"inline"`
	InputCriblmetrics         *InputCriblmetrics         `queryParam:"inline"`
	InputMetrics              *InputMetrics              `queryParam:"inline"`
	InputS3                   *InputS3                   `queryParam:"inline"`
	InputS3Inventory          *InputS3Inventory          `queryParam:"inline"`
	InputSnmp                 *InputSnmp                 `queryParam:"inline"`
	InputOpenTelemetry        *InputOpenTelemetry        `queryParam:"inline"`
	InputModelDrivenTelemetry *InputModelDrivenTelemetry `queryParam:"inline"`
	InputSqs                  *InputSqs                  `queryParam:"inline"`
	InputSyslog               *InputSyslog               `queryParam:"inline"`
	InputFile                 *InputFile                 `queryParam:"inline"`
	InputTCP                  *InputTCP                  `queryParam:"inline"`
	InputAppscope             *InputAppscope             `queryParam:"inline"`
	InputWef                  *InputWef                  `queryParam:"inline"`
	InputWinEventLogs         *InputWinEventLogs         `queryParam:"inline"`
	InputRawUDP               *InputRawUDP               `queryParam:"inline"`
	InputJournalFiles         *InputJournalFiles         `queryParam:"inline"`
	InputWiz                  *InputWiz                  `queryParam:"inline"`
	InputNetflow              *InputNetflow              `queryParam:"inline"`
	InputSecurityLake         *InputSecurityLake         `queryParam:"inline"`
	InputZscalerHec           *InputZscalerHec           `queryParam:"inline"`

	Type InputType
}

func CreateInputInputCollection(inputCollection InputCollection) Input {
	typ := InputTypeInputCollection

	return Input{
		InputCollection: &inputCollection,
		Type:            typ,
	}
}

func CreateInputInputKafka(inputKafka InputKafka) Input {
	typ := InputTypeInputKafka

	return Input{
		InputKafka: &inputKafka,
		Type:       typ,
	}
}

func CreateInputInputMsk(inputMsk InputMsk) Input {
	typ := InputTypeInputMsk

	return Input{
		InputMsk: &inputMsk,
		Type:     typ,
	}
}

func CreateInputInputHTTP(inputHTTP InputHTTP) Input {
	typ := InputTypeInputHTTP

	return Input{
		InputHTTP: &inputHTTP,
		Type:      typ,
	}
}

func CreateInputInputSplunk(inputSplunk InputSplunk) Input {
	typ := InputTypeInputSplunk

	return Input{
		InputSplunk: &inputSplunk,
		Type:        typ,
	}
}

func CreateInputInputSplunkSearch(inputSplunkSearch InputSplunkSearch) Input {
	typ := InputTypeInputSplunkSearch

	return Input{
		InputSplunkSearch: &inputSplunkSearch,
		Type:              typ,
	}
}

func CreateInputInputSplunkHec(inputSplunkHec InputSplunkHec) Input {
	typ := InputTypeInputSplunkHec

	return Input{
		InputSplunkHec: &inputSplunkHec,
		Type:           typ,
	}
}

func CreateInputInputAzureBlob(inputAzureBlob InputAzureBlob) Input {
	typ := InputTypeInputAzureBlob

	return Input{
		InputAzureBlob: &inputAzureBlob,
		Type:           typ,
	}
}

func CreateInputInputElastic(inputElastic InputElastic) Input {
	typ := InputTypeInputElastic

	return Input{
		InputElastic: &inputElastic,
		Type:         typ,
	}
}

func CreateInputInputConfluentCloud(inputConfluentCloud InputConfluentCloud) Input {
	typ := InputTypeInputConfluentCloud

	return Input{
		InputConfluentCloud: &inputConfluentCloud,
		Type:                typ,
	}
}

func CreateInputInputGrafana(inputGrafana InputGrafana) Input {
	typ := InputTypeInputGrafana

	return Input{
		InputGrafana: &inputGrafana,
		Type:         typ,
	}
}

func CreateInputInputLoki(inputLoki InputLoki) Input {
	typ := InputTypeInputLoki

	return Input{
		InputLoki: &inputLoki,
		Type:      typ,
	}
}

func CreateInputInputPrometheusRw(inputPrometheusRw InputPrometheusRw) Input {
	typ := InputTypeInputPrometheusRw

	return Input{
		InputPrometheusRw: &inputPrometheusRw,
		Type:              typ,
	}
}

func CreateInputInputPrometheus(inputPrometheus InputPrometheus) Input {
	typ := InputTypeInputPrometheus

	return Input{
		InputPrometheus: &inputPrometheus,
		Type:            typ,
	}
}

func CreateInputInputEdgePrometheus(inputEdgePrometheus InputEdgePrometheus) Input {
	typ := InputTypeInputEdgePrometheus

	return Input{
		InputEdgePrometheus: &inputEdgePrometheus,
		Type:                typ,
	}
}

func CreateInputInputOffice365Mgmt(inputOffice365Mgmt InputOffice365Mgmt) Input {
	typ := InputTypeInputOffice365Mgmt

	return Input{
		InputOffice365Mgmt: &inputOffice365Mgmt,
		Type:               typ,
	}
}

func CreateInputInputOffice365Service(inputOffice365Service InputOffice365Service) Input {
	typ := InputTypeInputOffice365Service

	return Input{
		InputOffice365Service: &inputOffice365Service,
		Type:                  typ,
	}
}

func CreateInputInputOffice365MsgTrace(inputOffice365MsgTrace InputOffice365MsgTrace) Input {
	typ := InputTypeInputOffice365MsgTrace

	return Input{
		InputOffice365MsgTrace: &inputOffice365MsgTrace,
		Type:                   typ,
	}
}

func CreateInputInputEventhub(inputEventhub InputEventhub) Input {
	typ := InputTypeInputEventhub

	return Input{
		InputEventhub: &inputEventhub,
		Type:          typ,
	}
}

func CreateInputInputExec(inputExec InputExec) Input {
	typ := InputTypeInputExec

	return Input{
		InputExec: &inputExec,
		Type:      typ,
	}
}

func CreateInputInputFirehose(inputFirehose InputFirehose) Input {
	typ := InputTypeInputFirehose

	return Input{
		InputFirehose: &inputFirehose,
		Type:          typ,
	}
}

func CreateInputInputGooglePubsub(inputGooglePubsub InputGooglePubsub) Input {
	typ := InputTypeInputGooglePubsub

	return Input{
		InputGooglePubsub: &inputGooglePubsub,
		Type:              typ,
	}
}

func CreateInputInputCribl(inputCribl InputCribl) Input {
	typ := InputTypeInputCribl

	return Input{
		InputCribl: &inputCribl,
		Type:       typ,
	}
}

func CreateInputInputCriblTCP(inputCriblTCP InputCriblTCP) Input {
	typ := InputTypeInputCriblTCP

	return Input{
		InputCriblTCP: &inputCriblTCP,
		Type:          typ,
	}
}

func CreateInputInputCriblHTTP(inputCriblHTTP InputCriblHTTP) Input {
	typ := InputTypeInputCriblHTTP

	return Input{
		InputCriblHTTP: &inputCriblHTTP,
		Type:           typ,
	}
}

func CreateInputInputTcpjson(inputTcpjson InputTcpjson) Input {
	typ := InputTypeInputTcpjson

	return Input{
		InputTcpjson: &inputTcpjson,
		Type:         typ,
	}
}

func CreateInputInputSystemMetrics(inputSystemMetrics InputSystemMetrics) Input {
	typ := InputTypeInputSystemMetrics

	return Input{
		InputSystemMetrics: &inputSystemMetrics,
		Type:               typ,
	}
}

func CreateInputInputSystemState(inputSystemState InputSystemState) Input {
	typ := InputTypeInputSystemState

	return Input{
		InputSystemState: &inputSystemState,
		Type:             typ,
	}
}

func CreateInputInputKubeMetrics(inputKubeMetrics InputKubeMetrics) Input {
	typ := InputTypeInputKubeMetrics

	return Input{
		InputKubeMetrics: &inputKubeMetrics,
		Type:             typ,
	}
}

func CreateInputInputKubeLogs(inputKubeLogs InputKubeLogs) Input {
	typ := InputTypeInputKubeLogs

	return Input{
		InputKubeLogs: &inputKubeLogs,
		Type:          typ,
	}
}

func CreateInputInputKubeEvents(inputKubeEvents InputKubeEvents) Input {
	typ := InputTypeInputKubeEvents

	return Input{
		InputKubeEvents: &inputKubeEvents,
		Type:            typ,
	}
}

func CreateInputInputWindowsMetrics(inputWindowsMetrics InputWindowsMetrics) Input {
	typ := InputTypeInputWindowsMetrics

	return Input{
		InputWindowsMetrics: &inputWindowsMetrics,
		Type:                typ,
	}
}

func CreateInputInputCrowdstrike(inputCrowdstrike InputCrowdstrike) Input {
	typ := InputTypeInputCrowdstrike

	return Input{
		InputCrowdstrike: &inputCrowdstrike,
		Type:             typ,
	}
}

func CreateInputInputDatadogAgent(inputDatadogAgent InputDatadogAgent) Input {
	typ := InputTypeInputDatadogAgent

	return Input{
		InputDatadogAgent: &inputDatadogAgent,
		Type:              typ,
	}
}

func CreateInputInputDatagen(inputDatagen InputDatagen) Input {
	typ := InputTypeInputDatagen

	return Input{
		InputDatagen: &inputDatagen,
		Type:         typ,
	}
}

func CreateInputInputHTTPRaw(inputHTTPRaw InputHTTPRaw) Input {
	typ := InputTypeInputHTTPRaw

	return Input{
		InputHTTPRaw: &inputHTTPRaw,
		Type:         typ,
	}
}

func CreateInputInputKinesis(inputKinesis InputKinesis) Input {
	typ := InputTypeInputKinesis

	return Input{
		InputKinesis: &inputKinesis,
		Type:         typ,
	}
}

func CreateInputInputCriblmetrics(inputCriblmetrics InputCriblmetrics) Input {
	typ := InputTypeInputCriblmetrics

	return Input{
		InputCriblmetrics: &inputCriblmetrics,
		Type:              typ,
	}
}

func CreateInputInputMetrics(inputMetrics InputMetrics) Input {
	typ := InputTypeInputMetrics

	return Input{
		InputMetrics: &inputMetrics,
		Type:         typ,
	}
}

func CreateInputInputS3(inputS3 InputS3) Input {
	typ := InputTypeInputS3

	return Input{
		InputS3: &inputS3,
		Type:    typ,
	}
}

func CreateInputInputS3Inventory(inputS3Inventory InputS3Inventory) Input {
	typ := InputTypeInputS3Inventory

	return Input{
		InputS3Inventory: &inputS3Inventory,
		Type:             typ,
	}
}

func CreateInputInputSnmp(inputSnmp InputSnmp) Input {
	typ := InputTypeInputSnmp

	return Input{
		InputSnmp: &inputSnmp,
		Type:      typ,
	}
}

func CreateInputInputOpenTelemetry(inputOpenTelemetry InputOpenTelemetry) Input {
	typ := InputTypeInputOpenTelemetry

	return Input{
		InputOpenTelemetry: &inputOpenTelemetry,
		Type:               typ,
	}
}

func CreateInputInputModelDrivenTelemetry(inputModelDrivenTelemetry InputModelDrivenTelemetry) Input {
	typ := InputTypeInputModelDrivenTelemetry

	return Input{
		InputModelDrivenTelemetry: &inputModelDrivenTelemetry,
		Type:                      typ,
	}
}

func CreateInputInputSqs(inputSqs InputSqs) Input {
	typ := InputTypeInputSqs

	return Input{
		InputSqs: &inputSqs,
		Type:     typ,
	}
}

func CreateInputInputSyslog(inputSyslog InputSyslog) Input {
	typ := InputTypeInputSyslog

	return Input{
		InputSyslog: &inputSyslog,
		Type:        typ,
	}
}

func CreateInputInputFile(inputFile InputFile) Input {
	typ := InputTypeInputFile

	return Input{
		InputFile: &inputFile,
		Type:      typ,
	}
}

func CreateInputInputTCP(inputTCP InputTCP) Input {
	typ := InputTypeInputTCP

	return Input{
		InputTCP: &inputTCP,
		Type:     typ,
	}
}

func CreateInputInputAppscope(inputAppscope InputAppscope) Input {
	typ := InputTypeInputAppscope

	return Input{
		InputAppscope: &inputAppscope,
		Type:          typ,
	}
}

func CreateInputInputWef(inputWef InputWef) Input {
	typ := InputTypeInputWef

	return Input{
		InputWef: &inputWef,
		Type:     typ,
	}
}

func CreateInputInputWinEventLogs(inputWinEventLogs InputWinEventLogs) Input {
	typ := InputTypeInputWinEventLogs

	return Input{
		InputWinEventLogs: &inputWinEventLogs,
		Type:              typ,
	}
}

func CreateInputInputRawUDP(inputRawUDP InputRawUDP) Input {
	typ := InputTypeInputRawUDP

	return Input{
		InputRawUDP: &inputRawUDP,
		Type:        typ,
	}
}

func CreateInputInputJournalFiles(inputJournalFiles InputJournalFiles) Input {
	typ := InputTypeInputJournalFiles

	return Input{
		InputJournalFiles: &inputJournalFiles,
		Type:              typ,
	}
}

func CreateInputInputWiz(inputWiz InputWiz) Input {
	typ := InputTypeInputWiz

	return Input{
		InputWiz: &inputWiz,
		Type:     typ,
	}
}

func CreateInputInputNetflow(inputNetflow InputNetflow) Input {
	typ := InputTypeInputNetflow

	return Input{
		InputNetflow: &inputNetflow,
		Type:         typ,
	}
}

func CreateInputInputSecurityLake(inputSecurityLake InputSecurityLake) Input {
	typ := InputTypeInputSecurityLake

	return Input{
		InputSecurityLake: &inputSecurityLake,
		Type:              typ,
	}
}

func CreateInputInputZscalerHec(inputZscalerHec InputZscalerHec) Input {
	typ := InputTypeInputZscalerHec

	return Input{
		InputZscalerHec: &inputZscalerHec,
		Type:            typ,
	}
}

func (u *Input) UnmarshalJSON(data []byte) error {

	var inputCribl InputCribl = InputCribl{}
	if err := utils.UnmarshalJSON(data, &inputCribl, "", true, true); err == nil {
		u.InputCribl = &inputCribl
		u.Type = InputTypeInputCribl
		return nil
	}

	var inputDatagen InputDatagen = InputDatagen{}
	if err := utils.UnmarshalJSON(data, &inputDatagen, "", true, true); err == nil {
		u.InputDatagen = &inputDatagen
		u.Type = InputTypeInputDatagen
		return nil
	}

	var inputKubeEvents InputKubeEvents = InputKubeEvents{}
	if err := utils.UnmarshalJSON(data, &inputKubeEvents, "", true, true); err == nil {
		u.InputKubeEvents = &inputKubeEvents
		u.Type = InputTypeInputKubeEvents
		return nil
	}

	var inputCriblmetrics InputCriblmetrics = InputCriblmetrics{}
	if err := utils.UnmarshalJSON(data, &inputCriblmetrics, "", true, true); err == nil {
		u.InputCriblmetrics = &inputCriblmetrics
		u.Type = InputTypeInputCriblmetrics
		return nil
	}

	var inputKubeMetrics InputKubeMetrics = InputKubeMetrics{}
	if err := utils.UnmarshalJSON(data, &inputKubeMetrics, "", true, true); err == nil {
		u.InputKubeMetrics = &inputKubeMetrics
		u.Type = InputTypeInputKubeMetrics
		return nil
	}

	var inputSystemState InputSystemState = InputSystemState{}
	if err := utils.UnmarshalJSON(data, &inputSystemState, "", true, true); err == nil {
		u.InputSystemState = &inputSystemState
		u.Type = InputTypeInputSystemState
		return nil
	}

	var inputCollection InputCollection = InputCollection{}
	if err := utils.UnmarshalJSON(data, &inputCollection, "", true, true); err == nil {
		u.InputCollection = &inputCollection
		u.Type = InputTypeInputCollection
		return nil
	}

	var inputModelDrivenTelemetry InputModelDrivenTelemetry = InputModelDrivenTelemetry{}
	if err := utils.UnmarshalJSON(data, &inputModelDrivenTelemetry, "", true, true); err == nil {
		u.InputModelDrivenTelemetry = &inputModelDrivenTelemetry
		u.Type = InputTypeInputModelDrivenTelemetry
		return nil
	}

	var inputWindowsMetrics InputWindowsMetrics = InputWindowsMetrics{}
	if err := utils.UnmarshalJSON(data, &inputWindowsMetrics, "", true, true); err == nil {
		u.InputWindowsMetrics = &inputWindowsMetrics
		u.Type = InputTypeInputWindowsMetrics
		return nil
	}

	var inputSystemMetrics InputSystemMetrics = InputSystemMetrics{}
	if err := utils.UnmarshalJSON(data, &inputSystemMetrics, "", true, true); err == nil {
		u.InputSystemMetrics = &inputSystemMetrics
		u.Type = InputTypeInputSystemMetrics
		return nil
	}

	var inputJournalFiles InputJournalFiles = InputJournalFiles{}
	if err := utils.UnmarshalJSON(data, &inputJournalFiles, "", true, true); err == nil {
		u.InputJournalFiles = &inputJournalFiles
		u.Type = InputTypeInputJournalFiles
		return nil
	}

	var inputSnmp InputSnmp = InputSnmp{}
	if err := utils.UnmarshalJSON(data, &inputSnmp, "", true, true); err == nil {
		u.InputSnmp = &inputSnmp
		u.Type = InputTypeInputSnmp
		return nil
	}

	var inputWinEventLogs InputWinEventLogs = InputWinEventLogs{}
	if err := utils.UnmarshalJSON(data, &inputWinEventLogs, "", true, true); err == nil {
		u.InputWinEventLogs = &inputWinEventLogs
		u.Type = InputTypeInputWinEventLogs
		return nil
	}

	var inputRawUDP InputRawUDP = InputRawUDP{}
	if err := utils.UnmarshalJSON(data, &inputRawUDP, "", true, true); err == nil {
		u.InputRawUDP = &inputRawUDP
		u.Type = InputTypeInputRawUDP
		return nil
	}

	var inputExec InputExec = InputExec{}
	if err := utils.UnmarshalJSON(data, &inputExec, "", true, true); err == nil {
		u.InputExec = &inputExec
		u.Type = InputTypeInputExec
		return nil
	}

	var inputKubeLogs InputKubeLogs = InputKubeLogs{}
	if err := utils.UnmarshalJSON(data, &inputKubeLogs, "", true, true); err == nil {
		u.InputKubeLogs = &inputKubeLogs
		u.Type = InputTypeInputKubeLogs
		return nil
	}

	var inputMetrics InputMetrics = InputMetrics{}
	if err := utils.UnmarshalJSON(data, &inputMetrics, "", true, true); err == nil {
		u.InputMetrics = &inputMetrics
		u.Type = InputTypeInputMetrics
		return nil
	}

	var inputCriblTCP InputCriblTCP = InputCriblTCP{}
	if err := utils.UnmarshalJSON(data, &inputCriblTCP, "", true, true); err == nil {
		u.InputCriblTCP = &inputCriblTCP
		u.Type = InputTypeInputCriblTCP
		return nil
	}

	var inputNetflow InputNetflow = InputNetflow{}
	if err := utils.UnmarshalJSON(data, &inputNetflow, "", true, true); err == nil {
		u.InputNetflow = &inputNetflow
		u.Type = InputTypeInputNetflow
		return nil
	}

	var inputGooglePubsub InputGooglePubsub = InputGooglePubsub{}
	if err := utils.UnmarshalJSON(data, &inputGooglePubsub, "", true, true); err == nil {
		u.InputGooglePubsub = &inputGooglePubsub
		u.Type = InputTypeInputGooglePubsub
		return nil
	}

	var inputTcpjson InputTcpjson = InputTcpjson{}
	if err := utils.UnmarshalJSON(data, &inputTcpjson, "", true, true); err == nil {
		u.InputTcpjson = &inputTcpjson
		u.Type = InputTypeInputTcpjson
		return nil
	}

	var inputOffice365Service InputOffice365Service = InputOffice365Service{}
	if err := utils.UnmarshalJSON(data, &inputOffice365Service, "", true, true); err == nil {
		u.InputOffice365Service = &inputOffice365Service
		u.Type = InputTypeInputOffice365Service
		return nil
	}

	var inputWiz InputWiz = InputWiz{}
	if err := utils.UnmarshalJSON(data, &inputWiz, "", true, true); err == nil {
		u.InputWiz = &inputWiz
		u.Type = InputTypeInputWiz
		return nil
	}

	var inputTCP InputTCP = InputTCP{}
	if err := utils.UnmarshalJSON(data, &inputTCP, "", true, true); err == nil {
		u.InputTCP = &inputTCP
		u.Type = InputTypeInputTCP
		return nil
	}

	var inputCriblHTTP InputCriblHTTP = InputCriblHTTP{}
	if err := utils.UnmarshalJSON(data, &inputCriblHTTP, "", true, true); err == nil {
		u.InputCriblHTTP = &inputCriblHTTP
		u.Type = InputTypeInputCriblHTTP
		return nil
	}

	var inputFirehose InputFirehose = InputFirehose{}
	if err := utils.UnmarshalJSON(data, &inputFirehose, "", true, true); err == nil {
		u.InputFirehose = &inputFirehose
		u.Type = InputTypeInputFirehose
		return nil
	}

	var inputOffice365Mgmt InputOffice365Mgmt = InputOffice365Mgmt{}
	if err := utils.UnmarshalJSON(data, &inputOffice365Mgmt, "", true, true); err == nil {
		u.InputOffice365Mgmt = &inputOffice365Mgmt
		u.Type = InputTypeInputOffice365Mgmt
		return nil
	}

	var inputFile InputFile = InputFile{}
	if err := utils.UnmarshalJSON(data, &inputFile, "", true, true); err == nil {
		u.InputFile = &inputFile
		u.Type = InputTypeInputFile
		return nil
	}

	var inputDatadogAgent InputDatadogAgent = InputDatadogAgent{}
	if err := utils.UnmarshalJSON(data, &inputDatadogAgent, "", true, true); err == nil {
		u.InputDatadogAgent = &inputDatadogAgent
		u.Type = InputTypeInputDatadogAgent
		return nil
	}

	var inputSplunk InputSplunk = InputSplunk{}
	if err := utils.UnmarshalJSON(data, &inputSplunk, "", true, true); err == nil {
		u.InputSplunk = &inputSplunk
		u.Type = InputTypeInputSplunk
		return nil
	}

	var inputWef InputWef = InputWef{}
	if err := utils.UnmarshalJSON(data, &inputWef, "", true, true); err == nil {
		u.InputWef = &inputWef
		u.Type = InputTypeInputWef
		return nil
	}

	var inputAppscope InputAppscope = InputAppscope{}
	if err := utils.UnmarshalJSON(data, &inputAppscope, "", true, true); err == nil {
		u.InputAppscope = &inputAppscope
		u.Type = InputTypeInputAppscope
		return nil
	}

	var inputHTTP InputHTTP = InputHTTP{}
	if err := utils.UnmarshalJSON(data, &inputHTTP, "", true, true); err == nil {
		u.InputHTTP = &inputHTTP
		u.Type = InputTypeInputHTTP
		return nil
	}

	var inputAzureBlob InputAzureBlob = InputAzureBlob{}
	if err := utils.UnmarshalJSON(data, &inputAzureBlob, "", true, true); err == nil {
		u.InputAzureBlob = &inputAzureBlob
		u.Type = InputTypeInputAzureBlob
		return nil
	}

	var inputHTTPRaw InputHTTPRaw = InputHTTPRaw{}
	if err := utils.UnmarshalJSON(data, &inputHTTPRaw, "", true, true); err == nil {
		u.InputHTTPRaw = &inputHTTPRaw
		u.Type = InputTypeInputHTTPRaw
		return nil
	}

	var inputZscalerHec InputZscalerHec = InputZscalerHec{}
	if err := utils.UnmarshalJSON(data, &inputZscalerHec, "", true, true); err == nil {
		u.InputZscalerHec = &inputZscalerHec
		u.Type = InputTypeInputZscalerHec
		return nil
	}

	var inputSqs InputSqs = InputSqs{}
	if err := utils.UnmarshalJSON(data, &inputSqs, "", true, true); err == nil {
		u.InputSqs = &inputSqs
		u.Type = InputTypeInputSqs
		return nil
	}

	var inputKinesis InputKinesis = InputKinesis{}
	if err := utils.UnmarshalJSON(data, &inputKinesis, "", true, true); err == nil {
		u.InputKinesis = &inputKinesis
		u.Type = InputTypeInputKinesis
		return nil
	}

	var inputConfluentCloud InputConfluentCloud = InputConfluentCloud{}
	if err := utils.UnmarshalJSON(data, &inputConfluentCloud, "", true, true); err == nil {
		u.InputConfluentCloud = &inputConfluentCloud
		u.Type = InputTypeInputConfluentCloud
		return nil
	}

	var inputEventhub InputEventhub = InputEventhub{}
	if err := utils.UnmarshalJSON(data, &inputEventhub, "", true, true); err == nil {
		u.InputEventhub = &inputEventhub
		u.Type = InputTypeInputEventhub
		return nil
	}

	var inputKafka InputKafka = InputKafka{}
	if err := utils.UnmarshalJSON(data, &inputKafka, "", true, true); err == nil {
		u.InputKafka = &inputKafka
		u.Type = InputTypeInputKafka
		return nil
	}

	var inputElastic InputElastic = InputElastic{}
	if err := utils.UnmarshalJSON(data, &inputElastic, "", true, true); err == nil {
		u.InputElastic = &inputElastic
		u.Type = InputTypeInputElastic
		return nil
	}

	var inputOffice365MsgTrace InputOffice365MsgTrace = InputOffice365MsgTrace{}
	if err := utils.UnmarshalJSON(data, &inputOffice365MsgTrace, "", true, true); err == nil {
		u.InputOffice365MsgTrace = &inputOffice365MsgTrace
		u.Type = InputTypeInputOffice365MsgTrace
		return nil
	}

	var inputSplunkHec InputSplunkHec = InputSplunkHec{}
	if err := utils.UnmarshalJSON(data, &inputSplunkHec, "", true, true); err == nil {
		u.InputSplunkHec = &inputSplunkHec
		u.Type = InputTypeInputSplunkHec
		return nil
	}

	var inputCrowdstrike InputCrowdstrike = InputCrowdstrike{}
	if err := utils.UnmarshalJSON(data, &inputCrowdstrike, "", true, true); err == nil {
		u.InputCrowdstrike = &inputCrowdstrike
		u.Type = InputTypeInputCrowdstrike
		return nil
	}

	var inputLoki InputLoki = InputLoki{}
	if err := utils.UnmarshalJSON(data, &inputLoki, "", true, true); err == nil {
		u.InputLoki = &inputLoki
		u.Type = InputTypeInputLoki
		return nil
	}

	var inputPrometheusRw InputPrometheusRw = InputPrometheusRw{}
	if err := utils.UnmarshalJSON(data, &inputPrometheusRw, "", true, true); err == nil {
		u.InputPrometheusRw = &inputPrometheusRw
		u.Type = InputTypeInputPrometheusRw
		return nil
	}

	var inputSecurityLake InputSecurityLake = InputSecurityLake{}
	if err := utils.UnmarshalJSON(data, &inputSecurityLake, "", true, true); err == nil {
		u.InputSecurityLake = &inputSecurityLake
		u.Type = InputTypeInputSecurityLake
		return nil
	}

	var inputS3 InputS3 = InputS3{}
	if err := utils.UnmarshalJSON(data, &inputS3, "", true, true); err == nil {
		u.InputS3 = &inputS3
		u.Type = InputTypeInputS3
		return nil
	}

	var inputPrometheus InputPrometheus = InputPrometheus{}
	if err := utils.UnmarshalJSON(data, &inputPrometheus, "", true, true); err == nil {
		u.InputPrometheus = &inputPrometheus
		u.Type = InputTypeInputPrometheus
		return nil
	}

	var inputS3Inventory InputS3Inventory = InputS3Inventory{}
	if err := utils.UnmarshalJSON(data, &inputS3Inventory, "", true, true); err == nil {
		u.InputS3Inventory = &inputS3Inventory
		u.Type = InputTypeInputS3Inventory
		return nil
	}

	var inputEdgePrometheus InputEdgePrometheus = InputEdgePrometheus{}
	if err := utils.UnmarshalJSON(data, &inputEdgePrometheus, "", true, true); err == nil {
		u.InputEdgePrometheus = &inputEdgePrometheus
		u.Type = InputTypeInputEdgePrometheus
		return nil
	}

	var inputOpenTelemetry InputOpenTelemetry = InputOpenTelemetry{}
	if err := utils.UnmarshalJSON(data, &inputOpenTelemetry, "", true, true); err == nil {
		u.InputOpenTelemetry = &inputOpenTelemetry
		u.Type = InputTypeInputOpenTelemetry
		return nil
	}

	var inputSplunkSearch InputSplunkSearch = InputSplunkSearch{}
	if err := utils.UnmarshalJSON(data, &inputSplunkSearch, "", true, true); err == nil {
		u.InputSplunkSearch = &inputSplunkSearch
		u.Type = InputTypeInputSplunkSearch
		return nil
	}

	var inputMsk InputMsk = InputMsk{}
	if err := utils.UnmarshalJSON(data, &inputMsk, "", true, true); err == nil {
		u.InputMsk = &inputMsk
		u.Type = InputTypeInputMsk
		return nil
	}

	var inputSyslog InputSyslog = InputSyslog{}
	if err := utils.UnmarshalJSON(data, &inputSyslog, "", true, true); err == nil {
		u.InputSyslog = &inputSyslog
		u.Type = InputTypeInputSyslog
		return nil
	}

	var inputGrafana InputGrafana = InputGrafana{}
	if err := utils.UnmarshalJSON(data, &inputGrafana, "", true, true); err == nil {
		u.InputGrafana = &inputGrafana
		u.Type = InputTypeInputGrafana
		return nil
	}

	return fmt.Errorf("could not unmarshal `%s` into any supported union types for Input", string(data))
}

func (u Input) MarshalJSON() ([]byte, error) {
	if u.InputCollection != nil {
		return utils.MarshalJSON(u.InputCollection, "", true)
	}

	if u.InputKafka != nil {
		return utils.MarshalJSON(u.InputKafka, "", true)
	}

	if u.InputMsk != nil {
		return utils.MarshalJSON(u.InputMsk, "", true)
	}

	if u.InputHTTP != nil {
		return utils.MarshalJSON(u.InputHTTP, "", true)
	}

	if u.InputSplunk != nil {
		return utils.MarshalJSON(u.InputSplunk, "", true)
	}

	if u.InputSplunkSearch != nil {
		return utils.MarshalJSON(u.InputSplunkSearch, "", true)
	}

	if u.InputSplunkHec != nil {
		return utils.MarshalJSON(u.InputSplunkHec, "", true)
	}

	if u.InputAzureBlob != nil {
		return utils.MarshalJSON(u.InputAzureBlob, "", true)
	}

	if u.InputElastic != nil {
		return utils.MarshalJSON(u.InputElastic, "", true)
	}

	if u.InputConfluentCloud != nil {
		return utils.MarshalJSON(u.InputConfluentCloud, "", true)
	}

	if u.InputGrafana != nil {
		return utils.MarshalJSON(u.InputGrafana, "", true)
	}

	if u.InputLoki != nil {
		return utils.MarshalJSON(u.InputLoki, "", true)
	}

	if u.InputPrometheusRw != nil {
		return utils.MarshalJSON(u.InputPrometheusRw, "", true)
	}

	if u.InputPrometheus != nil {
		return utils.MarshalJSON(u.InputPrometheus, "", true)
	}

	if u.InputEdgePrometheus != nil {
		return utils.MarshalJSON(u.InputEdgePrometheus, "", true)
	}

	if u.InputOffice365Mgmt != nil {
		return utils.MarshalJSON(u.InputOffice365Mgmt, "", true)
	}

	if u.InputOffice365Service != nil {
		return utils.MarshalJSON(u.InputOffice365Service, "", true)
	}

	if u.InputOffice365MsgTrace != nil {
		return utils.MarshalJSON(u.InputOffice365MsgTrace, "", true)
	}

	if u.InputEventhub != nil {
		return utils.MarshalJSON(u.InputEventhub, "", true)
	}

	if u.InputExec != nil {
		return utils.MarshalJSON(u.InputExec, "", true)
	}

	if u.InputFirehose != nil {
		return utils.MarshalJSON(u.InputFirehose, "", true)
	}

	if u.InputGooglePubsub != nil {
		return utils.MarshalJSON(u.InputGooglePubsub, "", true)
	}

	if u.InputCribl != nil {
		return utils.MarshalJSON(u.InputCribl, "", true)
	}

	if u.InputCriblTCP != nil {
		return utils.MarshalJSON(u.InputCriblTCP, "", true)
	}

	if u.InputCriblHTTP != nil {
		return utils.MarshalJSON(u.InputCriblHTTP, "", true)
	}

	if u.InputTcpjson != nil {
		return utils.MarshalJSON(u.InputTcpjson, "", true)
	}

	if u.InputSystemMetrics != nil {
		return utils.MarshalJSON(u.InputSystemMetrics, "", true)
	}

	if u.InputSystemState != nil {
		return utils.MarshalJSON(u.InputSystemState, "", true)
	}

	if u.InputKubeMetrics != nil {
		return utils.MarshalJSON(u.InputKubeMetrics, "", true)
	}

	if u.InputKubeLogs != nil {
		return utils.MarshalJSON(u.InputKubeLogs, "", true)
	}

	if u.InputKubeEvents != nil {
		return utils.MarshalJSON(u.InputKubeEvents, "", true)
	}

	if u.InputWindowsMetrics != nil {
		return utils.MarshalJSON(u.InputWindowsMetrics, "", true)
	}

	if u.InputCrowdstrike != nil {
		return utils.MarshalJSON(u.InputCrowdstrike, "", true)
	}

	if u.InputDatadogAgent != nil {
		return utils.MarshalJSON(u.InputDatadogAgent, "", true)
	}

	if u.InputDatagen != nil {
		return utils.MarshalJSON(u.InputDatagen, "", true)
	}

	if u.InputHTTPRaw != nil {
		return utils.MarshalJSON(u.InputHTTPRaw, "", true)
	}

	if u.InputKinesis != nil {
		return utils.MarshalJSON(u.InputKinesis, "", true)
	}

	if u.InputCriblmetrics != nil {
		return utils.MarshalJSON(u.InputCriblmetrics, "", true)
	}

	if u.InputMetrics != nil {
		return utils.MarshalJSON(u.InputMetrics, "", true)
	}

	if u.InputS3 != nil {
		return utils.MarshalJSON(u.InputS3, "", true)
	}

	if u.InputS3Inventory != nil {
		return utils.MarshalJSON(u.InputS3Inventory, "", true)
	}

	if u.InputSnmp != nil {
		return utils.MarshalJSON(u.InputSnmp, "", true)
	}

	if u.InputOpenTelemetry != nil {
		return utils.MarshalJSON(u.InputOpenTelemetry, "", true)
	}

	if u.InputModelDrivenTelemetry != nil {
		return utils.MarshalJSON(u.InputModelDrivenTelemetry, "", true)
	}

	if u.InputSqs != nil {
		return utils.MarshalJSON(u.InputSqs, "", true)
	}

	if u.InputSyslog != nil {
		return utils.MarshalJSON(u.InputSyslog, "", true)
	}

	if u.InputFile != nil {
		return utils.MarshalJSON(u.InputFile, "", true)
	}

	if u.InputTCP != nil {
		return utils.MarshalJSON(u.InputTCP, "", true)
	}

	if u.InputAppscope != nil {
		return utils.MarshalJSON(u.InputAppscope, "", true)
	}

	if u.InputWef != nil {
		return utils.MarshalJSON(u.InputWef, "", true)
	}

	if u.InputWinEventLogs != nil {
		return utils.MarshalJSON(u.InputWinEventLogs, "", true)
	}

	if u.InputRawUDP != nil {
		return utils.MarshalJSON(u.InputRawUDP, "", true)
	}

	if u.InputJournalFiles != nil {
		return utils.MarshalJSON(u.InputJournalFiles, "", true)
	}

	if u.InputWiz != nil {
		return utils.MarshalJSON(u.InputWiz, "", true)
	}

	if u.InputNetflow != nil {
		return utils.MarshalJSON(u.InputNetflow, "", true)
	}

	if u.InputSecurityLake != nil {
		return utils.MarshalJSON(u.InputSecurityLake, "", true)
	}

	if u.InputZscalerHec != nil {
		return utils.MarshalJSON(u.InputZscalerHec, "", true)
	}

	return nil, errors.New("could not marshal union type Input: all fields are null")
}
